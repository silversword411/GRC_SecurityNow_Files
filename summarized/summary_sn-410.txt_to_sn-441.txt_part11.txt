GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#410	

DATE:		June 26, 2013

TITLE:		Interesting & Useful Intel History

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-410.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with another post-PRISM week of security industry news, Steve and Leo wind up and release their propeller beanies for a deep dive into the early history of Intel processor memory management - which, it turns out, has direct application to Steve's current work on SpinRite v6.1.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news, more about the NSA, and then he's going to talk about some of the things he remembers he learned way back when, when he was writing SpinRite, that are still true today.  A look at Intel memory management and more, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 410, recorded June 26th, 2013:  Interesting Intel History.



It's time for Security Now!, the show that protects you, your loved ones, your privacy, your security.  Man, there wasn't - there couldn't be a better time.  We thought when we started doing this show seven years ago that we'd run out of topics.  



STEVE GIBSON:  Yeah, and maybe take about 20 minutes a day, or a week, 20 minutes a week, just sort of a quick little touch base.  What happened?



LEO:  I have a new prediction.  Steve Gibson, our host and Explainer in Chief, I have a new prediction.  This show's going to get longer, and there's more stuff.  In the next 10 years, privacy and security are going to be THE topic of the day.  That's my thought.



STEVE:  It's funny because Elaine quotes for her transcription cost based on the length of the podcast.



LEO:  Oh, it's been getting longer, huh.



STEVE:  So, well, I've tripled my budget for...



LEO:  Oh, geez.  Oh, man.



STEVE:  ...for the transcripts that we create from the podcast.



LEO:  We'll go in with you.  Contact Lisa.  We'll split the cost.  Steve is here.  He is the man at GRC.com, the creator of SpinRite.  And that's going to be germane, and you'll find out why in a moment.  It's the world's finest hard drive recovery and maintenance utility.  He's also a great benefactor to all humankind with the free stuff he puts up at GRC.com - well, all computing humankind - like ShieldsUP!...



STEVE:  A subset.  A worthwhile subset.



LEO:  ...Password Haystacks and more.  And what are we going to do today, Steve?  I see the title.



STEVE:  Well, okay.  So our - yeah.  Our listeners know, because I talked about it briefly the last couple weeks, that I'm back at work on SpinRite.  And frankly, I was a little nervous about mentioning it.  I've actually been working on it for about two months.



LEO:  You don't want deadlines.



STEVE:  Well, I don't.  I don't work with deadlines.  But I was worried that it would stop its sales.  I mean, that if people knew there was a new one coming, they'd say, oh, I might as well wait for that.



LEO:  True.



STEVE:  But the fact is, sales has not been hurt by my talking about it.  And it is the case that all - I've made the promise to all existing SpinRite 6 owners that what I do next will be free, that everyone who has it will be able to update themselves to this next one I'm working on.



LEO:  Isn't that generous.



STEVE:  Well, it just, I mean, it's been nine years, and people are saying, oh, we want to give you more money.



LEO:  Has it really been nine years since the last?



STEVE:  Yeah.  I finished - it was '04 that SpinRite 6 launched.  And not a byte has changed in nine years.  On the other hand, not a byte has changed in nine years.



LEO:  Right, it didn't need to be.



STEVE:  Well, it didn't need to be.  But over time there have been some things that have come along.  For example, now drives often have the so-called "advanced format" with 4K sectors, rather than traditional 512-byte sectors.  And so that could interact.  I mean, the drives are, like, upward compatible.  SpinRite, frankly, has been rather amazingly upward compatible, such that it's nine years old and still is recovering data for people without any problems.  But there are a bunch of things that I can make better.  And I got all these other things done, and it's like, okay, SpinRite was calling.



So what I'm going to talk about today I think everyone is going to find interesting.  It's one of our - we haven't done this actually for years, one of our fundamental technology propeller-head episodes.  Anybody who pays attention, I don't know if you could, I mean, you have to be listening to this in order to understand it.  But none of this is difficult.  And essentially what I'm going to explain is how what seems to be a mistake, an oversight in the early design of the evolution of the Intel processor, from the 8088 that we first got in the IBM PC to the 286 to the 386, right back in that region, something was discovered.  And it turns out I need it today for SpinRite, for the next - for the evolution of SpinRite.  And I had sort of a hazy understanding of it a week ago.  Now I'm an expert.  I know exactly what happened.  I know how it happened and why it happened and what it does.



And so we're going to go back in time and look.  And the old-timers among us will be sort of familiar with all this, but maybe not have ever focused on it as much as I have had to recently.  And I think everyone's going to find it interesting, even young kids.  It's like, oh, you mean there actually was a history before the Internet?  Yes, there was.  There was.  We had computers before...



LEO:  And you and I remember it.  I mean, we were there.



STEVE:  Yeah, yeah.



LEO:  You were writing for InfoWorld at the time.



STEVE:  So that's our topic.  And we do have a bunch of interesting stuff, I mean, like at the top of the show, as usual.  My very favorite bit of NSA PRISM humor was - I've embellished on the concept, which I got from Twitter, Matt Surabian, I think that's how he would pronounce his name.  So it's short, being a tweet, although I did enhance it.  So it is:  "Okay, NSA.  How's this for a compromise?  You add packet-level virus detection and removal to your splitter boxes, and we'll call it even."



LEO:  Yeah, at least we saw something for it.



STEVE:  Yeah, exactly.  It's like, hey, you add Internet-wide antivirus, and it's like, oh, okay, then we'll go ahead.



LEO:  Did you see that...



STEVE:  Oh, yes.  I even know what you're going to say.



LEO:  Do you really?



STEVE:  I bet I do.



LEO:  So if you use encryption or Tor...



STEVE:  Yes.  It's in the notes here, Leo.  I know.  You are presumed guilty.



LEO:  Yeah, it's like, oh, we're definitely capturing that traffic.  I don't care where you are.



STEVE:  If you didn't - yeah, well, okay, I'm getting ahead of myself.  But so...



LEO:  All right, save it.



STEVE:  But, yes, I did see it.  And I was just like, oh, my goodness.



LEO:  Unbelievable.



STEVE:  So since we talked last, another drop of news from our friend - or some people don't like him, other people think he's a hero, blah blah blah.  He's certainly controversial.  Our controversial entity, Edward Snowden...



LEO:  The leaker.  The AP Style Guide says you're supposed to call him a "leaker."



STEVE:  Okay.  I think that works.



LEO:  Because if you call him a whistleblower, that means you like what he did.  If you call him a traitor, that means you don't.



STEVE:  Now we have espionage, of course.  Now he's, I don't know, is there a - are you a something if you are guilty of espionage?



LEO:  It's a spy.



STEVE:  It's a spy, okay.  So...



LEO:  Yeah.  He's being accused under the 1917 Espionage Act.  And it's ironic that they're - the U.S. is accusing him of spying for revealing that the U.S. is spying on us.



STEVE:  Yeah.  Exactly.  Well, and again, it's that fantastic Stephen Colbert tweet, why are you upset about - and I'm paraphrasing because I don't remember it exactly.  But it was like, why are you getting upset about what the NSA is doing with their secret spying program that they're hiding from everyone?  So it's like, okay.



LEO:  [Growling]



STEVE:  Yeah.  Anyway, so the news was, and many people tweeted this to make sure that I was aware of it, that it turns out the U.K. is engaged in as large, if maybe not even larger, an Internet spying operation.  And this time we know that they are tapping all of the fiber optic cables coming in and out.  So this was the first time we've seen contemporary - I don't know if this is confirmation of my theory, but many people have felt it was because, in the news that we got that was most recently released, it was, okay, the U.K. is tapping everything.  Oh, and they are of course cooperatively sharing with the U.S.



LEO:  Which means it's I'm sure reciprocal.  It's not like the U.S. would say, please give us everything.



STEVE:  No.



LEO:  Yeah.



STEVE:  Even though we've probably already seen it.  We'd like a second copy.  Oh, goodness.  And so, yes.  And so here in my notes I said "additional clarifications to Congress."  This came out during the hearings that have resulted from Edward's leaking.  And that is, the NSA's guidelines and regulations state that "encrypted communications," just the fact that they're encrypted, is in and of itself suspicious due to what it might contain and is therefore subject to lawful capture and storage.  So if you're encrypting it, that's suspicious in and of itself, so we can save it.  So now we do know where all of those zettabytes are going.



LEO:  Mm-hmm.



STEVE:  Yeah.



LEO:  And if you use Tor, same thing.



STEVE:  Oh, yeah.



LEO:  Unbelievable.



STEVE:  So we just had yesterday a new release of Firefox.  The "Countdown to 23" is what I call this because 23 is when third-party cookies get blocked by default.  And that's still happening.  Mozilla is still rattling their sabers, and it's still causing upset and concern.  On the 19th of this month the Washington Post in the Business Technology section said Firefox - the headline was "Firefox Browser to Move Ahead with Do Not Track."  And actually that was a little bit of a misprint or misstatement because what they were actually talking about was third-party cookie blocking.  So that's slated for 23.  As we know, it was pushed back until August.  And so that should be when we see 23.



LEO:  Oh.  So you're talking about third-party cookies, not Do Not Track.



STEVE:  Yes.



LEO:  Oh, okay.



STEVE:  Yeah, Do Not Track is already there.



LEO:  So third-party cookies are blocked on Safari by default.



STEVE:  Correct.



LEO:  What does Chrome do?  Chrome, I think, doesn't because...



STEVE:  Unh-unh.  Chrome's not...



LEO:  ...Google's an advertising company.  So they're never going to...



STEVE:  Precisely.  Precisely.  It'll be really interesting to me if Chrome is, I mean, as you said, Safari has always been a third-party cookie blocker.  Mozilla and Firefox, which is super popular, of course, will join that camp.  Microsoft always talks about it and then never does it.  Several of the betas have had that on, and then they always backpedal because of pressure from the advertising industry.  So that will leave those two, essentially.  Well, and Opera, although Opera doesn't have a large market share.  So of the two biggies, IE and Chrome, we'll see what happens.



My sense is this is a battle the advertising industry is losing because they're not - essentially, if you look at the dialogue going on, they are refusing to budge.  They're unwilling to honor Do Not Track.  And so Mozilla is saying, fine, we're just going to block third-party cookies, if you guys won't come to the table and negotiate in good faith.  And the advertising industry is saying, you can't understand, we have to track people.  And but, you know, they're not tracking Safari users, and they're soon not going to be tracking Firefox users.



LEO:  Well, there may be an unfortunate unintended consequence because they've said now, well, we're just going to go to fingerprinting.  Which we've talked about before, this ability.



STEVE:  Yup.



LEO:  They don't need cookies really.



STEVE:  No.



LEO:  And the fingerprinting you can't really stop.



STEVE:  Oh, yeah.  Oh, yeah.



LEO:  You have to work in incognito mode or something; right?



STEVE:  Well, we can - no.  We'll talk about that.



LEO:  Oh, good.  All right.



STEVE:  Yeah, we can block that, too.  I just - my take is nothing will happen.  This is much to do about nothing.  Nothing will happen.  Advertising will still work.  Revenue will still flow.  The whole ecosystem, it does actually not depend upon this.



LEO:  Well, also because in all likelihood most people will leave it on, if it's on by - off by default.



STEVE:  No, no, that's the point.  It's going on by default.



LEO:  Right, right.  But...



STEVE:  So right now...



LEO:  Internet Explorer and Chrome occupy what percentage of the total browsing?



STEVE:  You're right, they're - Chrome is...



LEO:  80%?  70%?



STEVE:  Chrome is really making inroads.



LEO:  Yeah, so...



STEVE:  And I don't think IE has ever dropped below 50 because it's just the default browser.



LEO:  And if they start using fingerprinting, they're not going to announce it.



STEVE:  No.



LEO:  Fingerprinting, we should mention, is the ability to figure out who you are, not based on any cookie, but just things like browser resolution and just - if you put enough factors together, everybody's unique.



STEVE:  Well, it's - yes.  We've talked about this in various contexts.  It is the metadata that your browser sends...



LEO:  Oh, that old word "metadata."  That old black magic got me in its spell.



STEVE:  It's all of the headers, see, because in the headers, for example, are things like all of the different versions of add-ons that you've got.  Like Java adds itself to the headers, and all these different packages have many-digit version numbers.  And so you add them all, when you look at them as an aggregate, it ends up being that - and it was Panopticlick was the site...



LEO:  Right, right, right.



STEVE:  ...that deals with this.  It turns out you can still get a pretty good lock on a person.  But all we have to do is rearrange the headers and scramble the data a bit and change it.  So it'll be very easy for people to do, for example, browser add-ons which completely blow fingerprinting.  Fingerprinting is only useful at the moment because all that data is relatively static.  But none of it needs to be kept static.



LEO:  Right.



STEVE:  So anyway, we just got yesterday Firefox v22.  It's fixed 14 vulnerabilities.  And that's why I was saying I call this the countdown, or the count-up, to 23.  We're one version away from third-party cookies being blocked by default in Firefox, which is still my go-to browser.  Chrome has just gotten so bloated, Leo.  I launch it, and I watch my memory just collapse.  So I'm hoping at some point that Google will come back to that.



And remember we talked about it here, how much focus the Mozilla folks put on memory.  They got to a point where they said, okay, we've just got to stop and fix our memory consumption problem.  They had leaks, and they had memory that was just, I mean, it's sort of natural in the development cycle to be adding features, and under deadline, and you're under the gun.  And so you're writing code, and it works, and then you just send it.  Well, it all takes up space.



And so the notion of examining memory consumption is very similar to examining security problems, that is, authors who are just writing code to make it work aren't always thinking about security.  They're not always thinking about memory consumption because they're just like, well, okay, I need this much memory, and so they grab it.  Or if they're not sure how much, they grab more than they need because, if you grab less than you need, then you're in trouble.  So it's a sort of a different phase of, in the same way that you audit an app for security, you can audit it for memory consumption.



And we'll remember that it was about a year ago that Firefox really got serious about memory problems because it was out of control.  And, frankly, that's where Chrome is now.  I don't launch Chrome unless I really have to because it's just - it's just ridiculous.  Opera is like a fraction of the consumption.  And, you know, they all sort of work in the same way.



So with v22, just released yesterday, of Firefox, we got for the first time in Firefox a set of new standards, which Chrome already has, called WebRTC.  And I've not yet done a deep dive into it.  So I'll just quote from TechCrunch that explained it well.  TechCrunch said:  "WebRTC allows developers to create web pages with built-in video and audio calls, as well as filesharing, without the need for any plugins or third-party software."



LEO:  Yeah.  This is something Google's been pushing and we want to use because, you know, we use Skype right now, but...



STEVE:  Yes.



LEO:  ...we are very interested in having a WebRTC implementation that would just mean we could give you a private website, you'd go to it, and you'd be on.



STEVE:  So think about this.  I mean, this is huge.  This means that audio, video, and file interaction would be - will be, it is now in Chrome, it will be in Firefox - natively available so that just JavaScript, using new APIs to access the WebRTC, allows these apps to run in the browser.  So, I mean, this is a big step forward towards the browser is everything model.



And so continuing what TechCrunch said, they said:  "Until now, only Google's Chrome supported the budding standard in its mainstream browser releases.  Now that Firefox [with release 22] also supports it in its stable branch, we will likely see a large number of startups and established companies examine this technology far closer.  Microsoft so far remains the only major vendor who has decided to go ahead with a different" - oh, my god - "with a different standard for the same functionality.  But I wouldn't be surprised if Internet Explorer, too, would support WebRTC out of the box in the near future."  So that's cool.



And then the technology that is really interesting - not only because it has "asm" in its name, Leo.  Yes, it is, they're calling it asm, a-s-m, asm.js.  We've talked about this before.  And it's really interesting.  It is a - the guys working on JavaScript speed realized that a lot of time was being spent in JavaScript on things, on features in JavaScript that, eh, you could live without.  Because JavaScript is sort of an automatic language, the way it creates and destroys variables, there's the need to do garbage collection.  If it realizes that things you've referenced are no longer useful or no longer being referenced, and not going to be, then it says, oh, I can free up this memory.



Well, that's - there's like an overhead associated with being that smart which adds a layer of complexity to the entire language.  So what they realized was, you know, if we defined, carefully defined a subset just of JavaScript, still JavaScript, but, like, only allowed certain features and explicitly disallowed a bunch of these fancy ones, we could make this much faster.



LEO:  Yeah.



STEVE:  And so that's what asm.js is.  It is a subset of JavaScript that screams.  And there is, for example, a compiler called Emscripten which can compile C and C++ code into this subset of JavaScript.  And compared to native performance, it's running as fast as only half as fast, which is a bad way of saying it.



LEO:  You only have a 50% hit.



STEVE:  Yes.  Which is amazing because, I mean, native code is screaming on today's processors.  And so now we're talking about completely browser, I mean, we're talking about a web page being able to execute code that is only half as fast, which is still amazingly fast.  And in fact Mozilla has a page - shoot, I can't remember the name of it now.



LEO:  I'm going through a presentation about it.  And I guess the point being is that hand optimized - there's so many good optimizations that people don't use when they hand - when they write in JavaScript.  And so hand-optimized code is not going to be as good unless you really pay attention to it.



STEVE:  Right.  And so but the point is that, by formally denying access to the whole JavaScript language...



LEO:  Right, a subset, yeah.



STEVE:  Yes.  By formally denying access to all of the things that are expensive and slow, you end up with a subset fully useful which is extensive enough that you can write a compiler to compile standard C and C++ into asm.js, and it runs like a bat out of hell.  So that's how I should have said it.  Runs like a bat out of hell.



LEO:  Bat out of hell.



STEVE:  Bat out of hell.



LEO:  And I love it that it's C.  I mean, I feel very comfortable with that.  JavaScript always looked a lot like C.  But...



STEVE:  Yeah, well, it's sort of - we've come up with sort of this agreed-upon pseudocode.  If you look at articles in Wikipedia or in computer textbooks, they sort of use code that anybody can read because it's sort of like Basic, it's sort of like C, it's sort of like Pascal, it's just sort of this goop that sort of like, oh, looks generic.  And that's sort of what JavaScript looks like.



LEO:  Just running it through something like this also, as they point out, because it's got formal type checking, you're going to avoid a lot of common JavaScript bugs.



STEVE:  Yes, yes.  Exactly.



LEO:  Yeah.  So this is good.



STEVE:  Yeah.  So it's really nice.



LEO:  It's not the first time somebody's done something like this.  There's quite a few of these.



STEVE:  Yes.  There'll be many different types.  Like there's JIT (Just In Time) compilers and different approaches.



LEO:  Well, Google has GWT, which is used in a lot of Android stuff, GWT, the Google Toolkit.  Yeah, there's Coffee, there's, boy, there's a lot of stuff,  CoffeeScript.  Huh.  Cool.  So you think this will be widely adopted.



STEVE:  Okay.  Well, it needs to go multibrowser.  So at this point...



LEO:  You just like it because it's asm [laughing].  If only somebody would write an assembly language JavaScript compiler.  That's what we need.



STEVE:  Well, and Google does have their own native code project that they're working on.  So we're seeing everyone wanting to move toward more performance and to give browsers enough speed that we can implement full applications in the browser and continue to add more power.  So this is just another step in that direction.  I'm glad to see the Mozilla folks doing it.  I'm glad for what Google's doing.  Ultimately we'll come up with a standard.  And maybe Microsoft will support it.  We can hope.



Bruce Schneier is actually where I picked up on an article in The New York Times that had one of the most interesting quotes from the EFF about all of this I have seen.  But I'll hold that for a minute because what Bruce had to say, and his blog posting that caught my eye, was "New Details on Skype Eavesdropping."  And you probably ran across this, too, in the last week, this "Project Chess," Leo?



LEO:  Yeah.



STEVE:  Okay.  So The New York Times article, this is Bruce writing:  "This article on the cozy relationship between the commercial personal-data industry and the intelligence industry has new information on the security of Skype."



So now switching to The New York Times article, quoting from that:  "Skype, the Internet-based calling service, began its own secret program, Project Chess, to explore the legal and technical issues in making Skype calls readily available to intelligence agencies and law enforcement officials, according to..."



LEO:  This is way pre-Microsoft.  This is under eBay.



STEVE:  Yes.  Years, years.  Yes, yes, "...according to people briefed on the program who asked not to be named to avoid trouble with the intelligence agencies.  Project Chess, which has never been previously disclosed, was small, limited to fewer than a dozen people inside Skype, and was developed as the company had sometimes contentious talks with the government over legal issues, said one of the people briefed on the project.  The project began about five years ago, before most of the company was sold by its parent, eBay, to outside investors in 2009.  Microsoft acquired Skype in an $8.5 billion deal that was completed in October 2011.



"A Skype executive denied last year in a blog post that recent changes in the way Skype operated were made at the behest of Microsoft to make snooping easier for law enforcement.  It appears, however, that Skype figured out how to cooperate with the intelligence community before Microsoft took over the company, according to documents leaked by [none other than] Edward J. Snowden, a former contractor for the NSA.  One of the documents about the PRISM program made public by Mr. Snowden says Skype joined PRISM on February 6, 2011."  So about six months prior to Microsoft's closing their acquisition deal.



So back to Bruce Schneier, who continues his blog, saying, "Reread that Skype denial from last July, knowing that at the time the company knew that they were giving the NSA access to customer communications.  Notice how it is precisely worded to be technically accurate, yet leave the reader with the wrong conclusion."  And this is Bruce speaking, saying, "This is where we are with all the tech companies right now.  We can't trust their denials, just as we can't trust the NSA - or the FBI - when it denies programs, capabilities, or practices.  Back in January, we wondered whom Skype lets spy on their users.  Now we know."



LEO:  He points out, he says, Bruce says, you can't trust the NSA, and you can't trust these companies.  Their denials are meaningless.  So we just don't know what's going on.



STEVE:  We just, yeah, we don't know.  In that article, as I mentioned before, was a quote from Dan Auerbach, who's a technology analyst with the EFF, the Electronic Frontier Foundation.  And I thought this was the best thing I read.  He said, "We reached a tipping point, where the value of having user data rose beyond the cost of storing it.  Now we have an incentive to keep it forever."  And I think that's just exactly it.  We know what's happened to the cost of storage in the last few years.  It's just - it's ridiculous how large drives have become and how inexpensive per byte storage has become.  At some point the cost to store drops so low that the perceived value of keeping everything outweighs it.  And as he says, we've crossed that tipping point.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Thus five zettabytes in Utah, five billion terabytes.



LEO:  I paid 250 bucks for this thing called a Memoto.  It's a camera that records an image every 30 seconds.  You wear it around your neck or on your lapel.  And then it uploads.  It does a lot of parsing of this data, puts together stuff...



STEVE:  Life blogging?



LEO:  Yeah, it has GPS in it, uploads it to their server, stores it.  I mean, I think this is a good - and they say it's great for later when you get Alzheimer's because you can just go back and look.



STEVE:  "I never went there."  "Oh, yes, you did, Grandpa."



LEO:  And the name recognition, you know, there's name recognition, and Picasa does it; Facebook does it.  So you just kind of apply some of these engines to it.  Pretty soon you've got a whole record of everything you ever did.



STEVE:  And so does the NSA.  Because they're happy you're doing this, Leo.



LEO:  I couldn't care less if they do.



STEVE:  I know.



LEO:  You know?  Go ahead, fine.  If you're really that - that's why, well, the trick is to overload them.  Say you have so much on me, you've got - what are you going to do?  I know they're - I'm using PGP.  I'm dead already.



STEVE:  We ought to just have - create an app that just sends out pseudorandom noise.  Because that looks like encryption. 



LEO:  And then they're going to record it all.  But that's the, you know...



STEVE:  Exactly [laughing].



LEO:  Yeah.  If there were somewhere...



STEVE:  Just spew it out of our ports.



LEO:  If there were somewhere one could go, I would consider going there.  But I don't know - there's nowhere.  You know, everybody's...



STEVE:  The only thing that I think is kind of cool is when we have an app, when we have like an instant messaging app, where we absolutely know that it is secure, like the one I talked about last week, Threema, where you actually, to get the highest level of security, you have to face your phones, they have to face each other, and they each look at the other's private key.  I mean, at the other's, like, Q - what is it, QRC?  I can't think of the name.



LEO:  What?



STEVE:  You know, the little square barcode, Q something.



LEO:  Oh, QR code, yeah.



STEVE:  QR code.  Yeah, QR code.  And that you have - they have to be physically in proximity.  Then they can exchange directly their public key that matches their private key, and then you get three green dots.  And forever on after that, you know that, when you send a text through the Threema system to a recipient...



LEO:  I like this.



STEVE:  I do, too.  And it's like...



LEO:  You have to meet them in meatspace at some point; right?



STEVE:  Yes, exactly.



LEO:  For this to make sense.  But it's - that's...



STEVE:  Yeah, you have - yes.  You have - there's three levels of security.  You can use their distribution server, but then you only get two dots, and I think it's orange, and one dot is red.  And it's only when you have, as you said, meatspace, m-e-a-t, that you have proven you've been in proximity to the other device.  Now you have absolute authentication.



LEO:  I love this.



STEVE:  And afterwards, I just - I like the idea.  I just - I guess it's a little thumb of the nose.  I'm sending this, and absolutely nobody else on the planet can possibly intercept it and read it.  I don't need that.  No, I don't need it because, you know, I'm talking to Jenny about when we're going to meet for dinner.  But it's just like, yeah.



LEO:  Well, that's my plan.  I just want to swamp them.  I think if all of us honest folks just swamp them, I mean, IBM estimated that it's 55...



STEVE:  It'd be good for the Utah real estate market, Leo.



LEO:  I think we can swamp - I know zettabytes are a lot.  But already there's a lot - what was - IBM had a Big Data, total amount of data generated every day.  What was it?  It was...



STEVE:  Well, this whole move to going digital, it's, I mean, we've all seen the quotes.  It's like the total amount of data that exists that is created every week is, like, more than ever existed in the history of man or something like that.  I mean, it's just - it's gone exponential already.



LEO:  So according to IBM, and this is on their Big Data page, every day we create 2.5 quintillion bytes of data.  90% of the data in the world today has been created in the last two years alone.  So I think we can - I don't know, how many quint - not 2.5 quintillion bytes.  How many zetta - how long before we fill up a zettabyte?  Somebody do the math.  And all we have to do, probably all we have to do is double or triple that, and there'll be so much noise, let them try to find the needle in a haystack.



STEVE:  Yup.



LEO:  That's why I'm going to record every 30 seconds a high-res picture of what I'm up to.



STEVE:  [Laughing] And send it up.



LEO:  And send it up to the cloud.  Go ahead.  Enjoy, NSA.



STEVE:  Send it on.



LEO:  It's all yours, baby.



STEVE:  Now, the other little bit of interesting Edward Snowden news to arrive was picked up by The Daily Beast, who interviewed Glenn Greenwald, who's our friend at the Guardian who's been sort of the main contact person for Snowden.



LEO:  Poor Glenn Greenwald is getting trashed.



STEVE:  I know.  And it's...



LEO:  He's a journalist, folks.  You know?



STEVE:  Yes.



LEO:  This is what we're supposed to do.



STEVE:  Boy, I was disappointed that...



LEO:  First Amendment.  David Gregory, what a dick.



STEVE:  Yes, I was just going to say, David Gregory's question on Sunday was just - it was ridiculous.  Although he said, "To the extent that..." is the way he started it.  And it's like, well...



LEO:  It's like saying, no offense, but are you a spy for the bad guys?  No offense.



STEVE:  Yeah, it was really, really, really...



LEO:  He basically implied that, in his journalistic - that Glenn wasn't a journalist, or that in his journalistic endeavor...



STEVE:  He was aiding and abetting.



LEO:  He was aiding and abetting.  And, you know, this is called the First Amendment.  This is called, you know, I just - it's shocking.



STEVE:  Yeah, I - yeah.



LEO:  I'm telling you, if there were somewhere I could move, I would.  But I don't - there's nowhere to go.



STEVE:  We're in the best place.



LEO:  Yeah, we are.  At least we can talk about it freely still.  Nobody's pounding on our door.  No storm troopers.



STEVE:  And that's why I love the country.  I mean, I do.



LEO:  It's not over yet.  Let's fight for it.



STEVE:  These are - and of course we know that the Supreme Court did the right thing, I think.



LEO:  They did one bad thing last week, or Monday, and one good thing today, so.



STEVE:  Yeah.  Anyway...



LEO:  They're 50-50.



STEVE:  Anyway, this is not a surprise, but this was interesting to have it made more explicit.  And this is Eli Lake, writing for The Daily Beast, who interviewed Glenn Greenwald.  Eli wrote, "As the U.S. government presses Moscow to extradite former National Security Agency contractor Edward Snowden, America's most wanted leaker has a Plan B.  The former NSA systems administrator has already given encoded files containing an archive of the secrets he lifted from his old employer to several people.  If anything happens to Snowden, the files will unlock.



"Glenn Greenwald, the Guardian journalist who Snowden first contacted in February, told The Daily Beast on Tuesday" - which is yesterday from this podcast's recording date - "that Snowden 'has taken extreme precautions to make sure many different people around the world have these archives, to insure the stories will inevitably be published.'  Greenwald added that the people in possession of these files 'cannot access them yet because they are highly encrypted, and they do not have the passwords.  But,' Greenwald said, 'if anything happens at all to Edward Snowden, he told me he has arranged for them to get access to the full archives.'



"The fact" - now back to Eli.  "The fact that Snowden has made digital copies of the documents he accessed while working at the NSA poses a new challenge to the U.S. intelligence community that has scrambled in recent days to recover them and assess the full damage of the breach.  Even if U.S. authorities catch up with Snowden and the four classified laptops the Guardian reported he brought with him to Hong Kong, the secrets Snowden hopes to expose will still likely be published.



"A former U.S. counterintelligence officer following the Snowden saga closely said his contacts inside the U.S. intelligence community think 'Snowden has been planning this for years and has stashed the files all over the Internet.'  This source added, 'At this point there is very little anyone can do about this.'



"The arrangement to entrust encrypted archives of his files with others also sheds light on a cryptic statement Snowden made on June 17 during a live chat with The Guardian.  In the online session he (Snowden) said, 'All I can say right now is the U.S. government is not going to be able to cover this up by jailing or murdering me.  Truth is coming, and it cannot be stopped.'



"Last week NSA Director Keith Alexander told the House Permanent Select Committee on Intelligence that Snowden was able to access files inside the NSA by fabricating digital keys that gave him access to areas he was not allowed to visit..."



LEO:  Wow.



STEVE:  I know, "...as a low-level contractor and systems administrator.  One of those areas included a site he visited during his training that Alexander later told reporters contained one of the Foreign Intelligence Surveillance Act (FISA) court orders published by The Guardian and The Washington Post earlier this month."



So clearly our intelligence agencies are really looking closely at what's come out that they're aware that Snowden has, and then backtracking all of their logs of his access to figure out what more he may have.  But anyway, so what's interesting is that there is a dead man's switch.  He's created that.  And it's funny, Leo, because there's so many times now in, like, plots in movies and on TV, where it's like, well, okay, why didn't you send - put this all in an envelope and send it to your attorney, or send it to your mother, or do something, you know...



LEO:  Well, to be fair, a lot of movies they do that also.  I mean...



STEVE:  Yes, yes.  Yeah, and so you're right, it's been a - it's a plot device.  And but I don't put it at, I mean, it's funny because we've seen criticism of Edward a lot in the last couple weeks.  But I watched the video a couple times of him being interviewed.  And it seems very clear to me that this guy is no dummy and that he did all of this on his own schedule.  Everything has been on his own schedule.  And even his move to Hong Kong that was roundly criticized by all the talking heads that wanted to be critical...



LEO:  Paid off.



STEVE:  That all worked exactly according to plan also.  And now he's got Julian Assange and his team working with him, and he's now moved to Russia, and asylum in Ecuador is apparently in the works.  So anyway, we'll see how this plays out one way or the other.  We'll certainly talk about it from a news angle.



But given that this was all on his schedule, I wouldn't be the least bit surprised if this is exactly true, that somehow, something needs to - we've even talked about, what was it, Daniel Suarez's network-aware technology.  I mean, it would be easy for bots somewhere to be monitoring news and reading news stories and act at that level.  Or just he has to do something on the Internet, send email to somewhere, and it bounces around or who knows what every so often in order to keep something alive.  Or maybe it's just an agreement with people who know that they have this information.  If it appears that I disappear, press this button, or do this, or send this to somewhere, whatever.



LEO:  Didn't the same article say that Greenwald's computer was stolen after he mentioned on Skype that he had data on this computer?



STEVE:  Ooh.  I hadn't...



LEO:  Yeah.  He's in Rio.  I mean, this whole thing is...



STEVE:  Wow.



LEO:  If, as some say, Snowden is making it all up, it sure is annoying somebody in D.C. a lot.  A lot.



STEVE:  Yeah.  Yeah, well, and in fact, in that first video he made, he said, "Yeah, we've got the CIA field office just down the block from here," he said.  "I imagine they're pretty busy right around now."  Yeah, I bet you do, and they are.  So anyway, enough on that.



There was a bunch of - I sent something out on Twitter that I tweeted.  I tweeted:  "To the NSA's question asking us, 'If you have nothing to hide, why is your communications encrypted,' I ask in turn, how would you know?"  And I got back a bunch of fun tweets.  But the best one of all came from Nathan Long, tweeting as @sleeplessgeek.  And he said, "One might say I have nothing to hide from people I trust."



LEO:  Oh, there you go.



STEVE:  And I thought that was exactly right.



LEO:  That's a good way to put it.  That's a good way to put it.



STEVE:  That's exactly - that's exactly it.  It's not that I have anything to hide.  I have nothing to hide from people I trust.



LEO:  Right.  But we just can't trust the government to not misuse that information.



STEVE:  Well, for me, it's the gloves are off when the Director of National Intelligence...



LEO:  Lies.



STEVE:  ...flatly lies to Congress.  That's it.  It's like, sorry, that's - you can't - our system depends upon oversight.  And it was in the law.  It was built in.  And if you short-circuit it, then, sorry, you don't get anything anymore.



LEO:  Yup.



STEVE:  A couple TV notes:  Monday night we had the premiere of the Stephen King novel-based TV series "Under the Dome."



LEO:  Oh.  Did you read that?  Did you like it?



STEVE:  Well, no.  However, I heard...



LEO:  Thurrott liked it.  He didn't like the end, he said, but he liked the book.



STEVE:  Yeah, I heard that.  Actually someone - I tweeted earlier that the first episode, the premiere episode was Monday.  It is being repeated, I didn't note what night.  But probably, like, this weekend.



LEO:  Eh, it's on demand.  What do you need to...



STEVE:  Okay.  So for all of our listeners, for what it's worth...



LEO:  Get Hulu Plus.  Watch it on Hulu Plus.



STEVE:  This is not giving anything away because you know this from even the name and the previews.  But a small town suddenly gets instantly cut off by a force field which just appears out of nowhere, and it's the story of that, and based on a Stephen King novel.  Now, I downloaded it because I thought, okay, I can't wait for, like, this to be doled out to me a week at a time.  So I thought, I'm just going to read the book.  Oh, my lord, is it big.  I mean, even the Table of Contents...



LEO:  I know.



STEVE:  Even the Table of Contents scrolls on and on and on.



LEO:  I'm on a break from Stephen King.  I finished "The Stand," and now I need a breather for a year or two, and then I'll look at "Under the Dome."  He writes a lot of words.



STEVE:  Boy.  So the response I got, that I saw before I shut down my Twitter client for the podcast, was that the people in the series and both inside and - the people in the book, both inside and outside the dome, don't behave in a realistic manner.  And if that's true, that would really annoy me because I hate when writers do that, when writers make their characters do things that are, like, dumb.  It's like...



LEO:  I think that's a fair knock on a lot of King's stuff.



STEVE:  Oh, well...



LEO:  Yeah.  Have you read any of his other books?



STEVE:  I've never been a Stephen King reader because I just - I've got so much sci-fi going on.



LEO:  He's a great writer.  And I think...



STEVE:  I like the movies that have been made from his stuff.



LEO:  Yeah.  He's a very good writer.  But I think you could - that is a fair complaint to make about almost everything.  It's so plot-driven that the characters have to work in support of the plot.



STEVE:  Yeah.



LEO:  And this isn't always, you know, "The Stand" had a number of characters that just were wooden because they were forwarding the plot.  They weren't...



STEVE:  M-O-O-N.



LEO:  Yeah, there you go.  You did read "The Stand."



STEVE:  Oh, I saw it.



LEO:  Oh, it was a show, okay.



STEVE:  Yeah, yeah.



LEO:  Yeah, that's a good example, actually.



STEVE:  Yeah.  So also "Falling Skies," I mentioned it before, I wanted to reiterate, wow.  Season 3 is really, I mean, it's - I'd be hard-pressed to say whether it's worth putting up with the first season and most - the first half of the second season.  The second season began to get really good.  They're really onto something now.  It is, I think, the best of the low-budget sci-fi TV series that are on right now is "Falling Skies."  I think it's great.



LEO:  It's low-budget?



STEVE:  Well, yeah, I mean, they're all trying to not spend as much money as they, I mean, to minimize the cost.  And so special effects are like, eh, okay, I mean, they're fine.  But they're character-driven sci-fi settings.



LEO:  I kind of like character-driven.  I don't mind character-driven.



STEVE:  Yeah.  And it's gotten - it's really gotten better.  And I got two tweets, I will just say, in response to my recommending "The Killing," the series on AMC, which I talked about last week.



LEO:  Oh, whoo, I can't watch that [vocal shuddering].



STEVE:  And one, @Abdullah_Hamad in the UAE, he tweeted:  "Thanks for recommending the TV series 'The Killing.'"  He said, "The acting is beyond excellent.  They all deserve an Oscar."  And that's what it is, Leo.  I just - I want to, like, watch it again just to watch the acting.  It is superb.  And then someone, @md_seuss tweeted, he said:  "Thanks, I think, for the recommendation on 'The Killing.'  I can't stop watching it.  It is great."



LEO:  Good.



STEVE:  So he's as sucked in as I was, which is cool.



LEO:  Do you want to do a SpinRite testimonial?



STEVE:  Well...



LEO:  In some ways this whole show is about SpinRite, so...



STEVE:  Precisely.



LEO:  Yeah.  So we'll do that in a second.  We'll talk about what you've learned, some Intel history, useful and interesting.



STEVE:  That I needed.  Something that I needed from the 20 years past.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Let's talk about memory.  Steve Gibson, Leo Laporte.  Time to learn some history that is still of great value.



STEVE:  So, okay.  A little to set the stage here.  This was driven by my current R&D effort, essentially, for the next release of SpinRite, which I'm calling 6.1.  My intent is not to rewrite SpinRite.  That would take a long time.  And it's really not necessary for what SpinRite is today.  I do, because we've seen that SpinRite is able to recover SSD drives - like as far as we know it's got a great track record of doing that.  That to me says, okay, it's not going away anytime soon.



So I'm fully looking at a v7 which will actually be a restart because I want to add features that the current user interface just can't handle and, in fact, that whole architecture is not designed for, like going into the file system, having it be file system aware, allowing you to say I want to pull this file off of the drive, rather than just fix the whole drive.  Or I want to pull all of my documents.  Or I want to prioritize recovering files over recovering space.  Or I want to clone a dying drive to another drive.  These are things that people have asked about.



And it's like, well, yeah, but that's not what SpinRite - that's not the way it was originally designed.  It was first designed when people only had one hard drive.  It was, like, the most expensive component of their entire computing system because 10MB was so expensive back then.  And so the goal was just to fix that one huge investment you had.  People just weren't plugging hard drives in right and left.  So in terms of my overarching plan, I'm fully intending to scrap everything I have right now.  But not yet.



So what 6.1, and there's probably going to be a .2 and .3, the focus is fix everything that I can, which in fact brings SpinRite current for the features that we've talked about, that all these testimonials are based on and so forth, but just makes it better.  But not different.  Different will be v7.  And I'm going to have to go away for a long time to create that.  So we need an update to v6 in the meantime.



So I'm very methodical in the way I approach things.  The first thing that I looked at was that SpinRite sometimes has a problem just with FreeDOS booting.  And SpinRite, before SpinRite even gets a chance to run, some users have FreeDOS explode on them, and they never get a chance to run SpinRite.  And the good news is that they'll shoot an email to, I mean, it doesn't happen often, just it's a low, low, low level.  But it's been on my radar for a while.



Greg is always able to fix that, just by helping them use MS-DOS rather than FreeDOS.  We include FreeDOS because it's license-free.  MS-DOS you have to have Windows.  But there are sites on the Internet where you can download it.  But even in XP, that doesn't have DOS, you can have XP create a DOS-bootable floppy, for example.  And so there's - MS-DOS is in Windows.  It's still there.  It's just you get to it when you say I want to make a bootable floppy.  So we can fix that.



But so I started this project a couple months ago.  And I started looking at the FreeDOS kernel.  Why is it blowing up?  Well, it turns out that FreeDOS does something that MS-DOS doesn't, which is it tries to open a dummy file from every drive, on every partition of every drive it finds.  And it does that to populate some tables that are used to manage the FAT systems on each of the drive's partitions.  And it does that, it turns out, because some random Norton utility blew up if you ran this Norton utility from the Dark Ages on FreeDOS and asked it to access a drive that FreeDOS had not accessed before.  And so they added this thing to FreeDOS where it went out and tried to open a file on every partition of every drive.  And in some cases of a particular type of disk damage, that will cause FreeDOS to die.



So the first thing I did was create a custom kernel.  So we have that now.  I added a new line to config.sys.  It just says "skipinit=1."  And so in the FreeDOS kernel that will be coming with the next version of SpinRite, in the config.sys it'll say "skipinit=1" because SpinRite doesn't need that.  And actually it's dangerous, as we've learned, to have FreeDOS do that.  So, okay, first problem was solved.



Second problem was the question of Mac compatibility.  And I talked about how I rewrote the keyboard interface, and now it's running on the Mac.  It's running on my MacBook Air without any problem.  There's more work to do there over on the booting side.  But essentially that's resolved.



So the next problem, and this was substantial, was to get SpinRite to operate all drives in what's called UDMA,  Ultra DMA mode.  Many BIOSes do that, but not all do.  And so if you're - and SpinRite today has still been using the BIOS to perform its bulk data transfer.  That is, all of the reads and writes that it does, it just asks the BIOS for.  The logic behind that is we just get complete compatibility because the BIOS always knows how to talk to the controllers that are on the motherboard.



But the BIOS doesn't always know how to do it fast.  And it really doesn't need to because in today's world the BIOS just gets the OS booted, and then the operating system uses its own drivers in order to talk to the hardware and take over.  Which is why anyone who's ever set up a new operating system on a PC-style machine knows that the motherboard comes with drivers, and you quickly install those in the OS so that it's able to talk to the hardware efficiently.  So essentially SpinRite needs to add to itself, it needs to acquire an understanding of all of the latest hardware, the mass storage hardware that exists on motherboards.



The other thing that it needs to do - oh, and I should mention, so I now have so-called "PCI bus enumeration."  That's all done and working.  I wrote it in Windows.  The gang in the grc.spinrite.dev newsgroup pounded on it and tested it.  And so now SpinRite has the ability to understand the PCI bus and fully explore every controller on the PCI bus, finding all the mass storage controllers that are accessible in the machine.  So even if the BIOS doesn't support something, it's still a PCI peripheral, and SpinRite will now find it.



One of the problems that we've had with performance, because performance is one of the areas I'm really focused on, you know, people have talked about how SpinRite can spend weeks recovering, like struggling on a really damaged hard drive.  Typically it takes maybe hours.  But it can take weeks.  Clearly, a huge aspect of convenience would be speed.  We all - none of us want SpinRite to be slow.  So one aspect is that SpinRite will incorporate its own low-level device drivers to talk directly to the hardware on the motherboard.  And in fact one of the things that has happened with drive evolution and controllers, we had the original IDE interface, also known as the ATA interface.  Then when PCI came along, there was something known as "native PCI" which was sort of a bridge between the way the IDE controller worked and the PCI bus.



And then the latest type of controller is called an AHCI.  This is an Intel standard, Advanced Host Controller Interface.  AHCI mode is believed to be faster, but actually isn't faster, than native, the so-called "native IDE" or "native PCI" mode.  And BIOSes differ in the way they are configured.  Most people just, if they're building a new system from scratch, they will install the OS on their BIOS or on their motherboard and run it.  Most BIOSes are still defaulting to this compatibility mode, this native PCI which is compatible with IDE, rather than using AHCI.



People believe AHCI is faster.  Arguably, it's faster in a server setting because it allows drives to be given many things to do at once and for the drive to schedule their completion and essentially, whether it's reading or writing data, to perform that as they are able to in order to improve the overall throughput through the drive.  But that really requires that the system have many different sorts of things to do at once.  And typical single-user workstations don't.  The system sits around most of the time, waiting for something to do.  So it really isn't clear that that's a benefit.



One of the requirements that SpinRite has imposed, SpinRite 6 has imposed on its users is that, if SpinRite doesn't see the drive because the motherboard has been set for AHCI mode, that the user who wants to run SpinRite manually change the BIOS over to this compatibility mode.  And then SpinRite will see it.  You run SpinRite, it does its recovery job, and then you switch it back.  The good news is all of that will be automatic because it turns out that all of the AHCI controllers also support the original compatibility mode, and SpinRite will be able, without you having to mess with the BIOS, to just make the switch for you.



But the big problem is buffer size.  The traditional track on a hard drive was 17 sectors.  An MFM, a Modified Frequency Modulation track had 17 sectors.  Then we went to RLL, and we got 26 sectors.  That's a 50% density improvement with run length limited encoding.  We got 26 sectors.  But in the BIOS there are only 5 bits to specify the sector number.  Well, 5 bits gives you from zero to 63 in binary.  And so that's technically 64 different possibilities, except that sector zero was never valid.  There was never a sector zero.  For some reason, we don't know why, there's a head zero, there's a cylinder zero, but sectors were always numbered from one.  So who knows why.  So that means you could only have 63 sectors on a track.



Well, that 63 sectors, if we round it up to make the math easy, that's 64.  And sectors are 512 bytes each, which is to say half a K each.  So that means that a track buffer was 32K.  The problem is that SpinRite 6 today is working with 63-sector buffers, that is, slightly smaller than a 62K buffer, and transferring chunks of the hard drive at this buffer size back and forth as fast as it can.  What we really need, though, are much larger buffers.



And this is where I hit a problem last week, essentially, as I was methodically moving forward, solving one problem after another in this update of SpinRite's low-level data transfer architecture.  I needed megabytes of buffers.  In fact, you know me, if I'm going to do it, I'm going to do it all the way.  All of the late-model drives, and actually drives that have followed the ATAPI standard, or the ATA standard, for many, many years, they support a transfer of up to 64K sectors.  So that 64K, 512-byte sectors, you can actually tell the drive, I want you to transfer that block.  Well, that is 32MB.  And it turns out that's 32 binary megs, which is 33.55 actual million bytes of data in a single transfer.



Well, now, that's fabulous because what that means is that the drive would start at whatever sector we tell it, and it would either write data or read data nonstop until it has transferred 32MB of data from a single request.  And the one thing that drives have gotten right - remember SpinRite was born to fix the interleave of drives, in order to allow them to transfer as much data as possible per rev.



LEO:  That was what SpinRite was designed for originally?



STEVE:  Yes.



LEO:  How interesting.



STEVE:  Yes.



LEO:  I probably used it that way.  I remember changing the interleave on my old Seagate...



STEVE:  Oh, exactly, the ST-253, I think it was.



LEO:  253?  Yeah.



STEVE:  255 maybe?



LEO:  One, I thought.  But anyway...



STEVE:  251, the ST-251, you're right.



LEO:  Yeah.  It was the first to not use - what's the successor to MFM it used anyway?



STEVE:  It was RLL.



LEO:  RLL, that's right.



STEVE:  It was the early RLL drive.  And they were all interleaved wrong.



LEO:  Yeah.



STEVE:  And so SpinRite was - I wrote it to be an interleave optimizer.



LEO:  So I bought it in v1.



STEVE:  Yeah.



LEO:  Wow.



STEVE:  And the reason I had to add all this other technology is that sectors were marked bad in logical sectors.  But if I rearranged the interleave...



LEO:  Oh, yeah.



STEVE:  ...then the...



LEO:  It would be meaningless.



STEVE:  ...the error in the sector went to a different logical sector because it was in the same physical location.  So that meant I had to detect errors.  I had to do pattern testing.  I had to verify the surface.  I had to do all this other stuff just to interleave, just to safely re-interleave the drive.



LEO:  How funny.  How funny.



STEVE:  And so of course we lost that.  No one is doing messy with their interleaves anymore.  They're all 1:1. 



LEO:  Right.



STEVE:  Yet because - oh, and the other thing is, if I was going to - because the only way to change the interleave is to do a new low-level format.  I had to re-low-level format one track at the new interleave.  Well, if I'm going to do that, then I'm going to wipe out all the data.  That means I have to absolutely recover absolutely everything that is there.  So all of the stuff that we use SpinRite for now is actually a side effect of the fact that I had to do - as you know, my nature, it was going to be right.  And the only way to do it right was to absolutely do data recovery and then surface analysis in order to safely and properly re-interleave the drive.



LEO:  And I had those 251s.  I upgraded my FidoNet BBS to those RLL drives.  And I remember we were trying to get the most - I was trying to get the most speed out of them.  And I remember that that's where I met Steve for the first time.  That's great.



STEVE:  And I did something in my InfoWorld column that was the most popular thing probably I ever did.  It was called "Steve's Dream Machine."  And...



LEO:  Yes, I remember that, yes.



STEVE:  ...one of the things I noted was that the drives we were all using actually had some unused cylinders at the end.  And if you did something, I don't remember the details now, to, like, fudge the size of the drive, you could then get two maximum-size 32MB partitions on the same drive.  You could get a C and a D, and neither of them could possibly be any larger because of the sector count problem that we had in that version of DOS.  And so everyone loved the idea that you could just sort of like push - you could get just a few more cylinders out of the drive and then get two beautiful 32MB partitions, a C and a D.  So that was all craziness that we were up to back then.



But so here I am, with drives in the world, everyone listening to this has drives that can transfer 32MB at once.  And of course, if I'm going to do this, I'm going to figure out how to make that happen.  But the problem is SpinRite is a real mode program.  DOS, FreeDOS, MS-DOS, all DOS is real mode.  Real mode is what was originally - there was nothing called "real mode" in the beginning because there was no alternative mode.  So no one called it "real mode" when it was the only mode you had.  It was just the chip, the 8088 and the 8086.  The 8088 was in the original IBM PC.  And it allowed you to access 1MB of memory.



And remember we had the Apple II at that time.  And that allowed you - it had a 16-bit address bus, and 16 bits allows you to do 64K.  So it allowed you to do 64K of memory.  And so one of the big deals about the IBM PC was that it had this next-generation Intel processor.  There was the 8080, and it was very much like the 6502 chip that was in the Apple II, similarly had a 64K memory size limitation.



So for the 8088, Intel added 4 bits to the address bus.  So the 8088 had a 20-bit, 16 plus 4, a 20-bit address bus.  And that allowed it to access 16 times 64K of memory, which was a meg.  And because that seemed like an insane amount of memory back then, they allocated, they just took up the upper third, 384K was just sort of squatted on by the display memory, and the BIOS was up in the high memory area, and ROMs that came with different controllers that you might plug in and so forth.  Everything lived, all of that, sort of the I/O space for video and BIOS and things, was in the upper 384K.  The lower 640K was RAM available to software.  And of course, oh, 640K, who's ever going to fill that up.



So that was the 8088, with 20 bits of address space.  And that is the world that SpinRite was born in, and it's the world that SpinRite still exists in.  When you boot FreeDOS, you're in so-called "real mode."  It wasn't until the next chip, the 8286, where Intel introduced something called "protected mode," and it was because they added protected mode that they said, okay, well, what are we going to call that other mode?  Like what it's always been before?  What the 8088 and the 8086 and so forth chips are?  And they said, well, let's call that the "real mode" because that's all, for one thing, no software understood protected mode.



When they came out with the PC/AT, that was - it was the PC/AT that had a 286 chip in it.  And they again added 4 bits, so that had a 24-bit address bus, so now you could get 16MB of memory, although it was incredibly expensive, and nobody did that initially.  So that's why they were calling the original mode the so-called "real mode."



Okay.  So here I am today with SpinRite.  When all of these processors boot up, they are in real mode.  The BIOS is in real mode.  DOS is still around, it turns out, because it's still being used as a loader for other operating systems.  And so real mode has never gone away.  It's still supported in the very latest chips because it's still the foundation of how these systems operate.  So SpinRite operates in real mode.  And real mode knows, it has this memory concept that I was just describing for the original IBM PC of 1MB.



Now, that has never been a problem for SpinRite, ever, because the code itself, we often remark about how small it is.  It's written by hand in assembly language.  It was less than 64K for several generations.  It was a COM file, which is just an image that gets loaded into memory.  And then it had to outgrow that with SpinRite 3, I think it was.  But it's always been able to operate with relatively small buffers.



For 6.1 I need to change that.  If everyone's drives can transfer 32MB at a time, that's what I want SpinRite 6.1 to be able to do.  But I'm in real mode.  And there's no way to access more than a megabyte in real mode.  That's always been the case.  And protected mode is completely incompatible with real mode.  I mean, they're oil and water.  They're just - they just don't get along in any fashion.  But of course, when Intel created the 8286, they realized, I mean, if Intel has ever been anything, it's backward compatible.  And really that's been the success story of all of these companies.  Microsoft is backward compatible.  They always arrange for their new operating systems to run the oldest code you've ever seen, I mean, way, way back.



Intel has always adopted the same policy, and that is forward, as they move forward, they're going to retain backward compatibility.  So the 8286 chip similarly booted, just as all of the chips today do, even the 8386 and our Pentiums and our Core i7, everything, they all boot up in real mode.  Intel then created the ability to switch into this so-called "protected mode."  And in protected mode you finally had this notion of a supervisory process, sort of like the operating system actually exists as an entity, rather than just sharing memory along with the various programs that are running, and it's sort of as an executive.  And it's able to manage the programs that are running underneath it.



And the programs using the so-called protected mode, this protection is then being protected from each other and protected from having direct access to the system's hardware which could allow the programs too much freedom and power.  So the programs are constrained.  So the way, back on the Intel 8088, it was a 16-bit processor.  I mean, it was still a 16-bit machine.  But remember it had a 20-bit address bus.  That is, it was a 16-bit machine that could access 20 bits' worth of memory, 1MB of memory.  How's that possible?



Well, what Intel did was they created the concept of segments.  And that's, I mean, "segment" is a word that probably many people have heard before.  That was an innovation where Intel said, okay, we have a 16-bit machine.  But we somehow need to roam around within 20 bits.  We need to access more than 64K, which is all we can access with 16 bits.  So they took a second register, the so-called "segment register," and they shifted it over, they shifted it left 4 bits.  And the value of that register would then be added to the 16-bit value that the instruction was able to offer in order to generate a total of a 20-bit address.



And so that's the so-called "segmentation" concept that Intel processors have always used.  Back in the 8088 there was - so the idea would be the segment register would sort of specify which 64K region within the megabyte of memory of the 8088 you were able to access.  And that's what I programmed in.  And SpinRite today still has a lot of that logic because it runs in real mode.



When Intel went to the 286, they said, okay, we're going to change the way segmentation works.  Rather than taking the value of the segment register and multiplying it by 16, which is what shifting it 4 bits to the left does, we're going to still have a 16-bit segment register.  But it's going to refer to a table in memory.  And the table in memory will specify the starting address of the segment, and it will specify the size of the segment, that is called the "limit" of the segment.  And all those cool other properties that we want segments to have, like is it a code segment or a data segment?  Can you execute in this or not?  Is it readable?  Is it writable?  What is the privilege level?  So by creating sort of this indirection table, Intel gave us protected mode.



So the segment, the value in the segment register, back in real mode it's just multiplied by 16 and then added to what's called the "offset," the original 16 bits.  Instead, Intel said, okay, we're going to have that refer to a table that has much more exotic properties.  It can be any offset in memory, so that'll be 32 bits.  And the limit register, we're going to keep that at 16 bits.  But we'll have a granularity bit where the values either specify bytes or 4K chunks.  And I'm sorry, the limit register was 20 bits, and the base is 32 bits.  And the granularity specifies either bytes or 4K chunks.  And the beauty of that is 20 bits of the register in 4K chunks gives you 4GB, which is 32 bits.  So that's where this notion of 4GB of address space came from, and this 32-bit base address in this table.



But now Intel had a problem with their design because, back in the 8088, as instructions were being executed, and they were referring to segments and offsets, the hardware to do that was trivial.  You would take whatever was in the segment register.  You could shift it left by 4.  Actually, hardware can do that instantly.  You just sort of wire the bits over 4 spaces.  And then you add the offset into that segment to get the 20 bits.  So, I mean, that's like instantaneous.  That's no trouble at all.



But with the design of protected mode in the 286, remember that the segments refer to tables in memory.  So that would mean, as you were executing instructions, and these instructions were referring to segments, the chip would have to be going out and fetching the entry in the table that the segment register referred to, getting all of that data, the base of the segment, that's 32 bits, the limit.  And then it would have to take the base, add that to the offset, then check it against the limit to see whether you were exceeding the bounds of the segment.  So it was like, wait a minute.  This thing's going to be slower than the 8088.



Well, the answer from a computer science standpoint is pretty simple.  You use a cache, which is exactly what Intel did in the 286.  The idea is that the segment registers, they're not changing all the time.  They're loaded with a value when the code wants to work within that segment.  And normally it sits in there within a given segment for a while.  And it may be referring to data in several other segments.  But it's roaming around within the segment.  The segment itself is not changing.



So the idea is any time the segment register is loaded, only when it's loaded does a reference have to be made to this table in main memory to get all of the data that that segment register is referring to.  And in fact it's called a "selector" now.  It's selecting a set of descriptors that are in this table, and the chip caches them.  Essentially, it reads them once from the table into its hardware, into its internal hardware, so that then all references to memory in that segment can be instantly fixed up.  They can be added.  They can be limit checked.  They can be checked for read and write and code and data and priority level and all those things that were added to create the segmented, the sort of this constrained in control architecture as Intel was moving forward.  So that's how the 286 operated.



Now, there was a problem with the 286.  And that is there was no way to take it out of protected mode back to real mode.  At all.  There was an instruction in real mode for switching to protected mode.  But the engineers at Intel thought, hey, this is a better mode.  Why would you ever want to go back?  And it turns out everyone did because nothing ran in protected mode at the time.  And the BIOS was in real mode.  DOS was still in real mode.  When you plugged controller cards in, they brought their own BIOS.  There was a video BIOS that controller cards had.  There was a disk BIOS that disk controller cards had.  They were all set for real mode.



So nothing ran in protected mode.  So it was a catastrophe that you were unable to switch the 286 back into real mode.  And so, believe it or not, the IBM engineers who realized they had a problem, they said, well, only thing we can do is to reset the chip.  And so they actually did that on the fly.  The original OS/2 operating system that was the early operating system for the PC/AT, whenever it needed to use the BIOS or do any I/O with any of the peripherals, it would do this on-the-fly reset.  It would literally reset the chip.  The chip would come back up in real mode, as all Intel processors always do, and they would save the state of the chip just before the reset in some of the RAM of the clock controller.



LEO:  Oh, wow.



STEVE:  The clock chip had some unused RAM.



LEO:  What a hack.



STEVE:  It was a hack, it was an unbelievable hack.  And so when the chip would come out of reset, it would go to the BIOS, and then it would check the data in the clock RAM to see if it looked reasonable.  Did it match the pattern of, oh, crap, I was just in protected mode, and now this is what I have to load my registers with, and this is where I have to go.  And so it was an incredible kludge.



When they did the 386, Intel fixed this.  This was clearly a mistake.  I mean, it was just a - it was bizarre that you could not switch the chip back to real mode.  Everyone wanted to.  So the 8386 does allow you.  There's a bit in control register zero, it's the zero bit, that you turn on, and now you're in protected mode.  And you turn it off, and now you're in real mode.  It's just like, I mean, it couldn't be any simpler.  I mean, they completely fixed it.



But how did Intel emulate real mode in their advanced processors?  And this is the key.  How did they emulate real mode?  Real mode, as I've said, has these segments that are limited to 64K.  I mean, that's all you can address with 16 bits.  And in real mode on a 386, on an Intel Core i7, on any of these chips in our Macs and in our PCs, we've got 32-bit registers.  You have AL is the low 8 bits.  AH is the high 8 bits.  AX is them together, making 16 bits, and so-called EAX is the Extended AX, and that's 32 bits.  We've got all the registers that are 32 bits.  But in real mode we only have the lower 16 valid.  We are only able to access 64K in a segment, no matter how much memory the system may have.



And so here I am looking at SpinRite in real mode and realizing that I need 32MB buffers.  Yet I'm in real mode, and I cannot have them.  And I can't run in protected mode because DOS doesn't, and SpinRite doesn't, and nothing does except protected mode operating systems, but that's not what I have.  And I can't rewrite everything.  That'll be v7.  But still, the reason I want these 32K buffers is that disks have gotten so dense that if I'm only able to issue 63-sector transfers in 32K buffers, not megs, 32K, then I ask for the data, and it's read.  Then I ask for the next.  But in the interval, I've lost the next sector.  And so I have got to go all the way around again.  It's like the drive is mis-interleaved.



I mean, it works.  SpinRite today works.  We're selling it.  People are using it.  It's doing data recovery.  But it is not as fast as it could be.  I don't know yet how much faster SpinRite will be with 32MB buffers.  But my guess is at least, at least twice as fast.  Because I'm probably missing a revolution for every small block of sectors I ask for, I've got to go all the way around again and get the next block, all the way around again and get the next block.  So drives today are optimized for reading in a forward direction without ever missing a spin.  So I would be able to read - so we're talking about going from 32K to 32MB.  So I would be saving a thousand revolutions of the drive when I transfer 32MB.  And so it's worth doing.



Well, the answer to this is what Intel did was they simulated real mode with their protected mode technology.  They had all that fancy technology with base addresses and sector limits and so forth.  So when the chip comes up out of reset, the microcode, the firmware in the chip, it loads those caches.  Remember that in real mode there are no caches.  There's no segment descriptor caching in all of that.  That doesn't exist.  All we've got is the simple math of multiplying the segment register by 16, that is, shifting it over 4, in order to give us a total of 20 bits of addressability.



So the firmware behind the scenes, it loads these caches, the segment descriptor caches, with 64K limits and allows full read and write, code or data, no protection at all, because there was - you could do anything you wanted to with the memory in an 8088, in a real mode processor.  There are no constraints.  And so the only thing then that real mode is doing is multiplying the segment register by 16 and adding it.  Behind the scenes there is the limit registers and the privileges and things.  But you never see them in real mode.  Since the only way to take the 286 out of real mode was resetting it, real mode was always exactly like that.



But remember that I said the 386, Intel realized they'd made a mistake.  Obviously people needed to drop back to real mode all the time.  So they made it as simple as resetting a bit to drop back to real mode.  What Intel forgot was to change the cache for its segmentation when they do that.  It turns out that when you drop the 386 or any subsequent processor ever made back to real mode, and they can all do that, although the firmware in the chip when it boots, when the chip first comes up out of reset, the firmware loads those caches with real mode segments.  When you're up and running in protected mode, and you've been loading descriptors from RAM and loading the caches and so forth, when you turn that bit off, the only thing that Intel does is they go back to multiplying the segment register by 16.  They never again touch those descriptor caches.



So what that means is it is possible, and I did it yesterday, which is why I'm so excited about this, it is possible to switch into protected mode and to put into memory a 4GB limit, that is, all F's, 5 F's for 20 bits' worth of F in the limit register.  The granularity is set to 4K, so that stretches all the way to 4GB.  Set all the privileges to "free," read, write, code, data, anything you want to do, fully privileged.  Then you load each of the segment registers.  There's a code segment, data segment, extra segment, stack segment, and then there's an F segment and a G segment.  You load them all with that descriptor, which completely sets them for 4GB of access.  Then you simply drop back out of protected mode to real mode.



Now you are back in real mode, everything works.  DOS works.  The BIOS works.  SpinRite runs.  Everybody's happy.  Yet there is no limit any longer on the size of the segments.  Since we've got 32-bit registers in all of our 386 and subsequent processors, you can then put full 32-bit addresses into those registers, and they directly access physical memory.



So what this means is that SpinRite 6.1 will - oh, and this is not something I just discovered.  This is well understood, well known.  It's been known for - actually we're not sure how long it's been known for.  IBM got a patent on this that they issued the patent in 1994.  They called it an "artifact" of Intel's protected mode.  They got, in '94, they submitted the patent.  It was granted in '97.  Oh, and it was '97, August 24th of 1997, two days ago and 16 years.  Meaning that, since patents have a 17-year life, it's got one year left of the patent.



Except that people were using this in the early '90s.  Wikipedia says that game developers who needed more space, this is sometimes called "unreal mode."  There's real mode, and this is called "unreal mode."  Or sometimes called "huge real mode," "big real mode."  Because it never officially named, it's known by all kinds of things.  I call it "extended real mode" because it gives me access to what has always been considered extended memory in the original real mode context.  And so it looks like there was active use of this predating IBM's filing and being granted a patent.  So the patent is probably not valid.  Everybody uses it.  DPMI, the DOS Protected Mode Interface managers use it.  Himem.sys, emm386.sys, everybody has taken advantage of this.  So it's probable that there's plenty of prior art here.



What I wanted, though, was not to use any of those memory managers because they don't operate the way I need them to.  They copy blocks for you down from extended memory, down into conventional memory or back up.  So they sort of shuffle things back and forth.  You never really get access to it.  I needed SpinRite to have full direct access to the entire physical memory, up to 4GB.  I'll now then with 6.1 have 32MB buffers and be able to transfer massive blocks of data at a time.  And, since I've got 32-bit registers, SpinRite will simply be able to reach right up out there into the stratosphere and do whatever it needs to with the user data because of this weird little fluke in the Intel design.



Oh, and by the way, they can never change it because everybody uses it.  It's one of those things where it may have been an oversight because, when you come up for the first time, you're absolutely restricted to 64K.  It's only when you go into protected mode, change the "shadow cache," as it's called, the shadow descriptor cache, and then drop out, that you're like, oh, look, I can now access all of memory, and I'm in real mode.  So it's the best of both worlds.



LEO:  Cool.



STEVE:  Yeah.



LEO:  Does this change how you do anything?



STEVE:  Well, all of the PCI utilities, all of the disk controllers, they have access to this full memory.  So SpinRite will operate with the disk controllers, set them up, and instruct them to transfer 32MB of memory at a time.  I will probably use several of these buffers.  So, for example, while one is being transferred, SpinRite is working with the other.  For example, it does the bit inversion, where it inverts all the bits and then writes it and then reads it back and verifies it and then inverts them again and writes it and reads it back and verifies it.  I can use, essentially, a double buffering scheme so that there's data being transferred in one buffer while I'm busy inverting and verifying the other buffer and so forth.  So, yeah, there's lots of games that I can play having access, essentially, to the entire system's memory from within real mode.



LEO:  Steve Gibson.  It's an education to listen to you.  And a trip down memory lane, I must say.



STEVE:  Yup.



LEO:  What fun.  Somebody said you should write a textbook.  I don't know if there's a lot of use for this particular information anymore.  But it's fascinating.  I guess it's somewhat useful.



STEVE:  Well, it's funny, too, because...



LEO:  If you're writing low-level disk drivers.



STEVE:  Even Intel's contemporary documentation does - they get this wrong. 



LEO:  Really.



STEVE:  They say, yes, they say as long as you don't change the segment register, the cache will not be invalidated.  It turns out that's wrong.  And I went looking through all kinds of source code, like I was looking at the FreeDOS source code, and no one quite understands it the way I've just explained it.  I've explained it in exactly the way I have watched it operate and verified it.  So, I mean, there's a lot of misunderstanding and confusion about exactly why this happened and how it works.  As far as I know, what I've just explained is the whole story.



LEO:  Hey, an update on the Snowden case.  I'm reading The New York Times blogs.  It's not what you think.  When the people came to Edward's house, particularly lawyers advising him, he would have them put their cell phones in the fridge to block eavesdropping.  Apparently...



STEVE:  That's pretty clever, though.



LEO:  It's very smart.  It's got metal walls.



STEVE:  The guy is not stupid, yeah.



LEO:  So just a tip for anybody who wants to make your cell phone have a little privacy.



STEVE:  It's a kitchen-based Faraday cage.



LEO:  Yeah.  Yeah.  You might want to put it in a plastic bag to keep it from getting wet, condensation.  And be careful when you take it out.  Wow.



STEVE:  It's interesting, too, because you could tell people to turn it off, but do they really?



LEO:  Right.



STEVE:  But when you tell them, okay, we're going to stick it in here with the...



LEO:  We're going to put it in the fridge.



STEVE:  We're going to put it with the lettuce and the onions, that's pretty clear.



LEO:  A stainless steel martini shaker is the other [laughing].  It's a perfect Faraday cage, according to this article in The New York Times.  So everybody get a stainless steel martini shaker and...



STEVE:  That would, that actually would be pretty good.  I've always - I marvel at the fact that metal on metal somehow doesn't leak.  Every time I see the bartender shaking this, I'm thinking, how is that not leaking?



LEO:  I know, it should.  You need a grommet, an O-ring or something.



STEVE:  I want a grommet, yeah.



LEO:  Yeah [laughing].  Just love it.  Steve, you are amazing.  What a fun show this was.  I hope everybody got a kick out of it and maybe even learned some useful information, information about Intel history.  Steve is at GRC.com.  That's where you'll find 16Kb audio for those of you with bandwidth limitations.  Also transcriptions, getting more expensive by the minute, literally.



STEVE:  [Laughing]



LEO:  You can get all of Steve's freebies, and you can get the latest SpinRite with a guaranteed upgrade to the next version.  GRC.com.  Next week it's a Q&A episode.  That means you should go there and ask any questions you have.



STEVE:  Yes.



LEO:  GRC.com/feedback is the place to post your questions, and Steve will pick 10 for next week.



STEVE:  And I think, since people are kind of - they're all asking me about perfect forward security and SSL.  There's been a concern about whether the NSA is capturing traffic now for later decryption, and whether getting someone's private SSL keys at any time in the future would allow them to - would allow the NSA to decrypt all of the captured communications in the past.  So in two weeks our topic will be Perfect Forward Secrecy and SSL.



LEO:  Excellent, as always.  You da man.  If you want to watch this live, you can, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC on Wednesdays at TWiT.tv.  But we do make on-demand audio and video, high-quality audio and video available on our site, TWiT.tv/sn.  And the best thing to do is subscribe.  That way you'll always have Security Now! for your listening pleasure.  Steve, we'll see you next time on Security Now!.



STEVE:  Thanks, Leo. 



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#411	

DATE:		July 3, 2013

TITLE:		Listener Feedback #171

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-411.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got questions from our audience.  We're going to answer those, talk a little bit about the math around NSA's 5ZB, also some more revelations on SSL security.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 411, recorded July 3rd, 2013:  Your questions, Steve's answers, #171.



It's time for Security Now!, the show that protects you and your loved ones online, your privacy, and also gives you deep insight into how computers work, how technology works, how the Internet works, with this guy here.  Yeah, he's the Explainer in Chief, Mr. Steve Gibson.  Hello, Steven.



STEVE GIBSON:  You know, Leo, I wondered whether maybe we'd gone a little, you know, there's the expression "jump the shark," or off, over the top or something last week.  But I got a lot of tweets from people who said, and even mail in the mailbag that I found today when I was putting our show together, that they really liked the heavy-duty, wind up the propeller beanie episodes.  And so we haven't, I mean, certainly we have a widely distributed demographic.  And it must have been that some of what I was...



LEO:  No.  No, no, no.  No, no.  You can assume this is extremely narrow.



STEVE:  Well, within the extremely narrow demographic, there's a spread of people.



LEO:  I guess that's true, yes.



STEVE:  It must be that there were people who were like, huh?  What?



LEO:  What is he talking about?



STEVE:  Yeah.  But I got a nice tweet, for example, from a Jerome, who said, "Loved SN-410 on Intel architecture.  For me, having to rewind is a sign of a good podcast."



LEO:  That's right.  He wants more.  I would say that that's a safe bet.  Our audience is smart.  We don't - there's plenty of general interest and crappy technology programming.  I've got to play for you at some point this CBS This Morning woman who did the screed against passwords, and said passwords - she literally said passwords were security theater.



STEVE:  Oh, goodness.



LEO:  And gave us the worst way of making up passwords I ever heard of.  And this is on CBS This Morning.  So no, no, I think people who listen to this show are pretty serious.  Pretty serious.



STEVE:  They're ready.



LEO:  They're ready.  I don't think you should ever feel like you have to hold - don't hold back.



STEVE:  You know, I never - we never dumb it down.



LEO:  No.



STEVE:  It's the serious stuff.  And as you said, it does keep our listeners engaged.



LEO:  Our listeners are well above average.



STEVE:  Yeah.  They are.  They're great, as I can tell from the questions that they submit.  We're going to go through actually 11 because some will be quickies.  And there's a combo one, I think, between 4 and 5 that basically asked the same question.  First one was rather elaborate, and the second guy summarized it much more succinctly.  I thought, oh, well, these both have to be voiced.



LEO:  [Laughing] Great.  Great, great, great.



STEVE:  Just to show two different approaches.



LEO:  Did you see the Mother Jones article today about Edward Snowden?  Now, this goes back a little ways, too, because we talked quite a bit about your theories about PRISM, which in every respect, the more we learn, the more accurate I think your theories have been.



STEVE:  Actually, there was a phrase in a piece on CNET.  Declan McCullagh, who we've...



LEO:  He's been doing a great job, yeah.



STEVE:  Yes, whom we've quoted often.  There's actually a paragraph here where he said:  "Documents leaked by former NSA contractor Edward Snowden confirm that the NSA taps into fiber optic cables upstream..."



LEO:  "Upstreaming," they call it, yup.



STEVE:  "...from Internet companies and vacuums up email and other data that flows past.



LEO:  They have a name for it.  They call it "upstreaming."



STEVE:  Upstreaming.



LEO:  So there.



STEVE:  So anyway, so actually this is the first time I have seen what I've proposed as what was going on written somewhere.  So, and I wasn't aware of any additional documents which further confirm it, but maybe...



LEO:  Oh, no, they released two new slides on Sunday at the Washington Post.



STEVE:  Oh, okay.  Ah.



LEO:  And they had the upstreaming information.



STEVE:  Okay.



LEO:  So the more we know, the most accurate you are.  And then the other thing that's an interesting question is, how come Snowden knows all this?  And I think Kevin Drum, who's writing in Mother Jones, nailed it.  He thinks that the evidence, and even the verbiage that's used about him, shows that he was a hacker for the CIA and the NSA; that his job was to build a target list of vulnerabilities for cyberwarfare.  And I think that that sounds about right.



Stuart Staniford wrote:  "I speculate this is going to turn out that Snowden was an electronic intruder on government payroll.  His last job was working at an NSA threat detection center, suggesting knowledge of computer security.  He previously worked for the CIA, including overseas, suggesting a cyber offense role."



STEVE:  I guess I just wonder, that seems like kind of more of a big deal than we have been led to believe.  But he was also stationed in Hawaii, which sort of seems like, okay, why was he out there and not, like, at the mothership?



LEO:  Pacific intercepts?  I don't know.  I truly think that he probably - that they're downplaying his role.  The federal government wants to downplay his role.  It's in their interest.  I think it's fascinating.  Anyway...



STEVE:  I do think that the guy, I mean, I watched that first introductory video of him several times.  And he's clearly no dummy.  I mean, many of the talking heads and the politicians have gone out of their way to paint him as a high school dropout.  And it's like, well, folks, Jobs, Wozniak, and Gates all dropped out of college.



LEO:  The best hackers are, that's right.



STEVE:  So, yeah, okay.



LEO:  Yeah, that's not a - no strike against him.  So let's get into it.



STEVE:  We've got news.



LEO:  We've got questions, but let's get into the news, yeah.



STEVE:  So actually it's this article I wanted to share with our listeners, about the first half of it.  Declan's article that I quoted from has the headline that - it actually leads into next week's topic nicely, and many people have picked up on variations of this.  And the title of his piece was "Facebook's outmoded web crypto opens door to NSA spying."  And then the subtitle was:  "It's relatively easy for the National Security Agency's spooks to break outdated web encryption after vacuuming up data from fiber taps, cryptographers say.  But Facebook is still using it."



Okay, now, it's absolutely unfair to point at Facebook because most people are still using it.  So, first of all, that's the first - I guess Facebook being Facebook is a target.  Maybe it makes for a better headline.  But the fact is very few people have yet moved their public key length up to 2048.  Most, I think, are probably still back at 1024.  And that's essentially the substance of this.



But there's some interesting details here.  He says:  "Secret documents describing the National Security Agency's surveillance apparatus have highlighted vulnerabilities in outdated web encryption...."  Now, okay.  It is certainly noteworthy, though, that the documents that Snowden released are highlighting these, meaning that this is certainly not falling on deaf ears back in Virginia.



So, he said, "...highlighting vulnerabilities in outdated web encryption used by Facebook and a handful of other U.S. companies."  Okay, it's a very large handful, as I said.  And then there's the paragraph that says, that I mentioned before:  "Documents leaked by former NSA contractor Edward Snowden confirm that the NSA taps into fiber optic cables upstream from Internet companies and vacuums up email and other data that flows past - a security vulnerability that HTTPS web encryption is intended to guard against.



"But Facebook," and he says a few other companies, but I don't think that's accurate, "still rely on an encryption technique viewed as many years out of date, which cryptographers say...."  Well, for example, all of Google's certificates are 1024, and they've got more than anybody else.



LEO:  Oh, well.



STEVE:  "[F]ew other companies still rely on an encryption technique viewed as many years out of date, which cryptographers say the NSA could penetrate reasonably quickly after intercepting the communications."  And this will be the topic of next week.  We're going to delve into the - back into the security setup protocol of SSL/TLS in order to look at this question of what can you get knowing what from captured communications, and how does the so-called "perfect forward secrecy" help to prevent that.



So it says:  "Facebook uses encryption keys with a length of only 1024 bits, while web companies including Apple, Microsoft, Twitter, Dropbox, and even MySpace have switched to exponentially more secure 2048-bit keys."  And so, okay, there's a handful who have, but they've only done so recently because this is only recently - essentially, this is another side effect benefit of the fact that certificates are expiring constantly.  Remember that they only have a one, two, or three-year life; EV certificates only a maximum of two years.



So I've grumbled about that in the past, saying, well, it's a pain in the butt, and it's expensive because basically you're just continually shelling out cash to the people who are signing your certificate to say yes, we've proven yet again that you are still you.  The flipside is that this deliberate expiring of the certificates does allow for this kind of rolling upgrade.  That is, if at a certain time processing power has increased to the point where a 2048-bit certificate is no longer considered burdensome to use in establishing a connection, well, then, let's get that.  I mean, you could still ask for 1024.  In some cases it's believed to help with compatibility.



But everyone now is using 2048.  And, for example, GRC is.  I was at 1024 until just the holidays, when I replaced all the servers and updated everything.  So this is really just sort of happening.  We're in the cusp where we're beginning to switch over.



And continuing from the article:  "Eran Tromer, an assistant professor of computer science at Tel Aviv University who wrote his 2007 dissertation on custom code-breaking hardware, said it's now 'feasible to build dedicated hardware devices that can break 1024-bit RSA keys at a cost of a million dollars per device.'  Each such dedicated device would be able to break a 1024-bit key in one year, he said.



LEO:  [Laughing]



STEVE:  Okay, so, yeah, exactly.



LEO:  Okay.



STEVE:  Now, this is something that scales, though.



LEO:  Right.



STEVE:  So $10 million...



LEO:  So for a hundred million you could do it in three days.



STEVE:  Yeah, well, exactly.  Exactly.  Perfect.  So realistically, quoting still:  "'Realistically, right now, breaking 1024-bit RSA should be considered well within reach by leading nations, and marginally safe against other players,' Tromer said. 'This is unsatisfactory as the default security level of the Internet.'"  And that's really true.  It is time to give up 1024-bit keys, especially given the fact that we recognize security as a function of how much you want to break it, and unfortunately there's very little doubt anymore about what the interest is in breaking security.



LEO:  Well, one could presume that this Utah data center would have one half billion dollar custom ASIC facility that would crack the stuff in less than a day.



STEVE:  This next line, yes, the next line in the article is "The NSA's budget is estimated to be at least $10 billion a year."



LEO:  Yeah.



STEVE:  So they'll have to put up their walls and put up their power plant and buy their 5ZB of storage.  But then they're going to say, okay, wait a minute, let's start building cracking boxes.



LEO:  We need one of these.



STEVE:  And we have to assume...



LEO:  It's on the list.



STEVE:  Yeah, we have to assume.  And in fact I tweeted maybe three weeks ago, I made a tweet that was sort of prescient in this regard.  It said something like "Capture everything.  Brute-force decrypt selectively."



LEO:  Yeah.  And presume that, in time, you'll get the capability to break other stuff.



STEVE:  Yes, yes.



LEO:  And that's why they're saving the PGP, Tor, and all that stuff because they figure, well, we can't crack it now.  Now, if you go to 2048, that's more than doubling the amount of time.  That's exponential; right?



STEVE:  Oh, whoa, whoa, Leo, it's exponentially more difficult, yes.  It's like, okay, now we're in a whole new ball game.  Continuing:  "Facebook declined to comment on this article."  And I don't, I mean, what could they say?  Okay, well, we're not alone is what I would have said, but maybe just "no comment" is better.  "A person familiar with the company's encryption development plans, however, said the social network is working on switching over to 2048-bit relatively soon.



"Encryption that's used to shield the privacy of web browsing is known as RSA, a form of public key cryptography based on the fact that it's immensely difficult to factor large numbers.  As microprocessor speeds continue to advance, however, RSA keys with lengths that were previously viewed as secure have fallen to brute-force attacks."  And that's really the meat of this article.  It goes on to talk about previous cracking and lengths and so forth.



But, so essentially, I guess I would walk back the screaming headline a little bit and say that, not just Facebook, but Google and many other companies who are using 2048 - sorry, still using 1024-bit keys, only because two years ago or three years ago that seemed fine.  Well, I imagine everybody will be moving now as their keys expire.  And in fact I did see, I think it was Adam Langley quoted here.  He's a neat guy.  He and I corresponded, I mean, he's literally maintaining the source code of the security side of Chrome.  And it was with Adam that I exchanged email when I wanted GRC to be built into Chrome's SSL-only list so that Chrome will refuse a non-SSL connection to GRC.  I think it was here.  Oh, yeah, here.



"Langley, the Google software engineer, said his employer could devote some of its massive computing" - oh, this is not what I wanted to read - "could devote some of its massive computing resources to breaking a 1024-bit RSA key, if it chose to do so."  Okay, well, thanks for that.  He says:  "'It could be done today.  We could do it if we really wanted.'  But, he adds, there are better ways to spend millions of dollars in a way that will 'advance the state of the art of cryptography research.'"



And actually we'll be talking a little bit about that later.  I'm sure in this article Langley was quoted as saying of Google that - oh, yeah, here it is.  He said - oh, here.  "Google also uses 1024-bit keys, but in 2011 it implemented a clever trick called 'forward secrecy,' meaning a different key is used for each encrypted web session instead of a single master key that's used to encrypt billions of them."  Okay, and that's not quite true because it requires cooperation.  So we'll be talking about that.



"The company said last month it will switch over to 2048-bit keys by the end of this year."  And we've already spoken previously about Google's early warning of their intention to do so, and that in that move of going to 2048-bit keys, remember that they said do not use certificate pinning, as it's called, where you're locking on to specific certificate serial numbers.  Those are going to break.  Do not assume we're going to be using the same hierarchy of signing.  Do not assume we're going to be using the same certificate authority as our root, and on and on and on.  I mean, basically, anyone who's not been playing by the rules to take shortcuts, get prepared to be unhappy because we're going to change everything.  So we know that that's happening.



And now, says Adam:  "'We would have preferred to move sooner; but, operating at the scale we do, client compatibility is always an issue.  Everything on the planet seems to connect to us.'  Langley added:  'We would have totally eaten the cost and the speed years ago if we could have done it without worries.'  As an additional precaution, Langley said, Google usually rotates its RSA keys every two weeks."  And it says in parens here:  "(Facebook does it once a year, and is also planning to make forward secrecy a default for users, which few other companies do.  Once Facebook switches to 2048-bit keys and forward secrecy, its users will be better protected against NSA surveillance than almost any other company.)"  And that's of course only true until everybody else catches up.  So, interesting little piece.  And I thought that needed some clarification.  And it will, it gives us a little built-in tease for next week's techie topic.



LEO:  Good, good, good.



STEVE:  There was another one I thought was interesting, Dan Goodin, who we've also often covered, writing for Ars Technica.  The headline was "How the U.S. (probably) spied on European allies' encrypted faxes."  A bunch of our listeners picked up on this and made sure I was aware of it.  And the subtitle here was "Grainy image stokes speculation of old-school, Tempest-style attack."  And since this feeds into the concept of side-channel attacks, and we've talked about this sort of Tempest stuff before, I thought this was fun.



From the article, Dan writes: "U.S. intelligence services implanted bugging tools into cryptographic facsimile devices to" - oh, and by the way, the EU is really unhappy about this news - "into cryptographic facsimile devices to intercept secret communications sent or received by the European Union's Washington, D.C. outpost, according to the latest leak from former National Security Agency staffer Edward Snowden.  Technical details are scarce, but security experts reading between the lines say the program probably relies on an old-school style of espionage that parses electric currents, acoustic vibrations, and other subtle types of energy to reveal the contents of encrypted communications."



Remember we've spoken of many things like this once.  There was some question of the lights blinking on router switches, someone claiming you could read the traffic off of the blinking light.  There have been experiments about, like, recognizing what people were typing just by listening to the sound of the keystrokes on the keyboard because there's something, keys are individually distinctive.  And so once you - if you recorded enough of a single keyboard being typed on, then ran that through frequency analysis of the language in which it was being typed, you could discern which was the E, the T, the S and so forth, and then begin to figure out what they were doing.  So it's all very fuzzy, but arguably better than nothing, again, if you are really determined, and you have a lot of money and time to figure this out.



Anyway, continuing:  "The bugging method was codenamed Dropmire, and it appears to rely on a device being 'implanted on the Cryptofax at the EU embassy in D.C.,' according to a 2007 document partially published Sunday by The Guardian.  An image included in the document, presumably taken from a transmission traveling over a targeted device, shows highly distorted text that can just barely be read by the human eye as the letters 'EC,' followed by 'NCN.'  The fax device was used to send cables between foreign affairs ministries and European capitals, according to Sunday's report."



And then later down in the article, this is the line that I loved:  "Markus Kuhn, a computer scientist and senior lecturer at Cambridge University, wrote in a blog post published Monday," so two days ago, "'Having done many experiments to eavesdrop on office equipment myself, the noisy image at the bottom third of the sample picture looked instantly familiar.'"  Oh, I just get goose bumps when I read that.  It's like, oh, I mean, that's exactly what you would think.  An independent academician has done this, too.  And when he looks at what that is supposed to be in the lower portion, he says, yup, that's exactly what you would get from this technology.



And continuing Markus's quote, it says:  "'It is what you might get from listening with a radio receiver on the compromising emanations of a video signal from a page of text.'  Three security experts Ars spoke with agreed with Markus's analysis.  They said it makes a strong case that the attacks targeting the EU encrypted fax devices were relying on what's known as side-channel attacks, which target weaknesses in a specific cryptographic implementation rather than the underlying cipher or mathematics it's built upon."



So this is another - it's a classic instance of the cryptography is not the weakness, the system is the weakness.  And since the system involves at some point preencrypted plaintext, if it emits radiation or sound or light that in some way represents what you're sending prior, you know, like when it's being digitized, when it's being scanned, and if you can capture that - and there's going to be noise, there's going to be background noise, all kinds of interference.  But if you can find the signal in the noise, that is, if the signal-to-noise ratio is such that you can extract it.  And again, we're very good at doing that.  We solve CAPTCHAs, god help us, that computers can't because we're good signal-to-noise discriminators.  So anyway, really interesting piece, I thought.



Just in other little quick news, Ubisoft has lost their password database.  I would imagine, I got a lot of tweets from people saying, hey, just got a letter from them...



LEO:  Now, we should - I'm going to say this real quickly.  This is not YubiKey, this is a game company called Ubisoft.



STEVE:  Good.



LEO:  Because it's an audio podcast, people might...



STEVE:  Thank you.



LEO:  And we talk a lot about YubiKey.  That's not the Y-u-b-i, this is U-b-i soft.



STEVE:  Right, yes, good.



LEO:  It's a game company.



STEVE:  Thank you, Leo.



LEO:  Yeah, yeah, because Stina would be mad if we...



STEVE:  Yes.  They posted:  "Hello All" - and we don't want Stina to be mad.  Now she lives nearby.  "Hello All.  We recently found" - this is Ubisoft.  "We recently found that one of our websites was exploited to gain unauthorized access to some of our online systems.  We instantly took steps to close off this access, to begin a thorough investigation with relevant authorities, internal and external security experts, and to start restoring the integrity of any compromised systems.  During this process, we learned that data were illegally accessed from our account database, including usernames, email addresses and encrypted passwords.  No personal payment information is stored with Ubisoft, meaning your debit/credit card information was safe from this intrusion.



"As a result, we are recommending you to change your password."  And then in the blog posting, "Click here to change your password.  Out of an abundance of caution, we recommend that you change your password on any other website or service where you use the same or a similar password."  And I would argue that that's now become de rigueur.  It's standard operating procedure, first of all, not to use the same password across multiple sites.  But certainly, if you learn that on one site there's been a problem, then the argument is you really need to change it everywhere and take that opportunity to use a different password on different sites.



There was a slide that was actually tweeted to me.  And Leo, you might want to bring that, click that link...



LEO:  Sure.



STEVE:  ...and bring up the image because it's interesting.  I asserted, back when I was talking about my theory for PRISM, that the problem was - the argument, for example, about why would tapping Google help, because all Google Gmail browser access is going to be over SSL.  Well, unfortunately now we know that it's over 1024-bit SSL through the end of the year.  But my point was that SMTP itself, the protocol, is almost never encrypted.



Well, it turns out that people have been looking into that since.  And of the four major web-based mail providers - Google, Hotmail, Yahoo!, and AOL - only Google offers SMTP server-to-server encryption.  So that makes my case.  Essentially, if email goes anywhere, that is, to any - since encryption has to be supported at each end, then Google to Hotmail, Google to Yahoo!, Google to AOL, and any other combination of that, will always be decrypted.



LEO:  But Gmail to Gmail would be safe.



STEVE:  Well, yes.  There's an interesting question about General Petraeus's strategy in communicating...



LEO:  He blew it.  If he's just stayed within Gmail he'd still be the Chairman of the Joint Chiefs of Staff or whatever the hell he was, yeah.



STEVE:  Yeah.  So Google to Google, if we assume that they transit on the public Internet over SMTP between data centers, I mean, we know very little about Google's internal infrastructure.  But essentially, only if it was Google to some other server also supporting secure SMTP, would they negotiate security after establishing a connection.  But, for example, no Hotmail, no Yahoo!, no AOL email would ever meet that level, and neither sending nor receiving to or from a Gmail user.



So today, unfortunately, there's still lots you can get from tapping a fiber optic link.  Even though a lot of traffic is encrypted, once it emerges, it will be decrypted for you.



LEO:  The good news is more and more people are using Gmail.



STEVE:  Yes.  Yes, right.  So Gmail to Gmail is probably going to be...



LEO:  I'm sure that stays within the Googleverse.



STEVE:  I would think so.  And a couple, just as a further sort of random follow-up to my talking about PRISM a couple weeks ago, a number of people said, well, wait a minute, you know, Facebook, you're always staying in Facebook.  So when you go to Facebook, I mean, Facebook's brought up security.  Assuming that you're browsing in Facebook and posting in Facebook, then all of the data is secure.  Well, except anything coming out of Facebook mail-wise is not, or going in is not.  But more importantly, and this is significant, I believe the slide that we saw with that weird-looking timeline, kind of a green arrow with yellow ovals on top of it, what I remember making a note in my mind was that Facebook was added in '07.



Well, the point was Facebook, as we know, only very recently, it was last year in 2012, got serious about HTTP security.  They were only being secure during logon, thus the reason that Firesheep was such a problem for them, because their insecure token was being sent back and forth, and we were immediately seeing all these Facebook users pop up.  If you fired up Firesheep at Starbucks, that's what you saw was Facebook profiles.  So this is an interesting point because the FBI has referred to often the "going dark" problem, as they call it.



So what we have is a situation exactly like that, where a substantial amount of time and effort and money and trouble was invested in '07, if we're right about what PRISM is, in tapping Facebook and as establishing fiber optic taps into the Facebook data centers.  And back then it was a treasure trove because all of the pages, except for login, were in the clear.  Well, the NSA could not have been happy when Facebook did what was a benefit for its users last year, which was to get serious about SSL and first offer the option, and then switch it to default, which of course is where we are now.



So it is unarguably the case that that tap that was good for five years has largely gone encrypted, which doesn't mean they're not still sucking stuff in, but it's not as easy as it was before.  So my point being this is a moving target.  And they got five years of data.  Maybe it did them some good before Facebook said, well, I think maybe we should be encrypting.



LEO:  I have to think that anybody who's doing seriously bad things at this point is not trusting Facebook to communicate with their cells in the United States.



STEVE:  Yes.  Yes.  Although...



LEO:  Seriously.  Come on.



STEVE:  ...from a metadata standpoint, all of this adds up for, like, networking.  For example, you might have a network of bad guys talking about their favorite sandwich meats...



LEO:  Right.



STEVE:  ...on Facebook, and then doing all of the - being sneaky when they talk about anything that involves bad stuff.  But their network has still been established using metadata to link them together when they had their guard down.  So it's still useful.



LEO:  They never have their guard down.  All you have to do is look at "Zero Dark Thirty."  Osama bin Laden was living in a compound where there was no Internet access at all.



STEVE:  Right.



LEO:  He knew.  Why do you think they live in caves in Tora Bora?  They know Internet access is a bad idea.  They ain't using Facebook to - I firmly believe the government doesn't do this to capture terrorists.  They do it because it's a great way to get even.



STEVE:  Leo, they do it because they can.



LEO:  They can.



STEVE:  Yeah.



LEO:  Useful.  And I'm not convinced it's of any help in fighting the real bad guys.



STEVE:  Well, and the arguments that Udall has been making is that for years in the oversight committees they were pressing the intelligence services to demonstrate that they succeeded with the program, and they were unable to.



LEO:  No, of course not.  They do it because they can.  You're exactly right.



STEVE:  So, yeah.  So you hear these, you know, on the Sunday shows, oh, it's foiled countless plots.  Well, wait a minute.  Oh, and I love it, too, when they say, oh, but the number is classified.



LEO:  We can't tell you.



STEVE:  What do you mean?  Why can you not tell us what number, how many?



LEO:  But it's a large, large...



STEVE:  Yeah, yeah, yeah.



LEO:  I just read an article, a blog post by a law professor who estimates that we break three federal laws, everybody breaks three federal laws a day because the federal laws are so broadly written and stupidly written, particularly in electronic communications and so forth, that we - everybody.  And so they're collecting all this.  And if they ever should, heaven forfend, decide they don't like somebody, they've got plenty of ways to go after them.



STEVE:  Well, I just - when I heard the intelligence guy say, well, a great many plots have been foiled, but the number is classified, it's like, what?  A number is classified?  What, 34?  27?  42?  How can a number be classified.  Anyway...



LEO:  No.  Because the number is zero, is why.



STEVE:  Well, and the point is, because we don't have to tell you.  We will not tell you anything we don't have to tell you.  So it's like, oh, okay, fine.  Now, okay.  I don't get this.  This seems like the strangest thing ever.  So we'll try to figure out - I've got two topics under the category of Browser Watch.  The first is Firefox v23, which, by the way, is the next biggie, slated for next month, August.  This is the one I've been waiting for because, what was the phrase, "God willing and the creek don't rise," I think?  They're going to be, Firefox will be disabling third-party cookies by default.  But something else happened in the v23 development channel which really sparked off a firestorm.  They have removed the checkbox to disable JavaScript, and they reenabled JavaScript if it was previously disabled.



LEO:  That's cold [laughing].  That is cold.



STEVE:  Wow.  So updating to v23, the next one, because I just got 22, and I restarted the browser, silently enables previously disabled JavaScript - no warnings, no pop-ups, no notices at all - and removes the ability to disable it from the UI.  So this caused a big ruckus.  And, I mean, it's like, what?  What?  Huh?  And as you can imagine.  So the argument seems to be that sophisticated users are sophisticated.  So they will know what to do.



Then the counter argument, of course, is wait a minute, but if they turned it off, they would expect it to still be off.  It's been silently reenabled.  Then the response then is, well, about:config, and then you dredge around in about 20,000 configuration settings.  You use the search because you have no other choice.  And somewhere you will find JavaScript:enable, and you change that from a one to a zero.  But of course that's not user-friendly because it's not in the UI.



So then the argument comes back, well, there are much better tools available - in other words, NoScript, and NoScript is referred to by name in this back-and-forth in the text of this discussion.  So if people want to turn JavaScript on and off, that's what they should use.



So I quoted two paragraphs here from this discussion:  "The ability to share your experience, including turning off JS, is offered in many different ways."  I'm sorry, "the ability to shape."  I think I said "share."  "The ability to shape your experience, including turning off JavaScript, is offered in many different ways.  Not everything needs to be in the primary browser UI.  We did not actually remove a choice, just reduced the visibility" - like, to nothing - of that particular choice.  That does not go against either of these principles in the manifesto."  And then they said, again, quote, a little bit lower, "Note that, if we removed the preference from the UI, but left JavaScript disabled, this would make life really hard for non-expert users" - and I'll add parenthetically who were expert enough to turn it off, apparently - "that accidentally changed this..."



LEO:  You know, if you were told, turn off Java, and you hit JavaScript, and then the web broke, I can see that's not an unusual circumstance.  Some of this may be just to avoid tech support calls, you know.



STEVE:  Actually, that's exactly - there was an argument in there that the IT people will be happy because they get tech support calls when people turn off JavaScript, and then things break and don't work.  So anyway, for what it's worth...



LEO:  I think that's not unreasonable.  We're smart enough to know, oh it's turned on.  Or use NoScript.



STEVE:  And it is the case that, well, okay, first of all, you're not using IE.  So you've made your first big step towards...



LEO:  Right.  But again, a lot of people do this stuff because they hear people tell them, oh, you've got to use Firefox, and don't forget to disable Java.  And then they disable JavaScript.  The web is broken.



STEVE:  Good point, good point.



LEO:  I think that that's not...



STEVE:  I mean, you have to argue, I mean, your argument is sound, and that is that there's a big ambiguity between Java and JavaScript.



LEO:  Right, right.



STEVE:  So much so that people thought one is a scripting version of the other, which we've disabused everyone of.



LEO:  Is Java turned off by default?



STEVE:  Versioning is definitely verified now.  I don't remember whether it's off by default.



LEO:  And Web8013 makes a very good point, that you shouldn't just turn something back on by default because that's not appropriate either.



STEVE:  I know.  Give them a popup and say, hi, we noticed that in moving from 22 to 23 we are removing this from here.  We moved it over there.  And by the way, how do you want your new default to be?



LEO:  Right.  That would be fine.



STEVE:  Yes.  No one would argue with that.



LEO:  Although, again, confusing for Grandma or Grandpa.  And that's the problem.



STEVE:  Good point.  And now they're doing silent updating.  So it's like, wait, whoa, whoa, whoa, what are you doing, updating my browser?



LEO:  Huh?  But to silently turn back JavaScript, turn JavaScript back on if someone had turned it off, it does seem like...



STEVE:  I think that's wrong.



LEO:  That doesn't seem right, yeah.  Okay, I just wanted to mention, somebody in the chatroom said that Doug Engelbart has passed away.



STEVE:  Oh, wow.



LEO:  Yeah.  88 years old.



STEVE:  Oh, well, he had a good run.



LEO:  It's a great run.  The inventor of the computer mouse while he was at SRI.  I remember interviewing him on The Screen Savers 10 years ago, and just a legend.  So, yeah.  Just thought I'd mention that.



STEVE:  Second browser update is, okay, I don't think this is going to turn out well, but it'll be interesting to see.  Chrome is experimenting with a new protocol that Google has put together called "QUIC."  We are to pronounce - it's an acronym which we are to pronounce "quick," of course, stands for Quick UDP Internet Connections.  Quick UDP Internet Connections.  And I'll just read briefly from Wikipedia, since there's already an entry there, and I have not gone into it for a deep dive, although I expect I will because that's what we do here.



"QUIC supports a set of multiplexed connections between" - connections, remember, that's an important word because UDP is a connectionless protocol.  TCP is a connection-oriented protocol.  So what essentially they're doing is TCP over UDP, which is - and therein lies a story.



"QUIC supports a set of multiplexed connections between  two endpoints over User Datagram Protocol (UDP) and was designed to provide security protection equivalent to TLS/SSL, along with reduced connection and transport latency, and bandwidth estimation in each direction to avoid congestion.  The protocol handles packet loss well.  Besides packet-level forward error correction, QUIC aligns cryptographic block boundaries with packet boundaries, so the impact of packet loss is even lower."  I mean, these are all really exciting things.



"QUIC also allows higher level application protocols, such as SPDY, to reduce or compress redundant data transmissions, such as headers.  One of the motivations for developing QUIC was that in TCP the delay of a single packet induces head-of-line blocking for the entire set of SPDY streams; QUIC's better multiplexing support means that only one stream would pause.  As improving TCP is a long-term goal for Google, QUIC aims to be nearly equivalent to an independent TCP connection, but with much reduced latency - goal is zero roundtrip time connectivity overhead - and better SPDY support.  If QUIC features prove effective, they could migrate into a later version of TCP and TLS."



So, okay.  So my misgivings are that UDP connections are so different from TCP connections.  They're different with proxies, which won't pass UDP, but do pass TCP.  They're different with firewalls, same goes.  They're just - it's very different.  Also there is so much technology which has been built into TCP over time, incrementally and carefully.  Now, it's all open, public domain open source.  So the guys who were wanting to implement the critical aspects, retransmission and queuing and rate management and buffer, we've talked extensively about buffer bloat and so forth.  They can take all the lessons learned.



And it is the case that the problem with TCP is remember that it guarantees in-order delivery.  The exact sequence in which you put things into your end is guaranteed to come out the other end.  Well, that means that, if a packet gets lost along the way, then the other packets that are in - that have already been sent in send-ahead, they will start being saved at the receiving end.  And when the receiving end doesn't acknowledge the packet that was lost, the transmitter, the transmitting end, which has been saving up these packets it's sending until it gets the acknowledgment, it will resend the lost one.



Well, so that does stall the entire flow.  And if you've got multiplexed connections over a single connection, TCP connection, they all get stalled.  And also the idea of aligning encryption boundaries with packet boundaries is brilliant because you cannot do that in TCP because there's no notion of packets in TCP.  In TCP, the application simply sends a stream out.  There's no packet-level awareness.  But that's not the way UDP operates.  The application itself generates and sends individual UDP packets.  So it can explicitly align the encryption boundaries with the packet boundaries.



So anyway, really interesting.  And I guess I wonder a little bit about what the gain will be because remember that modern TCP there is some overhead, the whole - the triple handshake roundtrip and then some - it starts slow, and it ramps its speed up in order not to immediately over-congest the connection, so it sort of - it feel its way forward.  All of that happens per connection.  And a browser will normally look like an octopus, sending connections out all over the place if it's populating its page with ads, for example, from far and wide.



And boy, when I look at what NoScript, sometimes I'll go to a site, it's like, okay, I need to enable scripting here, and I look at the amazing list of sites that are being blocked, it's often like 25 or 30 different places that have - they're all wanting to get their scripting into this page.  I just think, okay, it's nice, if nothing else, to know.



So anyway, it'll be interesting to see how this develops.  Google will always err on the side of caution.  So it may be that they will - their servers will support QUIC.  Chrome will support QUIC, but fall back to TCP, obviously, if it can't establish a QUIC connection.  And then they'll see, they'll do big studies and statistical analysis and figure out where there are problems and where it's working, and they'll move forward if they can.  So certainly from a techie standpoint I'm intrigued by this.  And if more comes of it, we will certainly understand it all on this podcast.



A little bit of errata, one piece:  Last week, when everyone's propellers were wound up, I was talking about sector sizes and said that the sector count was five bits.  Well, of course I know better than that.  It's six.  Somebody said, eh, Steve, you got your math wrong.  It's like, oh, duh, of course.  Five bits is 32.  Six bits is 64.  So just to correct the record.



LEO:  Of course.



STEVE:  Now, Leo.



LEO:  Yes.



STEVE:  I am 64% of the way through Stephen King's "Under the Dome" novel.



LEO:  And you know that because you read it on the Kindle.



STEVE:  I know that because I look down.  Yes, I read it on a Kindle.  I actually read.  I'm not having it read to me.  I am reading it myself.



LEO:  Wow.  How ambitious.



STEVE:  And, boy.  It's funny, my favorite quote was, "Hard as this novel is to put down, it's even more difficult to lift up."  Not on a Kindle, of course.



LEO:  No, yeah.  I can only imagine.



STEVE:  But I guess in the pulp, in the wood pulp version, this thing I guess is monstrous.  I am really loving it.  And I have to say I tweeted, I guess it was yesterday or the day before, I read through a really chilling part.  And Stephen King has a message here.  I strongly doubt it's going to come through in the TV version.  First of all, the TV edition, as always is the case, is so inferior to the novel.  I mean, people are doing ridiculous things on TV.  And it's sort of fun to see the characters that have been chosen for the characters in the novel.  Essentially the only thing that is carrying over from Stephen King's novel is the concept of being under a dome.



LEO:  Yeah, yeah.



STEVE:  And the roles of some of the characters very roughly, the names.  I mean, but it's radically different.  So, I mean, actually I'm going to stop watching the TV series.



LEO:  Yes.



STEVE:  Because it's too confusing for me to say, wait a minute, Rose didn't do that.  Oh, that's right, that was in the novel and not in the TV.  So I'm going to - actually I think I'll be finished with the book by the time we speak next week because I hadn't started it when we spoke last week.  But the only little takeaway, and the thing that prompted my tweet, was the observation that people give up freedom in time of fear.



LEO:  Yeah.



STEVE:  And we gave up freedom after 9/11.



LEO:  Yup.



STEVE:  Because fear was stoked, and present, also, but stoked.  And those who had a reason to want more power obtained it during the window.  And, I mean, Rahm Emanuel was quoted famously as saying, "Never let a good emergency go to waste" or something to that effect.  I mean, use these things.  And that's what politicians do.  And so I feel very much like Stephen King has created a microcosm with authority, outside authority cut off.  And then he watches what happens inside.  And it is really interesting.  I mean, I'm loving the book.  I can't put it down.



So I don't know, for people who are interested, you know, people - I saw criticism, I don't know if it was of the book or the movie, that people were not acting in a reasonable way.  Well, it's absolutely true in last Monday's episode.  One of the sheriffs just went off the deep end.  It's like, what?  I mean, it was ridiculous.  And, well, I can't say anymore without spoiling.  But anyway, so that isn't in the book.  I'm very pleased with the behavior of the people in the book.  And in fact one of the things that Stephen King is known for is building really understandable people.  And, Leo, this doesn't often happen, I'm encountering words I don't know.  I ran across "commodious."



LEO:  Yeah.



STEVE:  And I thought, what?  He was in the backyard, and she had a - I think it was...



LEO:  Commodious kimono?



STEVE:  No, a commodious backyard.  It means roomy and comfortable.



LEO:  Yes.



STEVE:  And it refers, like as in furniture, or like a commodious couch, or a building could be commodious.  And then this morning was "comestibles."



LEO:  Oh, yeah.  Food.



STEVE:  And it's food.



LEO:  Yeah.



STEVE:  And I thought, okay, wait a minute, maybe Stephen is reading through the entire dictionary, and he happened to be...



LEO:  He's a literate guy.



STEVE:  He happened to be in the C's.  I mean, "commodious" and "comestible," and those are the two words I have never seen before?  It's like, okay, wait a minute.  He happened to be in the c-o-m section of the dictionary he was reading when he was writing this.  He thought, oh, I'll just drop "commodious" in here, and "comestibles."



LEO:  This is - you had never read any Stephen King before.  Is that right?



STEVE:  No.  No, I haven't.



LEO:  I think you'd like his other stuff.



STEVE:  Yeah, well, and he's advertising on the show "Dr. Sleep" or something.  Looks very creepy.  Something about...



LEO:  Yeah, I know that.



STEVE:  ...somebody's demons, they were with him when he was young, and he grew up, and so did they.  It's like [voice shiver], okay.  Okay.  So Simon Zerafa, our frequent contributor, offers - he's been throwing out all kinds of attempts at NSA humor.  And one really landed well.  So I thought I would share that one.  He said, so the same NSA guy, our NSA guy who has his favorite bar, he walks into his bar and orders a beer, says "I want a beer."  The bartender asks, "Domestic or imported?"  NSA guy says, "What's the difference?"  So I liked that.



LEO:  Oh, I get it.



STEVE:  Okay.  Not as good as the first one, but...



LEO:  No, I get it.



STEVE:  You should have seen the other ones.  Anyway, no.  So Kevin in New York, I'll share this briefly, says "SpinRite fixes an old 1GB flash drive."  And actually there's a lesson here for our listeners that I wanted to share.  He says, "In testing how well SpinRite can work on flash memory, I tried it on an old 1GB Sony MicroVault flash drive.  Basically, the issue was corrupting data, e.g., placing any large file on the flash drive would cause the checksum to come back differently.  It was no longer reliable.  So I decided to run SpinRite on the flash drive using Level 4 since I didn't care if it killed the drive since it is slow, and" - I love this phrase, I just, like, roll over in my, not yet in my grave - "and 1GB is no longer very useful."  Okay, what land do we live in now where 1GB would...



LEO:  It comes in a cereal box, that's right, yeah.



STEVE:  ...no longer be useful.  Anyway, so - and the point of Level 4, of course, is that it inverts the data, reads it back, inverts it again, writes it and reads it back to verify it, doing like essentially a full refresh.  And that's controversial on non-spinning mass storage because non-spinning mass storage is known to have a write-cycle life.  Anyway, so he says, "Anyway, running it on Level 4 COMPLETED FIXED," in all caps, "the checksum issue, though SpinRite reported no trouble, and I can now copy a large ISO" - see, that's useful - "file to the flash drive..."



LEO:  That's true.  For a CD, not a DVD.



STEVE:  For a CD, yeah, "...with no problem.  I still do not trust the flash drive for anything important" - that's wise - "but it was interesting to try it and see what it would do with the flash drive."



Now, I wanted to walk back a little bit the prohibition about SpinRite on solid-state storage at anything more than Level 1 or 2 because, okay, it's just two writes.  It writes it upside down, then it writes it back right side up.  So it's like, yes, you don't want to do it continuously.  You don't want to put your swap file on a flash drive.



LEO:  No, yeah.



STEVE:  Where the light's constantly blinking on your hard drive.  But if you want to, like, do a better job of cleaning up a drive which is a little dodgy, and/or maybe if Level 1 or 2 doesn't fix the problem, it's not like Level 4 is going to just fry it, I mean, just because SpinRite's got superpowers or something.  It's just all it's doing is writing it all upside down, then right-side up.  All the ones become zeroes and zeroes ones, and then vice versa to put it all back.  And that's what this drive needed.  So that was cool.



I just thought I would give a little weekly update on the progress on the next version of SpinRite, since sales has not been killed.  I really thank our listeners for that, especially because everybody who is buying it will all get 6.1 for free.  Last podcast was of course about the weird anomalies in the Intel architecture that allowed large access, 32-bit access in real-mode, which is normally limited to 16 bits.  That's all implemented.  It's all working now.



I now have a completely mature, built-in memory manager, extended memory manager in SpinRite, which is able to go out and explore all of high memory.  It maps out all of the regions because there's various weird little chunks that are taken out with the goal of finding for itself 32MB to establish a maximum size transfer buffer because all of our new drives are able to transfer 64K sectors in a single burst, so SpinRite will be able to do that also.  It's also compatible with external memory managers.  If you've already got an extended memory manager, it'll see that and use that instead.



And next on the list - and this is all just finished yesterday, we got everything wrapped up and tested.  Next is it's also completely enumerating the PCI bus, finding all of the disk controllers of every type that there are.  However, there are three types.  And it will only be able to work in super high-performance mode with one of the three, that is, the so-called "native PCI mode."  You could have your controllers in compatible IDE mode, which doesn't give access to all of the upper memory regions, or in AHCI mode, which is the Advanced Host Controller Interface.  That's the next-generation, super-advanced one.



The good news is, from what we've seen so far with, like, one exception in a hundred people and many hundreds of systems this has been run on now, SpinRite, I'm expecting, will be able to change the controller into the mode it wants.  All of, like, for a long time any of the advanced ones have always been able to be set back to this native PCI mode.  So that's the next round of work we'll be doing, and I'll have an update on that next week.



LEO:  How exciting.



STEVE:  Yeah.  Oh, and there have been some people who are really anxious for the Mac version and have been asking, like, for a pre-release version that runs on their Mac.  Where I'm really going is to support UEFI booting, which would allow USB sticks, USB drives to boot by holding down the Option key at boot time.  That's still a ways away.  But the much easier solution is the way people have been using SpinRite with limited success because of the keyboard problem, and that's on a CD.  You can hold the "C" key down, meaning "C" for CD, and the system will boot in a PC-compatible mode from the CD.  And that I think we'll have pretty soon.



My goal is to get all of this new hardware-level, data transfer, large buffer stuff written and solid, I mean, absolutely solid.  I certainly won't let anything out that would be a problem.  And then I'm going to do - my plan is to do an interim release, not 6.1, but just a development-level release, but which works and is way faster and compatible and all that.  And at that point it's already got the Mac keyboard stuff fixed.  So you could burn it on - you could take the ISO and put it on a CD and run SpinRite on your Mac.



So I think we'll have - as long as you've got a CD drive, that's my point, is that, like some of the Macs now, my Air, for example, I had to buy a CD for it separately.  So I know that older Macs, of course, do have CD drives, but some of the newer solid-state drive Macs don't.  So not long.  Maybe a few weeks, if all goes well.



LEO:  Hey, I just wanted to make a little bit of a note that Twitter has - this is something our audience would be very interested in, I'm sure, and the chatroom reminded me.  Twitter has announced that it's going to allow advertisers to target you, if you are a Twitter user, based on your activities off Twitter.



STEVE:  Ooh.



LEO:  Third-party browsing.  They'll also use email addresses to target the ads you see.  You won't see more ads on Twitter, they say, but you may see better ones.  Fortunately, Twitter has put in some opt-out boxes in your settings so you can implement Do Not Track.



STEVE:  Okay.  So what this means is that they will - the advertisers will bring their knowledge of you from when you're not on Twitter to Twitter.



LEO:  Right.



STEVE:  So that the ads you see convey that knowledge.



LEO:  And that Twitter will be giving ad partners more information about you based on what it knows.



STEVE:  Oh, goodness.



LEO:  So, I mean, this is no different than what Facebook does at this point.  But it might be something people - our audience, given, I know, their strong feelings about Do Not Track...



STEVE:  Yeah, I also saw - did you see that thing about Bing and Windows 8 or Windows Blue or whatever?



LEO:  Yeah.  Yeah, it's going to put ads in the search results.



STEVE:  It's like, oh, my goodness.  You're going to monetize my Windows search results?



LEO:  Yeah, isn't that - well, the first step was putting Bing results in your search results.  And that should have been a red flag.



STEVE:  Yup. 



LEO:  It's like, why would you do that?  Oh, now I know why.



STEVE:  Uh-huh.



LEO:  Uh-huh.  Oh, lord.



STEVE:  See, this punishes the few people who actually do upgrade because most of us are just going to stay with 7, Leo.



LEO:  Yeah.  I think that's a pretty clear message for a lot of people.



STEVE:  Yeah.



LEO:  Are you ready for questions, Steve?



STEVE:  Let's go.



LEO:  Let's go:  11 questions, thoughts, and comments.  This is Listener-Driven Potpourri #171, starting with John Shattuck, Information Security, in Washington state.  John queries:  I just listened to the thing on PRISM.  What makes you think the NSA hasn't required that Google pass along, and MSN and Yahoo for that matter, their 128-bit encryption keys?  My guess is they've been given the keys under the ask of national security, the same way they've been given or they've taken a piece of real estate to build data centers in their buildings.  Could they just say, hey, give us the SSL keys?



STEVE:  I don't know that they could not.  I mean, I think yes.  I mean, I think they, unfortunately, can compel a company to do anything they want.



LEO:  Almost anything, yeah.



STEVE:  And, now, it's not 128-bit encryption keys.  Those are negotiated on the fly.  We're going to get into this seriously next week, this difference between symmetric and asymmetric, short keys and long keys and so forth.  It's complicated, but that's - we explain that stuff here.  But...



LEO:  So they'd be 1024 keys.



STEVE:  They would be, yes.



LEO:  Or 2048 keys.



STEVE:  They would, yes.  In the case of Facebook and Google, famously, they would be there.  Basically the private key, which they never let out of their control, which is the only way we have of authenticating them, essentially, their security certificate.  I don't know that anything prevents our governments from saying it's a matter of national security, are you not patriotic, and here's a letter compelling you to give up your private key.  And by the way, we'll need you to refresh this when you change your private key.  I mean...



LEO:  Sure they have that information, actually.



STEVE:  Unfortunately, unfortunately, this is the world in which we now live.  I guess, you know, people have been saying, "Oh, Gibson, you're nave.  We've been living in this world for a long time.  What was it that Orwell wrote in '1984'?"  It's like, yes, I know.  But we've got a timeline now.  And storage has gotten so cheap, as this great EFF guy we quoted last week said, it's now so cheap to store stuff that it makes sense to store everything.



LEO:  Steve Good...



STEVE:  And, yeah - yeah.



LEO:  Yeah.



STEVE:  Sorry.



LEO:  Of course we can just presume this is happening.  Steve Good in Lexington, Kentucky wonders, do the numbers add up?  Steve, thanks for the great information on NSA's PRISM program.  I have a question.  If the spooks are splitting and duplicating the data upstream bit for bit, how much data is that?  I think we quoted a number from IBM, but I've forgotten.  We could do the math.



STEVE:  It's a lot.  It's a lot.



LEO:  How many days or months can they store in their 5ZB data farm?  I know this would require an estimate of the amount of data coming out of Google and other servers that are being tapped.  Do the numbers add up?  Can they actually store everything forever?  Not forever, no.  If they could store it all, what kind of system can search 5ZB of data in a useful timeframe?  I guess I'm trying to understand, how much is a zettabyte?



STEVE:  A number of people have been confused by this, so I wanted to come back to it briefly.  This system, as far as we know, the PRISM technology incorporates something that - a so-called "semantic analyzer."  And this is this thing, this equipment produced by Narus, N-a-r-u-s.  And we found the brochure for it that has on its second page a prism as its graphics, showing, like, what it does.  And anecdotally we've heard that the much-more expansive brochure has been removed from public access, where they're bragging about much more about what the system does.



The point is that these are like filters which can be tasked, as in giving it a task.  They can be tasked with pulling specific information from the flood.  So we don't know, we're never going to know, probably, whether in addition to that they're just pouring this into some huge sump somewhere and keeping it all, or they're saving the encrypted stuff for later.  We've verified that they feel they have the right, just on the basis of it being encrypted, that's reason enough to be suspicious of it.  So they're going to keep that for later decryption, perhaps.



Maybe, then, this Narus thing operates in parallel to, in real time, find things that they're actively looking for that it has been tasked to find.  Or maybe it is a filter behind which is storage, so it's only storing things of some specific relevance or interest.  And if they're to be believed, it would be selecting things that are believed to not have domestic endpoints on each end, but at least one end is foreign, because that was the authorization that they were given was to do this on foreign communications.  So we just don't know.



LEO:  So, well, I can do a little calculation - well, WolframAlpha can.  So according to IBM, the number of bytes of data created daily is 2.5 quintillion bytes, 2.5 quintillion bytes of data daily.  And by the way, they say 90% of the data in the world today has been created in the last two years alone.  So this number is getting bigger faster.  But let's say it stayed at 2.5 quintillion bytes.  So I asked WolframAlpha to convert a quintillion bytes into a zettabyte.  And that's 1/1000th of a zettabyte.



STEVE:  Whoa.



LEO:  Every day.



STEVE:  Three years.



LEO:  So, yeah, something like that.  But that's - but that makes sense.  That's even commensurate with what they're saying, isn't it.  We're not keeping it forever.  We're keeping it for a few years.



STEVE:  Real estate in South Utah, Leo.  That's where you want to make - you want to build...



LEO:  Hard drives.



STEVE:  You want to build - you want to buy land south of the current facility because they're going to have to grow that sucker.



LEO:  Yeah.  So it's 2.5 exabytes created a day of data.



STEVE:  I'm kidding, by the way, people.  Do not go buy real estate.  Just...



LEO:  Soon the whole state will be one giant data center.



STEVE:  I heard myself.  I thought, oh, no, no, no.  Okay, that's not real estate advice from your security person.  No.  Do not buy real estate in...



LEO:  Don't listen to that man.



STEVE:  No.



LEO:  But 2.5 exabytes a day of data is a lot of data.  And it's going up exponentially.  So presumably, though, their capacity is going to go up.  And they said 5ZB.  Who knows what the real number is? 



STEVE:  Yup.  And we've got some questions coming up about that, too.



LEO:  Yeah.  I mean, at this point, I don't believe anything those sons of guns say.



STEVE:  I don't either, no.



LEO:  And they even admit, well, we lie.  Don't believe anything we say.  They've even said that.  Because we're spies.  Jason in Newcastle, Australia shares some thoughts about "secure" email:  I thought you'd like this one, Steve.  I've been listening to Security Now! for a few months, and I am enjoying it on my long commute to work.  Because my commute is so long, I'm currently in the market for a new house to rent closer in.  But don't worry, I'll still listen.



So we followed the usual process, found and inspected a property.  The agent told us that there was an online application to fill in.  Being a sysadmin by trade, as well as having terrible handwriting, I thought, fantastic.  More services like this should be paperless.  I spent an hour filling in the form, then I arrived at the part where you need to verify your identity by uploading your scanned documents - license, pay slips, passport and the like.  They had two options on the site:  upload them over an encrypted SSL connection, or email them [laughing].  Do I even need to say which one I chose?



I spent the time scanning and uploading, fighting the irresistible urge to take the quick and easy way out by taking a photo of them and emailing from my phone.  Hey, it's my identity at stake here.  I'm not taking chances.



STEVE:  And they're asking him to prove his identity by sending these documents.



LEO:  Right.



STEVE:  So these are identity-proving documents.



LEO:  Yeah, these are the real deal here, no messing around.  I finished the application and received a confirmation email informing that I had put in an application for the property.  It began by saying "Your secure application has been emailed to <insert agent's email address here>."  Need I say more?  Thanks again for the great products and passing the time on my drive to work.



STEVE:  Oh, god.  Well, yes.



LEO:  SSL to us.



STEVE:  The lesson here, exactly, the lesson here is, we've spoken of it before, the weakest link in the chain.  So, yes, nobody could snoop his connection to their real estate application-accepting website.  But then for compatibility's sake they emailed it all off in the clear to the real estate agent.  It's like, here's...



LEO:  <Sigh>.



STEVE:  ...the proof, yes.



LEO:  <Sigh>.



STEVE:  Good story, Jason.  Thank you for that.



LEO:  Chris Lionetti, Bellevue, Washington, wonders if the numbers add up?  I'm a reference architect for NetApp, and I used to build datacenters for Microsoft for five years.  Datacenters and storage are my life.



STEVE:  Cool.



LEO:  There's a problem - so, yeah, this guy has standing.



STEVE:  Yeah.



LEO:  There's a problem with the NSA's new datacenter math.  Let's assume 4TB HDDs.  Let's assume they use the most dense rack storage available.  That's about 60 drives per Rack U of space.



STEVE:  Now, wait.  Now, stop right there.  60 drives per U?  How do you get 60 drives in one U of rack space?  That's...



LEO:  I don't know.



STEVE:  I don't know.  That's amazing, Chris.



LEO:  I wonder if - yeah.  That doesn't sound right.



STEVE:  I know.



LEO:  In a 40RU rack I could fit 600 HDDs.  So that rack's got 2.4 petabytes.  A common datacenter room would - just imagine the cooling.  A common datacenter room - and the noise.



STEVE:  And the power.



LEO:  And the power - would contain 90 racks long by eight rows wide.  That room would contain 1.7 exabytes.  This ties in nicely with the calculations we just did, that there's 2.5 exabytes of data created every single day.  Using 65 megawatts, I could power about six of these rooms.  That's closer to 200K square feet.  The info on the datacenter states 100K square feet of DC space.  Really?  I thought it was bigger than that.  Oh, well.  That would give me 10 exabytes.  I think the information you have claiming it was a zettabyte must have been wrong.  Five exabytes sounds more realistic, and that's still huge.  Just want your podcast to be accurate. You are still talking about one million spinning hard drives.  For comparison's sake, Microsoft's San Antonio datacenter is 150 megawatts, half million square feet.



And another email from Paul in Dallas simplifies the math even further:  I love the show, blah blah blah, very high praise.  In last week's podcast concerning the NSA and PRISM, you said X number of zettabytes of storage capacity.  Surely you meant petabytes or exabytes.  To have a zettabyte of storage would require one trillion terabyte hard drives.  That's just not possible, given the cost of material needed.  Have I done my math incorrectly?



STEVE:  Okay.  So, great points, representative of our sharp listeners, many of whom said, uh...



LEO:  Good critical thinking.  I like that kind of critical thinking.



STEVE:  Yup.  Now, first of all, I doubt that it was a typo because nobody's ever heard of a zettabyte before.  So it wasn't like some editor said, eh, what's a big thing?  Oh, a zettabyte.  So all we know, first of all, this number comes from the NSA.  This 65,000...



LEO:  This was their press release, my friends.



STEVE:  Yes, this is them saying this is what they're building.  Now, one thing occurred to me as I'm looking at the cognitive dissonance that this does set up, of course, is, well, are these hard drives?  That is, is a hard drive today the most dense way we have of storing something?



LEO:  Right.



STEVE:  Because hard drives are inherently online.  But nothing says these 5ZB might not have basically a massive hard drive cache on the front end and something archival on the back end.  I don't - I have not bothered to go into the current state of long-term, ultra-dense, ultra-large archiving.  But we know, for example, that Google with their S3 service allows you to tuck data, like, further away somewhere, and it takes maybe a day to get it.  But they've done something with it.  Maybe they just unplug their hard drives, so they've got to go get one and plug it in.  That's probably what's going on.



But for what it's worth, I mean, we could either say we don't believe the NSA, or we can say, well, maybe we need to think out of the box a little bit more, that it's not just - everyone just wants to multiply hard drive size.  But that assumes that's all we have to work with.  And maybe there is - I haven't looked for a long time.  I mean, back in the old days, IBM had all kinds of bizarre technology.  They had, like, spools of magnetic tape and a robot arm as a big library system.  And the robot arm would swing around, grab a spool, pull it out, and stick it into a reader.  So there were a limited number of reader/writer stations, but a vast wall of spools.  So you couldn't get to them all at once the way you can with a huge hard drive array.  But you could get to them eventually.



LEO:  So this is a slide from the Army Corps of Engineers about the plan.



STEVE:  Ah.



LEO:  And it gives us - doesn't say "data storage," but maybe our audience can crunch some numbers here:  65 megawatts, 60,000 tons of cooling equipment, four 25,000 square foot server facilities.  So only 100,000 square feet.



STEVE:  Total.



LEO:  Total.  So, yeah, I'd have to think there must be something more dense than hard drives.  Maybe not as fast.  But more dense.



STEVE:  Do we know that there's not a basement?



LEO:  What's in the basement?



STEVE:  Maybe there's an elevator that goes way down, Leo.



LEO:  Yeah.



STEVE:  Don't know.



LEO:  Salt mines, baby.  It's a great mystery.  'Tis a puzzle.



STEVE:  So thank you, listeners, for your sharpness.



LEO:  Yeah, good math.



STEVE:  Yup.



LEO:  And I really like it that people are using their critical thinking.  I looked at that number, and I just go, yeah, that sounds right.



STEVE:  Okay, big, wow.



LEO:  They said it.  Must be true [forced laughter].



STEVE:  Yeah.



LEO:  Apparently they're planning on scaling it to yottabytes.  Alex wonders, should we be creating our own certificates?  Steve, forgive me, I'm no expert in the area of certificates.  I want to understand.  That's why your podcast is the best.  So far I know I can obtain a certificate from, say, from CA Cert or my iCloud email cert provided by Apple, somehow by default.  This is nice, so I can provide verification of my person.  But I'd need a recipient to set up something similar on their end; and with that, I and a recipient can send encrypted email to each other.



But there is a middle man in this.  That's the authority.  I guess my question is twofold:  Can I trust the authority? Might their certificate be compromised somehow, or even stolen, allowing for spoofing of an identity?  In the spirit of suspicion, can I revoke the certificate at any time?  Secondly, can I create my own certificate?  The answer is probably yes, but how can anyone verify my certificate as trusted?  I'd be interested in Scenario 2 because I control the certificate and when it gets revoked and the frequency.



Please feel free to edit this question if you intend to use it on your show.  But after the NSA situation, I think it's good policy to practice as much encryption as possible.  With the Internet today, god knows how important your insights are.  One last thing:  If I do encrypt, how strong should the encryption be?  After all, the NSA has teraflops at their disposal.  Hey, the new Mac Pro has teraflops.  That's nothing [laughter].



STEVE:  So zenaflops, Leo, zenaflops.



LEO:  Yeah, yeah, yeah.



STEVE:  Okay.  So this is a great question.  And I want to step back from it a little bit and sort of look at the meta question, which is - and all of our dialogue up to this point, even just in this podcast, has been sort of nudging us in this direction, which is that the one weakness of the public key encryption technology, the so-called PKI, Public Key Infrastructure, is our reliance on a certificate authority and our need to trust that authority.  The authority signs our certificate.  And if we trust the signer, then we trust the signing.



So the problem is, if we build a system based on that, that is the weakness.  And as we saw, if the NSA or law enforcement compelled Google to give up their private key, if they compelled VeriSign to give up their private key, the trusted root certificate authority, I mean, why stop at Google?  Go another link up the chain.  Get the root authority private keys.



The point is, I don't want to get people worried about whether their tinfoil hats are tight enough or not.  But we're at a point now where we're seriously reconsidering the trustworthiness of the public key infrastructure, you know, on a theoretical basis.  And again, people can say, well, Gibson, it was never trustworthy.  It's like, okay.  But we now know, we now have more reason for tinfoil than we had before.



So my bottom line for Alex is the only way that we can have security moving forward, if that's what we really want, is to no longer use the public key infrastructure.  And that's essentially what I was referring to last week when I was talking about the Threema communications tool for Android.  And I don't remember if it's iOS, also.  I think it is, but not yet BlackBerry.  There, you use - you have, like, three levels of authentication.  The highest one, where you get three green dots, requires that the two devices be set face to face so they can simultaneously cross-snapshot each other's key.  And the point is we only require trusting a third party when that's not possible.



When the two parties, the end parties, cannot meet physically, we have to trust a third who has essentially met them each.  So the third party has met Alice, and the third party has met Bob, and is able then to assert to Bob and Alice that they are each who they claim.  Well, if we can't trust the third leg of that stool, then Bob and Alice have to meet.  When they meet, they can securely exchange keys, and then that's what we're reduced to, essentially.  That's where we are today is, rather than trusting a third party, we can arrange to essentially cut any third party out of the loop.  And I think we're going to see utilities more and more in the future like Threema that say, okay, this is what we do now.



LEO:  I don't know about Windows.  Mac has an easy way to generate your own certificates, self-signed certificates.  You can create one.  You can create a certificate authority, even, or create a certificate for someone else as a certificate authority.  So you can set yourself up as a CA.  This is with Apple's built-in Keychain Access that's in every single Mac that's shipped.  There also is, of course, I use PGP or OpenPGP.  The GNU Privacy Guard is my choice because I like open source software for this kind of stuff.  You really want to use open source.



STEVE:  Yeah.



LEO:  And the notion there is, when you use that, is that you create your own keys.  No one else has access to your private key except you.  And then you send your public key to a key server.  And then what you want to do is you could either have a signing party, this is the thing you talked about where you get together in physical presence, and you sign people's keys, because the more people who said, yeah, yeah, that's Leo's key, the more likely it is in fact Leo's key.



STEVE:  Right.



LEO:  And so what I could do is give out the hex number.  It's, I don't know, it's 10 digits or 10 hex digits that is my key and say, that's me.  I could do it out on the air, for instance, say please sign that key.  That is me.  And then people would sign it.  So that keeps a government party out of it entirely.



STEVE:  Right.



LEO:  No one has your private key if you generate your own certificate, or you create your own PGP key.



STEVE:  And, yes, no single centralized authority is making any representations.



LEO:  Right, right.  That's the negative is that you have to have - it's what they call in PGP terms a "circle of trust."  But I think that that's, increasingly, we've got to do more of that.  I think.  The fingerprint, yeah, that's what that, whatever, 10-digit code is.



Christian Loris, Melbourne, Florida, says maybe General Petraeus gives you more conclusive proof of Steve's PRISM Theory:  In your assertion that the NSA didn't need to be directly in bed with Google or Facebook, let's consider the story of General Petraeus's covert communication techniques with his girlfriend.  Going on the assumed facts that SSL is secure - he was using Gmail, I think; right?



STEVE:  Yes.



LEO:  ...and that PRISM is picking up the streams of unencrypted email and other traffic outside the major providers, General Petraeus communicated with his mistress via a shared draft folder on Gmail.  That's pretty clever, isn't it.  He didn't even mail it.



STEVE:  Uh-huh.



LEO:  He had a shared - he just would create a draft and save it, and they both could log into that server.  He knew that almost anybody communicating with Gmail's website is not suspicious to the NSA collection efforts.  Too many people use it to make it interesting in most circumstances.  Gmail's SSL is secure and/or difficult to break unless the NSA has a very specific set of traffic it wants to crack - or has their private keys.  NSA/PRISM would need some very specific information before getting a warrant that Google would be happy to comply with.  General Petraeus and his mistress would securely connect to Gmail, leave emails for each other in the draft folder of their shared account.  Boy, that's clever.  I'll have to remember that next time I want to have a girlfriend.  



STEVE:  Yeah.



LEO:  The message would never leave Google's datacenter and never be seen by PRISM.



STEVE:  Yeah.



LEO:  This pretty much backs up the fact that many of the Googles or Facebooks may not have been complicit in the spying.  At the time Petraeus was caught doing this, it was also commented this was a common technique used by drug dealers and terrorists to stay off the radar.  This points to an awareness of the types of collection efforts that might be in use by law enforcement or the NSA.  Yeah, you'd think Petraeus, what was he?  He was head of the FBI; right?  What was his job at the time?  I can't even remember.



STEVE:  I think he was in Afghanistan.  I think he was...



LEO:  Yeah, no, but then he came home, and he was...



STEVE:  Oh, yeah.



LEO:  Yeah.  No, director of the CIA.  He was the CIA director.



STEVE:  Oh, well, okay.



LEO:  So presumably he knows and knew...



STEVE:  What's going on.



LEO:  ...all about PRISM; right?



STEVE:  Yup.



LEO:  And knew what the capabilities were and thought - he probably thought, though, that he wasn't a subject.  Anyway, at the time I thought this was silly for them...



STEVE:  He didn't want to get - he didn't want - yeah, go ahead, I'm sorry.



LEO:  But now, in light of everything we've learned, it actually makes sense.  So he was doing what he thought would be safe, and obviously - now, as I remember, I think he turned over his Gmail when he was being investigated.  I don't think...



STEVE:  When he turned over his resignation.



LEO:  Well, but, yeah.  I'm trying to remember the whole - it is germane that the director of the CIA considered this a relatively secure method.



STEVE:  Mm-hmm.



LEO:  And did not send emails.  He said, no, we're not going to send emails back and forth.  That would be a bad idea.



STEVE:  Yes, no, exactly.  Notice what he wasn't doing.  He wasn't doing what everybody else was doing.



LEO:  Right.



STEVE:  Except the terrorists and the drug dealers.



LEO:  Drug dealers.



STEVE:  And so, again, we're the last to know.  Everybody else already knew all of this that was going on.



LEO:  Apparently.  It's the honest folks.



STEVE:  Yup.  



LEO:  Andrew Stevenson, Dorset, U.K. points out a great resource:  Steve and Leo, the Electronic Frontier Foundation has put together a nice list of alternative programs that can be used to help thwart tracking by the NSA's PRISM program:  prism-break.org.  Interestingly, near the bottom of the list, when detailing alternatives to iOS, it simply states that it is insecure since it contains hardware tracking.  Do not use.  I like the name "prism-break."  But it does make presumptions about what - presumptions about how PRISM works that we just don't know.



STEVE:  Well, it's an interesting page.  And it's a little sad in places.  For example - wow, they just changed it.  Huh.  They've changed it from this morning when I was looking at it because it made a sweeping statement about, under web browser category, it says Apple Safari, Google Chrome, and IE as proprietary.  And over under Notes it said you can't really use any of these browsers because we have no idea what's going on in them.  And it was like, whoa.  Wait, maybe it was operating systems.



LEO:  Yeah.  Huh.  Cloud storage?  So they've got three columns, or two columns:  Proprietary and Free Alternatives.  And presumably the free open source alternatives are - I don't know.  Stop reporting online - it's not really clear what they're saying at this point.  Are they saying that the free alternatives are safe?



STEVE:  Well, they've got a column of proprietary and different categories, then a column of free alternatives, which they're endorsing in lieu of these proprietary ones, and then notes to, like, embellish, like here are the concerns and here are the issues.



LEO:  So instead of using PayPal or Google Wallet, use Bitcoin or other alternative crypto currencies, for instance.



STEVE:  Right, right.



LEO:  And I guess when they use the word "free" they're not saying "free" as in beer, they're saying "free" as in freedom.  And they do say that iOS is insecure.  There is no free alternative to iOS [laughter].



STEVE:  Ouch.  Yeah.  Anyway, I do commend our listeners to it:  prizm-break.org.  Good stuff.



LEO:  Wow.  It's a good name.  Jack, Fairfax, Virginia, wondering whether "Chrome convenience" is going just a bit too far:  Steve, not sure if this has come up on Security Now!.  At work, my PC is pretty much locked down, and so many sites were nonfunctional under Internet Explorer, the admin agreed to install Chrome.  I promptly added NotScript and WOT extensions.  When I got home, I was at first quite pleased to find that the same extensions had auto-magically installed when I fired up Chrome on my Mac.  If you have syncing turned on, that's what will happen, by the way.  



While I appreciate the convenience of extensions replicating across installations and the consistency of experience this offers users, I had a tinge of concern that I had made a change at work, but it affected my computer at home.  I wasn't aware of the behavior.  Well, dude, you turned it on.  So it was a surprise to me - this is often the case.  People turn things on and forget.



STEVE:  And so it's not on by default?



LEO:  No.



STEVE:  Okay.



LEO:  In this case, a pleasant one, which is what Google is of course intending.  But couldn't the same mechanism be a foot in the door for someone up to no good?  Yeah, it asks you if you want to have syncing turned on.  It walks you through this.  In the converse - but probably he hadn't installed Chrome in a while; right?  In the converse situation, could someone sit down at my Mac at home while I get a beer and install a nefarious extension which quietly replicates to my desktop at work?  I realize all bets are off if someone gains local access to a device.  But in this case, is the remote system at risk, as well?



STEVE:  So I think they're saved a little bit by the fact that it's off by default.  But, I mean, he's certainly right.  This is another classic example of convenience versus security.  I mean, it's absolutely convenient to have your Chromes syncing through the cloud, even to the extent of installing extensions on other Chromes that you install on one.  But, I mean, yes, this could be used as a foothold to, like, get something nefarious in a work environment.  Essentially, the problem is that Chrome in this instance is creating a bridge between two different security perimeters.  You've got your high security perimeter at work and your relatively low security perimeter at home, where you're having beer and your friends are over and they're screwing around with your Mac.  And there's...



LEO:  Really easy thing to turn off.



STEVE:  Good.



LEO:  And it's completely granular.  You can say sync bookmarks, don't sync extensions; sync settings, but don't sync themes.  You can totally do it.



STEVE:  Good.  Good for Chrome.



LEO:  Yeah.  I think that this is an example of the problem exists between computer and keyboard or whatever that is, PEBKAC.  And I sync everything because I feel fairly secure in the knowledge that...



STEVE:  You have control of your environment.



LEO:  Yeah.  And these extensions - Chrome is pretty good about not installing dangerous extensions.  Although I can't say that there's definitely no dangerous extensions installed.



Wolfgang Muenst in Munich, Germany offers a note about our podcast length and composition [laughing]:  Just heard on a recent episode of Security Now! some listeners want to shorten the show or keep the general stuff out.  PLEASE DON'T!  I totally enjoy the way it is, actually prefer to broaden my horizon every now and then with content I've never come into contact with before.  Thanks to you and Leo.  Hopefully, we'll see at least another 400 episodes of Security Now!.  Thank you, Wolfgang.  Great.



STEVE:  Yeah.  And this does echo many sentiments that I saw after that discussion that you and I had about this last week or the week before, a lot of people saying, hey, no, don't change it, it's what we want.  You guys rambling around a little bit and talking about other stuff, that's good, too.  So thank you, everybody.



LEO:  Question 11 from Adam, Washington, D.C.  He wonders, when are you going to be in Petaluma again?  Steve, I'm a high school student, rising senior - congratulations, Adam - from Washington D.C. who, over the past two years or so, has become an avid listener of Security Now!.  This gives me hope for the youth of our nation.  Since I discovered the show, my interest in the field of Internet security has grown immensely, and it's thanks to you that a lot of my knowledge about the finer details of technology has expanded.  So I have become just giddy - giddy - about understanding security-related issues.  Thank you very much for the hard work you put in each week to create such a fantastic netcast.



My family and I will be heading to California this summer.  Oh, I guess he's in Washington state.  No, it says Washington, D.C.  We'll be heading down to California this summer for a vacation, and I've convinced them to take a detour on our trip down the coast to visit the Brick House on Wednesday, August 21st, in order to see Security Now! live.  I heard at the end of Episode 408 on PRISM you might be in-house one of the weeks in August, and I was wondering if you might have any more details on what week that would be.  Getting to meet you in person would be unbelievable, but I'd still be thrilled by the experience of seeing the show live and in person.



Regardless of when you'll be in town, let this message serve as a huge thank-you for all the time you've dedicated to the show.  I know it's a lot of work and can guarantee I'm not the only one you've inspired with your service.  Adam.  Man, this kid is eloquent.



STEVE:  He is.



LEO:  What a good writer.  Wow.



STEVE:  Yeah.



LEO:  So when are you going to be in town?



STEVE:  Unknown.  I will aim for the 21st.  I'm coming up to hang out for a while with Jennifer, my girlfriend, and she is going to be up visiting people in Northern California.  And so I'm going to definitely try to make it a Wednesday or a Sunday, so either Security Now! or TWiT.  But I just don't know yet.  Jenny is great on plans and running around, but...



LEO:  Not that one.



STEVE:  I never really know until she says, "Didn't I tell you that?"  "No, honey, I didn't get the word."  So as soon as I know, I will let everyone know because it'd be great to see listeners when I'm going to be around.  So other people have asked, and I just - I don't know yet.  But as soon as I get a date, I will, on the podcast preceding it or more, I will say.  So thank you very much.  And Adam, thanks for the great note.



LEO:  Jenny, Jenny, make up your mind.  Figure out when you're coming down here.  Up here.  So, Steve, that concludes this reading, this dramatic reading of 11 questions from our vast audience.



STEVE:  Until next week, when we're going to plow into the technology of handshaking and SSL connections and what can be done, the details of perfect forward secrecy which really is getting a lot of attention now relative to the NSA's presumed interest in sucking up the content and decrypting it at a later date.



LEO:  Well, friends, this is the deal.  You must go now to GRC.com.  You must browse through the vast stacks of information.  You must purchase a copy of SpinRite, the world's finest hard drive maintenance and recovery utility, and knowing that you will get a free upgrade to the Mac-compatible version whenever it is available.



STEVE:  Yup.



LEO:  You must...



STEVE:  Even before.



LEO:  You must, if you have - even before.  You must, if you have questions, go to GRC.com/feedback.  If you would like to download a copy of this podcast in glorious 16Kb audio, which sounds a little bit like it was recorded in the 18th Century.



STEVE:  Oh, Leo.



LEO:  Down a tube.  But small, small.  You can get that from GRC.com.  He also has - Steve has great transcriptions written by hand by a human, all at GRC.com.  We keep full quality audio and video available at our site, TWiT.tv/sn.  And you can even watch us do the show live, which we do every Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC.  TWiT.tv is the place for that.  Hey, Steve.  Have a great week.  Have a great Fourth.  Are you doing something tomorrow, day after tomorrow?



STEVE:  I'm going to be coding.



LEO:  No, it's tomorrow.  That's tomorrow.



STEVE:  I hope I...



LEO:  Coding.



STEVE:  I hope I'm coding up a storm.  I'm going to just code away.  Quiet days like that give me more chance to work, so that's what I want to do.



LEO:  Coding by the rockets' red glare.  That'll be Steve.  That's great.



STEVE:  Thank you, my friend.



LEO:  Thank you, Steve.  We'll see you next week on Security Now!.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#412	

DATE:		July 10, 2013

TITLE:		SSL & Perfect Forward Secrecy

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-412.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a bunch of interesting security news of the week and Steve's Sci-Fi and SpinRite development updates, Steve and Leo explore the already existing SSL/TLS technology known as "Perfect Forward Secrecy," which becomes useful in a world where encrypted traffic is being captured and archived.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He has a creepy thought.  We'll talk a little bit more about PRISM; about a form of SSL that provides Perfect Forward Secrecy, a defense against his creepy thought.  We'll also look at Microsoft's Patch Tuesday and the rather large number of patches.  It's all coming up next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 412, recorded July 10th, 2013:  SSL & Perfect Forward Secrecy.



It's time for Security Now!, the show that protects you, your loved ones, your privacy online with this man here, the Explainer in Chief, Mr. Steven Tiberius Gibson, a man who loves flowers and all things nature.



STEVE GIBSON:  Okay.



LEO:  One of those statements is a lie.  Hey, Steve, how are you?



STEVE:  Great, Leo.



LEO:  Good to see you.



STEVE:  We're going to have a good episode today.  It's just - this is one which is just, I think, right in the sweet spot of the kind of thing that this podcast does really well because it combines relevance and technical depth without probably losing the bulk of our audience in the depth of the technical.  And anyway, I'm really happy about this because there's just - there's so many angles at which we can approach this.  And I have, as a consequence of thinking about this, and some of the mysteries we still have about the NSA, I have a new really creepy idea to propose.  And I'm okay with doing it because they've probably already thought of it.



LEO:  I just want to show you something because you know there was another PRISM slide that came out today.  Have you seen it?



STEVE:  Yeah, yeah.



LEO:  Have you seen the word "upstream," collection of communications on fiber cables and infrastructure as data flows past?



STEVE:  Yup.



LEO:  And but what's interesting, it says you should use both upstream and PRISM collection directly from the servers of these U.S. service providers.



STEVE:  And, you know, I haven't ever mentioned this.  But does anyone realize, I mean, our audience, we have lots, a ton of savvy computer people.  There is no standard about any company's so-called "back end."  You know, Facebook just made it up.  Google made it up.  Apple has their own.  Twitter does their own thing.  I mean, none of these are the same.



So in order, I mean, if we're to believe what we're being told - and actually the theory I have today is really creepy and sort of solves this problem, believe it or not, as we'll see - but it would require, like, a custom, from-scratch interface, individual for every separate company's back end.  I mean, the idea that you could have a third-party connection to a completely random database architecture is, I mean, it is by itself farfetched.  To me it just - it stretches credibility, the idea that, well, and the other thing, that you could contain that information.  That would be a huge project that would deeply involve all of the database engineering and infrastructure engineering of a private company in order to disclose and design for a third-party a means to access their completely designed-for-themselves database.  I mean, it's really infeasible to suggest that that's what's happening.  So maybe that's why it took a long time.



I think this thing was stretched out over time because they had to build upstream monitoring for each of these companies one at a time.  Maybe, though, I mean, if we really believe this - and then of course you have the real problem with squaring these flat-out denials.  Maybe I'm nave, and in fact the CEOs are protected, they feel they're both ethically and morally, and certainly they are legally protected by the letters that they've received from the government.



But these secrets are hard to keep.  I mean, it's like the wingnuts that think 9/11 was actually created by the U.S.  You can't keep that kind of secret.  I just, you know, I don't believe that.  But this, a project this size, how could it, if it were true that there was that much involvement?



My point is it's serious engineering to create that kind of connection; whereas it is trivial to do it upstream, that is, as we've proposed, to collect on the fiber.  Now, even then, like the form data, the web data would - that would require enough engineering.  That is, that's where I could see it taking time.  So, for example, yes, you tap Google upstream.  Well, you still have to write interpreters for all of the web queries and web pages going back and forth, to strip out all the HTML and to lock onto the email content amid all of the other debris that is passing by.  So that could explain what was going on by government engineering, absent any private corporation engineering.  It's just - the way I, as I've been thinking about what it would take to quote, to actually create that kind of tap.  It's just like, okay.  It seems unlikely to me.



LEO:  Even with the cooperation of the companies involved.  And you could have a guy, you could dedicate a guy full-time, lock him in a room and say, hey, make an interface for the NSA.



STEVE:  But it wouldn't, no, no, it wouldn't be a guy.  It would be a team.



LEO:  Have to be a team.



STEVE:  These are massive systems that Facebook and Google and Apple and - and, I mean, and they're not even - they're not homogeneous, they're heterogeneous.  These things have evolved over time.  They've got random databases from different companies.  Oh, and, oh, well, the keys are being stored over here because we were doing that in Oracle at the time.  But now we're over here on SQL from blah blah blah, I mean, they're a disaster.  And the idea that you can just create an interface to that is, to me, it's - I'm skeptical.  And that you could keep it secret.  But anyway.  I have something to propose that is really creepy.



LEO:  [Laughing] Once again, continuing in the vein of this is the show designed to scare you with facts.



STEVE:  It's totally feasible, totally feasible, and probably happening.  And I wouldn't mention it if I didn't think it was probably already happening because otherwise I would not want to give them the idea.  So I don't think I'm giving them the idea.



LEO:  Oh, great.



STEVE:  It's really creepy.



LEO:  Hey, before we go much farther, today we're going to - just briefly we should say something that you mentioned last week, which is SSL and Perfect Forward Secrecy, which is implemented by some.



STEVE:  Actually, it's, well, we'll get into it deeply.  It is available and has been, like, actually Perfect Forward Secrecy predates Netscape's creation of SSL.



LEO:  Wow.



STEVE:  So the concept is old.  And the problem is, once again, it's one of these things where both ends have to agree.  And therein lies the problem because, for example, IE absolutely doesn't support it.  And my latest server, Server 2008 R2, it supports it, and I could offer it, except then I would be vulnerable to the BEAST attack.  And so in order not to get dinged by SSL Labs for, oh, GRC doesn't know what they're doing, they're vulnerable to the  BEAST attack, I have to, I have no choice but to put an RC4 cipher in first place.  And my server and Microsoft servers don't offer an RC4 cipher with Perfect Forward Secrecy, whereas, for example, Google does.  And Chrome understands it, and Firefox understands.  Anyway, it's a really interesting topic, and not - won't require too much speed on our propeller beanies.  So I think it's going to be good.



LEO:  Okay, Steve.



STEVE:  So we have just passed another Second Tuesday of the Month.  This one's got a disturbing - a fix for a disturbing problem which is in the wild, which is pretty much as bad as they get because even - I don't think even turning off JavaScript would protect you from this.  Microsoft has seven bags of patches, resolving 34 vulnerabilities across all versions of Windows.



LEO:  Is that the technical term, "bags o' patches"?



STEVE:  Bags o' patches.  Yes, they're in bags now.  Bundles.  The problem is that TrueType fonts, which are displayed on web pages, can now take over your computer.



LEO:  Wow.  Well, they've always been programs.  I think people assume it's just a dataset.  It's not.



STEVE:  Yes.  That's actually the real cleverness of TrueType is that the way you render the font, in addition to having just static data, you can provide hints and little algorithm snippets to help the rendering engine.  But the fact is, even static data, like PDF documents, are able to - if you're able to induce a buffer overflow, then you're able to cause your data to be executed, even if it wasn't ever intended to be executed.



LEO:  I seem to remember TrueType vulnerabilities in the past.  This is not the first time.



STEVE:  Oh, yeah.  We've had them.  We've had them. 



LEO:  And by the way, this is an Apple, well, Apple did it with Microsoft.  But Apple really led the charge on TrueType.  I wonder if this connects...



STEVE:  True because, remember, they were the leaders with the HP laser printer.



LEO:  Right.



STEVE:  The laser printer was the first - and that was a PostScript-based printer where you actually sent PostScript down to the printer, and it rendered it.  Those were the good old days, where, you know, K were K.



LEO:  [Laughing] Long time.



STEVE:  And you were glad, you were glad you had 16K.



LEO:  A long time ago.



STEVE:  And by damn, that's all you needed.  Yeah.  Anyway...



LEO:  But now you have little programs going down the...



STEVE:  And 16 trilobites [!] and petabytes, and it's like, okay, how many zeroes is that?



LEO:  I remember that Type 1 fonts, which were the PostScript fonts, were replaced by TrueType.



STEVE:  Yup.



LEO:  And Apple was the first to use them.  But Microsoft adopted them pretty early in Windows.



STEVE:  And then there's like an open - there's an open format.



LEO:  OTM, yeah.



STEVE:  Yeah, open, right.  And so eight flaws exist which have been fixed across the spectrum of Windows, all supported versions of Windows, and actually all of the unsupported ones, too.  But those are unsupported.  Eight flaws, one of which all you have to do is visit a website.  And it's interesting, I messed with fonts when I was working on the Off The Grid project because I wanted to offer - because people were going to be printing their grids, I wanted to be able to allow you to select fonts that you felt were the most visible and legible and had non-ambiguous characters in them because that would be very important.  And so I bought a bunch of fonts online, and my server hosts them.  And you can go to that Off The Grid page, and there's a dropdown list box, you choose fonts.



And so this technology is now ubiquitous.  It's been supported for many years across all browsers.  And unfortunately, bad guys can craft an evil font and so that you just go to their page, your browser downloads the evil font, hands it off to the OS, to Windows in this case, and Windows collapses in a way that allows them to execute arbitrary code in your computer.  Thus it's considered a critical vulnerability.  Six out of those seven bags o' patches are critical this month.  And not to be left out, IE is addressing the - the IE bag o' patch is addressing 17 critical vulnerabilities.  So this is one I would put high on the radar.  I saw other commentary, and I wanted to see someone ranting and raving, so I went over to theregister.co.uk.  And sure enough, they're like, oh, it's the end of the Earth and the end of life as we know it.



LEO:  They are maybe a little overdramatic, yeah.



STEVE:  Also, not to be left out, in addition to IE we have updates from Adobe, both Flash and Shockwave.  And I went over to see what Brian Krebs had to say.  And I liked what he said.  He said, "Shockwave?  Eh, really?  Does anyone still have that installed?"  And he said, "I feel about that the way I do Java.  You probably don't need it.  You probably should get rid of it because it's just bad if it's there."



LEO:  Right.



STEVE:  You know, it'll jump up and run if you give it a chance.  But if it's not present, it can't.  So get rid of it.  And if you do need Flash for some reason - and actually we do.  Unfortunately, websites still depend upon it.  I chafe.  One of my favorite sites is nutritiondata.self.com.  That's a fabulous site, nutritiondata.self.com.  You can just give it anything.  Like I was wondering about cottage cheese the other day.  Put "cottage cheese" in.  Oh, well, what kind?  Nonfat?  Skim?  Large curd?  Small curd?  Blah blah blah.  And then it just gives you a complete breakdown - if you have Flash.



So, you know, it's got beautiful charts, which are Flash-based, showing you the amino acid spectrum and where it falls in the - it's got a triangle with fat, protein, and carbohydrate in the three corners of the triangle, and it places it in that triangle.  Anyway, I can't go, I can't really get it on my iPad because the iPad won't do Flash.  So it's, you know, there are still some good uses for Flash, but they could certainly implement that all now with HTML5 if they chose to.  They just haven't.



Now, okay.  The award winner for the Most Tweeted to Steve item of the week, and there wasn't even a second-place runner-up here, this one swamped, was the problem with Cryptocat.



LEO:  Isn't it ironic, as soon as we recommend it [indiscernible].  It's only been there, what, seven months to 17 months.  We're not sure.



STEVE:  We're not really sure, yeah.  And, you know, I liked Cryptocat because it was the easier to use OTR, Off The Record, client.  And there was nothing wrong at all with all of that.  Everything that we recommended is absolutely bulletproof and fine and always has been.



LEO:  The thing that bugs me is I'm the guy who says get open source because then you know it's not - it's secure.  It's written right.  And I guess nobody was looking at the code, or what?  I don't know.



STEVE:  Well, okay.  So here's the deal.  The thing that chaps me a little bit is that Steven Thomas, who did the blog posting to inform us that there was a problem, is just, I mean, I want to use words I can't use on the podcast.  So I'll just say "jerk."  He's a real jerk.



LEO:  Okay.



STEVE:  He is a real big jerk.



LEO:  Bad jerky jerk.



STEVE:  Here was an opportunity, big, you know.  And if you didn't know that already, he's standing in front on one - he's, like, trying to raise money for some other project that he's dropped already a couple times.  Standing, looking, he's like done an al-Qaeda-style video to try to raise money, like with the blanket, you know, thumbtacked to the wall behind him.  And it's like, okay.  And he's got the beard and everything.  Anyway, so maybe this is his sense of humor.  Anyway, here was a teachable moment opportunity.  And he didn't do that.  He could have earned some esteem in everyone's eyes.



And the other real crypto people who I've checked in with were just kind of saying, yeah, well, you know, I mean, he makes some good points, but he didn't make them very nicely.  And so I think, I'm wondering if - he made it sound like the end of the world.  And for people who aren't fully up to speed on the technology, they're reading this guy who seems to know what he thinks.  I'm sure his mother is very impressed with him, that she raised a genius.  Okay, good, Mrs. Thomas.  So I'm not.



But you're right, Leo.  Looking at the sane analysis - and I should mention that reading Steve's page tells you nothing about what the problems were.  He basically is just ranting and laughing and pointing fingers and doing charts of his feeling of how strong the group chat has been over time.  And that's where the problem is.  It's that someone who is not a good programmer, and certainly not a good JavaScript programmer, did the coding.



And I will say that JavaScript is probably the most insanely difficult language to use for crypto that you could imagine because there are no integers.  I mean, crypto is about integers.  It's bits and bytes and words concatenated, and you need 128 bits for this and so forth.  JavaScript has real values.  It doesn't have integers.  And I've done crypto stuff in JavaScript.  I did, famously, the Off The Grid project.  The problem was there are so many possible grids that I couldn't seed a pseudorandom number generator with even a large number, like 256 bits, because compared to how many grids are possible, even the number of possibilities represented by 256 bits is a fraction.



So what I had to create was what I called at the time, and our listeners will remember, an ultra high entropy pseudorandom number generator in JavaScript.  And so I carefully wrote one and put it in the public domain.  It's free for anyone to use.  But the other thing that I did, which they could not have done, is I had it dump out megs of random numbers, which I then, I myself tested, and I posted them on the website, and people in our newsgroups who were following along all pounded on these, running them through every type of random number integrity testing software possible.  I used DieHard and DieHarder, which are like the pretty much industry standards, and it just came out perfect, I mean, absolutely perfect.



But if these guys had run their pseudorandom number generator through any, even a weak pseudorandom number randomness test, it would have just - they would have seen spike that stood out, saying, whoa, this is not random.  And then they would have looked further.



The problem with JavaScript is that everything is a real number, meaning a floating point number, where you have some number of bits of so-called "mantissa," which is like the part you see, the digits, and then an additional chunk of exponent.  And so the concept is that you can represent a huge range of values because - with many digits, many decimal digits of precision because you've got enough bits of mantissa, and then you scale that by a large enough signed exponent, which can be negative whatever it is, 128, to positive 128.  So it's that mantissa raised to that exponent.



So for normal sorts of things, it's easy to do.  But you have to be incredibly careful if you're going to do, like, stuff that really pushes JavaScript.  I actually, in my code, used all 53 bits of the mantissa.  So I was doing - basically I couldn't do - what would have been convenient would have been to do, like, 32-bit math, or you can't get 64-bit math, but 32 bits I could have done.  But, you know, 53 were there.  I wanted to use them all.  And I did, and I was really careful.  But you have to be really careful.



And to give you a sense for, that any of our listeners will be able to understand, of one of the mistakes these guys made, and it's just, again, it's lack of being really careful where it counts.  We've talked about, often, the need in crypto for good pseudorandom numbers.  It is a fundamental requirement that you're going to have secrets.  The secret is going to be generated on the fly, and this podcast later on is going to be about that, too.  The secret's generated on the fly from pseudorandom number generators.  Or, if you have them, random number generators.  And the latest Intel chip, the Sandy Bridge chips, and I'm sure all future chips, have a very cool actual random number generator, not pseudo any longer, built right into the Intel core.  And there's an instruction, you can say give me an actual random number.



LEO:  But aren't all algorithmically based random numbers pseudo?  I mean, how...



STEVE:  No, because you can use physical properties of quantum physics.



LEO:  So it's using, like, chaos theory to generate...



STEVE:  Yeah, it's actually using - it's using, for example, one of the actual random number generators is to reverse bias what's called a "tunnel diode."  And there's actual - if you put a reverse bias across the diode, it will not conduct.  But every so often an electron that is being - there is a charge there, pulling the electrons across.  But the diodeness prevents it.  But every so often one goes through.  But you never know when.  It's completely unpredictable.  And so you could create then hardware around that tiny little bit of actual quantum physics...



LEO:  That is cool, yeah.



STEVE:  ...to create completely unpredictable, true random numbers that will never repeat, that are not algorithm based.  And Intel built that into the silicon from Sandy Bridge on.



LEO:  Wow.



STEVE:  So it's neat.



LEO:  But you can't count on that in software.  You've got to have...



STEVE:  Well, sometimes there's a problem, which is that the - oh, and the other cool thing about this is it is high bandwidth.  And that's key because there have been low-bandwidth random number generators.  For example, you could use - turns out you can use the timing of the various clocks in the PC because there's - there are phase-locked loops that synchronize crystal clocks in a PC, and there is noise generated that is also truly random.  The problem is it's not much.  Many times, for example, a big server, which is really busy creating tons of SSL connections per second, it's hungry for randomness.  It's consuming, like, the pool of randomness in the server at a high rate.  So you need to be able to be adding more entropy at the rate that it's being consumed by the way that the server's operating.



So what often happens, what often is done is that random numbers are used to seed pseudorandom number generators.  So the PRNG, the pseudorandom number generator, is able to run at very high speed algorithmically, and then it's constantly being reseeded at a lower bandwidth rate, but still enough that the entropy never drains out of the entropy pool in the pseudorandom number generator.  Enough new entropy is trickling in to keep things completely unpredictable.  Anyway, really smart guys have thought about this and figured out how to do it.  It's very cool stuff.  An example in Cryptocat - and this is, again, this is the group chat implementation.



LEO:  This is not in one-to-one chat at all.  There's no problem.



STEVE:  No.  Never been a problem.



LEO:  And we should point out it's been patched.



STEVE:  Oh, immediately, yes.



LEO:  If you use 2.1 or later, you're fine.



STEVE:  Yes.  Has been patched.  I mean, I like the Cryptocat guys.  I went back over there, read their responses.  I just - I get a good feeling from them.  I just think they're neat people.  I think they were unnecessarily hurt by the approach that Steve Thomas took, which was just mean, mean-spirited.  It wasn't fair.  And, by the way, all of group chat is over SSL, so it's entirely encrypted by SSL anyway.  So there, I mean, there never was a problem.  No one eavesdropping could know what you were chatting about because it's as secure as SSL, which is what we're using as our only security on all of the Internet now.



So anyway, so this was much - this was very much a tempest in a teapot.  It's a little bit like, we're going to give you a belt and suspenders, and then you find out that, well, the clasp on one of the suspenders isn't as good as you thought, and then you scream about it.  And it's like, well, yeah, but you've got a belt.  It's like, well, okay.  So, yes, you did promise suspenders, as well.  I understand that.



So I'm trying to get this one example out because this is a - this is something, really, a perfect example.  At one point in the Cryptocat JavaScript source they're using a very good stream cipher called Salsa, Salsa20.  And from that they pull random bytes, random 8-bit bytes.  Now, for their purpose they need random digits, 0-9.  Now they have a problem because the byte can have any of 256 possible values, but they need to turn that into 0-9, which is one of 10.  And 10 doesn't divide evenly into 256, meaning that there's no correct, there's no good way to easily convert the byte value that they get into a decimal digit value so that the digits are equally represented.  And that's a problem.



Think about it.  You've got 256 combinations coming out of the - in a byte coming out of a good pseudorandom number generator from the Salsa20 stream cipher.  But now you want to turn it into - you want to change the range from 0-255 to 0-9.  But it doesn't divide evenly.  Well, I've faced this problem before in the Perfect Paper Passwords system, and there are good ways to do it.  They should have divided by 10, which would have given them a remainder 0-9, and then kept the result, and then added another byte to the high end, as they consumed the dividend, put more bytes on the high end and always simply dividing by 10 to pull out, to extract a range 0-9.



They did not do that.  What they did was they said, if the value is less than or equal to 250, we'll accept it.  So that means they're throwing away six of the values and keeping, they thought, 250.  But that was a mistake because they forgot about zero.  They said I want it, they said, less than or equal to 250.



LEO:  That's kind of a boneheaded mistake.



STEVE:  That's 251 values.  So then they divided that by 25 in order to get, they thought, an equally distributed range from 0-9.  But unfortunately, one of those numbers, because it wasn't actually 250 that they were then dividing into 10 buckets, it was 251.  So that skewed the random number generator enough that, if you looked at it, if you, like, used their random number generator and just put up pixels, you could see a pattern in the numbers it was generating.  And that's bad.  And if they had - and my point was they didn't test.  And you have to test.  I mean, that is test, test, test, test all along the way.  Had they ever taken numbers out of that where it was crucial that they be an evenly distributed random set and run them through any random number generator or randomness tester, it would have - they would have seen spikes, and they would have said, whoa, we have a problem here.



So anyway, so there was a mistake there.  But also the idea of taking a byte and discarding some that you don't like, eh, it just feels wrong.  And technically it's an infinite loop.  Think about it.  The Salsa generator could be spitting out numbers greater than 250.  I mean, there's not much chance of a long run of them.  But it's just not good code.



So in that area, I would hold their feet to the fire a little bit and say, yeah, you know, you guys maybe need - but, and this comes back to your point, Leo, in February they put up a program offering a bounty for people who found errors.  And it took until the Fourth of July for Steven, unfortunately the least graceful hacker you could conceive of, to take a look at their code and then really take them to task over it.  So it's certainly a good lesson.  The stuff we talked about, the point-to-point crypto using Off The Record, and the fact that Off The Record, they have an implementation of it, bulletproof, and all the other chat clients that support Off The Record are going to be similarly bulletproof.  And even the group chat was over SSL.



So it was never really true that their data could be decrypted by anybody who doesn't have access to SSL.  And incidentally, or coincidentally, this podcast's topic, once we get through with news, is about some creepy things having to do with access to SSL.



And speaking of secure chat, there's a new game in town, or coming to town, that really looks nice to me.  And Leo, I'd like you to play this video.  This is from a group creating a product called Hemlis, H-e-m-l-i-s.  And the website is Heml.is.  And the word "hemlis" means "secret" in Swedish.



[Clip]



MALE VOICE:  That's why we decided to build a messaging platform where no one can spy on you, not even us.



MALE VOICE:  Our system is based on N10 encryption.  Only you and your friend can read what you write.  We use an existing, proven technology to build the most secure, fast, and reliable service possible.



MALE VOICE:  Usually security results in complexity.  The only way to build something secure for everyone is to make it user friendly.  This is why we are building a simple and beautiful user experience.



MALE VOICE:  Other apps are funded by ads or selling your data.  There is a saying:  If you are not paying for it, you are the product.



MALE VOICE:  We're interested in helping, not selling users.  That is why we need you to fund Hemlis.



[End clip]



LEO:  So there's the pitch video.  Heml.is is the website.  And it looks like it's Android or iPhone.  It's a mobile platform.



STEVE:  Correct.  A mobile platform, point to point.  It's beautiful looking.  This is not hard to do.  It's three guys.  And Peter Sunde, S-u-n-d-e, he was one of the cofounders of the Pirate Bay.



LEO:  Oh, interesting.



STEVE:  And so he's one of the guys, and two others.  They're looking to raise $100,000.  It's very clear they're going to shoot past it.  I went for the vanity contribution of 50 bucks because I'm quite happy to have my name in the product.  This thing looks like a nice piece of work.  A couple of hours ago they were at 60K, six zero.



LEO:  They're at 71,000 now.



STEVE:  73,579 at the moment.



LEO:  Oh, wow.  They went up some more, yeah.



STEVE:  I tweeted about them after I gave them my money, saying, you know, this thing looks like the right thing.  I mean, this is what we need.  You could certainly argue that this is going to happen independent of these guys.  I mean, it's clear now that a consequence of, I mean, just the fact, for example, that Cryptocat had such a bright spotlight shine on it was as a consequence of the huge interest which has occurred, the increase in interest as a consequence of the whole NSA, and now we know not only the U.K., but France is also in the doghouse over this, too.



LEO:  Now, this is not - is this an open source - it is not an open source project.



STEVE:  I don't know.  It's probably not.



LEO:  So that, to me, you know, despite the issue with Cryptocat, I think actually Cryptocat's an example of the success of open source.



STEVE:  Oh, I agree.  I mean, yes, I mean, the fact that it was looked at and, again...



LEO:  It took a while, longer than you'd like, but nevertheless discovered.



STEVE:  Yup.



LEO:  And I think that you can never be sure with something that's closed source.  That's my only qualm about it.



STEVE:  Yeah, and I think that's a reasonable concern.  And I think we will end up with open source solutions.  I mean, one of the reasons that I like proXPN is basically they are an anchor for OpenSSL.  And we know - I mean, sorry, OpenVPN.  And we know OpenVPN.  I mean, that's really - if they were just another random VPN provider with a private system, it's like, okay, well, good luck, you know.  They're going to be as good as others.  But instead, we know what they are.  We know that they're an OpenVPN anchor.  So to me, that means something.  And somebody tweeted me earlier, saying, Steve, we need CryptoLink more than ever.  And I thought, you know, at this point, obviously I'm committed to SpinRite.  I'm doing nothing other than SpinRite.



LEO:  You were on the right track, but others have really jumped in on this.



STEVE:  Yes.  But no one has yet made a VPN that works the way CryptoLink would.  And the only way I would do it now is to open source it and make it free.



LEO:  Good.



STEVE:  So, you know, maybe if I have a chance after SpinRite...



LEO:  When you're retired.



STEVE:  ...I'll still do it.



LEO:  They say, by the way, in their blog post, "We have all intentions of opening up the source as much as possible for scrutiny and help."  That doesn't mean it's open source, by the way.



STEVE:  Correct.



LEO:  So "all intentions" does not open source make.  And open source has a particular technical meaning that just saying, hey, we're going to look for scrutiny and help does not satisfy.  So I would say it is not an open source project at this point.



STEVE:  Well, yeah.  Although you still have the problem, then, I mean, this is the debate that we've had, is then, I mean, if you're really going to go to the mat, you have to take the source yourself...



LEO:  And compile it, yeah.



STEVE:  ...scrutinize it yourself, and compile it yourself on a cleanroom computer, where you install the OS yourself, on hardware that you built from scratch where no components came from China.  And you have to really start by getting a bucket of sand from the beach and synthesizing...



LEO:  Oh, come on.



STEVE:  ...synthesizing silicon.



LEO:  I guess you're right.  It could be in the silicon.



STEVE:  I mean, yes.



LEO:  Yeah, yeah.



STEVE:  So, yeah, at some point, even if it's open source you're still downloading an app that had to be digital, had to be signed, and cannot be changed.  And of course that takes us to the next trouble, which is that 900 million Android devices, ever since at least v1.6, which was the Donut build of Android, have had a flaw which allowed any of their apps to be changed into malware without violating the digital signature on the app.  So there again, I mean, it's like, okay.



LEO:  I should point out that this was publicized in February.  By March Google had patched the Play Store, and they had patched the code that scanned third-party stuff in Android.  So it's highly likely, as long as you're getting stuff from the Play Store, it's highly likely this is not going to bite you.



STEVE:  Yes.  It was responsibly disclosed by Bluebox Security...



LEO:  Back in February.



STEVE:  ...that were a security research team, back in February, yes, of this year.  And Samsung...



[Talking simultaneously]



LEO:  They still haven't published code, and won't till next month in Black Hat.



STEVE:  Correct.  Well, at the end of this month, July 27th through August 1st, is the Black Hat Conference, yes.  And so there is a presentation there where they're going to say, okay, here's everything about it.  And apparently, I mean, there are companies that are still lagging behind.  But as you say, checking the store provides it preemptively.  Samsung has issued a fix, for example, for the Galaxy S4 so that the code, the Android code itself will no longer be tricked by a malicious app, if the app were changed and digitally signed, as they all have to be.



LEO:  Yeah.  And they have now this built in.  And you should check your Android device to see if it's available.  But certainly all Google Experience phones will have this "verify apps" checkbox that will then block or warn before installing apps that may cause harm.  That's the code that looks for that particular problem.



STEVE:  Nice, nice.



LEO:  Yeah, yeah.



STEVE:  So since we talked last, Leo, France, or the French government, has been added to the list of international electronic spying operations.  And apparently, in the case of the U.S., there's the argument can certainly be made by the NSA that we have legal right to do this and oversight by Congress.  We've discussed how we feel about that and to what degree that seems adequate.  But there isn't even that in France.  I mean, this, apparently, is entirely illegal, as I understand it.  



LEO:  Well, that's France for you.



STEVE:  So it's like, okay.



LEO:  Some people, I was surprised at the number of people who tweeted me, "Well, everybody else is doing it."  One person tweeted me, "You know the Founding Fathers were doing it, so what's wrong?"  It's like, well, that doesn't excuse it.  And we do have this thing called the Fourth Amendment.  And let's honor the Constitution.  Seems to have worked for us pretty well so far.



STEVE:  Yeah, if nothing else, it's really true that - we know that there are going to be countervailing forces.  There's going to be pressure.  I mean, tension requires things pushing against each other.  And so it certainly makes sense for people to be concerned about privacy, to be really upset at the idea that they're being monitored all the time, everything they do, by the government.  And if they want to march around with signs on the Fourth of July, I say more power to them.  I, you know, that's not me, but yes, I'm glad they're there calling attention to it.



And I tweeted as soon as this happened last week, that our friend on the run, Edward Snowden, has been offered asylum, first by Venezuela, and then quickly followed by Nicaragua and Bolivia.  And I got a kick out of the fact that Bolivia added themselves after the plane of the President of Bolivia, Evo Morales, was forced to reroute last week and land in Vienna over suspicions that Snowden might have been aboard and headed to Bolivia.  I mean, he was, you know, just furious.



LEO:  Yeah.



STEVE:  So basically he was denied access to international airspace, and his plane was forced to reroute because other countries said, no, you can't come into our airspace, clearly from pressure from the U.S., saying maybe Snowden is aboard, you know, we want to inspect that plane.



LEO:  This is how you make friends in the international community.



STEVE:  Wow.



LEO:  Mm-hmm.



STEVE:  Uh-huh, yeah.  Now, on a home note, there's a really rather disturbing Dropbox two-factor authentication bypass.



LEO:  Oh, no.



STEVE:  Which is in the news.  Yeah.  I don't remember what Dropbox's slogan is.  "Simplify Your Life," I think it is.  Anyway, I saw on one of these reports, "Dropbox:  Simplify Your Hack."



LEO:  [Laughing] We make it easy.



STEVE:  So, okay.  So we all know multifactor authentication is specifically designed to protect you from, for example, keystroke logging or phishing attacks, where somebody does something to acquire your account name and password.  But the good news is that's no longer enough because they need something you have, not just something you know.  Well, not quite.



Get a load of this one.  This one is just - it's easy enough to describe.  So an attacker knows your account name and password, which they would have obtained by keylogging, phishing, whatever.  And the point is that's why you have multifactor authentication.  Dropbox never verifies the authenticity of email addresses which are used to sign up for a new account.  They don't bother.  So a hacker creates a new temporary account, adding an extra dot anywhere in the email address.  We've talked about, for example, how Google considers that the same address.  So, like, if you're john.wilson or j.ohn.wilson@gmail.com, they're all the same.



So Dropbox apparently treats this differently in different instances.  If there's a dot in the email address when you're signing in, they treat it as a different account.  But they are still linked by the fact that the only difference in the left-hand part of the email address is the dotness, or the dot placement.  So you create a new - the bad guy creates a new temporary account, just adding a dot somewhere in the email address, enables two-factor authentication for the temporary account, and saves the long emergency recovery string.  Keeps that.  Logs out of the temporary account.  Logs into the account he wants to attack that differs only by a dot in the email address, so logs in with the account name and password which he has, using the real credentials.



Because two-factor authentication has always been enabled in that first account, the website will then prompt you for the one-time passcode.  You click on "I lost my phone."  Then it says, "What's your emergency recovery code?"  You give it the one you received on the other bogus temporary account, and that disables two-factor authentication for this account, and you're now in.  Unbelievable.



LEO:  [Laughing] That seems like a flaw.



STEVE:  What a mess.



LEO:  You know they're having their - they had yesterday their big Dropbox conference in San Francisco.



STEVE:  Uh-huh.  Yes.  This has been out for a few days, so probably just in the nick of time.  It's funny, I went back to - I was following the stories, and I always like to go back to the root to get it from the horse's mouth.  And that page is gone now.



LEO:  Oh, oh.



STEVE:  Uh-huh, uh-huh.  I'll be some mad attorneys called and threatened all kinds of nonsense DMCA crap.



LEO:  Yeah, yeah.



STEVE:  Anyway, so.



LEO:  Too late.



STEVE:  I believe everyone knows.  The horse is out of the barn.  It's too late.



LEO:  Too late.



STEVE:  Exactly.  So that's a problem.  I hope it's going to be fixed soon.  And this is a little disturbing.  But not very much, I guess.  I just - I thought I'd mention it because I saw a number of people picked up on it.  TechCrunch reported that Google and others are reportedly paying AdBlockPlus...



LEO:  Oh.



STEVE:  To show ads anyway.



LEO:  Oh, isn't that disappointing.



STEVE:  It is, actually.  Now, the good news is you can, in the standard settings for AdBlockPlus - and I use it like crazy.  It's not that I don't want ads, I just don't want them flashing neon, you know, wake up and look at me, when I'm trying to read something.  They're just really obnoxious.  So if the ads just sat there, they just laid there, I'd, like, okay, fine.  I'm just - I'm not here to read them, but I wouldn't mind.  So, I mean, I have AdBlockPlus installed everywhere, just because it quiets the page down so that I can see what I'm doing.  And there is, under Filter Preferences, "Allow some nonintrusive advertising," which is enabled by default.  You can turn that off, and then it removes it all.  So that's good.  And this apparently is a way for them to generate some revenue for themselves.  It's like, okay, don't really...



LEO:  Yeah, but by putting ads - this is all about not having ads.



STEVE:  Yes.  And then the point has been made that that means, then, the big guys that can pay to circumvent the filter...



LEO:  Get ads.



STEVE:  ...get their ads, and the smaller advertisers can't.  So it does skew it.



LEO:  Doh.



STEVE:  So since we talked, Leo, I finished Stephen King's novel, "Under the Dome."  Except I think I finished it not long after - because I remember I quoted you, I was like, maybe I was at 73% or something, and you chuckled because I knew that because I was reading on a Kindle.



LEO:  Right.



STEVE:  And yes, I was.  But at 83% I sent email to Jenny.  And I said, and this is not a - this doesn't give anything away.  But I think you'll - this summarizes it nicely.  I wrote to her, "'Under the Dome' turns out to be science fiction."  Now, yeah, obviously, I guess.  It's a force field dome.



LEO:  Yeah, dome, yeah.



STEVE:  Yeah, but who knows, it could have been some incantation of...



LEO:  Could be magic, sure.



STEVE:  ...the witches of Eastwick or something.  Yeah, it could, exactly.  Turns out to be sci-fi.



LEO:  Yeah.



STEVE:  "I guess it had to be," I wrote, "but I'm now at 83%, and it just surprised me with an entirely new idea in science fiction, very cleverly based upon the universal natural amorality of youth, before maturity brings an understanding and respect for the inherent rights of others by virtue of their equal right to exist."  I loved...



LEO:  I hope that's not a spoiler.



STEVE:  I loved the book.  I loved the book.



LEO:  Good.  You didn't mind the ending.  Because I haven't read it yet, but Paul felt like it was kind of a weak ending.



STEVE:  I loved it.  No, I thought the end - I've read, I've seen other people who thought the ending was a problem.  I did not at all.  I thought it was entirely consistent with the entire theme.  And, frankly, there were many messages in this book.  I mean, it was really thought-provoking.  And it wasn't just...



LEO:  I think we have a new Stephen King fan, ladies and gentlemen.



STEVE:  Well, I don't know that they're all that way.  But I'll tell you, not the TV series.  Oh, my god, Leo, it is horrifically awful.



LEO:  Well, that's too bad.  That's really a shame.



STEVE:  It is really bad.  It's got bad actors, but also it's just - the only thing that survived is "Based on a Stephen King novel" and the name.  That's it.  They've just - it's just - they just trashed it.  It's just awful.  So, you know.  Oh, and I also have reread "Ender's Game" since we spoke last.



LEO:  Oh, what a great book.



STEVE:  It is.  It is just...



LEO:  I'm not a fan of Orson Scott Card's politics.  But you know what, many science fiction authors have bizarre, incompatible politics with mine.  That doesn't mean they're not great writers.



STEVE:  Yeah, and, you know...



LEO:  He's a great writer.



STEVE:  He's not asking me to vote for him.



LEO:  No, no.



STEVE:  He's asking me to say hey, you know...



LEO:  And there's nothing overtly political in the book.  The book is great, yeah.



STEVE:  No, I saw nothing.  He - they were...



LEO:  Yeah.



STEVE:  Yeah, it was fine.



LEO:  Yeah.



STEVE:  So, oh, a little SpinRite update.  So I'm at a - I finished the round of work I was working on and am about to start on the next round.  So there were, as always the case - and again, this is why test, test, test.  We found in maybe a hundred systems there was one or two where the keyboard controller was acting differently than any other computer anyone had.  As weird as that sounds.  What happened, we were talking about the original 8088 with its 1MB limit of memory, and how, if you've got 20 bits, so those are address lines A0 through A19 - because, remember, zero is a number.



LEO:  Yeah, let's not forget.



STEVE:  Let's not forget like the crypto guys did, yeah, the Cryptocat guys did.  So when you go past a megabyte, like to all ones, 1111111, all the way up to 19, and then you add one to that, it wraps around to zero.  But if you don't have actually 20 bits, it doesn't wrap around.  It goes to a million and one, a megabyte and one.  Well, when IBM came out with the AT, it had 24 bits.  It went to 16MB, that is, using the 286 chip.  So that meant there was a problem because, believe it or not, there was software written for the original PC that depended upon the wrap.



LEO:  Ohhh.



STEVE:  It used the fact that there was that wraparound.  Lord knows why anyone would do that.



LEO:  Oh, dear.



STEVE:  But they did.  It's like, okay, well, okay.  Very much like Google warning people about they're going to change their certificates because things you should absolutely never have done, well, people did.  So it's like, okay.  So what happened was IBM was forced to create something called, and it's famous among veterans of the PC, called the A20 line, or the A20 signal.



LEO:  I remember that.



STEVE:  That was, yes, yes, that was the next address line.  And so what happened was, when the system starts up, and it's booting, it's always booting in compatible mode because - even if it's an AT, the IBM PC/AT, the keyboard - so what happened was they had this extra - okay.  I'm getting - I sort of scrambled this.  But the chip itself is producing up to, through address 23, zero through address 23.  And the problem is software wants to, is expecting that a million, when you go past a million, you go back to zero, not to a million and one.  But the chip itself went to a million and one.



What IBM did was - it's a kludge for all time.  This is the definition of "kludge," is they took an unused pin from the keyboard controller, just because they didn't use all of the pins on something completely unrelated to anything else, the keyboard controller, and they ran it over, and they shorted it to the 20th, the A20...



LEO:  A20.



STEVE:  Actually, the 20 - it's the 21st, technically, the A20 address line, holding it to ground so that when you went to a million and one, the million got shorted out and lost, like to zero, was forced to a zero.  And so all you saw was one.  So it acted just like a PC, that actually wraps around at a million.  And using this random pin, it's like the keyboard controller was actually a microcontroller, an 8042 microcontroller, which was mass programmed on the original PC to receive input from the keyboard, and later from the PS/2 mouse, when they added a mouse input.  And so it wasn't very busy doing very much.  It just had to talk to a few lines on the keyboard, and it had an 8-bit port.



So they said, oh, look, here's an extra pin we're not using for anything.  We'll call that "A20."  And so the point is, any software that wants to turn the wrap off, as I do, as himem.sys does, as any extended memory manager must, needs to be able to turn on, to enable, as it's called, the A20 line.  And so now we're in, like, 20, 25 years ago.



LEO:  Yes, but you've got to maintain it for compatibility, man.



STEVE:  Yes.  And so here's SpinRite, booting up its own OS.  And essentially what I have ended up writing is my own internal extended memory manager.  So I have a full extended memory manager now running, and rather mature, fully tested by hundreds of people in our newsgroups.  And it goes out, it inventories the system memory, it finds all the ranges, it allocates the 32MB of upper extended memory that it's going to be needing for its 64K sector huge buffers in order to get maximum performance in this next version of SpinRite.  And it needs to turn on the A20 line.



And it turns out that there were a couple chips, you know, being a careful programmer, if I want to change one pin, the right way to change one bit in a register is you read what's there, you set the bit, you change only the bit you want, and then you put it back so that other bits that may have other purposes that you don't know about aren't going to get altered.



Well, it turns out that one person had two old machines which were reading the byte it came - reading the bit, oh, it was - what was happening is, when it was running what we're calling "SpinTest," which is the platform that we're evolving for doing all this next-generation testing, it would reboot his machine.  And so I was scratching my head, thinking, well, how can I be rebooting the machine?  Turns out that's what the zero bit does on the keyboard controller.  It pulls down the reset line on the processor.



LEO:  Wow.  Wow.



STEVE:  So the zero bit reboots the machine.  The one bit is the A20 line.  And so when you read on this obscure...



LEO:  Was that so a keyboard could reboot or something?



STEVE:  Oh, it's so that, I mean, well, it's like how would you perform a reset?  I mean, you needed some way of doing the equivalent of the red button.



LEO:  Hardware reset, yeah.



STEVE:  Exactly, a hardware reset.  So they used the keyboard controller, one of the bits there, to do that.  And so when I was reading that port, even though it was technically a one, it was reading back as a zero.  And so I was then turning the second bit on and writing it back and resetting the machine.  And so we figured out what the problem was, and I thought, oh, I don't ever want to write a zero to bit zero of the keyboard port.  And so now I never do.  Now I always OR that with a one.



LEO:  Captain Kipper said you "bit" off more than you could chew.



STEVE:  [Laughing] So we have the A20 line working, extended memory manager built in.  It's also compatible with external memory managers.  So if you have one that you want to use, SpinRite sees that it's there, has it turn on the A20 line for it, has it find the memory for it, and then takes its buffers from it.  And a complete PCI bus enumeration is working and bulletproof.  And so now we move forward.  I'm going to now write the low-level driver as soon as the podcast is over and begin to move forward.



LEO:  Awesome.  Are you not awesome?  You are amazing.



STEVE:  We're getting there.  It's going to be good.  We're having a ball over in the newsgroups.



LEO:  How fun.  Let's talk about Perfect Forward Secrecy.  By the way, I noted that Cryptocat, as of now, implementing it on their SSL.



STEVE:  Yes.  Only for the last couple weeks.



LEO:  Yeah.



STEVE:  So they - but before this came out.  So this wasn't a response to this.  This was - this predated that.  So they were, you know, they were moving their security forward even before it became an issue.  So...



LEO:  Good on them.  But what is it?



STEVE:  Okay.  So - okay.  I've got to get back to...



[Talking simultaneously]



STEVE:  Okay, yes, exactly.  Okay.  So why is everyone worried about this all of a sudden?  Well, the reason we're worried about it is the specter of big government and the surveillance state recording our Internet traffic.  And we now know without question, because it's been said in, I mean, officially acknowledged, this is not Snowden documents, this is from the NSA, and worked out with legislation in the FISA Court, that they consider anything encrypted to be subject to capture and storage and subsequent later decryption.  The fact that it's encrypted makes it suspicious, is their logic.



So that means that, while we've all been happy that in general the Internet is raising the bar of how much of our overall traffic we're encrypting, and we're encrypting it more and more, you know, Google famously - we've basically been chronicling this over the life of this podcast because when we began, people were only going into secure mode to log on, and then dropping back out for the efficiency of not using SSL, eight years ago.



That's no longer the case.  More and more we're seeing, like GRC for example, you can only access my servers securely.  Same thing with Facebook in the default case now.  Google now makes it available, and so forth.  So the problem, though, is that, for a long time we were comfortable, except when we really looked closely at the architecture of SSL because there is a - I don't want to call it a "fault."  But it is a weakness that has always been present in the SSL that we've always been using.



And that is as follows:  The private key, as we know when we connect to a remote server securely, the private key is something that only the server has.  And the public key is signed by a certificate authority to authenticate that the public key belongs to the entity we want to connect to.  Only the entity we want to connect to who has the matching private key that they never disclose is able to decrypt what is encrypted with the public key.  So when an SSL connection is established - and anybody who wants more depth can go back to the podcast where we did SSL [SN-195].  We have an SSL podcast which takes this thing apart step by step.  I'm going to go, going to take the high points that are relevant here because we have covered it in full detail in the past.



The user, who is the client, wants to connect to the server.  They generate a random number and the list of cipher suites that they support.  And I'll explain exactly what that is in a second.  They send that to the server.  The server has its own list of cipher suites that it supports.  And so essentially what the server has received from the user is I know all of these different crypto technologies, and I've listed them in the order I think I would like you to choose them, hopefully strongest to least strong.  The server looks at that list, compares it with its list.  It has its own list of things it knows.



And so the idea is that it chooses, the server chooses the strongest cipher that appears on both lists, is the best way to say that.  And it generates a random number, which it sends back to the client.  That is, so it sends the cipher it chose, the random number it chose, and its certificate.  This is the certificate that it got signed by the authority, asserting to its identity and containing its public key.



So now the client says, okay, I know how to communicate cryptographically in a way that we both understand because from its big list one was chosen by the server and sent back.  The client knows its random number and the server's random number.  So, which form part of the handshake.  And this is where I'm not going to go into great detail because I did before.  It generates another random number, completely separate from that, and it mixes all this together.  And it encrypts that with the server's public key and sends that back to the server.



Now, that's the key.  Because this certificate has been used for authentication.  And the certificate containing the public key has also been used for encryption.  That is, what the client encrypts under the server's public key is the final agreed key that they're going to be using for their conversation.  This is the symmetric key, much shorter, 128 bits, maybe 256, typically not much more than that because that's still plenty, which is encrypted with the server's public key sent back to the server, under the theory that only the server can decrypt it.



Now, what's the problem?  The problem is, with this particular approach, the same key, that is, essentially the server's private key, is protecting both the authentication, that is, it's asserting its identity, and the encryption because the data exchanged is protected by encrypting with a public key which can be decrypted only with the server's private key.  And so that's the problem.



If the threat model is anyone storing your encrypted traffic, if there's somebody on the line, as we know there is, I mean, we don't know that there isn't somebody inside the organization.  I contend, as I did at the beginning of the podcast, and we've discussed it before, well, we don't know.  We may never know.  But we do absolutely know they're outside tapping the Internet, tapping the fiber optics all over the place and sucking in encrypted traffic.



So what does the tapping person get?  The person who is tapping the line gets all of the communications passing in both directions.  And if, as in my theory, they're right down at the spigot feeding Google, then they're going to see the client traffic going in, and the server traffic coming back, and be able to extract the conversation, as it's called, this SSL connection between TCP endpoints at the client and the server, and log that as its own thread.  That is, here is a piece of communication which we cannot today decipher.  And we believe that it is still extremely difficult for them to decrypt it.



Well, all they have to do is compel the release of the private key.  That is, if they are recording all of the traffic, then the NSA can say we have a national security need to access traffic in the past.  We need your private key.



LEO:  Yeah.  They can do that with a National Security Letter, and you'd never even know.



STEVE:  Correct.  And if they have the private key, then that - because that is protecting both authentication and encryption.  They can decrypt, just as the server could, that final packet containing the agreed-upon keying material for this symmetric cipher, just as the server does, and that then gives them access to the entire stream, just as both server and client had.



Now, the creepy thought I had was, imagine this:  Imagine that the NSA says, okay.  We don't want to be too onerous.  We understand that it represents a problem for you to give us your private key.  But, you know, you're going to be expiring those every two or three years.



LEO:  Yeah.



STEVE:  So we'd like to have it after you're done with it.



LEO:  Oh.  Because they're storing it all.



STEVE:  Yes.



LEO:  No problem.



STEVE:  So all they have to do is say, uh, don't delete that.  Just we want it when you're done.  After you've replaced it with your new keys, we want the old ones.



LEO:  There might be some precedent there because they've already said, and I think the law agrees, that after six months nobody really owns that data.  It's old data.  So what's wrong with having the key to it?



STEVE:  Yeah.  And, I mean, what's the argument?  It's like, well, they're never saying they want the key we're using.  They're just saying give us your old keys.  We'd like to have those.  And, by the way, that's patriotic.  Okay.  So it just occurred to me as I was putting this together, it's like, whoa, you know?  They don't have to demand the current one.  I mean, maybe if there's something, an absolute clear and present danger, oh my god, we're absolutely sure a terrorist attack is imminent, we have to have this.  Well, who's going to say no?  But it seems to me that it's entirely feasible that they just say, give us your keys when you're done.



LEO:  Just the old ones.  The old ones.



STEVE:  You're going to be getting rid of them anyway.  Every two or three years you're...



[Talking simultaneously]



STEVE:  Yeah, you keep the new ones.  Don't worry.  We'll be keeping all the new traffic for when you expire those keys.



LEO:  Yeah.



STEVE:  And so, yeah.  Very...



LEO:  I'm sure that's happening.  That's good, that's...



STEVE:  Doesn't it make sense?



LEO:  Sure.



STEVE:  It absolutely makes sense.  That's why I said I'm sure I'm not the first person to think about this, so I can mention it.  So how do we...



LEO:  It's obvious, almost obvious.



STEVE:  How do we prevent that?  The prevention has always been present, but even now is barely being used.  And that's this notion of these cipher suites.  A cipher suite consists of - in math jargon we call it a "tuple."  It's like a number of parameters.  It's the how are we going to exchange our keys, what algorithm are we going to use for - well, for example, how are we going to exchange our keys?  Well, RSA is what I was just talking about, using the RSA public key in order to protect the contents of the agreed-upon key as it finally goes over the wire.



A different approach is called - is Diffie-Hellman.  And we've talked about Diffie-Hellman a lot, the Diffie-Hellman key agreement protocol, very famous.  And it's a protocol that allows two parties to exchange keys in plain view such that somebody eavesdropping, not an active attacker but a passive attacker, someone watching them cannot figure out what the final keys are.  And it's very clever.  So there are different key exchange methods.



Then there's the next part of this tuple, is what's our cipher going to be?  Shall we use AES?  Shall we use RC4?  Shall we use DES, the Data Encryption Standard?  And so forth.  So what is our cipher?  Then the next part of the tuple is, oh, and how long is that symmetric key going to be?  128 bits?  Back in the old days, remember, it was 56 bits or 64 or even 40 at one point, back when there were export restrictions that required that.



So the idea was, I mean, this flexibility was built into SSL specifically so that it could meet export restrictions so that you could use a weak cipher on some connections and a strong cipher on others.  Essentially it's like choosing one from Column A, one from Column B, one from Column C, one from Column D.  Column D is what are we going to use for our message authentication code, the MAC algorithm?  Typically SHA is used in order to verify that the message has not been tampered with.  So the idea is that the client will be equipped with software protocols with various combinations of these.



For example, you might have SSL with RSA, with exportable 40-bit using RC4 encryption and MD5 authentication.  I just, actually, that's one that's in the list.  And in fact, Leo, there is a link here in my notes under SSL/TLS cipher suites [www.iana.org/assignments/tls-parameters/tls-parameters.xhtml].  If you click the link and scroll down about half a page, you can see that this has all been standardized.  All these cipher suites have been standardized by the IANA for use in SSL and TLS.  And so the key is that the - all of, pretty much the majority of the connections today being made are with RSA - the original, oldest, trusted, we know how this works, everybody supports it, key exchange method.



But many browsers today, and many servers today, support what's called Diffie-Hellman Ephemeral, DHE.  Ephemeral specifically means "just for the moment."  So this is DHE, Diffie-Hellman Ephemeral, is a technology that is decoupled - and this is the key, "decoupled" - from the server's authentication.  And as I just said with Diffie-Hellman, a third-party observing the interchange gets no knowledge.  That is exactly the protection we want in our SSL connections from long-term archiving.  Long-term archiving and subsequent revelation of the server's private key doesn't give anybody any help in cracking Diffie-Hellman Ephemeral protection.



Now, one of the reasons this has not been used, and for the same reason super-long public keys have not been used, is speed.  Diffie-Hellman is about three times slower in terms of computational burden to establish a key pair between the endpoints.  So there's a much bigger burden, which really ends up being focused on the server because it's the one where all these SSL endpoints are terminating.  The user ends up having two connections in HTTP 1.1 going to the server, and then reusing those connections.



So there is a newer variant called Elliptic Curve, ECDHE, Elliptic Curve Diffie-Hellman Ephemeral key exchange, which is dramatically less burdensome.  And Adam Langley over at Google, whom we've spoken of before, who's a cryptographer and security guy, he recently did some work on finding some very efficient elliptic curve algorithms that would further lower the computational overhead.  He did this with some other cryptographers.  And so those are available and have been standardized.



Here's the problem, though.  And I mentioned this a little bit before.  I would love to be offering Diffie-Hellman Ephemeral connections.  Not that we need them for GRC.  I mean, there's nothing happening at GRC that - we don't have, like, user accounts and so forth that the NSA is going to care about.  We've got people grabbing Perfect Paper Password and Perfect Passwords and stuff.  It's like, okay.  Still, of course, I would love to have it.  But Microsoft does not offer any Diffie-Hellman Ephemeral in Column A that also has RC4, which is the cipher, in Column B.  Unfortunately they're all CBC, Cipher Block Chaining.  And that's the encryption protocol which is vulnerable to the BEAST attack.



So if GRC, and remember this is all about the order in which the ciphers are chosen, and right now I have had to, in order to get an A score on SSL Labs and give people comfort that they're not vulnerable to the BEAST attack, which is really not a problem, but yes, it's a weakness in SSL, I've had to put a cipher suite, SSL with RSA, RC4, 128-bit key length, or cipher key length, and SHA.  That is No. 5 on the hit parade of IANA in the cipher suites.  That's got to be my first one, and it's the only choice I have.



I am hoping that Microsoft will get on the ball here and at some point will update the cipher suites on not only their latest and greatest server, which would be 2012, but also 2008, which I'm using.  And then, absolutely, I would love to put Diffie-Hellman Ephemeral cipher suites up at the top of the list if they've also got RC4.  Or actually, if we even had a smarter server, because the later versions of TLS, of Transport Layer Security 1.1 and 1.2, are not vulnerable to the BEAST attack.  They have fixed that.  But the problem is the server is not currently smart enough to see that the client is willing to do TLS 1.1 or 1.2 and then therefore choose a proper suite.  Right now the SSL version doesn't affect the choice of cipher suites.  And, oh, my god, it would be so cool if it did.  I don't know why nobody's done that yet, but they haven't.



So that's the story.  Essentially, we're in another one of these sort of transition periods.  I've seen some stats that show that, since Firefox and Chrome are both supporters of Ephemeral Diffie-Hellman key exchange, about a third, about 33% of both of those browsers' overall Internet traffic is using perfect forward secrecy.  And of course, again, what that means is that every time you make a connection, the key is negotiated for that connection, and is it used in other connections, and no capturing of traffic and later analysis will easily reveal that.  You'd have to do a brute-force crack on that one conversation.  And then, if you wanted another conversation from the same guy, go through a whole brute-force crack on that again.  And as far as we know, that just still takes too long to make it feasible.



But we are seeing perfect forward secrecy beginning to happen.  In trying to figure out, like, why it's not more widespread, one of the things I sort of picked up on is people are liking the fact, like web server vendors or corporations are liking the fact that they get credit for spending money on the EA certificate, on having the extended validation, EV, sorry, EV, extended validation certificate.  It lights up green on the address bar, and it's like, oh, okay, that seems like good.  And of course it is because it also means that your connection cannot be intercepted without you knowing it, or at least without losing EV, as long as you're using one of the good browsers.



There is no indication on the so-called Chrome on the UI, the user interface of a browser, any browser, if perfect forward secrecy is in effect.  And I don't have time to write browser extensions now.  I'm working on SpinRite, and that's what I should be working on.  But that would be a nice thing for browser vendors to do.  It ought to be built into the browser itself and not...



LEO:  That's an interesting idea, make it a - could you make it an extension?



STEVE:  It could be an extension, for sure.



LEO:  It doesn't have to be built into the browser.  It could be a browser extension.



STEVE:  Yeah, it could be a browser extension.  But, boy, it would make so much sense to start giving brownie points, bonus points, when connections are perfectly - have perfect forward secrecy.



LEO:  And the browser would do it, but the other end would have to do it, as well.



STEVE:  It's go to, yes...



LEO:  So it's mutual.



STEVE:  Both ends.



LEO:  It's like SSL.



STEVE:  Yeah, exactly.  Both ends need to agree on that, on Ephemeral Diffie-Hellman, on any Ephemeral Diffie-Hellman key exchange.  But then it would be cool if the browser said, hey, look, the server - see, and the point is, this is much more work for the server.  So the server's only going to be willing to do that if it's going to get some credit.  And so it's up to the browsers to say, hey, the server is giving you perfect forward secrecy.  So nobody - because, remember, it's the server that has the private key that is otherwise vulnerable.



LEO:  Perfect.



STEVE:  Yeah.



LEO:  Perfect, yeah.  An interesting topic.  I'm not sure I understood it, but I'm sure many did [laughing].  And for them, that's why we do this show, Steve Gibson.



STEVE:  Well, but the creepiness of the idea that the...



LEO:  Means it's moot, yeah.



STEVE:  ...NSA could be saying give us your used-up keys, those are useful to us, just makes so much sense to me.



LEO:  And even if you're using perfect forward secrecy, two years from now, if I have the keys, it doesn't matter.



STEVE:  Correct.  Does not matter.  It will not, does not weaken your privacy.



LEO:  Yeah.  That's - oh, so you're saying perfect forward secrecy will protect me in the future, as well.



STEVE:  Yes.



LEO:  Ah.  Then we must use it.



STEVE:  Yes.  That's what the "forward" means, forward into the...



LEO:  Forward in time.



STEVE:  Perfect, forward into the future, yes.



LEO:  Even if you had the keys.



STEVE:  Even if the NSA coerces or somehow gets the keys from anyone, that does not help them because the key is in - as long as you're using an authentication that is separate from your key exchange, then you're safe because all the NSA is going to get is the authentication key, not the key exchange crypto.



LEO:  Well, I think the time has clearly come for software folks, whether it's Firefox, Chrome, Safari, or somebody new, to recognize that there's a market demand for secrecy.



STEVE:  Yes, yes.



LEO:  And to start filling that market demand.  And I think it would be perfectly sensible for somebody to create a browser, the Secret Browser.  You know, we honor your Do Not Tracks.  We honor, you know, we use, we implement perfect forward secrecy when a server supports it.  Things like that.



STEVE:  Yup, you're right.



LEO:  It's an opportunity.



STEVE:  Yup.  And I think, if anything, maybe Mozilla is now suffering from their size.  There's just too much bureaucracy and politics for them to do that.  Look at the trouble that they've got with infighting among developers, saying, oh, well, we're going to remove the JavaScript.  Well, there's no way in this browser you were just imagining, Leo, that they're going to take away the "Disable JavaScript" button.



LEO:  Right, right.



STEVE:  But it's gone now in the next version of Firefox.



LEO:  It would implement HTTPS Everywhere.



STEVE:  Yup.  Yup.  It would absolutely tell you when you had it.  Oh, and many people have been asking for me to do a browser plugin that does my certificate verification.  It would do that.  You know?



LEO:  I hope somebody's listening with some skills.  It would have to be a group of people, obviously.  Writing a browser is no longer a one-man show, if it ever was.



STEVE:  No, no.



LEO:  But, boy, I'd love to see that.



STEVE:  There are a lot of people who would say, okay, I'm using the Secure Browser.



LEO:  Why not?



STEVE:  Yup.  The "Secrecy Counts" browser.  Yeah, exactly, why not?



LEO:  Why not?



STEVE:  Standards compliant, and yet it's got all the other goodies.



LEO:  And the truth is, what's going to happen is the populace is going to become more aware.  Bad guys have, I think, long known that it's a bad idea to use the Internet to plan their plots.  So they've stopped doing that.



STEVE:  Well, or remember, Leo, we're talking about encryption of the tunnel.  There's nothing to prevent you from encrypting the data through the tunnel, which is what a VPN does.  So if you do - and that's the point of Cryptocat was it is in the OTR.  The Off The Record chat, by the way, has perfect forward secrecy.  OTR is perfectly forward - perfect forwardly secret.  And what they screwed up on was the group version.  But even there they're using SSL, and they now have perfect forward secrecy on their SSL tunnels.  So but the point was OTR was tunneling through SSL, but itself was encrypted.  So the bad guys are using encryption inside the SSL.  So if the NSA did decrypt it, it's like, well, there you go, another layer of encryption, good luck.  And of course...



LEO:  Steve Gibson is - go ahead.



STEVE:  I was going to say that's why TNO.  That's why we say encrypt everything that you stick up on the Internet in the cloud.



LEO:  Steve Gibson is - no, no, no.  I just, you know, this show always gets the wheels turning.  He is the man at GRC.com, the Gibson Research Corporation.  If you want to follow him on Twitter, it's @SGgrc.



STEVE:  And if you want to send me notes, @SGgrc, mentions, as they're called.



LEO:  Mentions, you can just add him.  Of course he reads all of those whether he follows you or not.  I don't think he follows anybody.



STEVE:  I don't because I just can't.



LEO:  Follow No One, FNO.  He also is on there if you have a question, because next week we'll answer questions.  So GRC.com/feedback is the address.  You'll also find, of course, SpinRite, the world's best hard drive maintenance utility, on his site, and a lot of free stuff including 16Kb versions of this show for the bandwidth-impaired, transcripts written by a real human hand, Elaine Farris, who does a great job, so you can read along as you listen.  A lot of - I hear over and over again about schools that use this as courseware.  We welcome that.  That's fabulous.  Of course you're more than welcome to do that, and I know Steve loves it.  And I think those transcriptions will help you quite a bit if you are doing that:  GRC.com.



Now, if you want high-quality audio or video we have that at our website, TWiT.tv/sn, and of course wherever podcasts are aggregated - Instacast, Podcasts, DoggCatcher, iTunes, Zune, all of that.  Just look for Security Now!.  Thank you, Steve.  We will be back here next Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC for our next recording of Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#413	

DATE:		July 17, 2013

TITLE:		How Much Tinfoil?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-413.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Though regularly scheduled to be a Q&A episode, Steve and Leo had SO MUCH to cover in the week's news that there was no time left for questions.  We'll save those for episode #415 and this week enjoy a great discussion of the week's many events.  We'll wrap up with a discussion of the wide range of "tinfoil" solutions available and their convenience versus security tradeoffs.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got some tech news, security news.  But we'll also take a look at how much tinfoil you need to wear to protect yourself in light of the revelations about the government's spying.  "How Much Tinfoil?" next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 413, recorded July 17th, 2013:  How Much Tinfoil?



It's time for Security Now!.  Help me.  The show that helps you stay safe online.  There's never been more need for Security Now! than right now.  Here he is, the Explainer in Chief himself, from the Gibson Research Corporation, creator of SpinRite, coiner of the term "spyware."  And, boy, I hope your ears are burning on TWiT.  Steve Gibson,  Ed Bott was singing your praises on TWiT this week.  I don't know if you heard it yet.



STEVE GIBSON:  Really.  No.



LEO:  Yeah, you've got to go back and listen.



STEVE:  Wow.



LEO:  So I - we both know Ed for many years, Ed being chief of PC Computing and just a great guy.



STEVE:  Yeah.



LEO:  And he has been looking into, of late, a pernicious practice that we've talked a little bit about, but that really came up on Sunday's radio show.  A fellow called up, said I have this - my browser's been hijacked.  My home page is hijacked, my search engine hijacked by this tool.  And I got it from CNET's Download.com.  And I said, well, that can't be.  And then we looked into it, and the chatroom said, oh, yes, it can.  And Download.com, like a lot of other free download services, has been wrapping some of their downloads with their own software that asks you, although you may not pay much attention to the ask, is it all right if we change your home page, change your search engine, blah blah blah.  And if you say okay, it will.



STEVE:  Yeah.



LEO:  Same things...



STEVE:  Well, I mean, if you don't say no.



LEO:  Well, that's right, because it's opt-out, not opt-in.



STEVE:  Right, right.



LEO:  So you have to uncheck those boxes, which most people don't do.  And Ed said, yeah, I've been studying this, and it's gotten to be a real problem.  In fact, Oracle with Java has gotten even worse now.  You know they install the Ask Toolbar.  And they ask you - and I'm very curious about this checkbox on here.  When you're installing it, they say it will now and forever change your search engine [laughing].  And Rafe Needleman on his Google+ said, what is this change in verbiage, and what are they trying to say here?  Let me show you, I'll show you the...



STEVE:  Wow.



LEO:  Yeah.  So Ed said - well, and here's where you come in.  Ed said, "And Steve Gibson warned us.  He has been a voice crying in the wilderness about all of this stuff for a long time.  And, you know, people should give him credit because this guy has been talking about this forever."  So here's the - Rafe Needleman put a screenshot of this.  It says install - the two checkboxes, and of course they're checked by default.  Install the Ask Toolbar in Google Chrome, and then set and keep Ask as my default search engine, which implies that it will then take steps to make sure you don't change it back, or nothing else changes it back.  Can you believe that?



STEVE:  Yeah.  The problem is, Leo, there is so much money now behind these things.



LEO:  Exactly.



STEVE:  Mark Thompson was telling me he was experimenting with wrapping some of his freeware in one of these things, where it's opt-out, but still it's being promoted.  And I get email solicitations all the time from these people.  And sometimes they start phoning.  And I go, look, get this through your head.  I am never doing this.



LEO:  Good for you.



STEVE:  Never.  Remove me from whatever - I don't...



LEO:  How much money?  What are we talking about, though?  I mean, it must be a lot.



STEVE:  It's serious money.  It is serious.  It's like shocking how much money, if you have something that's being popularly downloaded, because all they need is some percentage of people to get this thing in their machine, and then they've achieved their mission.  And it's like, oh, it's just bad.  And the Ask Toolbar, they just want it on people's browsers.  And they will pay the people who convey it into the browser.  You get a piece of the results.  And it is - you have to have no commercial orientation in order to resist it, to say no, I'm not doing that.



LEO:  Right.  And he was saying, unfortunately, shareware authors aren't making what they used to.



STEVE:  No.  And one of the things that I've noticed is - I'm sure you have, too, Leo - is every so often I go looking around for something, like I'll need to convert a whole bunch of AVIs to MP4s or, you know, something, some random sort of thing.  All of what used to be even the reputable download sites, they are now impossible to navigate.  They're like, unless you are very careful, you end up going off on some sideline and downloading something you didn't want.  And, I mean, it's all now about upselling us and actually making money rather than offering a service of making files available.  It's sad.



LEO:  He recommended a couple of tools, one called PrivacyFix.  I don't know if you're aware of this one.  It's kind of interesting.  And one of the things PrivacyFix tells you is what you're worth to various companies.  According to PrivacyFix...



STEVE:  [Laughing] I've seen that.



LEO:  ...I'm worth 123 bucks a year to Google.



STEVE:  That's real money.



LEO:  So you're right, it is real money.  If these companies can get you to use their stuff, they're making a lot of money.  And even if they pass 10% along to the authors, I can see why they - they do it.



STEVE:  Yeah.  Times however many of your users are involved in downloading their thing.  I mean, it ends up being serious.  It's significant.  Ugh.



LEO:  Ed talked about Abine Online Privacy and PrivacyFix.



STEVE:  Yup.



LEO:  Abine's been bought by a massive, I think it was a web advertising company.  So...



STEVE:  Oh, boy.



LEO:  But PrivacyFix is still kind of an independent - and I have to say it's pretty impressive, at least just to install it - it's a Chrome plugin - and see, and just see.  It shows you who's tracking...



STEVE:  How you're being monetized.



LEO:  It's kind of like Ghostery.  He recommended Ghostery, which I know you've recommended before, that I already knew about.  Anyway, he gave you serious props for being a voice in the wilderness for many years.  And he said that's the problem is this stuff starts innocuous, but it gets worse and worse and worse.



STEVE:  Yup.



LEO:  And it's now in the getting worse stage.



STEVE:  Yeah.  If it's wrong, it's wrong.



LEO:  Wrong is wrong.



STEVE:  And it's not about scale, it's about some things are absolute.  And if it's wrong, it's wrong.



LEO:  Yeah.



STEVE:  It's like third-party tracking.  It's wrong.  And now we're going to start seeing it getting worse.



LEO:  Yeah.  I have to - I may correct myself on the Abine thing.  I'm not sure.  I'm trying to remind what he said about it.



STEVE:  Well, I did get a nice note from an Adblock Plus developer who said, Steve, we need to correct the record.  So that's one of the many things we're going to talk about this week.  Are we recording, by the way?  Did we start?



LEO:  Oh, yes.  Welcome to Security Now!.  Yeah, we started.



STEVE:  Oh, good.



LEO:  I just thought I'd throw in a unit of my own.  But mostly just to...



STEVE:  No, I'm glad.



LEO:  Sincere props from Ed Bott, who is one of the great guys in the business and, like you, wears a little tinfoil from time to time.  And I guess that applies to the topic of the day:  How Much Tinfoil?



STEVE:  Well, this was nominally scheduled to be a Q&A.  But the big news that dropped the day after last week's podcast - it always seems to be now timed to be the day after the podcast something huge happens.  But that's good because it allows dust to settle.  It allows people to weigh in.  And this was important in this case because Microsoft has just gone ballistic over the Guardian's most recent news, which was a point-by-point enumeration of Microsoft's complicity - complicity?  Complicit.  Complicity.  They're complicit, I know that.



LEO:  [Laughing] Complicitousness.  I don't know.



STEVE:  Complicitousness.  See?  It's a problem.



LEO:  Yeah, it's not a good word.



STEVE:  No, I should have come up with an adjective form,  then I got stuck.  With the, of course, with our good friends at the NSA.



LEO:  Compliant.



STEVE:  Compliance, okay.  Anyway, so we have to talk about that.  And then there was all kinds of other news.  And I just realized as I was beginning to put this together, I mean, the PDF of my notes is more than twice as big as our normal PDFs.  When it took a while to upload it to you on Google, I thought, what - how big is this?  And I checked, and it's 213K.  Normally they're about 100K.  So anyway, because there's so much to talk about, I thought, well, there's no way we're going to get to any questions.  So I downloaded 327 of them, but then I thought, okay, we'll just cover those in two weeks.



But after all the week's news, I thought, let's talk about how much tinfoil we really need.  Because what we're seeing is, we're seeing sort of - there's a spectrum of things people can do to protect themselves.  And if you just don't care, use SkyDrive and Google Drive and let your files be there.  Or, you know, Gmail with no other protection.  But then there are - I really believe there is a midpoint between the absolutism of you must read the open source and compile it yourself - there's a midpoint.  There are people who are explicitly on our side.  Microsoft is not.  I mean, that much is clear.



But there are people, and we've been talking about this, like the Hemlis folks and Threema and, you know.  Anyway, so we're going to talk about sort of where I think it makes sense to be, for people who care about privacy and security, short of the - I mean, like, working with people who have what I would call an open agenda, where it's clear why they're doing what they're doing.  BitTorrent Sync is another example.  So there are many good things people can do that back away from not caring at all.  But, yeah, they don't really meet your criteria, Leo, of being open source, but I would feel comfortable using them.  So the question is, how much tinfoil do we need?



LEO:  Excellent.  And some recommendations, it sounds like, for things we can do.



STEVE:  Yeah, yeah, yeah.



LEO:  Yeah.  And I want to ask you, well, we talked before the show, but I want to ask you about - I read that Edward Snowden used a particular email service, and I wanted to ask you about that.  But...



STEVE:  Actually, that's already in our topics for the week.



LEO:  I know, I know, I know.  So we'll hold onto that.  That's coming up in a second.  All right.  Let's get going, Stevie G.



STEVE:  Yeah.  Just a real quick note, following up on last Tuesday's Patch Tuesday.  Microsoft had some problems with their patches.  Apparently there were three different patches that had problems, but two of those three were very obscure.  One, though, is causing lots of problems.  So I just wanted to mention it briefly in case any of our users, our listeners had encountered it and were puzzled.  And the symptom - it was a patch in Media Player codec DLLs which caused, for whatever reason, the upper half of the video image to stay black.  So this is...



LEO:  That's a problem.



STEVE:  Yeah.  This is MS - unless everybody's down in the second half of the frame waving to you.  Then you're okay.  But this is MS13-057.  That's the bad one.  And Microsoft has not yet acknowledged that this is a problem, but everyone understands it is.  It's been spawning all kinds of complaints all over the Internet, that the top half of videos are displaying in black.  So if that's a problem for you, wait for them to fix it, I would say, is probably best.  If you can't, then you may be able to uninstall that one.  It's based on the Knowledge Base 2803821, which covers that.  And so they were trying to fix a malicious video problem where someone could deliberately malform a video and install malware through your Media Player.  They apparently did fix that, but at the cost of your Media Player working correctly.  So, oops.  Anyway.



The big news dropped the day after last week's podcast, which was Glenn Greenwald at the Guardian has kept saying that there is more coming.  We've got a lot more documents that Edward had already turned over to us that we just haven't released yet.  Well, they did another drop.  And it's significant enough, and Microsoft's reaction to it is significant enough, and it's interesting to see how this plays into the theory that we've developed on the podcast of what's going on.  And so I wanted to cover that.  I've got a ton of people saying, oh, my god.  I mean, of course all of the Linux people were saying, ha ha, you know, we haven't been supporting Microsoft for a long time.



Anyway, so what the Guardian said was Microsoft has collaborated closely - oh, and by the way, they're the first people on the timeline.  If you look at that weird timeline with that strange green arrow covered up by yellow ovals, the very, very far left beginning, Microsoft is No. 1.  So whatever it means that they were "participating" in the PRISM program, they were first.



So the Guardian says:  "Microsoft has collaborated closely with U.S. intelligence services to allow users' communications to be intercepted."  Now, so that's - that says - and in fact what I think we're going to come away with here is it's sounding like Microsoft knows they're being tapped, that is, it's still - nothing that I've seen so far violates the theory that this is an upstream tap.  And what I think we're going to see is evidence of the NSA coming to Microsoft, saying, okay, we need help with what we got because we don't know how to decrypt it.  So this all fits still, [Microsoft] collaborating "closely with U.S. intelligence services to allow users' communications to be intercepted, including helping the National Security Agency to circumvent the company's own encryption, according to top-secret documents obtained by the Guardian.



"The files provided by Edward Snowden illustrate the scale of cooperation between Silicon Valley" - and specifically Microsoft - "and the intelligence agencies over the past three years."  And a lot of this does revolve around specifically Outlook.com, that we'll talk about here in detail in a second, and of course Skype.  "They also shed new light on the workings of the top-secret PRISM program, which was disclosed by the Guardian and the Washington Post last month.  The documents show that Microsoft helped the NSA to circumvent its encryption to address concerns that the agency would be unable to intercept web chats on the new Outlook.com portal.  Also, the agency already had pre-encryption-stage access to email on Outlook.com, including Hotmail."



Well, that's exactly our hypothesis of what's been going on in all these programs.  The company worked with - "Microsoft worked with the FBI this year," and that's in February, "to allow the NSA easier access via PRISM to its cloud storage service SkyDrive, which now has more than 250 million users worldwide.  Microsoft also worked with the FBI's Data Intercept Unit" - there's an acronym for that somewhere - 'to understand,'" they said in quotes, "'understand' potential issues with a feature in Outlook.com that allows users to create email aliases."  So that sounds like they were noticing people could have multiple identities, and so they said, oh, help us disambiguate these multiple identities in Outlook.com through aliases.



"In July last year," that would be 2012, "nine months after Microsoft bought Skype, the NSA boasted that a new capability had tripled the amount of Skype video calls being collected through PRISM.  Material collected through PRISM is routinely shared with the FBI and CIA, with one NSA document describing the program as a 'team sport.'"  And they actually used that term, "team sport."



"The latest NSA revelations further expose the tensions between Silicon Valley and the Obama administration.  All the major tech firms are lobbying the government to allow them to disclose more fully the extent and nature of their cooperation with the NSA to meet their customers' privacy concerns."  And, boy, we'll get to that in a second because Microsoft has just gone ballistic over this.



"Privately, tech executives are at pains to distance themselves from claims of collaboration and teamwork given by the NSA documents, and insist the process is driven by legal compulsion.  In a statement, Microsoft said, quote" - oh, and this is - we're going to get this in two different places.  I love this.  It says:  "When we upgrade or update products, we aren't absolved from the need to comply with existing or future lawful demands."  Which is legal speak for "We had to put in backdoors."  They said, "When we upgrade or update products, we aren't absolved from the need to comply with existing or future lawful demands."  It's like, okay.



LEO:  But that's a given.  I mean, let's face it.  They work in the United States.  You have to obey the laws of the United States.  That's just the way it is.



STEVE:  Well, right.  But so they're saying...



LEO:  I mean, asking them to break the law is asking too much.



STEVE:  No, this is new, Leo.  This is saying we are modifying our products to be able to comply with requests, rather than saying we're unable to comply.



LEO:  Can you say you are unable to comply?



STEVE:  Yes.  You could say, I'm sorry, we don't - we're happy to give you this bunch of pseudorandom noise.  This is all we have.  So at this point there is no law that says that encryption is outlawed, or encryption must be defeatable.  All they're saying...



LEO:  There was talk about that.  But they never passed that.



STEVE:  Yes.  And, I mean, that's the other shoe.  I mean, that's why I aborted CryptoLink was, like, this is coming.  It's clearly coming.  And so I was unwilling to invest a huge amount of effort to create a commercial product that I would then have to put a backdoor into.



LEO:  So put yourself in Microsoft's shoes.  They might have decided preemptively, well, we might as well just do it because we're going to have to.  Right?



STEVE:  Yeah.



LEO:  They're, I mean, they're a business.  And they probably wanted to avoid this issue.  So they said, well, what the hell, it's for a good cause.  It's to prevent terrorism.  We'll do it.



STEVE:  So I have here this discussion...



LEO:  I wish they were more forthright about it.



STEVE:  Yes.  Well, and they're saying, I mean, they're really...



LEO:  Kind of saying it.



STEVE:  They're really upset.  I mean, they really - we'll get to that in a second because I've got a quote from Brad Smith, who's their executive VP and head of legal, who is like, I mean, they're livid over the fact that their hands are tied.



LEO:  Crocodile tears.



STEVE:  I know.  Well, you know.  But consider that this is, I mean, this is clearly costing them from a business standpoint.  Microsoft users are not just our listeners.



LEO:  Well, and the European Union, yeah.



STEVE:  Oh, yeah, yeah.  I mean, this is really - this is really a disaster.  I mean, what we're going to see, and I'm getting ahead of myself a bit here, is that it seems very clear that the NSA came to them and said, let's work together, and don't worry, it's all going to be secret.  And it's not now.



LEO:  Well, but they may have also come to them and said, we're going to work with you, and don't worry, it's going to be secret.  I mean, they may have said you want this Skype thing to go through?  How do you feel about - we don't - I think the government has far-reaching powers that may not be fully acknowledged.  And I don't think they'd be hesitating to strong-arm them and say, look, you're not going to get approval on this Skype acquisition unless you cooperate.



STEVE:  Oh, oh, you mean the acquisition.



LEO:  Yeah.



STEVE:  Wow.



LEO:  That's about when this happened.



STEVE:  Yeah.  Actually, well, the work on reengineering did predate the actual purchase.  But you're right, these things don't happen overnight.  I mean, surely there was six months of discussion going on.



LEO:  Right.  Well, and Skype was not a United States company until acquisition.



STEVE:  Correct.



LEO:  It was, I believe, was in Holland.  So I don't know.  I'm just saying we don't know how much pressure Microsoft was under to comply.



STEVE:  So the Guardian says the files that they have "show that the NSA became concerned about the interception of encrypted chats on Microsoft's Outlook.com portal from the moment the company began testing the service" last summer, July of last year.  "Within five months, the documents explain, Microsoft and the FBI had come up with a solution that allowed the NSA to circumvent encryption on Outlook.com chats."  So again, this is saying that the NSA is intercepting and tapping outside of Microsoft, but they're concerned that chats are going to be encrypted, and so they work out a way to solve that problem.



LEO:  Gee, Skype was owned by eBay, wasn't it, before it was sold.  So it was a U.S....



STEVE:  And wasn't it originally Israeli?



LEO:  No, it was the guys who did, of all things, Kazaa.



STEVE:  Yeah, that's right.  That's right.  Yes, yes, yes.



LEO:  It was peer-to-peer.  And they were from Luxembourg or somewhere.  I can't - anyway, non-U.S.  But it was eBay owned when Microsoft bought them.  You know, I could totally see the Justice Department, concerned about Skype being used and them not being able to tap it, and going to eBay and saying, look.  You want to get rid of this, don't you?  We can help.  We're going to go to Microsoft.  Let's work something out.



STEVE:  Oh, Leo.  Oh.



LEO:  Why not?  I mean, you have to understand, the guys who are doing this are not doing this out of evil intention.  They're doing it to stop terrorism.



STEVE:  Correct.



LEO:  And they feel, perhaps even legitimately, that this is something they need to do.



STEVE:  Well, I'll bet you that they are tapping communications of known bad people who are using Skype.  And they're frustrated.  They're frustrated to death that they...



LEO:  Well, they've talked about this a lot.



STEVE:  Yeah.



LEO:  This is their inability to tap these new electronic communications are very concerning to all law enforcement.



STEVE:  The "going dark" problem.



LEO:  But I think the big issue is federal law enforcement charged with fighting terrorism.  And it's hard, if a guy from the FBI comes in and says - the director of the FBI comes in, says you've got to help us fight terrorism.  It's hard to say no.



STEVE:  I, yes, I completely agree with you.



LEO:  Do you want to be the company that then the director of the FBI says, oh, by the way, we got no cooperation from these U.S. companies.  And as a result, this terrorist act was planned using Skype.  You don't want that.



STEVE:  No.



LEO:  So I don't - I wouldn't cast aspersions or blame on Microsoft.  I think it's important we understand what they're doing.



STEVE:  Yes.  They said also, "Another newsletter entry stated that NSA already had pre-encryption access to Outlook mail.  'For PRISM collection against Hotmail, Live, and Outlook.com emails will be unaffected because PRISM collects this data prior to encryption."  So there we are.  They're upstream, outside of - basically this is the problem we've discussed now several times about email, that the underlying protocol, SMTP, by which it moves across the Internet from server to server, is almost never encrypted.  Not absolutely never.  It can be.  But that requires an agreement at each end.



And, for example, remember, of four major email providers, only Google offers SMTP encryption.  Specifically, Outlook and Hotmail don't.  And Yahoo! doesn't.  And there's a fourth one, too, I can't remember.  But so only Google does, meaning that there isn't going to be encryption on SMTP going in or out of Outlook.com or IE Hotmail because it's not available at the server.  Which means they've got access to it.



Then it says:  "Microsoft's cooperation was not limited to Outlook.com.  An entry dated 8 April" - this year - "2013 describes how the company worked 'for many months' with the FBI, which acts as the liaison between the intelligence agencies and Silicon Valley on PRISM, to allow PRISM access without separate authorization to its cloud storage service SkyDrive."  Now, that's also new.  I mean, if true.



"The document describes how this access 'means that analysts will no longer have to make a special request ... for this, a process step that many analysts may not have known about.'"  So, "The NSA explained that 'this new capability will result in a much more complete and timely collection response.'  It continued, 'This success is the result of the FBI working for many months with Microsoft to get this tasking and collection solution established.'"



Now, I can't read - we can't technically parse that to understand what it means.  Unfortunately, the documents are NSA sort of capabilities overview summaries.  So they don't explain how this happens.  But, I mean, what we have in quoted terminology says that the FBI is the interface arm of PRISM, and they were working to establish access to SkyDrive of some sort.  Despite the fact that Microsoft furiously denies exactly that.



And then it says:  "A separate entry identified another key area of collaboration.  'The FBI Data Intercept Technology Unit" - that's the acronym I was mentioning, DITU - "team is working with Microsoft to understand an additional feature in Outlook.com which allows users to create email aliases, which may affect our tasking process."  So that was where they were talking about working on arranging to disambiguate aliased identities in Microsoft.  And then I have some stuff here about Skype, but we've already covered that.



Microsoft immediately, the same day these documents came out, briefly responded.  And so the first response was, in response to an article - this is Microsoft speaking.  In response to an article in the Guardian on July 11th, and this response is dated July 11th, Microsoft issued the following statement.  And this is - I'm reading from the press release on Microsoft.com:  "We have clear principles which guide the response across our entire company to government demands for customer information for both law enforcement and national security issues.



"First, we take our commitments to our customers and to compliance with applicable law very seriously, so we provide customer data only in response to legal processes.  Second, our compliance team examines all demands very closely, and we reject them if we believe they aren't valid.  Third, we only ever comply with orders about" - so far this pretty much says nothing - "comply with orders about specific accounts or identifiers, and we would not respond to the kind of blanket orders discussed in the press over the past few weeks, as the volumes documented in our most recent disclosure clearly illustrate.  To be clear, Microsoft does not provide any government with blanket or direct access to SkyDrive, Outlook.com, Skype, or any Microsoft product.



"Finally, when we" - oh, and here's this line - "when we upgrade or update products, legal obligations may in some circumstances require that we maintain the ability to provide information in response to a law enforcement or national security request."  I wonder if that includes upgrading SSL keys.  Anyway...



LEO:  Uh-huh.  Uh-huh.  Well, it certainly, well, here's the point:  It lets them off the hook.



STEVE:  Yeah.



LEO:  Right?  So if they wanted to, they could.



STEVE:  Yeah.  "There are aspects of this debate that we wish we were able to discuss more freely."



LEO:  But they can't.



STEVE:  "That's why we've argued for additional transparency that would help everyone understand and debate these important issues."  Okay.  And then, finally, yesterday came - this is from Brad Smith, general counsel and executive vice president, legal and corporate affairs,  Microsoft.  He says:  "Today we have asked" - so this is dated - this is yesterday, July 16th.  "Today we have asked the Attorney General" - and I guess that's Eric Holder - "of the United States to personally take action to permit Microsoft and other companies to share publicly more complete information about how we handle national security requests for customer information.  We believe the U.S. Constitution guarantees our freedom to share more information with the public, yet the government is stopping us.  For example, government lawyers have yet to respond to the petition we filed in court on June 19 [so nearly four weeks before] seeking permission to publish the volume of national security requests [just how many] we have received.  We hope the Attorney General can step in to change this situation."



LEO:  Same thing as Facebook and Google are trying to get them to do.



STEVE:  Yes.  Yes.  "Until that happens, we want to share as much information as we currently can.  There are significant inaccuracies in the interpretations of leaked government documents reported in the media last week," referring to the Guardian drop of news.  "We have asked the Government again for permission to discuss the issues raised by these new documents..."



LEO:  Okay.  That does have to be frustrating.



STEVE:  Oh, my goodness.



LEO:  Because the documents are out there, and they can't legally respond.



STEVE:  Right.



LEO:  Yeah.



STEVE:  And they said "...and our request was denied by government lawyers.  In the meantime, we have summarized below the information that we are in a position to share, in response to the allegations in the reporting."  So he says:  "Outlook.com (formerly Hotmail):  We do not provide any government with direct access to emails or instant messages.  Full stop," he wrote in a separate sentence.  So he says, "We do not provide any government with direct access to emails or instant messages, full stop."  Now, we can parse that.  What does "direct access" mean?  Because if any of what the Guardian said was accurate, and if there is filtering and capture technology standing outside of Microsoft, and it really looks like there is, then it could be that encrypted traffic is captured, and then letters are sent compelling Microsoft to provide the ability to decrypt it.



And so again, so if we parse this that way, then it's not blanket.  It's not everything.  And there's no direct access to Microsoft's backend, yet the same is achieved, essentially, but not on a wholesale basis, but rather on a NSA is grabbing it, can't decrypt it until they ask, until they send Microsoft a letter saying we wanted to decrypt this which we grabbed going off in this direction to somebody who we believe is a foreign person and is an entity of interest.



Then Microsoft continues:  "Like all providers of communications services, we are sometimes obligated to comply with lawful demands from governments to turn over content for specific accounts, pursuant to a search warrant or court order.  This is true in the United States and other countries where we store data.  When we receive such a demand, we review it; and, if obligated to, we comply.  We do not provide any government with the technical capability to access user content directly or by itself."  And we know they don't have to.  It doesn't have to be provided because all the NSA has to do is tap it upstream.



"Instead, governments must continue to rely on legal process to seek from us specified information about identified accounts."  And he goes on.  I'm going to skip the rest of it.  But so this is the position they're in.  And so you can - that does sound like they're - some of this is very carefully worded to be technically accurate, but also misleading, and that they really do want to talk more, and the government is saying no, you cannot.



So, I mean, I really do feel like this is really damaging the companies that are alleged to be complying to the degree that we were told they were four weeks ago; that they want to clarify it.  And this podcast probably is clarifying it, but of course it's not official, it's just conjecture based on the technologies that we understand.  And here's Microsoft's counsel saying we're directly asking the government, please let us respond to these damaging news reports.  They are truly damaging us.  And the government says, no, you can't.  And you'll remember, Leo...



LEO:  It's so hard to know who to believe because of course...



STEVE:  Yeah, it is.



LEO:  ...the slides imply very directly, clearly, that there is in fact full government access to - directly to the servers.



STEVE:  They say that, yes.  They say that.



LEO:  And it's probably the case that, if that were true, those companies couldn't say it was true.  On the other hand, their blanket denials imply - I don't think there's anything requiring them to blanket deny it.  Who knows.



STEVE:  Correct.  And remember, last time, last week I took the position that, I mean, the technology required to allow a third party's systems to go in and interpret encrypted databases is significant.  So...



LEO:  Somebody in the chatroom brought up the concept of a panopticon.  This was a prison designed in the 18th Century, never built, but designed in the 18th Century by a guy named Jeremy Bentham, the idea of which was that every prisoner could be observed by the guards, but without the prisoners' knowledge of whether they were being observed, the point being to create this impression that you could be observed at any time, anywhere, and you never knew whether you were or weren't, and that that would ensure good behavior.  And the philosophical - it's the philosophical basis for the notion that the government wants us to know this stuff because what they'd like to do is create this impression that in fact everything is being observed, collected.



STEVE:  We are in a surveillance state.



LEO:  Yeah.  Whether we are or not, they want to create the impression.  It is in their interest to create that impression.



STEVE:  Boy, it's really upsetting people, Leo.



LEO:  It's very upsetting.  It's very upsetting.  And it's not - it's not upsetting if you assume that the government is benign and the information they're gathering is for purposes of fighting terrorism.  It's only upsetting if you think that perhaps it might always not be that way.



STEVE:  My favorite quote came from someone who tweeted this, and I shared it before.  But it's even still being echoed by people who are catching up with my feed on Twitter.  "I have nothing to hide from people I trust."



LEO:  Right.



STEVE:  That just says it.  It's like, "Well, if you have nothing to hide, why are you encrypting?"  I have nothing to hide from people I trust.  So speaking of people we trust, you'll remember that in the first PRISM podcast I really - I was so upset with the testimony that James Clapper gave that we played it into the podcast, where he responded to Ron Wyden, "No, we're not collecting any data on American citizens, not deliberately."  Or "not wittingly," was his word.



Anyway, so the Guardian posted something, and then I found some further, I think it was in the Huffington Post.  Now Clapper, James Clapper, the Director of National Intelligence, yeah, DNI, Director of National Intelligence, he is the DNI, he said:  "I gave 'erroneous'" - he's now calling his answer "erroneous" - "because I forgot about the Patriot Act."  And so...



LEO:  Seems an odd thing to forget about.



STEVE:  Yeah, this is the headline:  "I gave 'erroneous' answer because I forgot about the Patriot Act."  And then the subheading of the Guardian story was "Intelligence chief tries to explain false Senate testimony by saying he 'simply didn't think' of NSA efforts to collect..."



LEO:  That's stupid.



STEVE:  Yeah, we're going to believe this.



LEO:  It's so stupid.



STEVE:  Oh.  And then the story reads:  "The most senior U.S. intelligence official told a Senate oversight panel" - this was a month, so this is recently, after the first Snowden revelations - "that he 'simply didn't think' of the National Security Agency's efforts to collect the phone records of millions of Americans when he testified in March that it did 'not wittingly' snoop on their communications."



Continuing:  "James Clapper, the director of national intelligence, made the comments in a letter to the Senate Intelligence Committee, released in full for the first time [yesterday] on Tuesday.  Portions of the letter, in which Clapper apologized for giving 'clearly erroneous' testimony at a March hearing of the committee," which was the snippet that we played, "were first reported by the Washington Post on Monday.  Clapper had previously said that his answer to the committee was the 'least untruthful' one" - and of course our boys on Comedy Central had a ball with that - "that he could publicly provide.



"In the full letter, Clapper attempted to explain the false testimony by saying that his recollection failed him.  'I simply didn't think of Section 215 of the Patriot Act,' he wrote to Committee Chairwoman Dianne Feinstein on June 21st, referring to the legal provision cited to justify the mass collection of Americans' phone data, first disclosed by the Guardian."



And the thing that makes this so ridiculous is that he was notified ahead of time that this question was going to be posed.  And then afterwards, after lying, clearly lying, he was - Wyden's office contacted him again and said, you know, do you want to correct the record?  And they said no.  So I just wanted to wrap up that little tidbit.  Meanwhile, the federal government has been disinvited to DefCon.  At the end of this month...



LEO:  They can still go, they just can't go officially.



STEVE:  At the end of this month, beginning of next month - yes.  They can sneak in.  But so Infosecurity magazine covered the story, said:  "As the annual DEF CON event prepares to launch in Las Vegas on August 1, 15,000 hackers are planning to descend upon the hot desert landscape.  Organizers have however warned federal agents, government security staffers, and law enforcement agents that their particular presence is not required.



"In a post titled 'Feds, We Need Some Time Apart,' conference founder Jeff Moss noted on the event website that a 'time out' is in order in the wake of the uncovering of PRISM, the widespread computer surveillance program that has been operated by the U.S. National Security Agency since 2007."  And that was when Microsoft first got involved, according to the documents.



And so remember that we have DEF CON and Black Hat, and those are adjoining conferences.  And General Keith Alexander has not been disinvited and is in fact a keynote speaker at Black Hat.  And Keith Alexander is famously the director of the NSA, in addition to being - and this was probably his main focus for Black Hat, was he's the commander of the U.S. Cyber Command, USCYBERCOM.  And so he's still on the agenda.  And so he will be speaking.  I imagine it'll be a rather boilerplate presentation, slide presentation about cyberwarfare and cyber contingencies and so forth, as befitting Black Hat.



But as for DEF CON, I mean, traditionally it's been a, yay, come on in, we're all in this thing together.  And the federal government's various agencies presented their credentials without any concern.  And not so much this year.  Okay, now...



LEO:  Which, by the way, is meaningless because they just go.  There's plenty of contractors.  You think Edward Snowden, an Edward Snowden from Booz Allen wouldn't go, or wouldn't be able to - of course.



STEVE:  Exactly, yeah.



LEO:  Yeah.  So, nice idea.



STEVE:  Now, this story - this story, Leo, is so bizarre that I thought it had to be a hoax.  And I pursued it back to its source, and apparently it's true.  Some offices in Russia are switching to typewriters because they've just given up.



LEO:  You know, I know ABC or NBC or somebody repeated this.  I just don't buy it.  But anyway.



STEVE:  I know.  I know.  But we have a photo of it now.  We know the model number of the typewriter.  I mean, yes, you can embellish the hoax...



LEO:  I trust no news coming out of Russia.  Come on.



STEVE:  Yeah.  So what we're led to believe, because this is just too funny, whether it's true or not, the "Kremlin returns to typewriters to avoid computer leaks."  Subhead, "The Kremlin is returning to typewriters in an attempt to avoid damaging links from computer hardware, it has been claimed."  So even the news guys are saying, okay.  So it says:  "A source at Russia's Federal Guard Service (FSO), which is in charge of safeguarding Kremlin communications and protecting President Vladimir Putin, claimed that the return to typewriters has been prompted by the publication of secret documents by WikiLeaks, the whistleblowing website, as well as Edward Snowden, the fugitive U.S. intelligence contractor.



"The FSO is looking to spend 486,000 roubles" - which actually doesn't buy you very much, around $15,000 - "on a number of electric typewriters, according to the state procurement agency.  The notice included ribbons for German-made Triumph Adlew TWEN 180 typewriters, although it was not clear if the typewriters themselves were of this kind."  So maybe they should just switch to Linux, rather than that.



LEO:  Yeah.  I don't think typewriters are more secure.  Not at all.



STEVE:  No.  No, in fact we know that, not only - well, and there was some actual - the story goes on to talk about how there's an advantage, which actually sounds a little more, makes it even sound a little more ridiculous, that you can always identify the source, the particular typewriter that types a document.  And of course we know you can also identify the particular printer that printed the document because of the little yellow dots that are scattered around in a given pattern.  So...



LEO:  It's just, you know.



STEVE:  I wanted to correct the record.  Thanks to...



LEO:  Yeah, Pilot Sum Ting Wong was flying the Asiana Air...



STEVE:  Oh, my god, did you see that, Leo?



LEO:  Unbelievable.



STEVE:  Oh, goodness.  Along with Wi Tu Lo, who was the copilot.



LEO:  Yeah, it's "Anchorman" in real world.  The moron newscaster just read what she saw on the prompter.



STEVE:  And being sued for it now.



LEO:  And rightly so because that's absurd.  Although apparently a summer intern at the NTSB did in fact confirm it.  We're talking about Channel 2, local news operation, which is normally a pretty good news operation, although all local television news is ghastly.  But their noon news - and I even know this anchor.  The anchor read clearly prank names for the four pilots of the plane that crashed in San Francisco.  You know, Sum Ting Wong, Wi Tu Lo.  They were offensive.  And if she was not a complete idiot, she would have noticed the minute she started saying them, and if she had had any brains would have said, no, no, no, this is wrong.  I'm not going to read this.  We're moving on.



STEVE:  And they were up on the...



LEO:  They were on the screen.



STEVE:  They were up on the screen.



LEO:  I thought it was an Onion thing until I saw that it was true.



STEVE:  I know.  I didn't believe it.  A buddy of mine sent me the link.  I said, no, come on.



LEO:  Ron Burgundy lives.  Unbelievable [laughing].  Anyway, I believe that story as much as I believe typewriters in Russia.



STEVE:  Yeah, good.



LEO:  I don't - you know, the mainstream news is so godawful nowadays, I don't trust them.  Just use your brain.  It doesn't make any sense.  Go ahead.



STEVE:  No, no.  Okay, here's what does.



LEO:  Yes.  I listen to Steve.  I trust Steve.





STEVE:  I got a tweet from one of the developers of Adblock Plus, who wanted to explain.  He sent me a link to an image which, Leo, you can bring up:  eyeo.com/images/acceptable-ads-facts.png.



LEO:  Okay.



STEVE:  Because last week we reported on a story in TechCrunch.  TechCrunch was saying Google and others reportedly pay Adblock Plus to show you ads anyway.  And that's where I had said, you know, that annoys me.  And right in the options there you can turn that off.  So here's the story:  Five Facts About Acceptable, what they call "Acceptable" Ads, which is a term of art for them.



They said, before we get into the five points:  "Online ads are annoying.  That's why millions of people love Adblock Plus.  However, ads play an important role in keeping content and services free on the Internet."  And there's no denying that.  I will argue that tracking doesn't, but ads certainly do.  Continuing with their note:  "For this reason, Adblock Plus started an initiative in 2011 called 'Acceptable Ads,' which aims to create a middle ground for websites and users, while keeping control firmly in the users' hands to determine how they want to experience the web."  That's all we want.



"Here are five key facts about it:  First, Acceptable Ads is only about unobtrusive advertising, usually small text links, the kind preferred by most users.  Banners, video ads, pop ups, et cetera, will NEVER" - all caps, their emphasis - "be allowed.  There is no way to 'buy' a whitelisting."  Which goes against what the headline was, the way TechCrunch reported this.  "There is no way to 'buy' a whitelisting.  If ads do not meet our criteria, they can never be whitelisted.  Our open community of over 27,000 members has the final say in whether ads comply with the rules, and the rules are completely unambiguous.  Third, whitelisting is free for small websites.  Only larger corporations pay."



LEO:  Well, I'm confused.  You can't buy a whitelisting, but corporations can?  Doesn't that contradict No. 2?  There's no way to buy a whitelisting.  Only corporations pay.  These are contradictory items.



STEVE:  "Whitelisting is free for small websites.  Only larger corporations pay."



LEO:  There's no way to buy a whitelisting, says Item 2.  No. 3, only corporations pay.



STEVE:  Well, somebody can figure that out.



LEO:  What they're saying is you can't buy a whitelisting if ads do not meet our criteria.



STEVE:  Correct.  There's no way to purchase around the criteria.



LEO:  However, there is a way to buy a whitelisting.  Pay us, and have the ads meet our criteria.



STEVE:  No.  If you want to be - if you're a large corporation, we will ask you to fund our effort.  And if your ads meet the criteria, then we will add you.  So large corporations have to pay to have acceptable ads accepted.  Small companies don't.  Yeah, so that does fit.



LEO:  Yeah.  Well, okay.



STEVE:  Hey, I love Adblock Plus.  Okay.  "Four, about 80% of all Adblock Plus users like Acceptable Ads."  And mine's turned again, by the way, because I have no problem with this.



LEO:  So you can't pay - unless you're a big corporation you can't pay.  And by the way, everybody likes it anyway.



STEVE:  80% does.



LEO:  80%.



STEVE:  And there's a checkbox.  "They view it as a fair balance" - the users, 80% - "as a fair balance between their interests and the interests of website owners and publishers."  And, finally, and for those who want to block ads of all kinds, every Adblock Plus user has a choice at any time to switch off acceptable ads with just one click in the Options menu."  So anyway...



LEO:  And that is true.  You can click that box, and you will never see any ads.



STEVE:  Yes.  And I've never turned mine off before.  I have Adblock Plus on all of my browsers, and nothing is ever jumping around and annoying me.  And I have ads on my pages.  They're just not crazy.  Sometimes I use someone's browser without it, and it's like, oh, my lord, is this what people view?  No wonder they're crazy.  Anyway, so, yes.  Are we done?



LEO:  Moving on.



STEVE:  I think it's fine.  Lavabit.com.  So what I got was a number of people - and I never found the story or where it was claimed that Snowden was using Lavabit.



LEO:  I know.  I never saw it, either.  I just read it.  It was all secondhand; right.



STEVE:  Yeah.  Yeah.  So I saw - and I thought, huh, what's Lavabit?  That's interesting.  So I did a dive into it to figure out what the story is.  Now - oh, and so I was - so what was tweeted was that Edward Snowden was using Lavabit, as if that was some wonderful, super-secure solution for email.  So of course I went there to find out what the story is.  And it's not.  Because it actually can't be.  And what I thought I remembered, and then I did go back and track that down, was that Greenwald was actually given, like, was given his initial communications months before this happened.  Snowden was trying to get him to use encryption of sufficient strength, and it was just because Greenwald wasn't a techie that they were unable to do that.



So anyway, okay, so here's Lavabit.  Lavabit, what Lavabit offers is very well-designed encryption at rest.  Which is to say that your email on their servers, they're an email service company.  So they offer ad-embellished email for free, or you can pay a nominal sum, like $8 a year, it's very inexpensive, and get an account with Lavabit.  And they will encrypt your email on their servers.



Now, they overstate, in my opinion, the value of that because they're saying they cannot comply with letters to compel them to turn over your email, which I believe.  But they are able to decrypt it when it comes in and when it goes out because the email itself is not encrypted.  Now, they do offer SSL connections between your email client, if it supports SSL, and their server.  So you would have an encrypted connection to them.  And when you log in with your username and password, that information they themselves receive.  Then they hash it, salt it, and use that as the key for decrypting - I'm sorry, as the key, yes, for decrypting the private key, which is then used to decrypt your stored email in order to send it in the clear back to you over SSL.  But at that time, they have it.  It's available to them when it's sent to you for you to receive it.



Incoming email - and this is the clever part.  Incoming email to you comes in, of course, unencrypted because email is, by default, a nonencrypted protocol.  They use your public key, which they keep in the clear, to encrypt incoming email, to store it so that only you are able to pick it up and decrypt it.  So I give them credit for doing something, for storing it in an encrypted format, which they then need you to log onto your account in order to decrypt the key that gives them access to it so they can decrypt it and send it to you.  So it's like, eh, it's better than nothing.  And so it's encrypted at rest and decrypted when you pick it up.  And if you're sending email out through them, then it would never be encrypted because they would have to - you use SMTP to send the mail to them outgoing somewhere else.  So they would not encrypt it, and it would not be encrypted when they send it.



So it would be incoming email to you, encrypted while it's stored, waiting for you to pick it up.  That's what they offer.  And maybe Snowden used that.  I mean, it sounds like he would, except we also know, and I have since verified, he uses Leo's favorite email encryption, which is PGP.



LEO:  Yeah.



STEVE:  And I found an article in The Huffington Post to fill in the facts, that "Edward Snowden first approached the Guardian's Glenn Greenwald in February," so many months before this was finally divulged, "and, by the journalist's account said he had information" - that is, Edward did - "'that would be of great interest.'  But there was a problem.  Snowden only wanted to communicate securely using PGP encryption, for which Greenwald didn't have the proper software installed at the time.  In an interview with The Huffington Post, Greenwald acknowledged that he's no expert in using such technology and said that Snowden even provided a step-by-step email and video to help secure their communication.  At that point, however, Greenwald didn't know what his would-be source had - or might not have - and continued to prioritize other stories" ahead of Snowden's.



So of course the benefit of PGP, I mean, that's - you need to use end-to-end encryption.  It's better than nothing to have it stored encrypted, but it's going to be decrypted when it's sent to you.  And of course what PGP does is it provides local pre-Internet, PIE, as we've the acronym, PIE, Pre-Internet Encryption, so that it's encrypted in your computer as it leaves your browser, and then it doesn't matter who has it along the way, or who stores it in the clear.  It's just noise.  It is pseudorandom noise.  Then only when it goes to the recipient who has access to your public key are they then able to decrypt it, so using - in standard PGP style.



LEO:  We should do a how-to on using...



STEVE:  Yeah, we ought to.  Or maybe on one of...



LEO:  Yeah, maybe one of the other shows or something.  I could do a special.  I recommend GNU Privacy Guard, which is an open source, open PGP...



STEVE:  GP - GPG. 



LEO:  GPG.



STEVE:  Reverse the letters, GPG.



LEO:  Yeah, it's at GnuPG.org.  And it's very easy to install.  There's Mac and Windows installers.  It's not hard.  The only negative, as we talked about last week, is that it's not signed by any third party.  It's not certificate ensured.



STEVE:  Right.



LEO:  So you get other people to sign your key, and you sign their key.



STEVE:  And it's person-to-person.  And so if I wanted to send email to you, I would use your public key to encrypt the email so that only you with the matching private key would be able to decrypt it.



LEO:  Exactly.



STEVE:  And then we've got point-to-point encryption.  And, I mean, bulletproof.  I mean, absolutely.  You need to get the key exchange made in a secure fashion.  So...



LEO:  Well, there are key servers, and that's one of the nice things about GNU Privacy Guard and PGP in general is MIT and others run key servers that you can go to.  And if you know somebody's key thumbnail or whatever, you can download their key.



STEVE:  Yeah.  And again...



LEO:  You can also put it on your website, if you want.  I mean, you know.



STEVE:  Right.



LEO:  I think it would be better probably just to put it on the MIT server.



STEVE:  Yup.  So a little bit of news about Google Authenticator.  And I don't know if they're going to fix this.  I don't know if Google - or how much they care that iOS7, the current beta, breaks Google Authenticator.  There's been a lot of information and thread about this.  And Google Authenticator has not been updated since 2011, for two years, which leads some people to believe that maybe it's abandonware.  I hope Google fixes it, or maybe that iOS7, when it's finally done, won't break it.  What happens is it just loses your settings and your sites.  And apparently, even if you put them back in, it then doesn't retain them.  So it's a problem.



And in the discussion thread about this over on code.google.com about Google Authenticator, two alternative authenticators have been suggested which are compatible.  They still use the One-Time Password, the open technology.  And it's one that - one of them referred to there is one that I have talked to our listeners about already, which is really pretty, and that's HDE OTP, available on iTunes.  And then one that also looks nice that I hadn't seen before is called Authy, A-u-t-h-y.  And that's at www.authy.com. 



So if you're using Google Authenticator on iOS platform, and you upgrade to iOS7 when it happens, and there isn't a fix for it before then, it may be necessary to look for an alternative.  And these two work just fine under iOS7.  So I don't know what's wrong with...



LEO:  Oh, they'll fix that.  That's...



STEVE:  I would think so.



LEO:  Remember, iOS7 is beta.  Nobody's supposed to be using iOS7.  It's beta for developers only.



STEVE:  Right.



LEO:  It'll be fixed.



STEVE:  Also, BitTorrent Sync.  I'm still waiting for the formal documentation from them of their protocol, but we'll talk about them, come back toward the end of the show, talking about things that I think that seem to me to be - I would call them "open intent."  Yesterday they just went to v1.1.42.  Android support has been added.  Ars Technica just reported hours ago that it had moved from alpha to beta.  I was contacted by them last week by their communications guy, his name's Christian, says, "Hey, Steve, we will be at beta, out of alpha at beta on Tuesday."  Looks like that was a day later than he expected back then.  But apparently it has happened.  So it's moving forward.  Android platform now.



And then I tweeted a link, in case anyone is interested in following up on this, or people who don't follow me on Twitter wouldn't know that someone who's in charge of their communication or their - his name is Dan Brown, BitTorrent's digital creative manager.  I guess Ars Technica was where I found out about this.  Then I went to his blog post.



And he said:  "I've been using BitTorrent Sync for syncing several gigabytes of RAW photos" - R-A-W photos, meaning big - "and video across my various machines," wrote Dan Brown.  "There is the occasional scenario, however, where I've wanted to grab a few files, but my other machine is turned off. To solve this problem, I'm using a Raspberry Pi as a low power, always-on device with Sync installed."  So BitTorrent Sync installed in his Raspberry Pi.  "Just for kicks, I'm also using ownCloud" - which is an open source cloud - "to provide me with a web interface for accessing my files from any computer, including my mobile phone."



And so what I have is - and I just tweeted this, so you could go to Twitter.com/SGgrc, and you'll find it.  Because he's blogged the step-by-step process.  And the blog is "How I Created My Own Personal Cloud Using BitTorrent Sync, ownCloud, and Raspberry Pi."  So I know that there's a huge interest in Raspberry Pi because it was such an incredibly inexpensive and cool little platform.  And if you've ended up not doing something with it, here's a way to use, basically to create a truly Trust No One point-to-point cloud, and give you Raspberry Pi something to do.  Which I think is cool.



And I responded to Christian with this news, saying, "Christian, thank you for the update.  I will share it with our listeners.  But I still want the public protocol, the protocol to be released publicly."  And he said yes, you know, as soon as they can do it they will.



And then totally off the path, except that this, I actually saw this happening, was Network Solutions was down, off the air under a DDoS attack for about an hour this morning.  Which caused a lot of pain for people who are hosted by Network Solutions.  And in Network Solutions' own Facebook posting - they needed to put something somewhere, they could tell people what was going on - they said "Network Solutions is experiencing a Distributed Denial of Service attack that is impacting our customers as well as the Network Solutions site."  And that's the case.  I was unable to get to their site.



"Our technology team is working to mitigate the situation.  Please check back for updates."  So there were many people who, as I said, are hosted, they've decided just to have their websites hosted by Network Solutions, and all of those sites were blown off the 'Net during this.  Yeah, I had not seen that before.



We spoke last week of Hemlis, which "hemlis" is the word that means "secure" in Swedish.  They were rapidly achieving full funding.  It took them less than two days to cross the 150% point, at which they closed down.  They went 50% over, and they closed down their offering for early funding.  And these are the simple, beautiful, secure instant messaging people.  One of them was the cofounder of the Pirate Bay.  And a nice little video online.  And I gave them 50 bucks last week before the podcast.  And a lot of people were interested in what they had to offer.  So they very quickly generated more than $150,000, and they're going to move forward and create the product, which is cool.



Update on SmushBox, which, Leo, you and I talked about.



LEO:  Yeah, where is our SmushBox?



STEVE:  Where's our SmushBox?



LEO:  I want my SmushBox.



STEVE:  On its way, apparently.  Well, not actually shipping, but moving forward.  They received their cases.  And I got email from them with a photo of all of the cases, the exterior extruded aluminum cases, sitting there on a big table.  So they're moving forward.  There's been an ongoing interest that really pleases them because they intend to commercialize this after they fulfill all of their Kickstarter early purchaser requests.  And so they're pleased that it looks like they've got a product coming.



And also, remember that we spoke quite a while ago about a movie that a local movie producer, Jonathan Schiefer, wanted to put together called "The Root Kit."  And he had attempted to launch it over on Kickstarter.  I think he was going for $50,000 and fell short of the goal in the period of time that he had allotted, and so it didn't happen.  Well, he's back.  And I looked at his video, which he has on his relaunch.  He actually sent a letter which indicated he would never do another Kickstarter project because apparently it just was a huge time sink to babysit Kickstarter for whatever reason.



LEO:  It's a lot of work, yeah, yeah.



STEVE:  Yeah, and he just said, okay, never, never, never again.  But he's back.  He's rewritten and has actually got his screenplay that can be downloaded by anybody who's curious.  What he's doing now is he's over at Indiegogo.com with a project called "Algorithm."  And the movie will be called "Algorithm."  He wants to presell the Blu-ray and DVD for the movie "Algorithm," use that to generate $30,000, which will finance the production of the movie and the production of the DVDs for all the people who want to see the movie.



So he said, "What's it about?  A hacker-for-hire discovers that the government monitors everything we do.  He and his friends fight back.  'Algorithm' is a story with a message, and the message is that we are not powerless; that we can fight back; that more than money or guns or nuclear weapons, computers have leveled the playing field.  If you want to know more, you can read the screenplay."  And then he provides a link to it:  spiritusvult.com/algorithm.pdf.



So anyway, I wanted to give people the heads-up.  They can go to TheRootKit.com, or his new link is TheHackerMovie.com.  And that is a redirect, actually, over to the Indiegogo page, where you can watch a video that Jonathan has produced explaining his plans, why he has the ability to do this, and so forth.  And I want to see it.  So I gave him 25 bucks to prepurchase a copy of the Blu-ray and DVD.  And so any of our listeners who feel similarly are welcome to.



And I had another nice SSD success that I wanted to share with our listeners about SpinRite, from someone named Dennie Warren Jr.  And he wrote to our tech support guy, Greg.  He said, "I am by no means a tech geek, but I do listen to Security Now! as much as I can and learn something every time I listen.  I did go ahead and purchase a Lenovo W530 laptop and replaced the C-drive with a Crucial M4 SSD as the main drive because it was too small" - oh, the original drive was too small for his liking.



He said, "On July 14, 2013 at 9:45 a.m., I noticed that three updates were waiting for me."  Oh, so that was last week's Second Tuesday of the Month update.  "Three updates were waiting for me to install, so I clicked to install them.  When I returned to my laptop, it said that I needed to restart it, so I did.  Well, then my laptop notified me that it could not boot into Windows because the drive was inaccessible."  Ooh.  "Even though my machine was SSD-based, I purchased SpinRite 6 and created a USB boot drive to see if SpinRite could fix the issues.  After about 45 minutes SpinRite had finished working its magic.  I restarted my laptop, and it booted into Windows 7.  And it worked normally, as it did before it had crashed.



"I jumped to the ceiling of my home, screaming with joy, and told my wife that we're renaming our son 'Steve.'  I won't share her response [laughter].  I won't share her response to me except that she's glad for me to have my computer working again.  It's working as if nothing had ever happened.  I can't remember what kind of updates caused this crash."  Wow, I wonder if it was a problem with the updates because...



LEO:  No, no no no.



STEVE:  Probably not.  However...



LEO:  It's coincidental.  Whenever you're doing a lot of disk writing...



STEVE:  Oh, it is coincidence because SpinRite fixed it, and it wasn't a matter of removing the update.



LEO:  Right.



STEVE:  "However, tell Steve I said thank you.  He is the best.  He is the one thing" - oh, he says, "It is one thing to hear others say how much they like SpinRite.  But it's a whole other feeling to have your computer rescued by it.  Did I mention that Steve is the best?  Jay.  Kind regards."



LEO:  UOSD Wiz said he should have said rename him DynaStat [laughter].  Forget Steve.  Rename him DynaStat.



STEVE:  His wife would really have a problem.



LEO:  Honey?  Hey - go ahead.



STEVE:  One thing I wanted to add was that Elaine sent me a first.  So Elaine said, "Steve, you're not the only one getting testimonials <grin>.  Had to show this to you."



LEO:  Oh, that's nice.



STEVE:  So she received a letter, said, "Elaine, I am a subscriber/listener of Steve Gibson's Security Now! podcast.  I just want to personally thank you for the wonderful transcription detail and clarity that you provide for a niche technical (and at times complex) recorded broadcast.  Your thorough, accurate, and complete approach preserves the culture/humanity of the podcast, while also making archival episodes easy to search on Google, et cetera, post-broadcast for years to come.  Appreciated, Ross Blaettner, Subscriber, Security Now!."  And then he said, "P.S.:  You are more than welcome to use my commentary in a testimonial because you are certainly deserving of all such praise."



LEO:  That's nice.



STEVE:  So, yay to Elaine.  Shout out for her.  [Elaine says thanks, guys.]



LEO:  We say that every day.  Yay to Elaine.



STEVE:  We do.



LEO:  Hey, before we get - I think we should talk - the subject matter is How Much Tinfoil?



STEVE:  Yeah.



LEO:  And I think we're going to talk a little bit about what you can do to protect yourself.  We've talked a little bit already.



STEVE:  What you should do, what's overkill, and so forth.



LEO:  Yeah.



STEVE:  In other words, how much tinfoil do you need?



LEO:  How thick does it have to be?



STEVE:  Yeah.



LEO:  Now, Steverino, let's get a little tinfoil.



STEVE:  Yeah.  I was trying to think, what would be the sequence that law enforcement would use if they wanted to access stuff that is available to them and is encrypted.



LEO:  You know what hackers say is first you get the dox, d-o-x.  And that's information:  date of birth, address, IP address, ISP.  The more you know; right?



STEVE:  Well, yes.  Right.  So you would learn where the target's traffic was transiting, and then you would tap that.  So you would collect traffic, and you would look at the IPs that the traffic was bound to.  You would know that it was coming from the target.  You would look at the IP addresses of where it was bound to.  And that would tell you, oh, this is going to Google Drive or - SkyDrive or Google Drive or email.  They're using Yahoo! as their email account.



So the idea would be you'd collect the traffic at the source to determine, like, what cloud providers they have chosen.  Then you'd go to the cloud provider and say, encrypted traffic was going to you.  We need you to decrypt it for us.  I mean, that would be the sequence of events.  So, okay.  So it's very clear that, first of all, many people aren't worried about this at all.  They go, well, okay.  I mean, and you've expressed an opinion, Leo, sort of one of resignation.  It's like, well, we're in a surveillance state.  That's going to happen.  There's tapping going on, and so that's - so we live with it.



It's clear that something is going on with these major terminuses - Microsoft, Google, Yahoo!, Dropbox, Facebook, and so forth.  They're on the PRISM timeline.  We don't know in detail, and we probably never will, exactly, I mean, precisely technically what's happening.  But the damage that we referred to earlier, that seems to me is clear, to their reputation as a consequence of this is that, if people felt creepy that the NSA had chosen these major providers for PRISM, whatever that is, then why not use one that's not on the list?  Which, you know, seems like that makes some sense.  Use anything that isn't a major target because clearly the NSA, I mean, if they're doing, and they seem at least partially to be doing what I originally suggested that made sense, which is tapping upstream of these major guys, they chose those big guys because such a large percentage of Internet traffic has chosen them because they are Microsoft, because they are Google, because they're Yahoo! or Dropbox or whomever.  So this argues for not going with one of these big guys, just to stay off the radar, stay off of, you know, so that your traffic is not participating in PRISM by default.



Now, if you're a target, then the other end of your traffic, as I initially started talking about, would be intercepted.  Clearly they have the ability to do that.  So that's a different scenario than the rest of us who are not targets for any particular reason, but just don't like the idea of pervasive surveillance.  So they're the big guys.  But then we've also talked about - and those are like, I don't want to use the word "Tier 1" because that refers specifically to Internet traffic transit providers.  But these are top-tier corporate cloud products - Microsoft, Google, Yahoo!, Dropbox, and so forth, the big guys.  And they're going to be targets.



Then you have your second-tier providers that are - and, for example, in our cloud storage podcasts [SN-349, SN-350, SN-351], where we went through 15 of them or so, many of them have poor security models.  But they don't care.  They've got beautiful-looking websites.  And people go, oh, look how pretty their website is.  They must be nice people.  And so people use those as their cloud storage provider, although not offering a great deal of security.



And among those there were - there was clearly a few who focused on a TNO model.  And so that's really where - that's where I come back to.  I mean, that's where I'm - it's Pre-Internet Encryption.  It's PIE, one of the early acronyms, along with Trust No One, that we coined because it's always been clear that that's the only way to be secure is this stuff is encrypted before it leaves, and it is not decrypted until it comes back.  And so that immediately rules out the generic use of SkyDrive and Google Drive and storage at Yahoo! or Dropbox, which are not pre-Internet encrypted technologies.  They're very convenient.  They offer lots of features.  But if you're able to use some foreign browser and get access to your content through a browser interface, that's not pre-Internet encryption unless the way it works is that it downloads a decryption technology into that browser and then does local decryption.  But that's not the way these things operate.



So those guys don't have end-user security as their first issue.  And so for me, they're just - unless you pre-wrap everything you're storing with them with your own local pre-Internet encryption technology, don't even consider using them.  But if you do pre-wrap your data, by all means.  All they're storing for you is pseudorandom noise that they have absolutely no ability to decrypt.  So the NSA or whomever can go to them and say we want this person's data.  And they apply the encryption keys, and it changes it from one set of pseudorandom noise to another one and still tells them nothing.



So I look at the cloud providers who explicitly want to protect our data.  I mean, they see that's their mission.  Microsoft doesn't.  Google doesn't.  I mean, they're not protecting, they're providing no protection at all.  And Dropbox doesn't.  They're, oh, yeah, yeah, we're secure storage.  Baloney.  You may be secure against hackers, not secure against somebody who can send you a warrant and say we want to look inside.  So if we're going to do something, then it's about pre-Internet encryption.



And so when I look at BitTorrent Sync, yes, I wish we had an open protocol.  They say they're going to do that.  But it is, to me, their intent is obviously to create, in the case of BitTorrent Sync, a truly secure Pre-Internet Encryption, Trust No One technology that allows us to link our machines together for large filesharing.  Hemlis, same thing, all about this can be simple.  It can be beautiful.  We're going to create something for iOS and Android.  Here's our model.  We're not going to make it free.  We're not going to put ads in it.  So we're going to ask you for a little bit of money, and that's how we're going to fund the backend that we need for linking this stuff together.  It'll be encrypted before it leaves.  It'll be decrypted when it comes back.  And we're going to solve all the details.  To me, that's who we want to work with.



Threema, the thing that we've talked about a couple times, currently shipping.  And those are the guys that have the three dots.  You either get one dot, two dots, or three dots based on what level of authentication you have achieved.  And you only get the green three dots when the phones are facing each other and directly exchange keys.  Then you have absolute authentication, and your then-encrypted communications between iOS and Android devices always show with three green dots, and absolutely impossible for a third party monitoring your traffic to gain access.



And then Cryptocat, same thing.  We talked last week about the disaster with the poor coding in JavaScript of their multiparty chat.  But their point-to-point chat always was and is secure and uses an open protocol, which they have a good implementation of.  They just gave it a nice web browser interface.  And so to me, that's where I am is - it's like, yes, these things are not open source always.  Even LastPass.  LastPass did something I thought was brilliant, which was they explained to me exactly how it works, so complete open protocol.  Then they went further and said we're going to demonstrate that this is the way we're encrypting.  We're going to prove that what we just said was true by giving you a web page with JavaScript that does what we just said it should do, and you can see by putting your own data into this web page that it works, that you can decrypt your stuff with this web page.  This is the way it was encrypted.  So it was a proof of openness, essentially, that was like, okay, for me, this is exactly the right solution.  I mean, Joe designed this thing so that it achieves - it was using the cloud for synchronization, but it was 100% Trust No One and Pre-Internet Encryption.  I haven't audited the source.  I don't need to.



I mean, so when I talk about how much tinfoil, I guess I'm at a softer place, Leo, than the absolute "ism" of it's got to be open source.  I think if it's open protocol, if it's open agenda, and if every scrutiny of the effort says these are good people, then it's like, okay, you know, I'm comfortable enough with that.  I mean, first of all, I need nothing.  I need to encrypt nothing except my data.  For example, if I were using a cloud provider and putting - and actually, for example, GRC's corporate books are encrypted by Jungle Disk and stored at Amazon S3.  Still using Jungle Disk.  That's pre-Internet encryption.  It's TNO.  It's local symmetric key.  And there's no way I would let our corporate books leave our control for cloud backup unless it was pre-Internet encryption.  So there you absolutely want to use good encryption.



But I don't, you know, my text messages are just to my friends.  So I don't need it.  Although when point-to-point text messaging encryption becomes ubiquitous or easy to use, like Hemlis is making it and Threema have made it, then it's like why not?  It's just kind of cool.  Just a coolness factor.



LEO:  Yeah.  Well, I just exchanged - somebody who was listening, obviously, to the show got my key off the key server and sent me email using my key, which I decrypted.



STEVE:  Cool, yup.



LEO:  I then got their key, because they had a key when they did it, and added it to my key.  In fact, it's on there right now.  And it's very easy.  Now, whenever I email Doug, it'll automatically be encrypted.  Transparently, without any effort on my part.



STEVE:  I'll bet you that at some point the world, I mean, I don't know, a decade...



LEO:  Let's just do it.  If everybody did this, yes, of course the NSA grabs your stuff.  I made my key 4096 bits.



STEVE:  Yup, to NSA that's...



LEO:  Planning for the future.



STEVE:  Yes.  Yup.



LEO:  And it's good.  It's the way to do it.  So make, you know, it's really easy using these GNU Privacy Guard tools.  The Mac thing is - it works with Apple Mail.  It's very transparent.  Little harder to do if you're using a web-based mail server, unfortunately.  It's really easy on a client like Mozilla Thunderbird or Apple Mail, something like that.  It's very easy on Thunderbird.



STEVE:  Well, and I would imagine there will be plugins at some point, if there aren't already, for specific browsers.



LEO:  There probably is for Gmail.  But it's - that's harder to do right.



STEVE:  Yeah.



LEO:  If you think about it.  So...



STEVE:  Yeah.



LEO:  You can't - and you know, by the way, you can use PGP locally.  Just take a block of text, encrypt it, and send it off.  So that works fine with any mail server.



STEVE:  And in fact the protocol, the PGP protocol is mature enough that I'm seeing other new efforts launching that are going to be using PGP as their well-proven crypto model because the code is available, and they're just going to package it up and use it for different - to transport different sorts of information than traditional email, as it's been used for.



LEO:  There was a Know How episode on this.  I did not know.  The last Know How episode, No. 50, shows you how to do this.  I'm not sure exactly how they did it.  I haven't seen it yet.  But my recommendation...



STEVE:  In fact, I remember hearing that there was going to be some thing special...



LEO:  Yeah, I'm glad they did that.  My recommendation, and I suspect, I'm sure that they - this is how they did it, is GNU Privacy Guard and GPG Tools.  They're really great.  Really great.  And it's open source, so you know it's not - there's no backdoor.



STEVE:  Yeah.  So I think, bottom line, we're never going to know what's going on.  We know now that our law enforcement agencies have taken the position that they need to capture everything and build networking models of interactions of people.  I think most of us it's sad.  It's a little creepy.  But it's the reality of the 20th Century, 21st Century, whatever century we're in.



LEO:  Yeah.  By the way, this is the command line interface for GPG.  It says - you just type "GPG."  It says, go ahead, type your message.  You type your secret message in cleartext.  And then if you have the right keys, which I haven't installed yet, it'll encrypt it, and you'll be given some junk that you can then paste.



STEVE:  Nice.



LEO:  And you just do it to annoy the NSA.  Here's another story, by the way.  This happened this morning.  I don't know if you heard about this, the NSA testifying before the Judiciary Committee.  An aide - during testimony on Capitol Hill today, a National Security Agency representative admitted that the government's perhaps looking at more data than we had thought.



STEVE:  [Sighing]



LEO:  So this is Chris Inglis.  He's the deputy director of the NSA, testifying before the House Judiciary Committee.  He said that analysts look two or three hops from terror suspects when evaluating terror activity.  Previously they had admitted to two hops.  That means, if they're following a terrorist, and he calls somebody, they could then look at the person that that person, the person the terrorist called, called.



STEVE:  Three degrees of separation.



LEO:  But now it's three hops, which means terrorist calls somebody.  That person calls somebody.  That person calls somebody.  They can start collecting data from that third person.  And that's pretty much everybody.



STEVE:  That really is, yes.



LEO:  Because according to a study at the University of Milan, we're all 4.74 steps away from everybody else.  So three hops, three degrees of separation is a vast universe.



STEVE:  Yeah.



LEO:  Very quickly means that everybody is involved.



STEVE:  It's funny, too, because the now head of the NSA, Alexander, who I was talking about before?  Apparently he was involved in Iraq and our efforts there.  And when he became involved, and they were using communications signaling intelligence in order to track down terrorists within Iraq, his solution was, instead of looking for a needle in a haystack, let's collect the entire haystack.



LEO:  Just the haystack.



STEVE:  Yes.



LEO:  And then when we need to look, we'll have it.



STEVE:  Yes.  So it was originally there, apparently a very successful approach over there was record everything, and then we'll sift through it when we know what we're looking for.



LEO:  By the way, the members of Congress, not being mathematically inclined, had no idea what he had just said.



STEVE:  And Leo, saying "not being mathematically inclined"...



LEO:  Is an understatement.  But nobody said anything.  But that's the first time the NSA's admitted three hops.  He said, eh, two or three hops.  Very casually.  As if it could be four.



STEVE:  Oh, as if it was nothing.



LEO:  And it could be five, really.  I mean, it could be, I don't know...



STEVE:  Let's explain exponentiation to you.  Please.



LEO:  Yeah.  They had no clue.



STEVE:  Wow.



LEO:  And I think that that's the other thing that happens, is the people at the NSA think, and they're probably right, that they're smarter than Congress.  And so they just mislead them.  They say things like that in a way that just misleads them.



STEVE:  Yeah.



LEO:  And when you mislead Congress, whatever you think of Congress, you're misleading us because they're the people who are supposed to enact this stuff.



STEVE:  Yeah, well, and the whole, I mean, part and parcel was oversight.



LEO:  Yeah.



STEVE:  And oversight means telling the truth when they ask you a question.  And that was my argument with Clapper and his ridiculous, oh, I forgot about the Patriot Act.  Uh-huh.  Yeah.



LEO:  Hard to believe.



STEVE:  Yeah.



LEO:  Hard to believe.  Well, Steve, thank you.  Once again, another great episode.  And I think you're right, we didn't have time for questions.  But we'll do it in a couple of weeks.  If you have questions for Steve, go to GRC.com/feedback.  While you're at GRC, get SpinRite, the world's best hard drive maintenance utility.  Yes, it works on encrypted drives.  Somebody asked in the chatroom.  Doesn't care what's on the drive.  It's right below everything else.



STEVE:  Yeah, actually a lot of people have used it.  When TrueCrypt hits a problem, it'll say - it'll stop and back itself out, saying, oh, I'm unable to decrypt this drive.  And so it's very much sort of like the way Microsoft used to have a problem when you were trying to convert from  FAT16 to FAT32.  If there were any bad clusters or sectors on the drive, you were unable to do a FAT16 to 32 conversion.  And so people - we sold a lot of copies of SpinRite to people who needed to fix their drive in order to convert to FAT32.  Similarly, people when they're trying to encrypt or decrypt using TrueCrypt, they'll often hit a problem that they didn't know they had.  And SpinRite will fix it, and then TrueCrypt will go ahead and operate.



LEO:  I should give a little more credit to some of the members of Congress.  Here's some of the things that members of the House said in this hearing.  Minority member John Conyers of Michigan:  "You've already violated the law, in my opinion."  Jerry Nadler of New York:  "I believe it's totally unprecedented and goes way beyond the statute."  Ted Poe of Texas:  "Do you see a national security exemption in the Fourth Amendment?  We've abused the concept of rights in the name of national security."  And Jim Sensenbrenner of Wisconsin, the author of the Patriot Act, said, hey, you know what, it's up for renewal in 2015.  The provisions for phone metadata collection, he warned, have got to be changed.  Otherwise, in a year and a half, you're not going to have it anymore.



STEVE:  I would say that what we need to respect are their staffs. 



LEO:  Yeah, because they're intelligent.  The staffs are intelligent.



STEVE:  The staffs do all the work, Leo.



LEO:  Congress represents us.  They are our representatives.  You voted for them.  If you don't like them, vote them out.  But they're what we got right now, and it's the only line of defense.  You've got to write to your member of Congress and say this will not stand.  It's not - we don't believe it's constitutional.  And you've got to overturn it.



STEVE:  What I would recommend to anybody who likes to follow this stuff, is to get yourself on the EFF's mailing list, the Electronic Frontier Foundation.  They really are leading this.  They've already filed a lawsuit against the NSA over this.  And they've got smart attorneys.  They know the law.  The EFF is a great organization.  And they're one of the Twitter feeds that I follow in order to see what's going on.  So I see what's going on with them.  But also, so either follow them on Twitter, and/or subscribe to email from them.  And then you'll know what's going on.  And they often send you, here's a link to a page that will immediately, on your behalf, you fill out your name and address and where you are, and it will send email or letters to your local representatives, it figures out all of that for you, to help you express your opinion to your local people in Congress and government.  So...



LEO:  And don't buy the BS that, oh, well, they're all in it, and Congress sucks, and the government's - because if you don't go through Congress, your only other alternative is leave the country or revolt.



STEVE:  And move, yeah.



LEO:  So let's try the democratic process, shall we?  It'll work.  But you've got to get involved.  You can't say, oh, they're all losers anyway.



STEVE:  Yeah.  I think it's true that there were some early - there were some people ahead of the curve in Congress, who under- who are on the Intelligence Committee, who realize this was not - what was happening was not what America thought.  And, I mean, right off the bat I said I would not do what Edward did because my oath would prohibit me from doing that.  But I'm glad he did.  I mean, and now, of course, look at the result.  The result is good.  This is all good.



LEO:  I'm glad we're having the conversation.



STEVE:  Yeah, although it sure has hurt those companies that we're enumerating.



LEO:  Well, good.  Because guess what runs this country?  Those companies.  And if it's bad for business, that's the best possible way to get this thrown out.  Bad for personal rights, big deal.  Bad for business, watch out.



STEVE:  Yeah.



LEO:  Microsoft has lobbyists.  They listen to Microsoft's lobby.  They'd listen to us if we'd pay attention.  But the electorate doesn't really pay attention.



STEVE:  No.



LEO:  GRC.com - enough politicizing here.  Although, hey, this is one case where the politics has a lot to do with what we talked about.



STEVE:  It's tech politics, yeah.



LEO:  And if people who understand technology don't get involved, well, who is?



STEVE:  And it's nonpartisan.  I mean, everybody's upset about this equally.



LEO:  Yeah.  We have 16...



STEVE:  GRC.com.



LEO:  Yup, 16Kb audio versions of the show, as well as Elaine Farris's fabulous transcriptions, available at GRC.com.  Full quality audio and video available after the fact on our website, TWiT.tv/sn, for Security Now!.  And of course you can always watch us do it live, 11:00 a.m. Pacific, that's 2:00 p.m. Eastern time, 19:00 UTC on Wednesdays, right here at TWiT.tv.  Steve, have a great week.  And I will see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#414	

DATE:		July 24, 2013

TITLE:		Inflection Points

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-414.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  This week we mix security news and updates with a discussion and analysis of the security industry's evolving reactions to the NSA/Snowden revelations.  Steve and Leo examine several of the more significant news items and blogs relating to the issues of widespread Internet surveillance.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of news.  We're going to talk about PRISM yet again.  Looks like Steve was right about the SSL keys, too.  And the most amazing memo you've ever heard of from Homeland Security.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 414, recorded July 24th, 2013:  Inflection Points.



It's time for Security Now!, the show that protects you and your loved ones online.  I'm Leo Laporte.  That's Steve Gibson, the Explainer in Chief.  Hello, Steve.



STEVE GIBSON:  Hi, Mom.  Hello, Leo.



LEO:  Does your mom watch?



STEVE:  No, no, no.  Jenny sometimes.  When she's, like, really bored.



LEO:  Or she wants to be bored.  She wants to sleep.  She says, "I'll watch" [snoring].  Well, Steve, it's nice to be here on the second anniversary of our move into the new, I still think of it as new, studio.



STEVE:  Well, and I got a very nice invitation from you guys to come up for it.  The problem is I'm in Orange County, and we have basically a shack for an airport, which it used to be.  It used to be a shack that was paved.  And then of course it grew a little bit.  But it's called John Wayne, quote, "International," which is a joke because it has a 10:00 p.m. curfew because the planes fly out over Newport Beach, where all the money is...



LEO:  Right, right.



STEVE:  ...and thus all the political power.  So you can't - and so many times when I've been coming across the country, we'll be delayed at O'Hare or something or...



LEO:  And now it's too late, right.



STEVE:  You can't land after 10:00.  So then they send you off to, what was that airport you and I - Ontario.



LEO:  Oh, no, that's the middle of nowhere.



STEVE:  I know, and then they bus you, and you end up getting here about 1:00 a.m.



LEO:  So you don't want to go anywhere, in other words.



STEVE:  Well, the point is that the only way to avoid that is to do about an hour and a half drive up to LAX, which is an actual airport.  And anyway, so with the logistics of the party you guys are having tonight, and I would have had to spend another night, and basically it would have taken two days out of my life to come up and say hi to everybody.  So I thought, well, I'll just wave.  See?  There, you see, here I am waving.



LEO:  We're glad you were here.



STEVE:  I'm virtually there.  And I'll be up later this year to actually be there in person, so.



LEO:  Oh, you will.



STEVE:  Oh, yeah.



LEO:  Oh, good.



STEVE:  Yeah, I'm going to come up.  I haven't seen my family for a couple years.  And so, yeah, I'm going to definitely come up.



LEO:  Well, it's appropriate.  That's good.



STEVE:  Yeah.  Yeah.



LEO:  So we are having a lovely Italian dinner for 30 after the shows tonight.



STEVE:  An intimate little thing.  That sounds great, actually.  Yay.



LEO:  An intimate gathering for staff and loved ones.



STEVE:  You guys have a neat Italian restaurant nearby?



LEO:  We have several.  It's kind of hard to choose.  But we're going tonight to Cucina Paradiso, which is about two blocks from here, and it's fun.  Or are we going to - no, we're going to Cucina Paradiso, yeah.  So it's fun.  I mean, two years.  It's kind of hard to believe we've been in here two years.  And now we finally have a sign.  I don't know if you saw, we put a sign up on the front so people can find us now.  For a long time it felt like we were renting.



STEVE:  Well, believe me, if those are tenant improvements that you've put in, then...



LEO:  Well, they are, and we paid for them.  We actually are renting.



STEVE:  Wow.



LEO:  But I figure - we've got a lease for a few more years.  And I figure by that time we'll want a new studio, so.



STEVE:  No.  No one's ever - you are never moving.



LEO:  Well, you know...



STEVE:  Can you imagine?  Can you just imagine doing this again, Leo?



LEO:  Yes.



STEVE:  Everybody would have a nervous breakdown.



LEO:  You forget, you forget, I have a whirlwind of a business partner, Lisa Kentzell, who does this in her sleep.  She could do it, I mean, seriously, I have no qualms.



STEVE:  The Indians would revolt.  The Indians would...



LEO:  No, they wouldn't.  They'd stay here, and suddenly one day we'd say, okay, don't come to work, come to the other place, and there would be a new building and a new studio.



STEVE:  Just magical.



LEO:  Well, and the other thing that has to happen is technology moves fast.  You know?



STEVE:  Yeah, but what I really love about the way you built that place is it's modular.



LEO:  Right.



STEVE:  You really can upgrade it incrementally.  I mean, it's really cool the way you have that basement that you can just drill right down to and run wires wherever you need to.



LEO:  Yeah.  And so it's true that we could upgrade technology.  In fact, you know, one of the funny things we were looking at at this point, we had a big engineering meeting, is the issue of whether to stay with Macintosh and Final Cut, or to look - because our Mac Pros that we edit with and we render with - you need a high-powered fast machine for rendering, it takes a lot of time, so the more cores the better - are getting a little outmoded.  And the new Mac is going to - I'm waiting to see, but I think it's going to be very pricey and not very...



STEVE:  With that weird little cylinder thing?



LEO:  Yeah, because it has no storage.  So you have to add Thunderbolt 2 devices, which don't even exist at this point.  And it's pretty limited.  It certainly doesn't have any upgradeability in terms of video cards.



STEVE:  You're talking about going pro, outside of the PC world?



LEO:  No, we have to go PC.  And what it means is we have to abandon Final Cut and go to Adobe Premiere, which is - we'll have to talk to the editors.  But I think we'll probably end up doing that because we're really getting to the end of the line on these Mac Pros.  So anyway, what happens - and they don't tell you this in the book, build your own studio book.  Stuff, it doesn't just stop.  Time moves, marches on.  And so we'll wait here for a few more years, for sure.  But eventually, I think, we'll be moving.



STEVE:  Would you think you would - the only reason I could ever justify a move is if you physically outgrew the space.  That, I mean...



LEO:  Oh, we've already physically outgrown the space.



STEVE:  No kidding.



LEO:  Oh, yeah.  They just took my wardrobe.  I used to have a nice closet where all my shirts were.  They just took it away from me so that Patrick Delahanty has a place, has an office, has a place to be a programmer.  So he's in my closet now.



STEVE:  Oh, okay.



LEO:  Well, the reasoning was programmers don't need windows.



STEVE:  No.



LEO:  We put a glass door.



STEVE:  Sometimes that distracts them.  If girls walk by, they just...



LEO:  No.  Focus.  Head down.



STEVE:  Exactly.



LEO:  So Patrick's happy, and I and my shirts are in the back.  We literally, we have, Steve, actually - we can't hire many more people.  We've actually outgrown it.  Now, we're subletting a third of the space to Pixel Corps.  But they don't...



STEVE:  They're still over on the other side.



LEO:  They're not showing any sign of moving, so I don't know what we're going to do.  Enough about me.  Let's talk about - what are we going to talk about today?



STEVE:  Well, I didn't know what to title this, so I titled it - well, okay.  I titled it "Inflection Points" because I'm feeling like from time to time in history there are periods where there's, like, a lot going on.  And in fact to sort of kick off the discussion of that in the second half of this podcast, I tracked down, because I wanted to get it exactly right, that recent and sort of famous now Rahm Emanuel quote, "You never want a serious crisis to go to waste."  And what I mean by that, says Rahm, what I mean by that, it's an opportunity to do things you think you could not do before.  So I want this week to, because this is still, I mean, every blog that I care about, every security site that I look at, I mean, we're still seeing the people working to understand what the Snowden revelations were about and what the NSA's position means.  And believe it or not, it hasn't all been said yet.  I've got some really interesting new things that I want to share.



And while I really want to keep us focused on technology, and obviously we were just two weeks ago.  We were talking about perfect forward secrecy and what that means with regard to, for example, the notion of traffic being stored and then decrypted later."  We'll get back.  But I almost feel like it would be wrong for us not to look at what's going on right now, to take a couple weeks when we have to, to say, okay, these things are still happening, so let's discuss some of this, what is still breaking news, essentially.  And Bruce Schneier has been writing some fabulous blogs and has some really, I think, insightful analysis of this that I want to share and then we'll discuss.



LEO:  You know, it's funny, people say, oh, let's not talk about PRISM anymore.  But it's such a story, such a huge story, such a big tech- it is a technology story.  If we don't cover it, I mean, you know CNN's moved on.  They've got the Zimmerman trial to talk about, the birth of Baby Boy George.  And so they've moved on.  But I think it's so important that we continue to talk about it, what it means, the ramifications.



STEVE:  Well, and then I see, even this morning, I start getting tweets from people saying, yep, Steve, you were right again.  And it's like, what, what?



LEO:  Yeah, the more that comes out, the more accurate your analysis seems to be, yeah.



STEVE:  Well, and it turns out, I mean, we were just discussing, last week or the week before, this theory I had about SSL keys, the pressure that would be put on.  And now comes this morning the story, and we'll be covering it here in a second, that in fact these major providers have been under pressure to turn over their SSL keys.



LEO:  Oh, my god.  Really?



STEVE:  Yes.  Yeah, you were doing Google this morning while this was happening.  And so we have multiple confirmed sources.



LEO:  Well, this is it.  This is the subject matter of the day.  I don't think there's any reason to hold back.  Let's launch into it.



STEVE:  Okay.  So first of all, I didn't know where to put this piece because this is crazy.  And I didn't want to, like, wait till the end because it might be all anybody remembered, this is so loony tunes.  And in fact, almost it's like that crazy - the pilots' names that the station in San Diego made up that got them in so much trouble?  My buddy sent me the link to...



LEO:  It was local here in San Francisco.  I wish it weren't true.



STEVE:  Oh, was it?



LEO:  Yeah, it was KTVU Channel 2.



STEVE:  Ah.  Anyway, I didn't believe it.  I thought it was...



LEO:  No, I thought it was The Onion.



STEVE:  Cannot be possible.



LEO:  No, yes.



STEVE:  It could not be possible.



LEO:  How could anybody be that stupid?



STEVE:  Well, in that vein, exactly.  If Bruce Schneier, whom we've spoken of often, who is a world-class cryptographer, who has designed several ciphers which are among the best, written several books - "Practical Cryptography," "Secrets & Lies," and there's a third one now that I can't remember the title of.  But, I mean, mainstream guy.  And so if this wasn't from him, I wouldn't believe it.  So this is July 17th.  The title of his blog was "DHS" - of course the U.S. Department of Homeland Security - "Puts Its Head in the Sand."



And Bruce wrote, "On the subject of the recent Washington Post Snowden document, the Department of Homeland Security sent this email out to at least some of its employees."  So someone forwarded this to Bruce.  Bruce redacted the "From" and the "To," and he had to remove some information from the "CC" also.  But the subject of this actual - and again, if it weren't from Bruce, I'd go, uh-huh, good, that's funny.  But no, this is real.



"Subject: //// SECURITY ADVISORY //// NEW WASHINGTON POST WEB" - this is from the DHS to its employees:  "NEW WASHINGTON POST WEBPAGE ARTICLE - DO NOT CLICK ON THIS LINK."  The letter reads:  "I have been advised that this article is on the..."



LEO:  [Laughing] I just read it [laughing].  Go ahead.  Sorry.



STEVE:  I know.  Can you believe it?  "I have been advised," says this letter, "that this article is on the Washington Post's website today and has a clickable link titled 'The NSA slide you have never seen' that must not be opened."



LEO:  If you're in the Department of Homeland Security.



STEVE:  Right.  If you are in the DHS, you cannot click this link....



LEO:  Why not, Steve?



STEVE:  ...on the Washington Post's website.  The letter goes on to explain why.  "This link opens up a classified document..."



LEO:  Yes.



STEVE:  "...which will raise the classification level of your unclassified workstation" - we're not making this up, folks - "will raise the classification level of your unclassified workstation to the classification of the slide, which is reported to be TS" - that's top secret - "/NF.  This has been verified..."



LEO:  Now, wait a minute.  Now, wait a minute.  Wait a minute [laughing].  Okay, keep going.



STEVE:  "This has been verified by our mission partner and the reason for this email.  If opened on your home or work computer, you are obligated to report this to the SSO as your computer could then be considered a classified workstation."



LEO:  Mine is because I opened it.



STEVE:  My god.  "Again, please exercise good judgment," says this guy, "when visiting these web pages and clicking on such links."



LEO:  Yes.



STEVE:  "You are violating your Non-Disclosure Agreement in which you promise by signing that you will protect classified national security information.  You may be subject to any administrative or legal action from the government."



LEO:  Oh, I would just quit.  I would just say, you know what, I can't work for somebody so stupid.  This is it.  I'm leaving now.  Here's my response.  Is it okay if I click the link and my eyes are closed?  Does he, now, he's not implying that the mere display of this JPG will somehow trigger this in my computer?



STEVE:  Yes.  Your computer would then have it in its cache, and this is top secret, and you are not allowed to be in receipt of this information.



LEO:  No, you cannot.



STEVE:  Despite the fact that the Washington Post and everybody else in the world...



LEO:  We all have seen it.  But it's top secret.



STEVE:  Yeah, and apparently you have to walk around also with your fingers in your ears because, my god, somebody might echo, they might read it to you, or they might want to discuss it with you.



LEO:  This is ridiculous.



STEVE:  So Bruce says...



LEO:  I'm embarrassed.



STEVE:  This is true.



LEO:  These are the people protecting us, ladies and gentlemen.



STEVE:  Yeah, yeah.  Bruce says, "This is not just ridiculous, it's idiotic.  Why put DHS employees at a disadvantage by trying to prevent them from knowing what the rest of the world knows?"



LEO:  Because it's top secret.  They don't know it.



STEVE:  Bruce says, "The point of classification..."



LEO:  Morons.  Morons.



STEVE:  "...is to keep something out of the hands of the bad guys.  Once a document is public, the bad guys have it.  The harm is done.  Can someone think of a reason for this DHS policy other than spite?"



LEO:  Oh, wait a minute.  Oh, we've got to send out a new memo.  Do not watch Security Now!.  The slide's on Security - oh, no!  Close your eyes, if you work for the DHS.  Close your eyes right now.  Oh, too late.  You've now seen the slide.



STEVE:  Confess your sins.



LEO:  Call the SSO.  You're going to have to be...



STEVE:  You have to go confess.



LEO:  You've got to go confess.  This is the most - this is the most embarrassingly stupid thing I've ever seen.



STEVE:  Just unbelievable.  Now you know why we had to lead with it, because we couldn't finish with it.  The rest of the podcast is serious.  But this is just loony tunes.  So...



LEO:  That makes me sad.



STEVE:  I had to share it.



LEO:  These guys are supposedly protecting us, folks.



STEVE:  Okay.  So CNET this morning, our friend Declan McCullagh - and you might want to click the link, Leo, and look at the page:  news.cnet.com/8301-13578_3-57595202-38/feds-put-heat-on-web-firms-for-master-encryption-keys.



LEO:  Yeah, oy oy oy.  This is what you said.



STEVE:  Yup.  "Feds put heat on web firms for master encryption keys."  The subheading:  "Whether the FBI or NSA have the legal authority to obtain the master keys that companies use for web encryption remains an open question, but it hasn't stopped the U.S. government from trying."



LEO:  So explain to us what having these keys would do.



STEVE:  I'm going to share the story here.



LEO:  Go ahead, go ahead.



STEVE:  He really covers it.  And then we'll discuss if there's any loose ends.  He says, "The U.S. government has attempted to obtain the master encryption keys" - and he'll disambiguate all this in a second - "that Internet companies use to shield millions of users' private web communications from eavesdropping.  These demands for master encryption keys, which have not been disclosed previously, represent a technological escalation in the clandestine methods that the FBI and the National Security Agency employ when conducting electronic surveillance against Internet users.



"If the government obtains a company's master encryption key, agents could decrypt the contents of communications intercepted through a wiretap or by invoking the potent surveillance authorities of the Foreign Intelligence Surveillance Act (FISA).  Web encryption - which often appears in a browser with a HTTPS lock icon when enabled - uses a technique called SSL, or Secure Sockets Layer.  'The government is definitely demanding SSL keys from providers,' said one person who has responded to government attempts to obtain encryption keys.  The source spoke with CNET on condition of anonymity.



"The person said that large Internet companies have resisted the requests on the grounds that they go beyond what the law permits, but voiced concern that smaller companies without well-staffed legal departments might be less willing to put up a fight.  'I believe the government is beating up on the little guys,' the person said.  'The government's view is that anything we can think of, we can compel you to do.'"



LEO:  They might not - go ahead.



STEVE:  "A Microsoft spokesperson would not say whether that company has received such requests from the government."



LEO:  They can't, by the way.  We should just point out they probably can't.



STEVE:  Yes, precisely.  "But when asked whether Microsoft would turn over a master key used for web encryption or server-to-server email encryption, the spokesperson replied:  'No, we don't, and we can't see a circumstance in which we would provide it.'



"Google also declined to disclose whether it had received requests for encryption keys.  But a spokesperson said the company has 'never handed over keys' to the government, and that it carefully reviews each and every request.  'We're sticklers for details, frequently pushing back when the requests appear to be fishing expeditions or don't follow the correct process,' the spokesperson said.  A Facebook spokesperson declined to answer questions."



LEO:  Oh.



STEVE:  I know.  "One person familiar with Facebook's internal procedures predicted that the company would vigorously fight a request for encryption keys.  Apple, Yahoo!, AOL, Verizon, AT&T, Opera Software's Fastmail.fm, Time Warner Cable, and Comcast all declined to respond to queries about whether they would divulge encryption keys to government agencies."



And anyway, so the article goes on to explain what we already all know, which is this is precisely what we were talking about in the last week or two.



LEO:  And to clarify, the real import of this is not so much that they could then watch you live now, although that would be one thing.  But more, if they get the old expired keys, that they could go back through the data they've been dumping and decrypt it post facto, ex post facto.



STEVE:  Yes.  So exactly as we were talking about when we were talking about perfect forward secrecy, the adoption of perfect forward secrecy - which is as yet incomplete.  The technology is there.  But remember it requires both sides to agree.  That technology means that having those master keys would not allow them to decrypt because the master key in an ephemeral key agreement is not used to encrypt the key itself.  It is used in all SSL, virtually all today.  It's only when both sides agree to this not-yet-in-high-use approach, the so-called, the ephemeral Diffie-Hellman that we talked about extensively - we did a podcast on it - only then would the master key not help.  So what they're talking about, and there's still this question, again I will - as I said, the thing that really creeped me out was the idea that all the encrypted traffic is being stored.  And when old keys expire, I could just easily see the government, I mean, what we're talking about now is the current key, the key in use. 



LEO:  Their denial is relevant to the current key only?  They might have handed over older keys?  Or that just depends on how they parse it?



STEVE:  Exactly, how you parse the language.  If they said, "We have never in our history turned over any encryption keys," then that's broader than "We've never turned over the keys we're using," for example.  But you can almost see, and this is why it's so creepy, you could see the government making the case for we don't want to decrypt what you're doing now. 



LEO:  Yeah, we don't care.



STEVE:  We want your old keys.



LEO:  Yeah, what about the old stuff?



STEVE:  But what this story says, the government is actually saying, well, and, Leo, get this.  I mean, the only reason they want those keys is they're tapping.  This also - this is...



LEO:  Right.  Unless they have the data, you don't need the key.



STEVE:  Right.  This is perfect confirmation that what the government is getting is encrypted data, which also confirms the theory, and we're seeing more confirmation of this coming around, that they're tapping the Internet, and then they're going to the people whose communications is doing the encryption, like Google, and saying we need the keys.  And Google is saying no.



LEO:  And I think there's legal, and I'm not a lawyer, but legal precedent for getting older keys because you remember that one of the stories was that the law deems email older than six months old as abandoned, that there is no right to privacy to anything older than six months old.  It's not yours anymore.  It's abandoned.  And so I would bet, and again, I'm not a lawyer, but I'm just trying to think logically, that that would be a justification, hey, what we're asking for the keys for is abandoned.  It's nobody's email.  It's just old stuff.  And I think it'd be harder to fight that in court.



STEVE:  Yeah.



LEO:  Anyway.  It breaks SSL in the sense that you're encrypted for everybody who doesn't have the key.



STEVE:  Yeah.  I'm thinking that, once I get SpinRite 6.1 launched, I'm going to have to do something I haven't ever done before, which is it's time to do some browser add-ons.



LEO:  Well, and look at this.  This is from SSL Labs, that SSL report on Google.com.  They are supporting a Google.com forward secrecy with modern browsers.



STEVE:  Yes.



LEO:  So your Google searches are protected if you use a modern browser.



STEVE:  Yes.



LEO:  And so getting the keys if forward secrecy is implemented is meaningless.



STEVE:  Well, so, but here's the problem.  Well, almost.  Remember that, because most servers don't get implemented on the server side, and only some browsers implement on the browser side, it's only when they both agree that it happens.



LEO:  Ah.



STEVE:  Now there's the possibility of a so-called "downgrade attack" where, when that first packet of ciphers goes off towards the server, somebody who's doing a man-in-the-middle just removes the Diffie-Hellman ephemeral ciphers from the list of ciphers the browser will support, in which case the server will choose one that doesn't have that, and you won't get perfect forward secrecy, even though both ends could.



LEO:  Wow.



STEVE:  Yeah. 



LEO:  You've got to figure they're working on stuff like that. 



STEVE:  Yeah.



LEO:  Every time a more secure system comes up, or a system they can't break into, law enforcement starts to whine "We can't wiretap these people," and starts making moves to getting access to that data once again.



STEVE:  Yeah.  So we're going to come back to this in the second half of the show, some of these issues.  I did want to mention the news - and I'm surprised at the persistence of this, Leo.  It was last Thursday that Apple announced that the developer site was hacked at Apple.com.  And this morning I went there, and the notice is still up, and the developer site is still offline.  What's Up says "We'll be back soon."  Now, this is almost a week now.



"Last Thursday an intruder attempted to secure personal information of our registered developers from our developer website.  Sensitive personal information was encrypted and cannot be accessed; however, we have not been able to rule out the possibility that some developers' names, mailing addresses, and/or email addresses may have been accessed.  In the spirit of transparency, we want to inform you of this issue.  We took the site down immediately on Thursday and have been working around the clock since then."  So now we're at seven days.



"In order to prevent a security threat like this from happening again, we're completely overhauling our developer systems, updating our server software, and rebuilding our entire database."  Which this raises more questions for me than it should.  They say, "We apologize for the significant inconvenience that our downtime has caused you, and we expect to have the developer website up again soon.  If your program membership was set to expire during this period, it has been extended, and your app will remain on the App Store.  If you have any other concerns about your account, please contact us.  Thank you for your patience."



So it's like, wow, you know, a week.  I can't imagine the nature of this, but it doesn't sound like a small problem.  It sounds like maybe this never really got the attention it deserved.  And when they gave it the attention it deserved, like when maybe some smart people said what happened, the looked at what was there and said, oh, my lord, how has this been allowed to be up for so many years?  So apparently they're just rebuilding the whole thing.



LEO:  Yeah, from scratch.



STEVE:  Yikes.  Yeah.  Now, and so who knows how long.  They just said "soon."  They're not projecting a time they'll be back.



LEO:  Coming up on a week now.



STEVE:  Yeah.  So security, the SC Magazine, that bills themselves the "Security Magazine for IT Professionals," carried an interesting article, not very long, and very frightening.  So, and I really can't paraphrase it without changing it, so I'm just going to share it with everybody.



"Hundreds of millions at risk from SIM card vulnerability."  This is Monday, two day ago.  "Berlin-based Security Research Labs flipped the mobile security market upside-down recently when they published reports about just how vulnerable SIM cards are to cyber attacks."  You know, SIM cards obviously are the little identity cards that many of our phones have that contain their identity.



"Karsten Nohl, founder of Security Research Labs, said his company had been working to crack SIM cards for three years, and they finally found a way to do it - most notably without raising alarms.  'We have a way of breaking SIM cards remotely,' Nohl told SC Magazine on Monday, 'without any evidence and with no way of preventing it or even noticing it.'"  So this sounds like a major SIM card security breach, which is effectively all SIM cards.



"An attacker who takes advantage of the vulnerability, Nohl said, will be able to download software onto the victim's SIM card, locate the phone, send texts and make phone calls to any phone number - including pricey premium numbers - and ultimately operate the device as the normal owner would.



"Anything else stored on the SIM card, such as credit card information, is also accessible, said Nohl, adding some finance groups are looking to move transaction payments to phones and that it might represent additional problems since the information will be stored on the SIM.



"What is opening up this kind of vulnerability to hundreds of millions of mobile phones worldwide, out of nearly seven" - okay.  Hundreds of millions, oh, out of...



LEO:  It's about one eighth of all existing phones.  It's not a huge number.



STEVE:  Okay, "seven billion SIM cards in existence..."



LEO:  Sorry.  It is a huge number, but it's still a fraction.



STEVE:  A fraction, "is the use of antiquated DES.  That's the Data Encryption Standard technology for over-the-air Short Message Service" - that's SMS - "transmissions used by mobile carriers."  So it's not all phones.  It's hundreds of millions that apparently haven't moved from using DES.



LEO:  It's not any modern phones.  It's not the iPhone.  It's not modern phones.  It's older phones.  The problem is there's a lot of older phones in use.



STEVE:  I'd ask the question, is it older SIM cards, or is it older phones?  So it may be the technology in the SIM card.



LEO:  Yeah, but if you have an old SIM card, it doesn't work in a modern phone.



STEVE:  Ah, okay.  And so, that's right, so you're getting a newer phone, it's like, oh, sorry, you can't use that SIM card, you have to use the new guy.



LEO:  Yes, yes.



STEVE:  Anyway, so what's going to happen is at the end of this month, at the upcoming Black Hat Conference, we're going to find out more about this.  They have notified - they did full responsible disclosure.  All the cell phone companies were notified many months ago in order to identify and remove these cards from service and/or upgrade the firmware, do whatever they need to in order to close this hole because a few weeks from now, actually I guess it's next week, we're going to be finding out how to do this.



LEO:  Triple, I mean, DES has been cracked for years.  Nobody uses DES.  It's old.  We use 3DES now.



STEVE:  The problem is the key is too short.  DES is a 56-bit key.  And so Triple, or 3DES, Triple DES, all it is is three DESes in series, and the key is concatenated.  So you take each of the 56-bit keys, and you stick them together to form a composite key that is three times as long, and then you run your plaintext through the first one with the first third of the key, through the middle one with the middle third of the key, and through the last one with the last third of the key.  So, I mean, so it's not that DES was ever really a bad cipher, but it's a classic case of it being so old that a key length that used to seem secure is laughable these days.



LEO:  Right.  This is not probably an issue in the U.S.  But in the Third World, and especially in continents like Africa, where they use their phones for e-payments, using things like M-Pesa, that could be huge.



STEVE:  Yeah.  And it must be that this is more than just a short key, or there must be some sort of a hack because, I mean, even if it's an over-the-air attack, it still would be burdensome to do any sort of a brute-force hack.  So it can't be that.  We'll find out in a week.  But, you know, because, I mean, we say, oh, 56 bits, that's nothing.  Except remember that 32 bits is 4 billion.  So this is, even though it's short relative to any kind of contemporary brute-force attack, you're trying to brute-force something over a cell phone connection.  That's still a lot of hacks. So it's something other than a brute-force attack.  We just don't know yet.  But as you say, it's not to be laughed at.



Okay.  Now this is - I got a bunch of tweets from people, and so I was made aware of this.  And this is worrisome.  The BBC carried the story that the U.K. was proposing requiring ISPs to default block online pornography.



LEO:  Isn't that nice.



STEVE:  Yeah.



LEO:  Thank you.



STEVE:  So...



LEO:  It's okay, though.  You can go to your ISP and say, hey, I want to see porn.



STEVE:  Yeah.  It's sort of interesting.  It says, "Most households in the..."



LEO:  [Laughing]



STEVE:  I know.  "Most households in the U.K. will have pornography blocked by their Internet provider unless they choose to receive it," said David Cameron in a speech a couple days ago.  He said, "In the balance between freedom and responsibility, we have neglected our responsibility to children."



LEO:  No.



STEVE:  "Mr. Cameron warned in a speech that access to online pornography was 'corroding childhood.'  Mr. Cameron also called for some 'horrific'" - his words - "Internet search terms to be 'blacklisted,' meaning they would automatically bring up no results on websites such as Google or Bing.  He told the BBC he expected a 'row' with service providers who, he said in his speech, were 'not doing enough to take responsibility' despite having a 'moral duty' to do so.  He also warned he could have to 'force action' by changing the law and that, if there were 'technical obstacles,' firms should use their 'greatest brains,'" as he put it, "to overcome them.



"In his speech, Mr. Cameron said family-friendly filters" - which is hard to pronounce - "would be automatically selected for all new customers by the end of the year, although they could choose to switch them off.  And millions of existing computer users would be contacted by their Internet service providers and told they must decide whether to use or not use 'family-friendly filters' to restrict adult material.  The filters would apply to all devices linked to the affected home Wi-Fi network" - and presumably wired networks - "and across public Wi-Fi networks 'wherever children are likely to be present.'



"Customers who do not click on either option, accepting or declining, will have filters activated by default, said the Tory MP Claire Perry, Mr. Cameron's adviser on the sexualization and commercialization of childhood," when interviewed by the BBC.  "The U.K.'s biggest Internet service providers have agreed to the filters scheme, meaning it should cover 95% of homes."



LEO:  Unbelievable.  Why be a parent?  We can let the government do it.  You know, let the government raise your kids.  That's a good idea.



STEVE:  So apparently also during this, "Other measures announced by the prime minister included new laws, so videos streamed online in the U.K. will be subject to the same restrictions as those sold in shops; search engines having until October to introduce further measures to block illegal content; and experts from the Child Exploitation and Online Protection Centre being given more powers to examine secretive filesharing networks."  Okay.  So...



LEO:  That should scare people.



STEVE:  Yeah, I know.



LEO:  How would you do that?



STEVE:  I know.  And there was one quote that really gave me a chill, only because this demonstrates the slipperiness of the slope.  This Ms. Perry, Claire Perry, who's this advisor on "sexualization and commercialization of childhood," she was quoted saying former child exploitation and online protection center - oh, no, that's the wrong quote.  Oh, here.  "Ms. Perry argued filters would make a difference, saying that the killers of schoolgirls April Jones and Tia Sharp had accessed pornography before moving on to images of child abuse."  So, I mean, it's like, this is all horrible.  But as you said, Leo...



LEO:  Not to mention millions of other Britons who'd never kill anyone.



STEVE:  Right, right.  It's like the argument...



LEO:  And who decides what's porn?  Is 500px porn?  Is Flickr porn?



STEVE:  I tweeted this morning, because I was reminded of the famous Supreme Court Justice Potter Stewart, who in 1964 said, when this was at the Supreme Court, "Well, I can't define it, but I know it when I see it."  And it's like - and so what I tweeted was "'I know it when I see it' is not a computer algorithm."



LEO:  Oh, lord.



STEVE:  And that's the problem.  And then, of course, every time we've tried to do filtering, we've found problems.  I was doing a little poking around, and I found a reference to an example under the topic of "Can filters work effectively?  Filtering pornography is fiendishly difficult to do accurately.  Although the technology is improving, filters set up in hospitals several years ago had to be switched off after doctors were unable to access clinical studies on breast cancer."



LEO:  Well, that's got boobs.



STEVE:  Exactly.  Can't have that.



LEO:  You can still have Page 3, but you can't have boobs.



STEVE:  From a programmer's standpoint, one of the worst, one of the most insidious things - and this is not even programming, but even the law - is a fuzzy definition.  I mean, a fuzzy definition gets you in all kinds of trouble.  Once upon a time, boy, back in the early history of the podcast, I did a podcast on, like, some of the problems that programmers have.  And one of them was fuzzy definitions.  If you ever define, like, a variable, and you give it a bad name, that is, you don't name it exactly what it means, or if you're writing something really complex, and you as the programmer aren't absolutely sure what it means, then you're in danger.  Whether it's a year later you come back and try to read your code, or even a week later when you're still writing the code, you could interpret its meaning differently.  And that's - it's a constant source of bugs is a funny definition of something.



And in the law we see this.  You see legislation all the time passed where you have to wonder if they couldn't have gotten it passed with a firm definition, so they softened it, kind of with a "wink wink" to the opposition, saying, well, let us have this, but look at the way we worded this.  This won't really be a problem.  Which ends up being what they fight over is exactly the fuzziness of that.



LEO:  So one of the ISPs in Britain, TalkTalk, is using a system called HomeSafe, which is created by - are you ready? - Huawei, which is owned by the Chinese government.  It harvests every URL visited by TalkTalk customers, follows them to each web page, scans for threats, creates a master blacklist and a whitelist of dangerous and safe URLs.



STEVE:  Wow.  So it's full-on spyware also.



LEO:  Yeah, among other things.



STEVE:  Yeah.



LEO:  And, by the way, Ms. Perry's website apparently has been hacked and loaded with porn [laughing].  Okay.



STEVE:  Yeah, in researching this, I mean, it's - as you said, Leo, the question is where is the responsibility.  And as you push responsibility upstream, away from the parents of children, I mean, I recognize this is a problem.  I mean, there is awful stuff on the Internet.  There's horrific imagery that you and I were not exposed to as children.  But the problem is unintended consequences.  And what's funny is, as I was thinking about this, again from a technology standpoint, the problem, the fundamental problem is the Internet was never designed for filtering.  I mean, and in fact just the opposite.  The Internet interprets filtering as a problem and routes around it.  I mean, it's designed to get data through.



And so it's like, in all these case studies, any time filters have been put up, people get around them.  They use proxies.  They use VPNs.  I mean, the Internet itself is ill-designed to be an enforcement mechanism, which is something we've talked about, come at from all different angles over the years in this podcast.  So you're inherently asking it to do something it's not designed to do.



LEO:  Well, let's hope it fails in this case.



STEVE:  Yeah.  I mean...



LEO:  I feel sorry for Britons.  And, frankly, it just makes your country a Third World nation if you filter the Internet.  So in the long run it's a very poor strategy.



STEVE:  Right.  If suddenly Google results don't give you the same things because your government has decided you're not mature enough to handle the consequences of the search criteria that you put in, yeah.



Now, this is interesting.  I only found one reference to this.  But I'm hopeful.  And again, Declan McCullagh at CNET does his homework.  The headline was "Google tests encryption to protect users' Drive files against government demands."



LEO:  Oh.



STEVE:  I know.  And this was Declan.  So he said in the subhead, "The search giant is seeking ways to armor user files, sources say, a move that could curb government surveillance attempts.  Google has begun experimenting with encrypting Google Drive files, a privacy-protective move that could curb attempts by the U.S. and other governments to gain access to users' stored files.  Two sources told CNET that the Mountain View, California-based company is actively testing encryption to armor files on its cloud-based file storage and synchronization service.  One source who is familiar with the project said a small percentage of Google Drive files is currently encrypted.  The move could differentiate Google from other Silicon Valley companies that have been the subject of ongoing scrutiny after classified National Security Agency slides revealed the existence of government computer software," blah blah blah.



So we know nothing about this yet.  But I will definitely keep my eyes open for this.  We know that the only way this can be done in TNO style is if there is software in the client and/or in your web page to pre-Internet encryption.  And it's entire doable.  I mean, and Google's in a perfect place to do this.  And the other really significant factor, I tried to - I saw a link somewhere, and I tried to find it again, and I was unable to track it down again.  But, and this is really significant:  If the provider does not have the keys, then they are not required to hand over any information.



LEO:  Ah.



STEVE:  And so that's the way the law is today.



LEO:  Well, and they couldn't.  They couldn't, right, if they don't...



STEVE:  They can't, yeah.  I mean, they can...



LEO:  Require all you want.



STEVE:  Yeah.  I mean, here's a blob.



LEO:  Well, wait a minute.  They could get the encrypted blob.



STEVE:  They could probably get the encrypted blob.  They could say we demand this, and then Google says, okay, here you go, but we cannot decrypt it for you.  And the point is, in a properly designed system, neither could the government.  We have all the technology we need.  We just haven't rolled it out yet.  And one of the really heartening things about this, I mean, this is why, from the first moment that we covered the Snowden news, I said I'm not unhappy that this happened because in this country we've got to shine light on these things in order to keep this from happening.  And as we'll see here in a minute as we continue, this has really raised some ire in important places where I think it needed to get raised.



So congrats, provisional congrats to Google.  It would be great if they actually turned Google Drive into a TNO encrypted drive solution.  They entirely could.  Absolutely, we have the ability to do that, if they chose to.



And I picked up a blurb in the SANS newsletter - this won't come as any news to anyone, but just actually it was a little surprising still - on the horrific state of Java.  SANS wrote, and they summarized a bunch of coverage of this, so I'll just use theirs:  "According to a study from Bit9" - it's a well-known security organization we've quoted often - "many organizations are running outdated, vulnerable versions of Java."  Okay, well, that's not a huge surprise.  But here's some numbers:  "82% of organizations were found to be running Java 6, which is considered to be the most vulnerable version.  Many organizations have more than" - okay.



LEO:  I'm glad there's agreement.  There's consensus.



STEVE:  Yes.  On one machine.  "Many organizations have more than 50 different versions of Java installed on their machines."



LEO:  Well, you don't want to get rid of any.  They might need them.



STEVE:  And you wonder, where did those 50 come from?



LEO:  Don't they uninstall when you install a new version?



STEVE:  No.



LEO:  No?



STEVE:  No.  This continues, says, "This is due to the fact that the Java installation and update process does NOT remove older versions of the software."



LEO:  Unbelievable.



STEVE:  It just piles up in there.



LEO:  Just keep it all.



STEVE:  You just wonder where those gigabytes of your hard drive are going.  Oh, goodness.  "Companies would be well-advised to update to the newest Java release, Java 7, Update 25," and counting.  And here is the final one:  "Less than 1% of organizations were found to be running this latest version of Java."



LEO:  What?



STEVE:  Yeah, 1%.



LEO:  One percent, wow.



STEVE:  And we keep seeing Java exploits are the way people are getting into things.



LEO:  Well, we know companies are conservative about, and IT departments, about installing software.  But this is one place where it would be better not to be.



STEVE:  Ooh, boy.  So I wanted - one of the things I have on my short list of topics is we're going to go in-depth into PGP because...



LEO:  Great, great, great.



STEVE:  Yes, we need to cover...



LEO:  Now, when you say "PGP," we should mention, PGP is a commercial product which is, I think, owned by Symantec now.



STEVE:  Okay.  Then, okay, the PGP protocol.



LEO:  You're going to talk about OpenPGP, which is the open source version of that.



STEVE:  And GPG.



LEO:  Which is the GNU Privacy Guard, which is the one I use and a lot of people recommend.  And by the way, I've been getting a lot of encrypted email from people, saying, hey, does this work?



STEVE:  Ah, cool.



LEO:  And I'm glad to be the other end of that.



STEVE:  Well, there is a very slick-looking - I have not vetted it, so that needs to be said - but a very slick-looking $2 app on iTunes for either the iPhone or the iPad, called iPGMail.  And you can go to iPGMail.com to get introduced to it.  As they say in their description:  "iPGMail is an iPhone/iPad app for sending and decrypting PGP-encoded messages.  With governments and corporations increasingly infringing upon our privacy, we must take steps to protect our private communications and files.  With PGP encryption, you can secure your messages and files to ensure that only the intended recipients are able to read them."  So this is TNO for email point to point.



Continuing their description:  "PGP is a well-established protocol for protecting data with strong encryption using public key cryptography.  It is widely used throughout the world for protecting private exchanges."  That's, for example, how Edward wanted to communicate with Glenn at the Guardian.  "And now it is available on your iOS-based mobile device for a nominal price, $1.99 U.S.



"With iPGMail you can exchange encrypted and digitally signed private messages with others in your PGP chain of trust from your iOS device.  iPGMail is fully functional.  It's not crippled with limited functionality to entice you to purchase add-ons, nor does it present you with ads or other nuisances.  The app supports key generation, public and private key import and export, and both encryption and decryption of files or email messages.  iPGMail supports Dropbox as a way to import or export keys or files..."



LEO:  Ah, that's where I keep my keys, good.



STEVE:  Yup, "...from the app and to enable easier sharing among your devices and computers.  iPGMail integrates with the iOS Mail application and" - oh - "integrates with the iOS Mail application and makes the process of sending or receiving secure private messages simple."  So I've not checked it out yet.  I will.  But I wanted to let everybody know.  It looks very nice.  I mean, they're saying all the right things.  $2 is the right price.  And for iPhone and iPad, with integration, they also have a developer API where they register their own URL schema, x-ipgmail:, and that allows other apps to interact with it, so they may be able to create an ecosystem around this.  And they've fully published it.  So it could also become a standard.



LEO:  I don't understand how it will work with iOS Mail.  I'm downloading it right now and installing it, so...



STEVE:  Yeah.  I haven't yet.  But we're going to get into this because this is, sadly, becoming increasingly important.



LEO:  Yeah, all right.



STEVE:  And a very interesting-looking item on Kickstarter that I wanted to give our listeners a heads-up to:  an NFC ring that you wear on your hand.  You can just Google "NFC ring," and you'll find not only the link to Kickstarter, but a lot of coverage about this because a lot of people are interested.  And I expected the thing might be a big, bulky, clunky thing, but it's actually very nice-looking.  It's got 25 days to go still, and it just shot past its funding goals.  It uses - oh, and Leo, if you want to play the video, it's pretty short.  The TechCrunch link there in the show notes, that's got the best of the videos.  The Kickstarter video has the guy explaining in much more detail.  But the TechCrunch-linked video is very short and has some nice sound in it.



LEO:  I like them.  They look like wedding rings.  You have the U.K. version, but there's a U.S. version, as well.



STEVE:  Ah, good.



[Begin clip]



NARRATOR:  Introducing the NFC Ring, wearable technology that can be used to unlock doors and mobile phones, transfer information, link people, and much more.  If you've not heard of NFC, it stands for Near Field Communication, a wireless technology that can transfer data over very short distances.  Built into the ring are two tiny transmitters, one for public information, the other for private data.  That's all.  No batteries.  No need for charging.  No fuss.  Just a low-profile ring that can be worn all the time to help perform everyday tasks simply by touching your hand against an NFC-enabled device.



So, what can it do?  It can unlock your NFC-enabled phone without the need to enter a PIN or even touch the screen.  Grab yourself an NFC door lock, and it can lock and unlock your door.  [LEO:  Ooh.]  [STEVE:  Uh-huh.]  Use it to share information, WiFi passwords, link to websites or photos, contact information, or anything else you think is suitable to be shared with your friends' devices.  It can be set to hold your public Bitcoin address, for example [LEO:  Ooh.] so you can receive payments.  Or you could use the NFC Ring to automatically launch apps with custom settings, making it a really easy way to personalize app experiences to match your ring.



On top of all that, the software we've developed is open source, so you're free to invent your own uses and create applications to have it act however you want.  This is just the beginning.  We've got big plans for the NFC Ring, and we believe that this tiny piece of wearable technology can make a big difference.  Thanks for watching, and thank you for your support.



[End clip]



LEO:  So does it all make sense?



STEVE:  It does.  There are several things that I like about it.  First of all, it is beautiful.  I mean, it's just a thin band.



LEO:  It looks like a little carbon fiber on the edges.



STEVE:  The idea is it has an orientation to it, so there is some coloration.  About half of the circumference is the public side, which you wear on the outside of your hand, facing the back of your hand.  And the inner side is much narrower, about a quarter of the circumference, and that's private.  So there's actually two separate NFC systems there, the idea being that the inside of your hand is the personal side, and so that's what you would grab the doorknob with to open, to unlock a door.  That's what you, when you hold your cell phone, the ring is up against the back of it, so you're communicating your personal side.  But the cool concept is the antenna is much larger on the public side.  So any attempt to query this from a distance would get the public signal more strongly than the private signal, so it would swamp the private one.  Or at the worst, they would mix together and get no reading at all.  Anyway, it just seemed like a nifty thing.  I'm glad to know that there's a U.S.-based link because, you're right, I had...



LEO:  No, there isn't.  I was mistaken.  Because it's a U.K. project, I guess everything's in British pounds.



STEVE:  Ah, okay.



LEO:  But it'll convert.  I mean, I'm signing up right now.  I can't decide, though, if I want the beefy man size.  Because it's one size, unfortunately. 



STEVE:  No, no, no.  In the small size you do get a range.  So you are...



LEO:  Ah, okay. 



STEVE:  You're able to tell them what your ring size is.



LEO:  And then so the basic, the 18GBP version's gone, but the 22GBP, plus 3GBP to ship, so 25GBP, which is about $35.  That's not bad.



STEVE:  Yeah.  Yeah, I don't think it's bad at all.  And it's potentially very cool.



LEO:  I should warn people, having had some experience with Kickstarter, you don't always get what you pay for.



STEVE:  May not work out.  May not.  But, I mean, I would say go there, look at all the videos.  The guy's very sincere.  He's been, yeah, he's been doing a lot of engineering and forming.  He's got a whole boxful of prototypes that he's been putting together.  So it looks like it could happen.



LEO:  You can have custom covers.  A custom message engraved on the inside of the ring.  All for different levels, you know.



STEVE:  Yes.



LEO:  Yeah.  Be a good wedding ring.



STEVE:  NFC ring.



LEO:  Give your spouse-to-be your PGP key.  She gives you hers.  And then you can go off encrypted into the future.



STEVE:  So today, on Amazon, there are a couple free books offered for the Kindle.  One is the very first Honor Harrington book.



LEO:  Oh, good.



STEVE:  "On Basilisk Station."  And, Elaine, you'll be glad to hear that I pronounced it correctly.



LEO:  Have you been pronouncing it wrong?



STEVE:  No, no.  I didn't know - I think I was originally pronouncing it wrong.  And when she heard my horrific pronunciation, she corrected me.  Apparently it's, what is it, it's some sort of a...



LEO:  It's like a gargoyle.  It's an evil creature.



STEVE:  I thought it was an amphibian thing.  I don't remember now.



LEO:  Well, you know, there's the basilisk in Harry Potter.  But I think it's like half-dragon, half-lion, half - let me look it up on Wikipedia.



STEVE:  Anyway, it is a great book.  If you have a Kindle, if you have not already plowed into the Honor Harrington series, here it is for free.  And believe me, this is a tease because you'll end up with the rest of the books, at least the next 14 of them or so.



LEO:  In European bestiaries and legends, a basilisk is the King of Serpents, said to have the power to cause death with a single glance.



STEVE:  Wow.  So I don't know how that's relevant to the book because...



LEO:  Clearly has nothing to do with the book at all.



STEVE:  There's no basilisks there.  But anyway, it's a great book, it's free right now on Amazon for the Kindle.  As is an interesting little, very short story, believe it or not.  This sounds like an oxymoron, a Peter Hamilton short story.  But actually it is, it's like 39 pages.  It's titled "If At First."



LEO:  [Laughing] I don't think Peter can really - that's not even a prologue for Peter.  That's...



STEVE:  No, it's not.



LEO:  I don't know if he can get started in that short a space.



STEVE:  Yeah, yeah.  And it's a neat story.  It's fun.  "If At First."  It's also free today.  And I'll talk about Peter in a second.  But since we last spoke, I've read another book, Leo.



LEO:  Wow, two.  You're good.  You're way ahead of the game now.



STEVE:  Yeah.



LEO:  Oh, just teasing.



STEVE:  I read cover to cover a book titled "House of Suns."  It's by a Welsh author, Alistair Reynolds.  And he's a well-known sci-fi author.  He's known for his Revelation Space series.  The first book is titled "Revelation Space," and then he's written other books set in the Revelation Space universe.  "House of Suns," I really enjoyed it.  And what's cool about it - and I'm always careful never to spoil, and this doesn't.  But this explores the idea, not so much of deep space as deep time.  Which is a cool idea.  In this universe, there is no warp drive.  There's no FTL, no faster than light; no wormholes, none of those gimmicks.  Einsteinian laws and relativity exist, and they've never been broken.  And so humanity has never succeeded in doing anything other than use vast amounts of power to really come close, 99.99999, some nines, close to the speed of light.  Well, we know what happens then.  You get relativistic time dilation so that...



LEO:  I hate it when that happens.



STEVE:  Oh, don't you?  Unless you've on the ship, in which case you come back to the Earth, and everyone you ever knew is just gone, of course.



LEO:  Yeah, everybody's dead.



STEVE:  So the idea, of course, with relativity, is that time appears from the outside frame of reference to be moving very, very slowly at the frame of reference on the ship.  So imagine a next, I mean, a culture where the humans are spending a large portion of their time moving around the galaxy at very close to the speed of light.  And during the time that they're doing this, civilizations rise and fall.  And so they end up at some point at the other end of the universe's or the galaxy's life, and the galaxy is filled with the leftovers.  I mean, like, massive huge engineering projects of civilizations long gone and all kinds of cool stuff.  So anyway, it was a really interesting read, and I enjoyed it.  So if anybody is looking for something, there's that.  But, Leo, I have started in on the trilogy.



LEO:  Uh-oh.



STEVE:  Yeah.



LEO:  Something else I'm going to have to read now?



STEVE:  Well, "The Dreaming Void."



LEO:  Oh, yeah, I've read that.  Thank goodness.  Whew.



STEVE:  Yeah.



LEO:  That's a long-ass trilogy, I might add.



STEVE:  Boy.  So everyone knows that Peter Hamilton has never written a short book.



LEO:  This is not my favorite, by the way.  I'd be curious what your...



STEVE:  Yeah.  I'm...



LEO:  There's good stuff in it.



STEVE:  Yes.  I'm enjoying it.  I'm 75% through book one.  And it's definitely a sequel to "Pandora's Star" and "Judas Unchained," those books, because there's lots of references back to those books.  So those are fabulous.  I mean, unreserved recommendations for those.  But I'm enjoying these.  So we'll see.  And what are you thinking about "[Great North] Road"?  Or are you still pursuing...



LEO:  It's long.  I've already - I'm already, like, 20 hours into it, and only about halfway through.  I don't know what that translates into pages, but it's long.  And it's good.  I love it.  If you like Peter F. Hamilton, it's just like living in his universe some more.  But it has lots of twists and turns, and it's quite the mystery.  So it slowly reveals more.



STEVE:  That's actually the way "The Dreaming Void" - the thing that put me off is that I thought, that doesn't sound like very much of hard sci-fi.  I mean, I want hard sci-fi.  And, like, some void of dreaming, that seemed a little bit too bizarre, sort of like where "The [Reality Dysfunction]" stuff all went, remember?



LEO:  Yeah, yeah.



STEVE:  They all, you know, like the people - well, I don't want to give it away.  But...



LEO:  It might not be quite your cup of tea.



STEVE:  Well, I'm into it.



LEO:  Oh, good.



STEVE:  And what I like now is, I mean, it takes a commitment because he launches about seven threads that aren't at all connected.  And you're learning about these very different sort of people, and you're going, why do I care about him?  And why do I care about her?



LEO:  You will.  You will.



STEVE:  Yes.  Oh, I know.  And then, then a little - kind of the threads cross over.  And it's like, ooh.



LEO:  Which one has Al Capone in it?



STEVE:  That was "The [Reality Dysfunction]" stuff.  That was the very first major set of books.  And it started off okay.  Then it kind of drifted off course.



LEO:  I was so sick of it by the end of it.  It was like, okay.



STEVE:  Yeah, yeah.  I agree.



LEO:  Yeah, that one, not crazy about.  Loved "Pandora's Star."



STEVE:  Yeah.



LEO:  And "The Dreaming Void," well, I'll be curious what you think.



STEVE:  Yeah.  I will let you know.  So SpinRite, we're continuing to work on it.  That's really all I'm going to say is that...



LEO:  Good man.



STEVE:  Yeah, all the PCI enumeration is done.  We spent the last week - when I say "we," I mean I and this great team that I've got working with me in the newsgroup.  Over last week SpinTest 8 and SpinTest 9 were produced.  The problem is that the PC goes back now about 25 years.  And some of the things I want to do have questionable levels of support in the BIOS.  For example, now we can find all the hardware, but it's necessary to understand what the BIOS sees that SpinRite has found and to associate the BIOS drives with the PCI controllers so that SpinRite can present a coherent picture because you could have devices which are not on the PC bus, which older machines would have, but which the BIOS knows about, so SpinRite needs to.  You could have devices which are on the PCI bus, but the BIOS doesn't know about.  Remember, famously, Greg spends a lot of time telling people, if the BIOS can see it, SpinRite can work on it.



Well, SpinRite 6.1 won't really care whether the BIOS can see it or not because it'll just nail it right down at the hardware level.  But we still - we can't ignore the BIOS.  We need to integrate them together.  And so there are a number of poorly supported APIs in the past which were giving us grief last week, and we've got it all tamed and nailed down now.  And so I'm working on the next iteration of this, which is going to pull it all together.  So work is proceeding, and we're going to have a good next release of SpinRite.  Which, as I have said before, will be free for all SpinRite 6 owners.



LEO:  Aren't you a wonderful feller.



STEVE:  It's the right thing to do.



LEO:  All right.  Let's talk about whatever it is.  Whatever this means.



STEVE:  Yeah.  I mentioned Rahm Emanuel's famous quote, "You never want a serious crisis to go to waste," which he got a lot of flak for saying, but then that's Rahm.



LEO:  A little too honest.



STEVE:  Yeah.  What I think we're going to see - and it's too early to know because we need to see how this settles out.  But certainly there are lawsuits filed.  There are hearings being held.  The question which we don't have the answer to yet is, post-9/11, was there legislative and law enforcement overreach?  That is, did that crisis allow the forces of surveillance in the United States to obtain more power than we wanted them to have?  And the arguments are that, fundamentally, due to the secrecy aspect of this, which is, I mean, and this is the dilemma because we're trying to have an open democracy, yet there is a really good case to be made for the fact that some of what is being done needs to be kept secret, maybe, I mean, that's a question, in order to catch the bad guys.  I think that's actually not as clear as the surveillance system would like it to be because they would absolutely like to operate with absolute secrecy and just a big "trust us."  And the problem is, as we've discussed in the past, that's not worked out well often.



So I feel like we're - the reason I called this podcast "Inflection Points" is it feels like we're at one again, we have been before, a period where there are competing forces and competing motivations and also time is a factor.  I remember famously, for example, after the horrible school shooting at Sandy Hook Elementary in Newtown, Connecticut, I was watching the talking heads.  And they were all very aware of the fact that right now everybody, you know, emotions were running high.  Everybody was upset.  Who wouldn't be?



But if the forces that wanted to use this as their big opportunity to further constrain gun rights were going to be able to succeed in doing so, they had to do it quickly.  The point was people would forget.  As you said, Leo, CNN has moved on to babies from Snowden, and royal births and all of this.  So unfortunately this is what happens.  I mean, this is the nature of that.



And so on a much larger scale, post-9/11 the country was in shock.  And there was a sense of, you know, we didn't - remember, I mean, like restaurant sales dropped because nobody was going outside.  We were all watching television.  And there was a real concern about what's going to happen next.  So it's natural for us to perhaps over-grant rights to law enforcement during that kind of time because we're scared, we're afraid, which essentially is the crux of what Rahm was saying when he says "Never let a serious crisis go to waste."  The point is you can use fear.  People, forces, can use fear to achieve.  Over time we recover.  That's what humans do is we understand the way the world has changed, if it has.  We accommodate a reality which is different than what we had before that event.



And maybe that accommodation has us always being somewhere else.  For example, maybe we will reach the decision that, yes, we want surveillance because we maturely accept the fact that that's the cost of dealing with asymmetric warfare and terrorism.  Or maybe we'll say, well, we don't want that much surveillance.  Or maybe we'll say we want - you can have it, but you've got to tell us about it.  We made a mistake allowing it to be secret.  Who knows?  I don't know.  And I really don't even have a horse in this race.  I have no control over it.  I'm an observer and interested to see how this turns out.



So just Friday, Ars Technica reported a headline that caught some people's attention:  "Snowden be damned:  Government renews U.S. call record order."  I don't know how that makes sense.  But their subtitle is:  "Again, feds argue there's no 'legitimate expectation of privacy' over metadata."  And so what happened on Friday, and this is interesting also, the Director of National Intelligence, our friend James Clapper [clearing throat], released a statement saying that its authorization, the DNI's authorization to compel telephone companies to share metadata has been renewed by the Foreign Intelligence Surveillance Court.



So what's significant, and I'm skipping down:  "The move is particularly noteworthy and unusual as this type of data sharing had previously been kept from the public."  But now, on the other hand, why bother keeping it secret now?  The cat's out of the bag.  "But now one of the country's top intelligence officials is publicly acknowledging that the FISC" - that's the court - "has sanctioned continuation of its powers.  In the new statement, Director of National Intelligence James Clapper wrote that he had declassified some information 'in order to provide the public with a more thorough and balanced understanding of the program.'



"In its new statement, the DNI also wrote, 'Consistent with his prior declassification decision and in light of the significant and continuing public interest in the telephony metadata collection program, the DNI has decided to declassify and disclose publicly that the government filed an application with the Foreign Intelligence Surveillance Court seeking renewal of the authority to collect telephony metadata in bulk, and that court renewed the authority.'



"Meanwhile, the government has formally responded to a lawsuit" brought by the ACLU versus James Clapper, suing - the ACLU, the American Civil Liberties Union, sued James Clapper, arguing "to halt the nationwide metadata spying program.  In its federal lawsuit filed on June 11th, the ACLU argued, 'This surveillance is not authorized by  Section 215,' which we discussed in our first podcast, 'and violates the First and Fourth Amendments.  Plaintiffs bring this suit to obtain a declaration that the Mass Call Tracking is unlawful; to enjoin the government from continuing the Mass Call Tracking under the VBNS order" - and that must be Verizon Business something or other - "order or any successor thereto; and to require the government to purge from its databases all of the call records related to Plaintiffs' communications collected pursuant to the Mass Call Tracking.'"



So this is what I mean when I say we're beginning to see the chips falling and lawsuits being filed and the government responding.  And I think, again, this is all good.  This is what has to happen.  And then at the same time, actually I think this was Monday, so a couple days later, two days ago, the New Jersey Supreme Court unanimously ruled that warrants were needed for phone tracking.  Computerworld reported that "Cell phone users have a reasonable expectation of privacy of their cell phone location information, and police must obtain search warrants before accessing that information, the Supreme Court of New Jersey ruled" - oh, I'm sorry, this was Thursday, also last week.



And this was important.  They said, although the great quote's here at the end, they said:  "'When people make disclosures to phone companies and other providers'" - so this is the court - "'and other providers to use their services, they are not promoting the release of personal information to others,' wrote Chief Justice Stuart Rabner in an unanimous ruling on an appeal.  'Instead, they can reasonably expect that their personal information will remain private.'



"The issue of boundaries in the use of cell phone data by law enforcement agencies has figured in other courts and state legislatures."  Yeah, no kidding.  "The Montana legislature passed a law recently requiring police and other agencies to obtain a search warrant from a court before tracking a person using location information from an electronic device.  Federal courts have been divided on the issue of cell phone tracking by law enforcement.  But historically, the New Jersey Constitution has offered greater protection to New Jersey residents than the Fourth Amendment to the U.S. Constitution, Rabner observed.  The Fourth Amendment protects against unreasonable searches and seizures."



And so here's the key line in this:  "'Under settled New Jersey law, individuals do not lose their right to privacy simply because they have to give information to a third-party provider, like a phone company or bank, in order to get service,' the judge wrote.  Evaluating the legal implications of cell phone technology, the judge wrote that, 'as a general rule, the more sophisticated and precise the tracking, the greater the privacy concern.'"



Well, so that's interesting because it is specifically this notion of third party that the government is using.  The end of that Ars Technica story says:  "In short, the government is relying on a well-established, but increasingly challenged, part of American case law known as the 'third-party doctrine.'  This notion says that, when a person has voluntarily disclosed information to a third party - in this case the telephone company - the customer no longer has a reasonable expectation of privacy over the numbers dialed, nor their duration.  Therefore, this doctrine argues, such metadata can be accessed by law enforcement with essentially no problem."



So what we have is we have a confluence of opposing opinions and forces that have all arisen as a consequence of the disclosure, which is why I'm glad that this happened.  You cannot do this in secret.  We have to have this public for our system to operate.



And then today, on this July 24th, just last night there was some argument in the House of Representatives.  There's going to be a vote, may have been by this time, on an amendment to the current, still in work, Defense Appropriations Bill to end the authority for the blanket collection of records under the Patriot Act, which would bar the NSA and other agencies from using Section 215 of the Patriot Act to collect records, including telephone call records, that pertain to persons who are not subject to an investigation under Section 215.  So I don't know what the vote was on that.  To me this seems premature.  It probably did not pass.



[Update 7/25:  House voted 217-205 to continue phone taps]



But as I said, we always see that we're initially upset, and then we sort of get used to the new status quo.  So the question is, how long does this last?  Where do we settle down on what we agree as a society to have in this balance of the need for surveillance and the fact that our Constitution wants to protect and give us individual privacy.  House Rep. Jim Sensenbrenner said on the 17th, "Section 215 expires at the end of 2015.  Unless you realize you've got a problem" - this was during a meeting in the House, so he was speaking to the Intelligence Committee, saying, "Unless you realize you've got a problem, [Section 215] is not going to be renewed.  There are not the votes in the House of Representatives to renew Section 215 at this time."  So again, 2015 is a long ways away.  Who's to say what position we will have been in, we will be in by then?



And then, finally, I'll wrap all this with - back to Bruce Schneier, who has been blogging brilliantly, I think, about these topics.  And he did a blog just yesterday, on the 23rd of July, "How the FISA Court Undermines Trust."  And Bruce cited a link to two samples.  First was Eric Lichtblau in The New York Times wrote, he said, oh, the title of the story was "In secret, court vastly broadens powers of NSA.  In more than a dozen classified rulings, the nation's surveillance court has created a secret body of law, giving the National Security Agency the power to amass vast collections of data on Americans while pursuing not only terrorism suspects, but also people possibly involved in nuclear proliferation, espionage, and cyberattacks, officials say.  The rulings, some nearly 100 pages long, reveal that the court has taken on a much more expansive role by regularly assessing broad constitutional questions and establishing important judicial precedents with almost no public scrutiny, according to current and former officials familiar with the court's classified decisions."  So that's the first point.



Second is in The Wall Street Journal, an article titled "Secret court's broad interpretation of 'relevant' enabled vast spying.  This change - which specifically enabled the surveillance recently revealed by former NSA contractor Edward Snowden - was made by the secret Foreign Intelligence Surveillance Court, a group of judges responsible for making decisions about government surveillance in national security cases.  In classified orders starting in the mid-2000s, the court accepted that 'relevant' could be broadened to permit an entire database of records on millions of people, in contrast to a more conservative interpretation widely applied in criminal cases, in which only some of those records would likely be allowed, according to people familiar with the ruling."



Okay.  So Bruce then steps back and gives us, I think, just a perfect analysis.  He says, "Surveillance types make a distinction between secrecy of laws, secrecy of procedures, and secrecy of operations.  The expectation is that the laws that empower or limit the government's surveillance powers are always public.  The programs built on top of those laws are often secret.  And the individual operations are almost always secret.  As long as the public knows about and agreed to the law, the thinking goes, it's okay for the government to build a secret surveillance architecture atop it.  But the FISA court is, in effect, breaking the first link in that chain.  The public no longer knows about the law itself, and most of Congress may not know, either.  The courts have remade the law, but they've done so secretly, without public comment or review."  Which I think exactly sums it up.



LEO:  Yup.



STEVE:  So that's really where we are.  The one thought that I had in reading all this, the part, I guess the thing that I wanted to sort of postulate as a solution - because we have a problem here.  There are even now defense attorneys, Leo, that are trying to subpoena the NSA records because they believe that they will help their case.  And so the argument actually has very, like, some strong legs to stand on, is the government has records which it's using to prosecute.  But legal precedent says that the prosecution must turn over all evidence, even if it would be exculpatory, even if it would be useful to the defense.  And to the defense attorneys are saying, hey, you've got to give it to us.  You've got it.  We have a right to use it to, for example, demonstrate that our client wasn't where you are trying to say he was, and his phone records will demonstrate he wasn't.  So give us the phone records because you've obviously got them.



LEO:  Yeah.



STEVE:  So the only thing I can think, the only way I can, like, say, okay, how do we solve this problem, is maybe to have an escrow.  The problem is that the people who want to do surveillance also want to be the people to have it all.  And the argument is that we have short-circuited the traditional process of obtaining a search warrant.  Nobody, none of the ISPs, none of the big cloud providers, none of them have a problem.  If a judge reviews a case and gives the FBI a warrant for the information, it'll be turned over.  That's, I mean, that's fine.  The problem is that taps have been installed on the Internet, and all of this data is being surveilled without warrant.  I mean, famously, "warrantless wiretapping."  Now it's warrantless 'Net tapping.  So imagine if this was taken away from the NSA.  That is, if the - I mean, I can sympathize with a need to build networks, to follow the call traces of possibly known terrorists, who did they talk to, and even to go back in history.  Thus the metadata, the big web that the data can be crunched through.



The problem is it has to have oversight.  It has to have - it just can't be that the NSA, who wants to perform the surveillance, gets to have limitless access to this information in secret, and just says "trust us."  And, I mean, that isn't the way our system works.  And so the only thing I can think of, as I look at the technology, coming again from a technology standpoint, is that there is an escrow; that all of this data is held, and by - give it to the ACLU.  They certainly aren't going to turn it over without due process.  And then return to the process of a judge saying, issuing a formal search warrant for search of specific individuals in this network, and then turn over that data.  That's the only solution I can see.  Either that, or we just decide, okay, we live in a world where our government now needs to watch everything we do, and so be it.



LEO:  I'm afraid the latter seems the most likely outcome. 



STEVE:  Yeah, well...



LEO:  But we'll do our best.



STEVE:  It gives us lots to talk about on this podcast, about TNO technology and end-to-end encryption and how we can, I mean, I hate the idea of needing to hide from the surveillance state.  And again, my favorite quote from someone who tweeted it is when people say, "Well, why do you care about encryption if you have nothing to hide?"  To which the response is, "I have nothing to hide from people I trust."



LEO:  Simple enough.



STEVE:  Yeah.  That's just exactly it.  Yes, I...



LEO:  That's a small subset of the total population.



STEVE:  Yeah.



LEO:  Steve Gibson is...



STEVE:  And we know about the danger of Big Brother.



LEO:  Yes, we do, unfortunately.  Steve Gibson is at GRC.com.  That's his website, Gibson Research Corporation.  You can find him on Twitter, @SGgrc.  If you go to GRC.com, you'll find of course lots of great stuff, including SpinRite, the world's best hard drive maintenance and recovery utility, and 16Kb versions of this show for the bandwidth impaired.  Transcriptions, too, by an actual human being who can spell and say "basilisk," Elaine Farris.  You can find full-quality audio and video at our website, TWiT.tv/sn.  And of course subscribe.  You'll get this show whenever it comes out on our favorite device.  There's lots of podcatchers out there now, plenty of ways to get Security Now! automatically.



If you'd like to watch live, we'd love you to do it:  11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC, every Wednesday.  That's when we open the cameras and let you watch us record the show live.  And of course the chatroom is always a big part of the show.  Hey, thank you, Steve Gibson, for being here. 



STEVE:  Always glad to be.



LEO:  If you've got a question for Steve, he's going to do, time and security news permitting, a Q&A episode next week.



STEVE:  Yeah, we've got to get back to our questions.  So we'll do, definitely do listener questions next week.



LEO:  So go to GRC.com/feedback and post a question or two.



STEVE:  Please.



LEO:  And we'll answer as many as we can next week.  Thanks, Steve.  Have a great week.  We'll see you next time on Security Now!.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#415	

DATE:		July 31, 2013

TITLE:		Listener Feedback #172

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-415.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to answer 10 of your questions.  He's going to talk about security issues.  Yes, there's another slide from the Edward Snowden deck.  We'll talk about what that all means, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 415, recorded July 31st, 2013:  Your questions, Steve's answers, #172.



It's time for Security Now!, the show that protects you and your loved ones and your privacy online and your security online.  Couldn't better be a better time to do a show like this, as we've said for the last six years.  Steve Gibson's here, the Explainer in Chief, from GRC.com.  He's the creator of SpinRite, which is his bread and butter for many moons now.  Is it 20 years now, Steve?



STEVE GIBSON:  25, my friend.



LEO:  Holy cow.  Holy cow.  But in the time, because SpinRite's been such a nice little daily earner...



STEVE:  Purring on.



LEO:  Purring on.



STEVE:  Also thanks to our listeners, many of whom have purchased it just to support...



LEO:  Isn't that nice.



STEVE:  Yeah, it really is.



LEO:  It's given him a little time and the inclination, I think, to investigate, first spyware.  He was the man who coined the term "spyware" many moons ago when he first discovered it and created the first antispyware tool.  He's created many other free tools at GRC.com.  And for the last 415 weeks - that's amazing - we've been talking about security on the show.  And you know, the show's gotten longer and longer and longer because there's been more and more to say.



STEVE:  Well, it's funny, too, because we introduced the concept of not trusting your data to the cloud several years ago and coined the term "TNO" for Trust No One.  And here we are now, I mean, it's like it's come full circle because now we absolutely know, with no doubt, and we're getting increasing level of detail, in fact, that the government and global governments have for some time been recording everything that's been done on the Internet.  And so there was a tweet that went by, and it didn't really catch me, but the guy was making - he was referring to our conversation, the dialogue we've been having about the whole concept of privacy, like the notion of, well, why does it matter if you're not doing something wrong?  And he said, well, I don't want a webcam in the bathroom.  And I thought...



LEO:  It's not like you're doing anything wrong in there.



STEVE:  Exactly.  But, I mean, there is this notion of not being watched as something valuable, just the concept of not being on some weird reality TV show.  And it turns out, as far as the Internet goes, that's pretty much the situation.  Just today, this morning, another piece of new information, part of the continuing Snowden drip of disclosures...



LEO:  That's kind of disgusting.  Okay.  Yes.



STEVE:  Well, just say that the Snowden is melting.  Yes, we have - anyway, Glenn - and it's funny because on the website it's G-l-e-n-n.  And I'm very particular about getting these things right.  But I'm sure I've seen it with one "N" elsewhere.  So it's two N's for everyone who's as crazy about details as I am.  Our friend Glenn Greenwald has been saying that there would be additional stuff coming.  And every time interviewed, one of the questions that the talking heads say, well, do you have more coming?  He says, oh, yes.



Well, today we learned about XKeyscore, which is the name of the program, from the Guardian.  Now, I have to say it continues to ratify the theory we first put forward about what PRISM was.  And nomenclature is crazy in all of this.  And in fact it might have been Bruce in one of his other blog postings, Bruce Schneier, who commented that our intelligence services were using acronyms as obfuscation in order to just confuse the legal system and legislators, and also to create this deniability where they could say, well, it's PRISM doing this.  And then, with a straight face, the intelligence person could say, no, that PRISM does not do that.  Because XKeyscore does that, or Slimy Underworld does that, or whatever their random program names are.



So what we have now, as of this morning, is knowledge of - on the Guardian's page there's a link to a scrolling series of slides which are amazing in detail.  For example, we now know that it's a massive distributed Linux cluster is the architecture for this.  So what Glenn and Snowden disclosed are slides which show that the NSA collects, quote, in their own words, "Nearly everything a user does on the Internet."  XKeyscore gives "widest reaching," in quotes, collection of online data.  NSA analysts require no prior authorization for searches.  So they can search anything they want to, any time they want to.  And it sweeps up emails, social media activity, and all browsing history.  And the word "all" is, like, littered throughout this.  And it's a little frightening when you see where they're saying "all."



So there are presentation training materials that have been posted showing really interesting new detail, which is the reason I'm talking about this, is it's not the same old stuff.  It's like now we're getting more stuff.  For example, they use an acronym DNI, which stands for Digital Network Intelligence.  And in the slide it says "DNI Exploitation System/Analytic Framework performs strong (e.g. email) and soft (content) selection.  Provides real-time target activity," which they refer to as "tipping."  And then, get this, "rolling buffer of approximately three days of ALL" - all caps, their emphasis - "unfiltered data seen by XKeyscore."



So this is - we've never had this before.  This is news.  This says - now, we've talked a lot about the quantity of information that is passing through these taps which they have.  And as we'll see in a minute here, the architecture as this onion is being peeled continues to substantiate my notion that this is outside of the major cloud service providers because none of this would be necessary if it had their cooperation.  So this is tapping Google just upstream of the datacenter where the data is raw.



And so now what we're seeing is that they're storing everything that goes through, as they refer to it here, "all unfiltered data" in a "rolling buffer," which again, if they said, Steve, we want you to design something for us, this is the way you do it.  This is how a computer science person would tackle the problem of too much data coming through to store it all, yet you need to be able to look back in time to perform searches.  So the raw data is essentially in a big scrolling buffer where you always have the most recent three days.  About after three days you start losing it off the end of the buffer as new data comes in because you just run out of your short-term buffer space.



So it says stores what they call "full-take," full hyphen take, so that's their jargon for "everything," full-take data at the collection site, which is then indexed by metadata.  So as this all pours in, they're pulling metadata from it which are email, and actually they enumerate those in a minute, email addresses, phone numbers, names, like sort of formatted keyword searching on the raw data which is then indexed on the fly, allowing them to then do queries against the metadata and then, within this three-day period, to extract from the buffer of the so-called "full-take data" specifically what they want.





And then it says "Provides a series of viewers for common data types."  And once again, that's exactly what you'd expect.  They'll have an email viewer.  They'll have a chat dialogue viewer.  They'll have an NNTP viewer.  They'll have these viewers which know how to take, which know how to format the raw data which has been just sucked up en masse out of the stream and presented in a same format.  They'll have an HTTP viewer, for example, something that knows how to reconstruct the web page just as a web browser does from the raw data, and also to show the web page metadata, the query and the response headers.



Then they call this also a "federated query system," where one query scans all sites.  Now, this is also amazing because amid these slides is a picture of the world showing red spots wherever the NSA has planted one of these facilities.  And it's in more than 150 sites, with more than 700 servers, literally all over the globe.  And so what we're saying is that they're tapping major data feeds in all of these locations.  And then this federated query system allows an analyst, presumably sitting somewhere in Virginia - or wherever, apparently Snowden was able to do it in his little bungalow in Hawaii - to insert a query into the system which then goes globally, and then all of the databases in all of these systems around the world in this federated query system are simultaneously asked for matches.



And so under Federated Query System it says, "One query scans all sites.  Performing full-take allows analysts to find targets that were previously unknown by mining the metadata."  So as this bulk of data goes by, it is being examined and metadata extracted from it and stored separately from this so-called "rolling buffer" of three days of everything.  So under a slide called System Details, they say massive distributed Linux cluster, over 500 servers distributed around the world.  Elsewhere they say 700.  System can scale linearly.  Simply add a new server to the cluster.  And then also under system details they said "federated query mechanism," which we just talked about.



Then they talk about the analysis plugins.  And these are these so-called, I would call them semantic analysis, where they need to extract the meaning from the raw data.  I remember, Leo, just after we finished the first podcast you switched over to This Week in Google, and Gina had a problem with this notion that you could get meaning from the stream.  And the way of course you do that is exactly like this.



The stream itself is raw data.  But it's only because a web browser expects the format to be something that it's able to show it to you as a web page, or an SMTP reader, an email system, expects the format to be email, that it knows how to show it to you.  So it's only a tiny step further to look at the raw data.  And any human can do this.  We do this all the time when we're doing packet-sniffing on the raw wire.  You can see, like, what the headers are and the way it's formatted.  It's like, oh, these are email headers.  Oh, these are HTTP headers.  Oh, these are newsgroup headers, or chat format.



So the idea is you start with the raw stream.  You apply a simple heuristic recognizer to it, to determine what type of stream this is.  And then you say, ah, you recognize what it is, and then you apply one of these plugins to format it for full recognition.  So they say "Email addresses:  Indexes every email address seen in a session both by username and domain.  Extracted files:  Indexes every file seen in a session, both by filename and extension.  HTTP parser:  Indexes the client-side HTTP traffic.  Phone number:  Indexes every phone number seen in a session."



And then they have in parens, "(e.g. address book entries or signature block)."  So, for example, when email goes by with a signature block in it, bang, it locks onto that and indexes phone numbers and the metadata in the signature block.  "User activity:  Indexes the webmail and chat activity to include username, buddy list, machine-specific cookies, et cetera."



So more data is coming out.  If anyone's interested, this is all over the news now, so you could go to the guardian.uk.co, or co.uk, rather, and track this down.  And there's a long article where Glenn pulls this apart and essentially parses what new has been learned from this.  And it is additional details that are a little chilling about the scope of this project.



LEO:  Yeah.  You know, I want to raise one point which - I don't know.



STEVE:  Yeah, do.



LEO:  Maybe this is a little conspiracy theory-minded.  It is in the strong interest of the NSA and the U.S. government to have terrorists believe that they know everything.  Right?  And I'm often puzzled.  In some ways they claim capabilities far beyond those we know to be possible, like decrypting strongly encrypted stuff.  I'm wondering if some of this is merely disinformation.  We mentioned this last week as the "panopticon theory," that the watchers would love it if all the watched believed that the watchers could see everything.  So there is a - the truth is that the NSA gains by all this information.



STEVE:  I don't know.  I really think that our intelligence system has taken a huge hit.  I mean, this has hurt the intelligence community.  This is not - in no way is this good for them.



LEO:  Okay.



STEVE:  I really think, I mean, I know I feel differently.  It's one thing to sort of suspect, oh, well, maybe this is going on, and something else to just have the dirty laundry aired like this.



LEO:  Right, right.



STEVE:  I mean, this leaves no one any doubt.  And these are - it's not like this was leaked, like, oh, whoops, we gave this to a senator, and we didn't intend for him to let his staff fax it.



LEO:  Yeah, that would be the easy way to do that, yeah.



STEVE:  Yeah, I mean, this truly was, I mean, this really was a bad guy, well, I don't mean a bad guy, a person who broke...



LEO:  A bad guy only in the belief of the Department of Justice.  Let's put it that way.



STEVE:  Yeah.  As I said, I'm not unhappy that this has come out because there's no way this is not going to force a seriously necessary reexamination of the system that we had put in place post-9/11.  And it may well be, as I said last week, we may just end up saying, well, that's the price we have to pay of having the surveillance that we need in order to detail with asymmetric warfare, which is the nature of terrorism.  And so be it.



LEO:  Well, isn't that exactly what happened a couple of days ago in the House, when they overturned the defunding of the phone taps?



STEVE:  Yeah, but it was, it was a close - close, Leo.



LEO:  It was close.



STEVE:  I was very surprised that it was 215 to 210 or something like that [205-217].  It's like, wow.  That really surprised me that, yeah, pulling funding...



LEO:  However, the will does not yet exist to stop this.



STEVE:  No.



LEO:  And I think it makes sense because you don't want to be the representative who voted to stop it, and then there's a terrorist...



STEVE:  I know.



LEO:  ...attack, and you look like you're the guy who made it possible.



STEVE:  Yeah.  I don't think blanket defunding was the solution, which is why I said last week that I thought this vote was coming up too soon.  It takes, you know, these wheels do not turn slowly.  And it is all politics.  And I don't have any, I mean, I'm just - as an observer, it's like, well, we'll report what we know, and we'll see how the cookies crumble.  And it's like, it is what it is.  I have no power to change it one way or the other.  My interest is in the technology, which I think is fascinating and interesting, and also in finding that the technology-driven line where, okay, email is probably not encrypted as it comes and goes.  But web services increasingly are.  So what does that mean?



And then we find out last week that there is in fact pressure to turn over the private keys of web servers so that they can decrypt because, as we would expect, increasingly web traffic is encrypted.  So that's where I think our proper place is, rather than taking a position.  I just - I have no interest in taking a position because there's nothing I can do about it.



LEO:  Well, you'll be pleased to know I'm getting now a fairly steady volume of people testing out their PGP keys and saying, is this encrypted?  Is it working?  And I do respond to everybody.  My PGP key is, if you want to get the key, is available at Leoville, my personal website, Leoville.com.



STEVE:  Well, we end this podcast with a couple PGP-related questions because it will take us into next week which is going to be all about PGP.



LEO:  Good.  Good, good, good.  Okay.



STEVE:  Now, this is not at all security related.  But I just sort of shook my head when I saw this.  It's like, oh, you're kidding me.  We all know how Microsoft named their new OS "Metro," and then turns out they didn't have trademark rights to Metro.  Well, they just lost the lawsuit on SkyDrive.  After all the...



LEO:  Holy cow.



STEVE:  Can you believe it?  After all the time and energy they put into it?  So the BBC posts:  "One month after a British court ruled that Microsoft's SkyDrive infringed..."



LEO:  Unbelievable.



STEVE:  I know.  It's unbelievable, Leo, "infringed on a British Sky Broadcasting (BSkyB) Group trademark, Microsoft has decided not to appeal and will find a new name for its cloud storage service."



LEO:  Wow.



STEVE:  You know, they're paying their attorneys too much for patents and not enough for trademarks, apparently.  It's like, Microsoft, get a clue.  "British Sky Broadcasting offered an online storage service called 'Sky Store & Share' between 2008 and 2011..."



LEO:  Really?  Really?



STEVE:  "...and it has trademarks such as Sky+, Sky Digital, Sky Broadband, Sky Go, Sky Mobile, Sky Bet..."



LEO:  They own "sky," huh?



STEVE:  Yeah, and Sky Photos.  And so Microsoft tried to get SkyDrive, and they said no.  The press release quotes...



LEO:  I'm actually feeling sorry for Microsoft, to be honest with you.



STEVE:  ...British Sky Broadcasting saying, "We are pleased to have reached a settlement after Microsoft agreed not to appeal the trademark infringement judgment in relation to its SkyDrive service.  We will remain vigilant in protecting the Sky brand and will continue to take appropriate action against those companies who seek to use our trademark without consent."



Now, of course we know Microsoft would have been every bit as crazed if anyone called Windows something, Windows this or Windows that.



LEO:  Yeah, oh, yeah, yeah.



STEVE:  They would have stomped the crap out of them in a heartbeat.  So it's like, but, you know, come on, Microsoft.  Do your homework.  So I just wanted to let our users know SkyDrive - what happened is there was an undisclosed payment made - oops - and Microsoft has been allowed to continue using the name while they phase in their replacement name.



LEO:  Wow.



STEVE:  So they're going to have to go find one.  It's like, oh...



LEO:  It is tough nowadays.  I remember even back in 1994, when we were trying to - or '95 - create the site for MSNBC, they needed a name that hadn't been used, wasn't trademarked, and had a dotcom that they could use, et cetera, et cetera.  And it's always getting harder, it seems like.  That's why - people wonder why all the baby talk names with new startups.  Now you know.  Because you can't use a real word.  They've all been taken.



STEVE:  Yeah.



LEO:  So Microsoft's going to call it "Ishkabibble" or something, and we'll all get used to it.



STEVE:  Leo, that's been taken.



LEO:  Yeah, it has, actually, the 1920s movie star.



STEVE:  And you just said it.



LEO:  I own it now, baby.  Prior art.



STEVE:  Yeah, I mean, it is the case, I know that when I've been looking for product names and associated domains, I've kept it quite close to the chest until I nailed it down because...



LEO:  It's become amazing.



STEVE:  Yeah, it is crazy.  So in crypto-related news, some researchers in the U.K. and the Netherlands cracked the crypto, and unfortunately it's an RFID standard, known as Negamos, or, I'm sorry, Megamos, Megamos maybe, crypto, which is used by a whole slew of Volkswagen-owned luxury car makes and others.  They gave Volkswagen and companies nine months' prior notice that they were going to explain what the problem was.  And this was going to be a paper presented next month at the USENIX Security Symposium, and it got stomped on a couple days ago by a judge.



The BBC reported that "The researchers said they'd obtained a software program from the Internet which contained the algorithm devised by [a defense company] Thales to provide the security feature.  They said it had been on the 'Net since 2009."  So they discovered a weakness in the code which had been published on the Internet, showing that it could be compromised, and added that there was a strong public interest that the information be disclosed to ensure the problem was addressed.



"However, VW and Thales argued that the algorithm itself was confidential information" - once again, even though it had been on the Internet since 2009 - "and whoever had released it on the 'Net had probably done so illegally."  Therefore, they said, "there was good reason to believe that criminal gangs would try to take advantage of the revelation in the academic paper that was going to be released to steal vehicles.  The researchers argued that this risk was overblown since car thieves would need to run a computer program for about two days to make use of the exploit in each case."  So this was a brute-force crack against a specific instance of the RFID crypto used on a given car.  Which still doesn't mitigate it.  I mean, if this is a Lamborghini, and by the way, that was one of the brands...



LEO:  It was very high-end cars.  It wasn't cheap cars.



STEVE:  No, no, no.  And so they said that removing the sections - so first it was asked if they could redact their paper to remove, like, too much information.



LEO:  The how-to, yeah, yeah.



STEVE:  Like the real - well, actually what I first read, this was a couple weeks ago, was the codes themselves, they wanted to say, here's a code of some sort.  And I don't know how that would be generally useful.  I didn't dig all the way in because I figured something like this was going to happen.  "They said that removing the sections which VW and Thales wanted expunged..."



LEO:  I think it's Tah-leeze [ph], by the way.



STEVE:  Oh, Thales?



LEO:  Or Tahlz [ph].



STEVE:  Oh, okay, thank you - "would mean their paper would have to be peer-reviewed a second time, and they would miss their slot at the conference as a consequence.  And they argued that their right to publish was covered by freedom of speech safeguards in the European Convention on Human Rights.  However, the judge ruled that, pending a full trial, the details should be withheld."



LEO:  This is really security through obscurity.



STEVE:  Yeah, it is, unfortunately.  "Tom Ohta, an associate at the law firm Bristows," which was not in any way involved in the case, "said the way the researchers discovered the flaw proved their undoing."  He said, "'An important factor here was that the academics had not obtained the software from a legitimate source, having downloaded it from an unauthorized website.  This persuaded the court,'" he said, "'that the underlying algorithm was confidential in nature, and bearing in mind the public interest of not having security flaws potentially abused by criminal gangs, led to the injunction.'"  So, eh, I mean, this is what the law helps us do in these cases, or a judge is trying to judge, is where the public interest falls.  And without knowing more fully - the problem with nine months' disclosure in this case is it's not like Microsoft or Sun with Java or Adobe with Flash, where they can fix it and push out an update and hold their breathe it'll actually happen.  I mean, unfortunately the Lamborghini has left the showroom, and it's got flawed crypto.



Now, what we do know, and the gangs know it now, too, the bad guys know it, is this crypto is weak in some fashion.  And there are lots of other smart people out there.  So I don't know at what level you can fix the algorithm.  It's probably embedded in silicon, not flashable, not updatable.  So now you've got all these very high-end cars...



LEO:  [Laughing]



STEVE:  Yeah, that are protected, I mean, and this is open - this is unlock the doors and start the engines.  I mean, this is full enablement of the car when you crack this.  So this is not like you can tweak where the mirror is pointed.  This is you can get in and drive away.  Whoops.



LEO:  Wow, wow, wow.  Do they have a list of all the makes?



STEVE:  Yeah, I saw them.  There are several articles about this.  And, I mean, it is a Who's Who of, like, Porsche, Lamborghini, and a bunch of others.  It's like...



LEO:  Yeah.  But Volkswagen makes the software, or...



STEVE:  Volkswagen is the parent company of a lot of these.



LEO:  Ah.



STEVE:  They've sort of been purchasing them quietly.



LEO:  They own Porsche, right, yeah.



STEVE:  Yeah, and Lamborghini, apparently.



LEO:  Lamborghini.  I don't know if Audis - I want to know because I'm about to buy an Audi.



STEVE:  I don't think Audi.



LEO:  I don't think I saw Audi on the list.



STEVE:  No.  And by the way, Audi's really - they've really got their act together, Leo.  I'm very impressed with what Audi's been doing lately.



LEO:  Come up and take a ride when mine comes.



STEVE:  I think it makes a great - you mentioned this before, and I thought, ah, that's a smart...



LEO:  I may actually drive down to see you.  I have to do something with the thing.



STEVE:  [Laughing]



LEO:  I'm going to get mine pre-hacked.  No, the good news is I'm getting a 2014 model.  So I'm hoping that they will not use Thales, or they'll update it.



STEVE:  You'll have the latest update.



LEO:  Oh, criminently.



STEVE:  Oh, goodness.



LEO:  Holy moly.



STEVE:  Mm-hmm.  That's why I'm happily driving an '01.



LEO:  Yeah.  With a key.  With a physical key.



STEVE:  Physical key, yeah.  So, following up on last week's ridiculous DHS email, I got many very good comments from people in the defense industry who understand this more than the common man would, only because they're subjected to the inanity of it.  And it's funny, too, because I have two - the email coming in sorts into two folders, anonymous and not.  And we know that it's nice to, as we're reading the Q&A, we like to say, oh, Scott Wilson from wherever he is said this.  It just sort of humanizes it more.  But as I was closing the folders - and as a consequence I tend to pull from those.  But as I was closing them before shutting down my email client in order to clean things up for the podcast, I looked in the Anonymous folder.  And that's where all of the reports about the DHS email were.  That is to say, anonymously submitted to me, rather than not so.  Anyway...



LEO:  Makes sense.



STEVE:  Many of them said different things, summarized by this one.  So I just pulled one from it.  And he used the initials "CC," and he's in Northern Virginia, is all he wanted to say.  He said, "Steve, even though the Snowden documents are publicly available, they are still classified."  Okay, so some of this still seems odd, but this is the view...



LEO:  This is how it works, yeah.



STEVE:  This is how it works.  "Even though the Snowden documents are publicly available, they are still classified.  I work as a contractor to a government agency (not the NSA), and we are also forbidden from even doing a search on the word 'Snowden.'"



LEO:  Wow.  That's ridiculous.



STEVE:  I know.



LEO:  Can they do it at home, or only on government computers?  Sounded like in that memo you couldn't even do it at home.



STEVE:  The machine - you're right, the machine at home would have its classification level raised if it received the document and, presumably, if the web browser displayed what was classified.



LEO:  Right, right.



STEVE:  So going on, CC says, "Until the President or someone in authority declassifies a document, it can only be viewed on a device that is cleared for the same classification as the document itself.  Viewing any Top Secret document, even one that is publicly available due to a leak, on an unclassified computer is called 'spillage.'  The system receiving the spillage remains at the classification level of the document until it is sufficiently scrubbed, and it must be immediately disconnected from an unclassified network.  The DHS memo may seem stupid" - may? - "but it is a standard policy that all contractors and government agencies are required to comply with or face very stiff penalties.  'Availability' does not modify the classification of the document."



LEO:  I believe I got similar emails from a number of people, one of whom said the originator of a document is the only one who could declassify it.  So you probably don't want to really reveal who you are.  Also we have somebody in the chatroom who says he's a government contractor, and he cannot look at them on his home computer, either.  He can't make those searches either.  So if you're a government contractor, you're really enjoined from doing anything, looking into this at all.



STEVE:  Wow.



LEO:  I suppose you can't go to WikiLeaks, I mean, the whole thing keeps, in a way, keeps our government in the dark.  They can't find out about this stuff.



STEVE:  Several people did explain, in longer email that was really too long for the podcast, actually, why it is this way, and why it's as rigid as it is, and that it cannot - you can't make exceptions.  You have to have it this way.



LEO:  Chain of command stuff.  You've got to do it this way.  I understand.



STEVE:  Yes, yes.  If it becomes soft and porous, then the whole system, the whole system crumbles and collapses.  So I do understand.  Okay, now, in this - we're into miscellany.  We only have one topic in miscellany.  And this is one of those things where I just wish - okay.



LEO:  Hey, what if you read it in a newspaper?  I mean, what if you got the Guardian, and you saw it in the Guardian?



STEVE:  I don't think it matters.



LEO:  I guess that's okay.



STEVE:  Because they can't get it legitimately.



LEO:  Yeah, right.  That's right.  Yeah, yeah, yeah.  Wow.  All right.  Sorry.



STEVE:  So this is another juicy Kickstarter item that makes me wish, I don't know what, there was more of me?  I had multiple me's?  Actually, that's one thing that is introduced in "The Void," the notion of multiple people, multiple bodies in a single brain.  I guess that wouldn't work.  I don't know.  Well, anyway...



LEO:  Multiple bodies in a single brain [laughing].  Could be problematic.



STEVE:  So that's very handy, it turns out.  Okay.  This is just, oh, my god, do I wish I had time to play with this.  It is too cool.  If you google "HackRF," all one word, H-a-c-k-R-F," you will find Michael Ossmann, who's been working with so-called SDRs, software-defined radios.



LEO:  Almost all ham radios are currently software defined, by the way.



STEVE:  Oh, Leo.  And in his blog he explains it.  He says, "I'd like to take a moment to properly introduce the project that is consuming most of my time this year:  HackRF, a software radio peripheral."  So this is a gorgeous-looking little surface-mount technology circuit board with an RF connector and a USB plug.  So you plug this thing into your computer.



LEO:  A reminder:  You need an amateur radio license to transmit on these things.



STEVE:  Oh, well.



LEO:  That's going to - there it goes.  Shot to hell.  Wow.



STEVE:  So it says, "Software radio or Software Defined Radio (SDR)" - and get this, I love his analogy - "is the application of Digital Signal Processing (DSP) to radio waveforms.  It is analogous to the software-based digital audio techniques that became popular a couple of decades ago.  Just like a sound card in a computer digitizes audio waveforms, a software radio peripheral digitizes radio waveforms.  It's like a very fast sound card with the speaker and microphone replaced by an antenna."



LEO:  Here's a clip of him showing this on Hak5 to a...



STEVE:  Yes.  "A single software radio platform can be used" - and this is what I love - "to implement virtually any wireless technology (Bluetooth, GSM, ZigBee, etc.)."



LEO:  You'd have to have the stacks on top, though.  Merely being able to do the frequency is not sufficient.



STEVE:  Well, and everything - this has actually been churning along, as I'm sure you know, for many years now.  And all of this is open source.  All of this is freely available.  So this is the hardware end.  And then the software end.  And, I mean, I've seen pictures of this where just beautiful-looking GUI instrumentation, where you're, like, looking at the whole spectrum of everything coming in on the antenna, and then you're able to, like, zoom in on it and find specific things and then decode it.  Oh, it's just great.



LEO:  I have, you know, over here in my ham shack, a very expensive, something like $10,000, Icom high-frequency ham radio receiver, transmitter/receiver.  And I was told by the Icom guy, it's basically all software.  Nowadays you'd be crazy to do it all in ICs.  Do it in software.



STEVE:  So as quickly as you can, you digitize the incoming signal.  And then from then on you just handle it in a DSP, in digital signal processing.



LEO:  That's how all modern ham stuff is done, as well.



STEVE:  Yeah.  And this is, so anyway, this is a $200 project.  He has several successful Kickstarter projects in his past.  Remember that wacky Throwing Star network tap?



LEO:  Yeah.  That was him?



STEVE:  That was him, yup.



LEO:  That one got funded, didn't it?



STEVE:  Oh, yeah, yeah.  And this is well on its way to be.



LEO:  So here's the Icom I was talking about, which is the - actually this is the 7600.  I have a little higher level.  Dual DSP for transmitter/receiver and spectrum scope.  32-bit DSPs.  That's, I mean, it's all done in those DSPs; right?



STEVE:  Yup.



LEO:  I mean, there's other stuff, obviously, filters and so forth.  But it's all done in software now.



STEVE:  It's funny, too, because a lot of the current music synthesis is they'll give you a keyboard with knobs, but the knobs, all they are is, like, digitizers that go to the board, and everything is digital.  The fact that it's a knob is just because that's a convenient user interface to people.



LEO:  And they go to 11.



STEVE:  Yes, because they are extra.  Would you like the one that the knobs go to 10, or the extra?



LEO:  Extra.  The funny thing is, when Ray Novak from Icom came over to install it, he put in some additional modules.  You can buy modules that will give them additional extra...



STEVE:  Extra features, yeah.



LEO:  And it's just software, just more software.  We're moving from the analog to the digital world, and that's how it is, you know?



STEVE:  Okay, Leo.



LEO:  Yes?



STEVE:  Do I look a little tanned to you, a little brown?



LEO:  You look good.  You look like you've been - where did you go, Hawaii?



STEVE:  I walked 17 miles yesterday with my Kindle.



LEO:  Why?



STEVE:  Because I can't stop reading the Void Trilogy.



LEO:  I love it.  You mentioned last week that you picked this up, yeah.



STEVE:  I picked it up.  And I tried to put it down and work on SpinRite, but then I just - normally when I'm reading I get to a point where it's like, okay, I'm kind of like - you kind of get tired of reading for a while.  I don't - I'm not - I haven't reached any point like that.  So then I gave up on SpinRite.  Not forever.  I'm now at 40 - as of last night, I'm a few pages past 45% of the third book.



LEO:  Wow.  Holy cow.



STEVE:  Oh, no, it's all I've been doing.



LEO:  No wonder you walked 17 miles.  That's a trilogy.



STEVE:  Yeah, and 10 on Monday.



LEO:  That's a long-ass trilogy.



STEVE:  It is a monster.  But oh, my god.  I'm taking the wraps off of any reservations I had about recommending this.  You absolutely have to read the first two.  This is really - it's better to stay...



LEO:  Is this the one - I'm trying to remember the story.  Is this Ozzie going around - what is the story here?



STEVE:  No.  So I'll get to that in a second.



LEO:  Okay.



STEVE:  So it is better to think of this as a quintology where, I mean, really.  I mean, just - and, okay, a quintology where "Pandora's Star" is the first one, and "Judas Unchained" is the second one.



LEO:  Right, which we loved.  I remember that, yeah.



STEVE:  And that's we're introduced to Nigel Sheldon and Ozzie and Paula Myo the investigator and Oscar Monroe and the Guardians and the Prime intelligence that evolves differently than organic people do.  And, oh, I mean, all this fabulous, I mean, it...



LEO:  Love the Prime.  Love the Prime.  They're the worst villains ever.



STEVE:  Yes.  And so that's the first two books.  So I was a little put off by this notion of a dreaming void.  It seemed a little too, I don't know.  Anyway, it's not.  It is fabulous.



LEO:  So I'm just looking at the Audible lengths for these.  And you have read now - the first book's 22 hours.  Second book, you know, from a reader who's reading probably a little slower than you because he's speaking it out loud, second's 25 hours.  So that's 47 hours.  And you said halfway through the next one.  You've read 57 hours' worth of content here.



STEVE:  And I am so glad.  It is so full of just, I mean, just thrilling parts.  When I was - I was finishing the first one, and I was out in the park.  We have a park nearby, which is why I'm getting the sun because I just want a chance, after five hours in one place, I want to go somewhere else to keep reading.  And I seriously considered getting Peter to read the end of the first book to us.  He would.  He and I have been in touch.



LEO:  Oh.  Oh.  You know Peter F. Hamilton?



STEVE:  Well, yeah.



LEO:  Can you arrange an interview with him on Triangulation?  Introduce us via email, would you?



STEVE:  Okay.



LEO:  Because we, I mean, look, we've probably sold a few books for him by this point.



STEVE:  Oh, that's how he tracked me down.  He said, "Steve, thank you for loving my books."  I said, "What choice do I have?  They're fantastic."



LEO:  It's not just him.  It's not just him.



STEVE:  They are - it is storytelling, Leo.  It is...



LEO:  He's a wonderful writer.  And that's...



STEVE:  It is world-class storytelling.



LEO:  Yeah.  That's what makes this stuff so good is that...



STEVE:  Oh, my god.  I mean...



LEO:  ...he's got a great imagination, but he can write.



STEVE:  ...deep characterization.  Also there is very amazing insight into the nature of human politics in this.  I just - anyway, if anyone loved - you cannot read these without reading first the first two of the so-called Commonwealth.  He creates this notion of a commonwealth which is our future.  And that is established in "Pandora's Star" and "Judas Unchained," which are themselves fabulous sci-fi.  But it doesn't stop.  You have to continue because everybody's back.  Paula's back.  The Silfen Paths and the Silfen, and Bradley's back, and Oscar, and we're on our way right now to go visit Ozzie.  We're not sure what's going to happen there.



LEO:  Oh, I do remember this, yeah.  I've read all of these.  I'm just - there's so many of them that I - but it does all fit together, doesn't it.  Even "Great North Road," which I'm reading now, fits into this.



STEVE:  And this weird void, we learn what that's about and why it's a problem and that it's a - oh, anyway.  Oh, it is - anyway.  So I just - I gave up.  It is consuming my life.  I eat, I sleep, and I read this.  Mostly now because I'm desperate to get back to SpinRite.  I mean, I'm...



LEO:  Oh, come on.  You're not abandoning SpinRite for this.



STEVE:  Completely.  I have no...



LEO:  Dude, you've got a job to do.



STEVE:  I have no control over it, Leo.  I can't - where I was with SpinRite requires a hundred percent of my concentration to take us to the next phase.



LEO:  Oh, dear.



STEVE:  And I was unable to split myself.  So I am reading about 18 hours a day.



LEO:  At least you're doing that.  You're getting through it.



STEVE:  Oh, no.  I'll be done - here we are Wednesday.  And I'm not getting much reading done.  I'm talking to you right now.  But all of Monday, all of Tuesday, all of Saturday and Sunday, all of the end of last week, basically it just took over.  And I'll be done in two more days because I can do 20% per day.  I started Book 3 on Monday and read.  And now at the end of Tuesday I was at 45%.  So two more days I'll be done.  I just - I'm going to - I have to finish it.  Then I'll be back a hundred percent on SpinRite.



So it just - I never take a vacation.  I work seven days a week on SpinRite.  So it's like, okay, I had a forced vacation.  I just didn't have any choice.  It is too good.  It is, I mean, people look at me strangely because I'll, like, exclaim something.  Where was I, and people - oh, I was outside yesterday afternoon and giggling.  And they're like, why is that guy giggling?  Because it's just - it's so good.  So, unreserved recommendation.



LEO:  Not just Kindle, by the way, and I should mention also Audible has a good selection of them, including this trilogy.



STEVE:  Yeah.  Yeah, by all means.  And I'm not...



LEO:  That's how I listened.  It's much easier for me.  They're too long. I can't...



STEVE:  I'm not picking up the "Great North Road."  It's sitting there in the Kindle.  I am not going to start.  I'm going to go back to SpinRite and get this next major rev done.  And my treat will be picking up the "Great North Road."  I tweeted yesterday when I was at - I think I was at 30%, and I just had to tweet because it was like, oh, my god, this is so good.  I mean, it's just incredibly good.  And I got back some responses saying that the "Great North Road" was as good.  So it's like, okay.  I have something to work for.  When 6.1 is released, then I'm going to - then I will pick up the "Great North Road."



LEO:  I'm not sure that you'll like it as well.  It's a mystery, you know.  It's more of a mystery novel than anything else.



STEVE:  I just - he is just, oh, my god, hats off to him.



LEO:  Really good writer.  It's beautiful writing.



STEVE:  It is world-class storytelling.  I just - I'm stunned.



LEO:  Apparently he's doing it - I was looking at his web page, which is PeterFHamilton.co.uk, and he's doing a children's book right now.



STEVE:  He is.  But he also has two more in the Commonwealth.  We're going to get this Commonwealth continued, also.



LEO:  He's smart because he's really created a very rich universe.  And there's a lot of material to be mined there.  You might as well just stay there.



STEVE:  Well, I love it, too, because each of these different authors creates a universe that they work in.  And so like the Honor Harrington universe, Weber's universe had the set of technologies that they are then faithful to.  And in Hamilton's, they have the so-called "TD," trans-dimensional links.  And it's a little unnerving that, no matter where you are anywhere, you can have a real-time conversation.  So you have to kind of get used to that.  It's like, oh, okay.  Because, for example, I just came from - where was I?  Oh, it was the Alistair Reynolds where they had the notion of deep time, where they had never broken the light barrier.  Whereas now we have both hyperdrive and ultradrive over in Hamilton's universe where they talk in terms of, like, 45 light years per hour is the rate at which they can travel.  So they're super hyperluminal speeds, but also instantaneous communication.  And so they're just opening up links to each other across the galaxy.  It's like, whoa, okay.



But again, it's all - so that's the universe he created.  And he's absolutely faithful to it.  But, oh, just fabulous storytelling.  That's how I would have to summarize it.  Just, I'm just - and you, like, you see something building, and you go, oh, please, please, please, please, please.  And then it happens just like we want it to.  It's like, oh, yes.



LEO:  [Laughing]



STEVE:  Wow.  Okay, I'm...



LEO:  Okay, enough, yeah.



STEVE:  I do have a very nice note from a Brian H. in Omaha, Nebraska, referring to SpinRite, the SpinRite we have today.  He said, "Several years ago I worked for a company whose IT shop rolled out whole drive encryption to all desktops and laptops and USB devices," he says, parens, "(until one exec got his iPod scrambled)."  So then they decided, oops, we're going to back off on that, apparently.  He said, "A colleague of mine was having issues that caused his machine to run slow, then blue screen.  I told him about SpinRite.  But we were required to go through the normal IT processes for any software touching our machines.  They told him that the hard drive was a total loss.  I said, then why not try SpinRite?  They swore it wouldn't work, due to the whole drive encryption.



"After much debate, where I told them SpinRite doesn't care, they decided to humor me and try it.  After less than a day of SpinRite's processing, it was still cranking away.  But I suggested noting where it was and rebooting the system anyway to see if it had fixed enough.  It had, and the system rebooted normally, worked perfectly.  My colleague got all of his relevant data back, and they replaced the hard drive.  Moral of the story:  SpinRite sounded too good to be true to everyone in IT, but we know better."  So thank you, Brian.



LEO:  Yay.  Steve, we've got questions.  You got answers?



STEVE:  Yay.  You bet.



LEO:  All right.  Let me pop up the...



STEVE:  It's the last day of July.



LEO:  Golly, how did that happen?  We're almost to the fall.



STEVE:  What's the weather been like up there?  We're having this weird, like, never really got to be summer.



LEO:  It's like cloudy, muggy.  Yeah.  We had a very hot two weeks, or three.  Really, really hot.  And then we're doing what you're doing, which is it's just kind of odd.  That's all right.  That's all right.  I'm happy because when the fall gets here, I'm going to Europe.  So September - and I should tell you, I don't know if I've told you, I'll be out of the studio September 17th through October 8th, but we will have somebody wonderful hosting your shows, probably Iyaz.



STEVE:  Yeah, Iyaz is great.  Because I know that Tom's now down here, so...



LEO:  Tom may be a sub, too.  We don't know.  We haven't figured that out.



STEVE:  ...Iyaz - oh, okay.



LEO:  Actually probably Lisa has, but I don't know because I just kind of...



STEVE:  You haven't been told yet.



LEO:  I roll in here and say, what do I do next?  Point me. 



STEVE:  Where do I go?



LEO:  Point me at the right microphone.  Where do I stand?  Question 1, Barry Ball, Woodstock, Ontario, Canada has some thoughts on Lavabit.  We were talking about Lavabit, I even signed up before I heard you talking about it.  Steve, I love the show, blah, blah, blah, my favorite of a dozen podcasts I listen to, blah, blah, blah, especially love the propeller hat episodes, blah, blah, blah, love SpinRite, blah, blah, blah, keep up the good work.  A couple of years ago you mentioned a small news item - a couple weeks ago, a small news item stating that Edward Snowden used Lavabit.  While you didn't actually say you were skeptical of the news, you sounded skeptical as you described in detail how the email is encrypted at rest, but still unencrypted server to server.  And of course we know the NSA is collecting that unencrypted traffic.



Since it's encrypted on the server, and if done properly, and it sounds like they are, all the authorities could get with a warrant is a blob of pseudorandom noise, which makes it better than Gmail at least in that respect.  This fits very nicely with a technique I learned about for the first time on your podcast a week or two prior, that of drug dealers sharing a Gmail account - drug dealers and/or CIA chiefs - sharing a Gmail account and having emails for each other in the draft folder.  It never leaves the server.  Even though the reporter is not willing to put the effort into setting up PGP, I'm sure he'd be willing to log into a mail server and look in the drafts folder.  Just a thought.  Have I missed anything?  Does that work?



STEVE:  Okay.  So there's a couple things going on here.  And I wanted to kind of clarify because there was some confusion about Lavabit because it is - this all is confusing about, like, when it's encrypted and when it's not encrypted and so forth.  So...



LEO:  It fooled me.  I bought a 10-year subscription.  But go ahead.



STEVE:  Yes.  So the problem is that the SMTP protocol is not by default encrypted.  Later on, the ability to negotiate encryption was added.  But, and I guess we do have certificates in the public key system involved there.  I was wondering whether you could do a man-in-the-middle attack on that.  Well, we know that you could downgrade the negotiation, and that's a problem.  Because what happens is when you initially start your - I'm not doing anything to clarify the confusion here.  When you initially start your SMTP negotiation, the server answering essentially declares the things it's capable of doing, one of which is whether it's able to initiate, to upgrade the initial connection to  secure.  And if so, and the connecting server is also able to, then they'll say, oh, let's switch to secure.



The problem is, anybody could interfere with that initial unsecure handshake and remove the announcement that security is available at the recipient end.  And then, because no security is so widespread, they would have an in-the-clear communication.  So email is just - it's a fundamental problem.  And it's why, with the NSA tapping upstream, for example, of Google, they get all of the Gmail.  They may not get it when it comes into Google through a web interface which is now HTTPS, but they get it the moment it leaves Google.  So that was the reason that I think it was Petraeus, right...



LEO:  Oh, yeah.



STEVE:  ...and his mistress were - they didn't let their dialogue ever leave Google.  They both connected securely to Gmail and used the Drafts folder, cleverly, in order to exchange mail.  And apparently, again, this is one of these things where, like, the bad guys know this, and the good guys never really bothered with it.  And so we're the ones having all of our traffic captured by the NSA.  So the problem is, it's nice that Lavabit encrypts the mail that they receive for your pickup.  But as they're receiving it, it is unencrypted.  So it's true that they probably cannot decrypt it until you log in to provide the credentials required to decrypt it, and then you're able to retrieve your email that's in the mailbox.  So that aspect is good.



The troubling part is that - and the only reason I really brought this up was so people didn't assume it was some sort of panacea that solved email encryption.  It isn't.  Because nothing coming into it will be encrypted unless it came from Google, for example, because Google does support SMTP encryption, and Lavabit does also.  However, among all the major email providers, Google, Yahoo!, Microsoft, and I can't think of the fourth one, there were four...



LEO:  Yahoo!?



STEVE:  Oh, Hot - well, no, Hotmail is Microsoft.



LEO:  Yahoo!, must be Yahoo!.



STEVE:  Hotmail, Yahoo!, Gmail, oh, and Yahoo!, yes.  Only Google does.  So none of the other ones do.  And again, I expect - one of the nice things that we may see come out of this whole Snowden NSA debacle is the providers actually taking efforts, making efforts to be more secure for us.  Much as we heard the rumor, there was a piece of news that I think CNET carried last week that Google was exploring encrypting Google Drive.  So it's like, oh, okay.  And of course it will need to be vetted to see whether they've done it in a useful fashion.  We know it's possible.  So it may be that all of this scrutiny that is being put on the major cloud providers, because encryption is completely possible, they may actually step up and do it.  Which would end up giving us more security than we had, arguably, before all this leaked.  So anyway, Lavabit, nice that it stores it when the data is at rest.  But unfortunately, with email, when it's in motion, it's almost always not encrypted.



LEO:  Really, PGP is the solution, and we're going to talk about that later.



STEVE:  We're going to be doing a series, actually, on email encryption, yes.



LEO:  Yeah.  Sami Flew in London, England wonders about VPN versus TOR.  That's good.  I'm glad he brought this up.



STEVE:  Yeah.



LEO:  Could you clarify for me, I'm a bit muddy on this:  A VPN and TOR - Virtual Private Network and The Onion Router - both seem to do the same job.  They allow you to anonymously surf the Internet.  [Buzzer sound]  Oh, sorry.  So what are the differences between them?



STEVE:  Right.  So the way to think of them both, what they have in common, a VPN and The Onion Router, I mean, he's right that there's some similarities.  In both cases you use a client on your computer to securely connect to something else.  In the case of a VPN, you connect to one something else, that is, the VPN server.  And it decrypts your traffic and releases it onto the Internet.  And it does so with essentially no performance overhead.  That is, your traffic already would have bounced around a while and then headed off onto the Internet.  In this case it goes to the VPN server and then is released on the Internet.



The Onion Router is very similar in that you have, as I said, a client on your machine that encrypts, and you connect to the first node of the Onion network.  But your client determines multiple hops specifically for adding obscurity to you.  The problem, for example, with a VPN is that, if traffic were analyzed coming into the VPN server and out of the VPN server, it's possible to correlate the public and the private traffic through the tunnel and use that to break anonymity.  And because the data's not encrypted coming into the VPN or leaving the VPN on the public side, you don't have encryption there, either.



So the VPN's use is best for when you're in a public WiFi hotspot, or you want to protect yourself from your ISP, that is, you want privacy from your local region.  You're in a hotel which has unencrypted WiFi or scary wired network.  We've talked in the past about how a hotel's wired network is very frightening.  The idea is you want to - you just don't trust where you are.  So a VPN gets you to somewhere else and then decrypts your traffic and releases it onto the Internet.  That's very useful, and it's efficient. 



What people complain about with TOR is that it is slow because the cost of obtaining obscurity and more anonymity by hopping all over the place is a real slowdown in the overall throughput.  But that's a tradeoff that you make.  So they're certainly similar, but they're different in what they provide.  The TOR system actively fights anyone associating your incoming public traffic to your outgoing private traffic.  A VPN server doesn't do that.  Its goal is to protect, to give you privacy, like privacy from where you are so that nobody in your location can eavesdrop on you.  And it does so very efficiently.



LEO:  Yeah.  Nicely said.  Let's see here.  Moving on.  Question - what happened to my questions?  What happened to my questions?  I must have closed them.  Sometimes I get ambitious.  Here it is.  Question 3.  Leo in Mountain View - not me - has heard that the NSA contributes code to open source software:  Recently I read the NSA openly and officially contributes code to open source software projects like Android and Linux.  Do you know and care about the functionality and nature of those contributions?  Long-time listener and fan.  This is well known, by the way.



STEVE:  Yeah, it is.  And I used to be a fan of SELinux.  A little hard to be a fan of that now.  SELinux is the so-called Security-Enhanced Linux.  And the NSA has been very active in creating a security-hardened kernel which provides much greater inter-application isolation than out of the box standard Linux.  And they've then moved that over to Android.  And actually, because Android is based on Linux, they've taken that technology, that inter-application hardening, basically better sandboxing around individual applications, and made that available over on the Android platform.  Now, it's important to note that the NSA is not just one organization, well, it is one organization, but not just one focus.



LEO:  Many missions.



STEVE:  Yes, thank you, perfectly said, many missions.  So there are absolutely different aspects of the NSA.  For example, I have a link in the show notes that Leo could bring up.  There's a page of these beautiful security configuration slides...



[nsa.gov/ia/mitigation_guidance/security_configuration_guides/operating_systems.shtml, nsa.gov/research/selinux]



LEO:  These are great.  I recommend these.



STEVE:  Yes.  For all different operating systems, Mac and Windows and all different OSes, for things to do to harden your operating system.  And it even has them for all the different versions of Windows back through time and in the future, the things you should do.  These are things to turn off and what to do to lock down your system.  Because this country, the United States, where the NSA is and cares about, is largely Windows systems.  It's better for the country's security if individual nodes of Windows are each operating more securely.  So this is in the national security for the NSA to say, here's how you tighten things down.



LEO:  You bet.  You bet.  And I've looked at these.  I'm sure you have, too.  They're fine.



STEVE:  They're great.



LEO:  And in fact, I wouldn't worry about the NSA unless you're accepting binary files from them.  That is, you can't look into them.



STEVE:  Exactly.  And so it's...



LEO:  If they offer an NSA antivirus, precompiled, you might treat that with some suspicion.



STEVE:  Eh, yeah.  Is it going to catch the things that they don't want to...



LEO:  But on the other hand, open source software, and you could bet that SELinux is looked at by a lot more eyes than perhaps other open source projects.  There's no way to do anything in there without showing it in the code.  Now, don't accept a precompiled version.  Compile it yourself.



STEVE:  My recommendation is to take a good, secure UNIX or Linux and then lock it down.



LEO:  Yeah.  Or BSD, even better.



STEVE:  Yes.  I'm a FreeBSD user.  And basically you just don't run anything you don't need.  Your firewall has only the rules you require.  And sort of there are lots of hardening guides around.  And I would absolutely draw from the NSA's.



LEO:  Yeah.  Everything in there is sensible.  Question 4 is Ian W., Ottawa, Ontario.  Another Canadian.  He got your attention apparently with the subject line:  "I think the NSA has GRC's certificates!"  What?  Did you get your certificates from DigiCert?  How did you do that?  Unless I'm mistaken, they come by email, at least for smaller businesses.  So NSA doesn't have to ask for them.  They already have them.  Am I right?  Until a month ago I would have thought I must be missing something, but this all seems kind of likely now.



STEVE:  The good news is no.  The only thing that DigiCert ever receives is our public key, which is what our servers give to anybody who wants it.



LEO:  Including the NSA.



STEVE:  Including the NSA.  Everybody who connects over port 443 to GRC.com, first thing they get is our public key.  It's signed by DigiCert, which is why it's worth trusting.  So the way this works is I use DigiCert's website, and I post in a secure form my public key.  And it doesn't really even need to be secure, but we want it to be secure.  Why not?  Well, actually so no one can intercept it.  I give them my public key.  They sign that and email it back.  And it absolutely doesn't matter if it's in the clear.  My private key never leaves my servers, and never has, to my knowledge.



And then any time someone wants to connect, I give them back essentially what I received in the email, my public key signed by DigiCert, which is a reason to trust it.  So the system is beautiful as far as it goes.  As we've spoken of often, it does have some problems.  And many people in the wake of this NSA Snowden business are saying are we absolutely sure that the NSA doesn't have a certificate authority of their own?  It's like, no, how could we be sure?



LEO:  Right, could be the Hong Kong Post Office.  We don't know.



STEVE:  Yeah.



LEO:  Marcus in Calgary is wondering about making his own secure passwords:  I saw somebody suggest that you use a personalized set of rules when making passwords.  That way you just have to know the rules, and you can figure out what the password was.  For example, say I sign up with Amazon, and I set up these rules - and of course these are just example rules:  Take first seven letters from the name of website after the www. and before the next dot.  If less than seven letters, then just add 1, 2, 3, and so forth.  Place a 5 between each character from Step 1.  Replace all vowels with FluffyKitty27.  If there are no vowels, just place FluffyKitty27 at the end.  And then add a bang, an exclamation mark, after every lowercase or uppercase "F."  What do you think, good way to generate a secure password?



STEVE:  Okay.  That would be a good way to generate exactly one secure password.  Because the problem is, anyone who were to capture that password, if Amazon.com were to lose control of their database...



LEO:  Which happens all the time.  Not with Amazon, but with others.



STEVE:  Not with Amazon, but unfortunately it's all too common.  They could scrutinize that, knowing what domain it came from, and reverse engineer your funky little algorithm.  That's why I went to all the trouble of developing the Off The Grid system, which I still need to finish the - it's all done, I mean, it's all documented.  We did a podcast on it and everything.  I just never took the pages public because I wanted to give it one final reading and solve a couple other - and, like, beef up the FAQ a little bit further.



But the whole concept with Off The Grid was that it was a similarly non-computer - it was an experiment.  Can I develop a paper-based approach where each website encodes to something completely unique so that seeing one of them tells you nothing about any of the others.  And so that's - certainly using a pseudorandom sequence and a database gives you that, no association between them.  My system was a cryptographic, a paper-based cryptographic association which was strong cryptographically.



But the problem, Marcus, with your approach is that, as we said, if you saw one or a couple, you could figure out what the algorithm was and then guess your password for some other website in order to break in.  And that's the weakness.



LEO:  Yeah.  You know, you don't have to stretch too far.  It's well known how to do this.  Get LastPass, which you've vetted.



STEVE:  Yup.



LEO:  And, boy, the more I use it, the more I love it.



STEVE:  Same way.  It is my go-to solution.



LEO:  Have it generate completely random long passwords.



STEVE:  And then it remembers them.



LEO:  And let it remember them.  You don't have to.  I don't know my password for anything anymore except LastPass.  And that's one where you could make it something that you can generate, and that's what I do.



STEVE:  Really screwball.



LEO:  You know, I'll use this as an example because I read it once, and I certainly don't use it.  But if you go through the last eight presidents, let's say, or make it 16 presidents of the United States, uppercase the Republicans, lowercase the Democrats, and then add a number for the number of years their term stretched, now, that's a good example of you're going to have a nice long password.



STEVE:  And we're going to give you an "A" in political science if you've even able to do that.



LEO:  I could start with Nixon and do that.  So if you put the number of years of the term, that gives you, I don't know what, 10, 11, it gives you a good number of characters.  That's not what I use but that's an example.  You're right.  You'd have to have a good memory for politics.  And then that's the LastPass password.  Which doesn't go out in the public anyway very often; right?  You only use it - I guess you would use it when you log into the LastPass website.  That would be the only place you'd use it in public.



Bill in Grand Rapids had a third-party cookie question:  Hello, Steve.  That's how they talk in Michigan, you know.  In the past few weeks, you've been talking about third-party cookies and why anybody would allow such a thing.  Well, here's a reason:  I do support for a company that collects certain data about users.  We're contracted by another company to display that data, the stuff we've collected, back to their customers.  They want their customers to stay on their website while viewing our data.  Hence, their web programmers provide a frame within which we display the person's data, an iFrame.  Our web programmers claim they must use third-party cookies in order to maintain that session.



Obviously, this has caused many problems with Mac users, where third-party cookies are blocked by default, and occasionally does with Chrome, IE, and Firefox users where they have chosen to block third-party cookies.  My job has been busy showing users how to allow third-party cookies from specific URLs, like ours.  I heard you made a comment once that third-party cookies were not needed to maintain session.  Hey, can you tell me how so I can pass this on to the programmers or the programmers at the other end?



STEVE:  Okay.  So there's a - so Bill's company is collecting data about users.  In other words, it's tracking them somehow.



LEO:  Right.  We don't - we can presume with their permission.  It's part of the deal.  Maybe they're a rating system for podcasts or something like that.



STEVE:  Right.  So this other company has created a frame in their browser page that allows Bill's company to fill the frame with the data that they have collected.  Normally what I would say, because the way the frame works, the frame is a URL provided on the web page that refers to a third-party server.  And so the frame has a URL that goes and gets the content being requested.  The nice way to do this would be for the URL to be customized so that, for example, the entity displaying the web page knows who this user is, the end user, looking at the web page.  So they use their token for that user and add that to the URL which they send off to Bill's data-gathering company to identify the user whose information they want to populate.



Unfortunately, this doesn't work in this particular case because Bill has an identity for the end-user which is unique to his company, different as a consequence of cookies, different from what the company displaying the page shows.  So in this instance I have to agree with Bill's web programmers, there is no other way to do this.  You absolutely need the cookie that would be normally used in the first party as data's being collected and gathered, to then be used in the third party to display this data in a frame.  And so this particular case I can't see how you could solve it without third-party cookies.  It's what you would need them for.  And so enabling them selectively is the only solution I could suggest.  So Bill, if your job is support for telling people how to turn on third-party cookies selectively, I think you have a good, secure job.



LEO:  [Laughing]



STEVE:  You're going to be doing that more.



LEO:  You'll be explaining that to people for some time to come.



STEVE:  You'll be explaining that.



LEO:  So there is a case for third-party cookies occasionally being...



STEVE:  Well, there's an instance where someone came up with a way to do it, I mean, it's...



LEO:  Could they do it without an iFrame or in another way that - well, anyway.



STEVE:  No, I can't see how they could because the browser will send that domain's cookie...



LEO:  Right.



STEVE:  That domain's cookie to the third party.  No, it's just it's not...



LEO:  If two websites want to interoperate in a way that keeps track of the session, you're just going to have to do that.



STEVE:  Well, no.  See, that's just it.  There you could definitely provide, the first-party server could provide URLs to the third-party containing unique tokens for the user.



LEO:  Ah, saying hey, this guy is authenticated, and give him the information.



STEVE:  Yeah, and here's who he is.  So that could definitely work.  The trick in this instance is they're wanting to use data collected elsewhere to show in this first-party site.  That's where the third-party-ness absolutely has to be present.  So, yeah.  In this particular case I can't see a way around that.  The browser...



LEO:  The right way to do this, by the way, would be for the third party to send the information, not to the client, but to the server of the first party, which would then serve it to the client.  In other words, instead of having this transaction, this triangular transaction, have a transaction server to server that then delivers the information.



STEVE:  And the problem is, if the browser is blocking third-party cookies, it won't identify its user to that third-party server in the first place.



LEO:  No, no, that transaction would have to be handled by the first-party server.  So in other words, you could go as a client, as a browser, to the first-party server, say I want to see my information, instead of doing - the iFrame is frankly a cheap...



STEVE:  It really is a cheap solution.



LEO:  ...way to do this.  Better to have the first-party server query the second-party server, get the information, then display it.  It's all first-party transaction at that point.  They're just saving programming, server-side programming, by doing an iFrame.



STEVE:  Yup.



LEO:  IFrame's cheap.



STEVE:  Yup.  And not well regarded because it's a serious...



LEO:  That's why.  You've basically opened a window in the browser to a third-party server.



STEVE:  Yup.  Yup.



LEO:  I wonder, with new technologies like REST and so forth, there are ways to do this.  Anyway, moving on, my friends.  Jesse in San Francisco says that "The Newsroom" predicted PRISM in Season One.



STEVE:  Oh, Leo.



LEO:  I remember this conversation, actually.



STEVE:  Oh, gosh.



LEO:  He says like - go ahead.  Want me to read the letter, or...



STEVE:  Yeah, read.  I'm sorry.  I just get too excited.



LEO:  You want to talk about this.  He says:  Like you, Steve, I'm a fan of "The Newsroom."  I was rewatching one of the episodes from the first season.  It struck me how Sorkin essentially predicted the NSA surveillance story.  His whistleblower/leaker, Solomon Hancock, was an NSA IT employee who revealed a secret program called Global Clarity which intercepts billions and billions of phone calls, emails and texts each day.  This aired in August 2012.  I'll play a clip from YouTube in a second [youtube.com/watch?v=r0AgBecuFdU].  He says:  I know Sorkin took some heat for basing storylines on events from the recent past, making his characters seem extra smart with the benefit of hindsight.  But maybe he should be given some credit because he's based his news story on events from the future.  P.S.: Love the podcast.



STEVE:  No, and it is creepy.  I want everyone to listen to this.  It is just - it's spooky.



LEO:  Yeah.  Here we go.  Let me just play a little bit of this.  You can listen or, if you're on video, you can watch.  This is a clip from "The Newsroom."



STEVE:  "The Newsroom" last year, well before all of this Snowden business.



LEO:  Just so they don't get mad at us, a wonderful show that airs on HBO.  Actually, I don't like it, but many do like it.



STEVE:  I love it.



LEO:  Steve loves it.



[Clip]



SOLOMON HANCOCK:  The project title is Global Clarity.  It intercepts 1.7 billion phone calls, emails, and texts every day.



CHARLIE SKINNER:  Legally?



SOLOMON HANCOCK:  By what standard?



CHARLIE SKINNER:  The law.



SOLOMON HANCOCK:  No.  It involves a significant amount of illegal warrantless wiretapping of American citizens.



CHARLIE SKINNER:  Just to be clear, when you say "warrantless," are you saying unnecessary?



SOLOMON HANCOCK:  Without a warrant.  Warrantless.  We could hunt for terrorists legally, but due to our bosses' devotion to Global Clarity, the NSA has been happily violating the Fourth Amendment, USSID 18, and about a dozen of the NSA's own regulations about spying on Americans.  You've got guys listening in on ex-wives, dropping in on calls from soldiers overseas, checking out what movie stars are up to.



CHARLIE SKINNER:  Why are you whistleblowing?



SOLOMON HANCOCK:  I fought the Soviets.  The way that government made their people live their lives was a very good reason to fight them.  After 9/11, we started doing the exact same thing.



[End clip]



LEO:  Now, I just want to say he doesn't look at all like Edward Snowden.  The point, and I think a lot of people have made this point, is that this isn't something we didn't really know about.  This warrantless wiretapping started under George Bush in 2001.  We knew this.  And Sorkin's not prescient.  We just didn't know the scope of it until Snowden came along.



STEVE:  Yes.  And it's good that this is getting fleshed out, I mean, that we have - this is going to - this allows our lawmakers and the public to say, oh, is that what we asked for?  Maybe it is.  But the question has to be asked.



LEO:  If you just search for "warrantless wiretaps," you'll see all the stories from 2001 about this.



STEVE:  Yeah.



LEO:  Andy in Michigan, a man of few words - actually none.  All he did was send us a link, a free and open source (FOSS) Skype replacement called Toxim, or T-o-x dot i-m.  Coming soon.  It's not here.



STEVE:  Correct.  So many people have brought this to my attention.  I just wanted to let people know I'm aware of it.  It is not yet released.  It looks very pretty.  They've got some nice screenshots.  Tox.im.  So it's "talks" as in t-a-l-k-s.  But in this case Tox.im.  And presumably super secure and everything that we want.  Don't know anything about it yet.



LEO:  Open source, as well, so you can validate it.



STEVE:  So at one point, when it happens, and if it looks like it's a useful thing, and it's multiplatform and does what we want, I will certainly tear into it and evaluate its security for all of our listeners.



LEO:  Who is doing this?  Do they say?  They don't.  They don't say who they are.



STEVE:  That'll be important, too.



LEO:  Yeah.  But it is open source, so one hopes that it will be validated, the source will be validated before we use it.



Ben in Australia wondering about PGP and encrypted SMTP:  Love the show.  Just caught up on Episode 413, heard you mention that Gmail has SMTP encryption.  Is this an "always on" feature, or is there something we need to do?  And how can we tell our mail is being encrypted?  I assume this is still not a 100% covered solution for keeping your mail private and that other steps should be taken as well.  As such, when Leo was talking about PGP, he mentioned there might be a plugin for Gmail.  Yeah, Mailvelope, it's called.  Are you aware of any such plugins to enable PGP in Gmail, short of installing the desktop app and copy-pasting?  I've been looking for such a thing for a long time.  Thanks, and keep up the excellent work.



STEVE:  Okay.  So we need to be a little bit clear about email and the protocols and as regards Gmail.  I'm talking about SMTP, the Simple Mail Transfer Protocol, which is the way the servers forward mail to each other and the way our clients forward mail to the server.  But getting mail uses the typically POP or - and I'm drawing a blank on the other one.



LEO:  IMAP.



STEVE:  IMAP.  Thank you.  POP or IMAP.  So that's used for connecting to the server's repository for obtaining mail.  So a setting, a user-settable choice in Gmail's configuration is to require Gmail's use of SSL for your POP or your IMAP connections.  And all contemporary email clients will allow an SSL connection to the server.  So that gives you encryption to and from the server.  Also SMTP encryption can be requested.  So your client can receive encrypted email over SSL, send encrypted email over SMTP in both directions with Gmail's configuration.  You have control of that.



The glitch is, when it leaves Google, it's almost never going to be encrypted, nor as it's coming in is it going to be encrypted, which is why the NSA sitting upstream makes so much sense from their standpoint.  They can get it all anyway.  And I'm going to be taking a very close look at Mailvelope because Leo's exactly right, that's the one.  It's www.mailvelope.com.



LEO:  It's a Chrome extension.



STEVE:  And Firefox, available for both Chrome and Firefox.  It comes preconfigured for Gmail, Yahoo!, Outlook.com, and GMX.  Open source, based upon the OpenPGP.js JavaScript library, and is very nice.  So the idea would be essentially it creates a minimal enhancement to those email services giving you PGP encryption.  And we'll know more about what that means in the next few weeks because I'm going to be spending the next few weeks plowing into, deeply, into that.  Oh, and also S/MIME, S-slash-M-I-M-E, actually predates PGP.  And that's been part of the RFCs for quite a while, and that's secure MIME.  It's sort of built into the email standard as opposed to being a separate add-on to it.  But highly recommended.  Mailvelope is beautiful.



LEO:  Yeah.  It's a little ungainly.  I mean, it's a lot easier to do this in your desktop email client.  But it works.  It works.  And what I did is create keys with open - actually GNU Privacy Guard and then imported them into Mailvelope.  So I can now in Gmail, as long as I'm using a browser with a Mailvelope plugin, I can encrypt and unencrypted, by the way, email.



STEVE:  Yeah, what I think we're going to be seeing is I think we'll have, because encrypted email is always going to be sort of the stepchild, there will be people with whom you are exchanging data that you want to remain confidential.  And it'll make sense for you to go through the trouble of getting your keys exchanged and using PGP where you really want encryption.  The upshot of all of what we've been talking about, Gmail and encryption and mail encrypted on the server versus encrypted in flight, blah blah blah, absolutely the only solution is Pre-Internet Encryption, PIE, where your data is encrypted before it leaves your computer.  Then it doesn't matter whether it's encrypted in flight or in storage along the way or anything.  It absolutely doesn't matter.  You encrypt it before it leaves.  It isn't decrypted until after it arrives.  That's the way to do it, and that's why we'll be talking about it for the next few weeks, all the ins and outs of how to achieve that.  Because I think there's probably an increased interest in true email encryption, and we're going to go into how it's all done.



LEO:  It's easy.



STEVE:  Yeah.



LEO:  I mean, not for - anybody who listens to this show it's easy.



STEVE:  Yes.  Glenn Greenwald put up a fuss because Edward wanted him to do that.  Finally he did, and then they were able to talk.



LEO:  Yeah.  Once you set it up, it's kind of straightforward.



STEVE:  Yeah.



LEO:  And then anytime somebody...



STEVE:  It's just ugly.



LEO:  ...contacts you - well, I'll show you.  When I use Apple Mail it's not ugly.  It's Mailvelope's a little ugly.  It's really ugly.  But when you use a desktop mail client that has PGP or OpenPGP implemented, it's pretty straightforward.  You could also use S/MIME certificate-based encryption.  That's maybe even easier.  But it's very straightforward.  It's very straightforward.



Anyway, here's Kevin Graham, our last question of the day.  He's in Colorado Springs.  He worries about PGP email address harvesting:  I'd like to try PGP, but I'm under the impression it's not much good without a way to distribute your public PGP key.  It seems to me if you publish your PGP key to any public site like pgp.mit.edu - that's the MIT key server - then you're asking for spammers and other organizations who collect information to harvest your email address.  Should folks avoid the public PGP key directories and only exchange PGP public keys in person?



STEVE:  My intention was to use this as our segue to our detailed coverage of PGP next week, where we'll go into all this.  If you have an opinion, Leo, I'd love to hear it.  But...



LEO:  It does.  You could harvest the email addresses from that if you wanted to.  So that would be certainly a solution.



STEVE:  Yeah.



LEO:  But I put - but really the value of PGP is putting it on the key servers.  In my opinion.



STEVE:  Or putting it somewhere where people - putting it somewhere you control, where people are able to obtain it from, like, from something you control.  For example, I could put my PGP key on GRC.com, and people who went there, GRC only allows secure connections.  The NSA does not have my web server certificates.  And so people could get the PGP key absolutely knowing that it was the key I was intending to distribute under my own name on servers I control, and they could get it and then, as you had mentioned at the top of the show, Leo, you're beginning to have some test messages back and forth to see that it works.



LEO:  Yeah.  I do both.  I of course publish my keys on the key servers.  That's the easiest way for all of us to kind of share our keys.  And it does have an additional feature.  People can then sign the key.  If it's not on a key server, a public key server, then you can't really sign somebody else's key.  And this is the one flaw in PGP is that you can generate your own keys.  So I could generate a key that says I'm Steve Gibson.  And there's nothing to prevent that.



So the key is to see if this key is signed by others who have taken steps to verify it.  For instance, people have key signing parties where I show you my driver's license, and I say, here's my key, would you verify this?  And you say yes, I checked his license, he really is Leo Laporte, and I signed the key.  So my key is signed by a lot of people because I have my key ID on my website, so you can be pretty sure that it's my key.  And that's something you need to do on a public server.



On the other hand, just go to my website.  You can download the key, install it in your PGP key ring, and then you'll be able to send encrypted mail to me and validate when you get email back that it is from me because only I have the private key.  So it's easy if you're a public person.  Steve and I can just say, go to our website, there's our key.  But for the rest of us I think it's really probably a good idea to...



STEVE:  Or maybe Facebook page.  Everybody has a Facebook page now.



LEO:  Spam shouldn't be a problem anymore, to be honest.  The spam filters are so good, I get very little spam.  Gmail, if you use Gmail, pretty much kills spam dead.



STEVE:  Yeah.



LEO:  There's lots of ways to do it.  My email address - the problem is, now, you do a very smart thing.  You change your email address regularly.



STEVE:  Yup.



LEO:  But my email address has not changed in more than a dozen years.  So I'm on every spam email list.  It's not like you're going to get anything new by searching for my name.



STEVE:  The other thing it's possible to do, you could also bootstrap.  You could use a distribution name like spammenot@gmail.com, set up PGP for that, and then over the secure PGP email you could send someone you care about your actual PGP key.



LEO:  Ah.



STEVE:  And so that way you have a public address used for distributing your private address PGP key.



LEO:  Ah.  That's clever.  There's ways around that.



STEVE:  Yeah.  We'll be talking about all kinds of neat things in the next couple weeks.



LEO:  Excellent, excellent.  That's going to be fun.  I'm looking forward to that.  And you can use me as a guinea pig.



STEVE:  And I will have finished the Void Trilogy, and I will be back at work on SpinRite, and I'll have a SpinRite progress report next Wednesday.



LEO:  He will be sunburned next week.  You doing another 17-mile walk today?



STEVE:  Well, not today because I did the first 10 miles was early in the morning because I had gotten myself sunburned Sunday and Monday.  So I was avoiding the midday sun.  And then I did the final...



LEO:  You should be reading these at night.



STEVE:  Well, there's not enough time.  I need all day, Leo.  These things are huge.  No, that's all I do.  I wake up, and I start reading.  I'm reading while I'm having breakfast.  I'm reading all day long.



LEO:  Wow.  That's a great way to do it because you are then really in...



STEVE:  Oh, baby, am I in.



LEO:  ...in the world, like, immersed.



STEVE:  Yup.  Yup.  I mean, I'm, like, exclaiming out loud, and people are looking at me when I'm walking.  It's like, well, okay, it's a good book.



LEO:  Yeah.  You don't walk into trees, do you?



STEVE:  No.  There are paths.  I have paths.  I have my own Silfen Paths.



LEO:  Doesn't it make you wish there were Silfen Paths?



STEVE:  Oh, yeah.



LEO:  Ah, yes.  Steve Gibson, when he is not busy reading, is writing things like GRC's amazing SpinRite.  You can get that at GRC.com, the world's best hard drive maintenance utility.  Not free, that's his bread and butter, but he does have lots of freebies, too, at GRC.com.  All sorts of information about security passwords and more.



STEVE:  And this podcast.



LEO:  This podcast is there, and some specials on no-carb and low-carb eating, which has been really amazing for so many of our listeners.  So many people come in here, almost every week, and say I lost 50 pounds.



STEVE:  I know.  I know.



LEO:  Somebody came in on Sunday and said, "I lost 50 pounds thanks to Steve."  You're saving lives, dude.  All of that's at GRC.com.  But, yes, as Steve said, he also has 16Kb audio, the crappiest-sounding audio you ever heard [not true].



STEVE:  And Elaine loves it because her satellite is able to download it.



LEO:  It's for the bandwidth-impaired.  And then Elaine types it all in.  A human being, Elaine Farris, actually writes a transcript.  So that's probably the most compact way.  But then you miss the nuance.



STEVE:  Yeah, you miss Leo's accents.



LEO:  You miss my funny voices.  That's at GRC.com.  You can also ask him questions.  We do Q&A episodes every other episode, usually.  GRC.com/feedback.  Do not email Steve.  He does not do email.  GRC.com/feedback is a form where you can fill that out.  We have high-quality audio that you could listen to if you've got enough bandwidth.  And even video, if you've got more bandwidth than God, you could just download beautiful, hi-def versions of this.  Watch Steve's suntanned face express, emote.  Every once in a while he hands come into the picture, and they get big.  It's really fun.  He's doing it right now.  GRC.com.



TWiT.tv is our site, TWiT.tv/sn for the Security Now! show, all 415 episodes there.  TWiT.tv/sn.  Actually, a little hint.  You could page back through all the episodes.  But if you just append the episode number, you'll get the episode you're looking for.  So as an example, TWiT.tv/sn414 will give you the 414th episode.  Goes all the way to - I think we have Episode 1.  Somebody - I think maybe not.  But we go back to, like, starting Episode 2 or 3.  That works.



And what else?  Oh, yeah, we are available for subscription at wherever you can subscribe to Internet broadcasts.  And that's the best way to get it, so you don't miss an episode.  I know a lot of schools are using this show for curricula.  They're actually teaching kids about security and stuff from these shows.  It's really great.  We thank you for doing that, and we thank you, Steve, for doing it.  And I will see you next week on Security Now!.



STEVE:  Okay, my friend.  Thanks so much.



LEO:  Happy reading.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#416	

DATE:		August 7, 2013

TITLE:		Black Hat 2013, Tor & More

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-416.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  With last week's Las Vegas Black Hat 2013 and DEFCON conferences just completed, Steve and Leo examine the most significant and worrisome revelations to emerge from that annual convocation, and also discuss and dissect the week's top security news.



SHOW TEASE:  It's time for Security Now!.  We were going to talk about PGP, but this week Steve found out so much stuff from Black Hat and DEFCON, he wants to talk about a big, big change in Firefox, and a flaw in Chrome that's not as bad as it sounds.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 416, recorded August 7th, 2013:  Black Hat, Tor & More.



It's time for Security Now!, the show that covers you, your security, your privacy online with the Explainer in Chief himself, Mr. Steven "Honor Harrington" Gibson.



STEVE GIBSON:  Actually, I think it's Steven "Peter F. Hamilton" Gibson, after...



LEO:  Yeah.  Did you finish?



STEVE:  Oh, I did.  I finished at the end of last week, as I expected.



LEO:  Steve was doing, what, 17-hour binges?



STEVE:  Well, no, it was a 17-mile walk on one day when I was reading with my Kindle.



LEO:  That's right, yeah.



STEVE:  Basically they were 18-hour binges.  I was just - I was reading, sleeping, and eating, and that's it.  My friends were saying, what happened?  Where did you go?  I said, oh, I can't talk to you right now.



LEO:  Oh, lord above.  Oh, my, my.  But you finished it.



STEVE:  And the problem is - I did.  I did.  The Void Trilogy, absolutely loved it.  I can understand people saying, eh, it wasn't his best work.  But if you just - if you're not in a hurry, if you don't, I mean, if you just want a really nice, rich, interesting storytelling and characterization in a sci-fi framework, I thought he did a really nice job.



LEO:  What is your favorite Peter F. Hamilton?  Do you have one?



STEVE:  Oh, I think it's got - well, the early Greg Mandel stuff is really fun.



LEO:  Oh, good.  I haven't read that.  Ill have to get that.



STEVE:  And gland.  "Gland" is the word I...



LEO:  Gland?



STEVE:  "Gland" is the word I was trying to remember when - because Greg Mandel has an ESP gland...



LEO:  Ah, yeah, that's right.



STEVE:  ...embedded in his head, and he squeezes, somehow he can...



LEO:  Squeeze out a little ESP every once in a while.



STEVE:  ...squeeze out a little juice in his brain that...



LEO:  Dribbles.



STEVE:  Yeah.



LEO:  I'd like that.



STEVE:  Anyway, yeah, the esper gland.



LEO:  The ESP gland would be nice.



STEVE:  Anyway, I think "Fallen Dragon," if I were to say...



LEO:  I agree, I agree.



STEVE:  It's a reasonable size.  It's beautiful characterization, really interesting story, fabulous ending.  I mean, that's - if I were to complain about his really long works, like...



LEO:  They just dribble off.



STEVE:  ...The Night's Dawn Trilogy was the first one, of course.



LEO:  Don't like that one, really.



STEVE:  And then - and even the Void.  It's like, he wrapped it all up, but it didn't have any, like, real kick and punch at the end.  And, oh, my goodness, "Fallen Dragon" has a wonderful surprise twist that you never see coming.  And so, yeah, I really just - I've read it several times.  And I wish for amnesia so I could read it again.



LEO:  I think my favorite trilogy is "Pandora's Star," the Pandora Star Trilogy.



STEVE:  Two books in that one.



LEO:  Dilogy.  Diology.  Yeah.  "Pandora's Star" and...



STEVE:  I agree.  "Pandora's Star" as a substantial piece of work.  Also his Commonwealth environment, his Commonwealth universe is really fun, the idea of having wormholes that you drive trains through because how could you better use a wormhole than by bringing back the train system.  That makes total sense.



LEO:  Yeah.



STEVE:  You know, so you have a transgalactic train system, courtesy of wormholes.  It's just - it's great.  So, and great - anyway.  So the Commonwealth universe I really like that he develops with "Pandora's Star."  And he is working on some additional ones.  So, and I'm glad for that.



LEO:  Oh, good.



STEVE:  But I'm not touching them for...



LEO:  This is not the science fiction show, despite appearances.



STEVE:  No.



LEO:  Now, last week you said we would do a PGP show, but current events have changed all that.



STEVE:  I should have known - well, yes.  I should have known better.  First of all, we've got the really interesting story of people discovering some spyware on their Firefox v17 browsers that are part of the Tor bundle which they are explicitly using for anonymizing themselves.  It turns out our U.S. law enforcement has figured out how to get in there and break anonymity.  So that would have been a big one.



Also Twitter just finalized yesterday, the second shoe dropped on their multifactor authentication.  And there's something really interesting that they've done for in case you don't have your phone with you after requiring you to have your phone with you, which we need to talk about.  And then of course Black Hat and DEFCON just happened.  And I should have known better than to think that we were going to talk about anything else after that major convocation in Las Vegas.



LEO:  Yes.  I should have - I should have thought of that, too.



STEVE:  So this is Black Hat 2013...



LEO:  This is our annual Black Hat show.



STEVE:  ...Tor & More podcast.  And we will do a Q&A next week.  And we'll start in on our - unless something else really significant happens.  Anyway, but in general I want to talk about email security as our ongoing background theme until we have it completely wrapped up, with interruptions for user feedback and any other events that happen, the first one of which is this week.



LEO:  Perfect.  All right.  Should we get to the Firefox story?  Is that where you want to start?



STEVE:  Yeah.  We just had, I think it was yesterday, Firefox v23, which was much anticipated.  We've talked about it several times.  And I'm sounding disappointed because I am.  We once again failed to get third-party cookie blocking by default, despite the fact that they've punted, this is the second time, punted on that.  There are several new features which are good.  And we also already discussed the disappointing one, that an easy way to disable JavaScript was expected to be removed from the user interface, and it's gone.



LEO:  Really.



STEVE:  So, yes.



LEO:  That's odd.



STEVE:  And remember that what they did was, in updating, even if you had it turned off, and you update to v23, they turn JavaScript back on and then remove the ability to turn it off.  Now, it's still, you can still get to it in the...



LEO:  In about:config, now; right?



STEVE:  Exactly, in that ridiculous, I mean...



LEO:  Chrome's doing that, too.  It is so ridiculous.



STEVE:  It's an amazing number of settings that are available in there, which are sort of more like tweaks than regular UI things.  Their feeling is this:  JavaScript is now - it would be like turning HTML off, is what they feel.  They're like, that setting is too potent.  The web depends upon JavaScript now to the extent that you cannot really practically run without it.  So they're saying we're going to remove it from the UI because it just no longer makes sense not to have JavaScript on all the time.  And if you are security conscious because, oops, I mean, the way the FBI got into Tor was through JavaScript, and those - okay.



LEO:  Whoa, you almost did a bad word.



STEVE:  I almost did a bad word.



LEO:  Those what?



STEVE:  Monkeys.  Monkeys.



LEO:  The monkeys.



STEVE:  The monkeys.  Even the Tor monkeys said, oh, you know, maybe we should have JavaScript on in the Tor browser by default.  It didn't used to be on.  And this would have never happened if they had left it off.  But even they succumbed to, oh, well, let's - people are complaining.



LEO:  Here's what I would say.  You know, I think if you're sophisticated enough to be using Tor, then you're sophisticated enough to know what to do about Java.  I can understand...



STEVE:  Well, no, but JavaScript.



LEO:  I mean JavaScript, I should say.  But I can understand why Firefox, which is a browser that they're trying to get everybody to use, might say, you know, if we let people just turn it off, they're going to - the experience is going to be so confusing that - but sophisticated users can either use NoScript, or you can actually bookmark the appropriate about:config statement to have a bookmark to turn it off and on if you want.



STEVE:  Well, and their point is exactly that.  They're saying that - now, what's controversial is they didn't tell you that they were turning it back on.



LEO:  Yeah.  No, they should have said.



STEVE:  And that's - they really - that's...



LEO:  You mean if I upgrade, it'll turn it back on if I have it off?



STEVE:  Yes.



LEO:  Oh, that's not right.



STEVE:  Yes.  Silently, with no indication.  So their position is that, if you want JavaScript off, nobody can actually live with it off.  So get NoScript.  So they're, I mean, they officially say that's - we're removing the ability to turn it off.  If people want control over JavaScript, you need to use a third-party plugin like NoScript, and that elevates you to an expert.  And again, there are people in IT who are celebrating this because people had turned it off and then didn't know why those sites broke.  I mean, first of all, it's not hard for a site to say, uh, hello.



LEO:  Right, you need JavaScript, yeah.



STEVE:  You've got it turned off.  This isn't going to work here with that turned off.



LEO:  Well, and in fact there is a standard in HTML going back to 3.3 where...



STEVE:  Yeah, [indiscernible]...



LEO:  ...you have a NoScript brack- you know, tag.  And it says, hey, it says, I mean, it's so easy to implement.  In fact, most of the time when you build scripting in, you always have, or I always do, a NoScript tag that says...



STEVE:  Deal with the case.



LEO:  Yeah, you're not seeing this plugin because you have JavaScript turned off.



STEVE:  Yup.



LEO:  Or offer, in a better world, offer a scriptless version of the same functionality, which would be also nice.



STEVE:  That, yeah, exactly.  Now, and, see, I'm hardened because I, of course, I fly with scripting disabled.  I'm using Firefox still because Google - unfortunately Chrome is just out of control in terms of bloat.  I'm hearing a lot of people, by the way, saying, wow, Chrome is getting really slow because it's just getting so big.  So at some point, I mean, and that happens.  We saw it happen with Firefox.  It's happened with Chrome.  So at some point they'll need to just sort of - sort of do a reset.  And they may be getting ready to do that as they move away from WebKit into their next rendering system.  They may not be worrying about it right now because they're waiting for things to settle.  But I love it from a security standpoint.  Chrome's doing a lot of things.  Although we're going to talk about a bit of controversy relative to passwords here in a second.



But Firefox - what I was thinking is I'm heartened by the fact that I am now frequently seeing sites that put up a little banner at the top of the page saying, oh, for full functionality of this site, you need to turn JavaScript on because it's not on right now.  And I think, oh.  And I look at the site, and I think, well, am I passing by?  Do I care?  Do I - is it worth - do I trust this site?  And again, because of everything we've seen, it's not the site so much as everything about it because we've seen JavaScript code being injected onto otherwise good sites.



And in the news also this week we are seeing now malicious ad servers are injecting JavaScript into ads which are being served.  So third-party ads being served up by good sites are running script now that can be malicious.  So again, our audience knows how I feel about scripting.  It's just absolutely it should be off unless you know you need to turn it on.  And if you're skipping around the Internet and clicking on links, you really want to do that with JavaScript off because it's now the way bad stuff gets in.  So that setting's removed from Firefox in v23.



There was an expectation that they were going to turn third-party cookies off by default, as Safari does.  I initially tweeted yesterday the news that they had done that, along with another couple things.  But then finally this morning I said, well, let me make sure about this because the wording is now misleading, the wording on their UI where they said "Keep cookies from sites you visit."  And so I thought, oh, yay, that's exactly what Safari says.



LEO:  And sites you don't visit.



STEVE:  Unfortunately, it also - and sites you don't, in the case of Firefox.  Now, many people don't know, because this is one of those deep technology projects that I did where, after I solved all the problems, I got a lot of the documentation done, but then something came up and it took me off in a different direction.  GRC has for years hosted a beautiful, if I do say so myself, cookie forensics system that instantly shows you exactly what your browser is doing.  And because it's not linked to the main menu, nobody knows about it.



But I created a little bit.ly shortcut just now for my correction tweet when I realized that Firefox v23 had not blocked third-party cookies:  bit.ly/checkcookie, all lowercase, c-h-e-c-k-c-o-o-k-i-e.  And that just redirects you to my site's secure cookie checking system which needs to have browser redirects enabled because that's the technology it uses for causing your browser to query and get responses, query and get responses, several times as it tracks exactly what cookies are sent and received in order to do all kinds of cool things like show you whether you've got stale cookies, fresh cookies, no cookies.  It actually plants cookies in icons, in iFrames, in page headers.



LEO:  It does that fast.  It's doing all that?



STEVE:  Yeah, oh, it does...



LEO:  Geez, Louise.



STEVE:  It does a whole bunch of stuff and gives you a cool summary, which it then interprets all that for you in English, telling you what you need to worry about and not.  And what's nice is for doing research in how various browsers are configured, it just allows you to quickly determine what's going on.  For example, some browsers, even Safari, if you disable cookies and then do this, it'll say, well, new cookies are disabled, but old cookies are still being sent.  And so you can go, ooh, and then close Safari and start it up again, and then see if that's still true.  And then, like, wipe out cookies and then see.  Anyway, it's fabulous for testing how cookies are handled.  So bit.ly/checkcookie.  And it's interesting because, when I tweeted this this morning, a bunch of people sent back surprises.  They said, wow, I thought I had third-party cookies disabled, but they're not, and I didn't know that.  So this little cookie forensics system that I built years ago when I was early on my third-party cookie campaign, it's always been there and works well.



So now they're saying that the Mozilla group are going to fall back to a new system involving cookie whitelisting and blacklisting, which is really disappointing.  Stanford University has something called the Center for Internet and Society.  And they're going to develop something called the CCH, the Cookie Clearing House, where they or someone decide which cookies you want and which ones you don't.  And it's like, oh, oh, okay.  So who knows.  That's not ready yet.  They've decided - apparently what was happening was, when third-party cookies were disabled, there were problems.



And we talked about this in our Q&A last week.  We had a listener who wanted to tell IT how to fix the problem that they're having.  And it is the case that you can, using some settings, often enable or disable third-party cookies per site, very much like NoScript does with scripting per site, which would be a nice way to handle this.  But it's a lot for the average user to deal with.  So this has been discussed at great length over in GRC's newsgroups.  And where many people settled out was to always accept third-party cookies, but only retain them until I close Firefox.  That's sort of a nice compromise.  Firefox does offer that, has offered it, still offers it.  So that way third-party cookies are accepted during your use of the web browser.  But when you close Firefox, it doesn't write them to permanent storage.  They're never written to disk, and so they're discarded.



So that solves the long-term third-party tracking problem.  The persistence of them is the problem.  I mean, one of the other things that would be nice would be if you said we want third-party cookies to be transmuted into session cookies.  Turn them into session cookies so they never live past the current session.  That would work, too.  But we don't seem to be given those sorts of options.



LEO:  Well, at least when you restart the browser.  That's actually surprisingly good.  I didn't realize they were doing that.  That's good.



STEVE:  Yes, and I like that.  That solves the long-term persistence, which is really what the third-party cookie problem is, without messing up short-term gluing of third-party sites to your first-party sites.



LEO:  Like the description the guy described last week that would work.



STEVE:  Yes, exactly.



LEO:  Those iFrames would work, yeah.



STEVE:  Yes.  And then, finally, they added - they've continued to march forward with mixed content.  Remember that mixed content is where you're on a secure page, but not all of the URLs are secure.  That's a problem because it means that some of the content coming back could have been messed with in addition to, of course, more easily spied upon, which is in the news currently, but could be altered.  And you really don't want any of your content to be alterable.  So it used to be that browsers would give you a popup and then would say - and most people just say okay, and then the mixed content page proceeds.



With v23, Firefox divides the insecure content which could be requested by the page you're visiting into active and inactive.  It figures that inactive content, meaning static JPGs and GIF images and boilerplate body copy and things, if the browser is asking for those over an insecure page, Firefox is going to go, eh, okay, that's - it's not active content.  But it's much tougher then on inactive, sorry, on active content.  It blocks it.  No notices, no warnings, it simply blocks it.  It will not come up.  And then a rather obscure new icon shows, or, yeah, well, a little image over in the very far left of your URL.  It shows a shield that is half filled in.  So it's like split, sort of a split shield.  And that's their indication that we have blocked active mixed content on this page.



If you click that, it drops down a little information window explaining what the shield means and giving you the option of allowing all content, even active insecure content, on this otherwise secure page.  So that's what they feel now for v23 is the right way to handle the mixed content problem is to allow inactive, block active, but then sort of make a note of it over in the URL in case something seems wrong to you, and then you can click it and allow the active content, the active insecure component of the page, to come through.  And a bunch of other updates and security fixes and so forth in v23.



So we're now at 23, and third-party cookies did not get blocked, and it doesn't look like they're going to be.  I don't - it'll be interesting.  Of course we'll be following the development of this CCH blacklist and whitelist.  And I hope they do a good job.  I mean, I guess anything's better than this right now, allowing them all by default.  And having misleading text where they say, "Only from sites that you visit."  It's like, okay, that really sounds like you're blocking third-party cookies.  That's what Safari says, and that's what it means.  But it's not what Firefox means.



Okay.  Twitter has evolved their multifactor authentication.  We covered the story that they had added SMS texting to add a factor to authentication.  And they did that sort of in a hurry.  In fact, there were people noting that there were employment ads for Twitter that were clearly looking for third-party authentication experts.  So what they did is something completely different, which is a mixed blessing.



It would have been nice, in fact it would still be nice if they supported what everybody else has supported, which is OATH.  Which is not OAuth, remember, it's OATH, O-A-T-H, which is the time-based one-time password.  There are beautiful clients for our phones, so it's easy to have with you.  We've talked about how nice it is.  Everybody else, as they're coming out with one-time password solutions, is supporting OATH.  But not Twitter.  Twitter's rationale was that OATH inherently requires a shared secret.  And we know that's true.



The idea is your phone has a gibberish-y looking, mumbo-jumbo, pseudorandom token, and that's the key that drives the sequence that OATH uses to generate, based on time of day, to generate the six-character password that changes every 30 seconds.  The same gibberish is then maintained on the server side.  So it knows what time it is.  It generates, using the same shared secret, it generates the six characters that you should be giving to it, and often maybe plus or minus one set so that, if your clock is a little bit slow, and you happen to be sending it in exactly on the change point, it'll say, oh, yeah, well, close enough.



Twitter didn't want to have a shared secret because the danger is, if their server were compromised, and this is the whole thing, this is the whole rationale for not doing what everybody else is doing, if their server were compromised, those one-time passwords could get out.  In which case a third party, potentially malicious, could generate the same token stream that you're generating.  And so that would mean, if the compromise were not found - and in fairness to them, typically these compromises are often not found immediately.  We often report that, oh, it was three months ago somebody got into the servers and got this stuff out, exfiltrated this data.  And so the trouble would be that in that window between which the secret got out from the server and it was discovered as being loose in the wild, all hell would break loose.



So they're saying we don't want that responsibility.  We want a system - and I can understand that.  I can salute them.  Also remember, if you were reusing that same token for multiple sites, then similarly to reusing your username and password, that they could, the bad guys who compromised, for example, Twitter's servers, wouldn't just have access to spoofing you on Twitter, but anywhere else you might have reused that same token, although the whole beauty of the OATH system and the clients that we like is that you've got a cool little lineup of tokens that are all changing at the same time.  So they said no, we're not going to do that.  So they went with two things.  One is very standard.  The second is not, but very cool.



Okay, so the standard thing they did was a simple RSA key pair.  So they're using public key encryption, whereas OATH is private key, symmetric key encryption.  They added to the Twitter app for iOS and Android, and it's there now if you update your iOS and Android Twitter apps, they added yesterday a 2048-bit, so nice and strong, that's the strength we want now, and we'll be talking a little bit later about one of the presentations at Black Hat was disturbing because of recent advances we'll see in academic number factoring which begins to make people worry about how much longer RSA is going to be with us.  So 2048-bit, nice long key pair.  The private key never leaves your Twitter app.  The public key is stored - I'm sorry.  Yeah, the private key never leaves the Twitter app.  The public key is what Twitter holds.  However, all that allows them to do is authenticate your phone.



Now, that's good.  Notice that that's the difference with OAuth.  If you have the OAuth key, because you generate the same token the phone generates, you can both authenticate and impersonate.  And so that's what Twitter wanted to avoid.  If Twitter has the public key, they cannot impersonate.  All they can do is authenticate.  So when you want to log onto Twitter on a web server, and you've set this up in your phone, you give them your username and password to identify your account to Twitter.  Then they see that this is set up, and they, Twitter, send your phone a "long random challenge," as it's called in crypto parlance, 190 bits, which is turned into 32 characters as a so-called "nonce," n-o-n-c-e, a pseudorandom nonce challenge.



Your phone, which uniquely holds a private key that was generated by the Twitter app, cryptographically signs the challenge, meaning that it probably hashes it and then encrypts it using the private key that it has, and returns it.  Twitter, the only thing Twitter can do is verify the challenge by decrypting the signature that you made and verifying that it is the proper hash of the challenge it sent.  Only someone having the private key can do that, so it says that very nicely validates you are you.



So that technology we have now.  They like it because it avoids SMS and the possibility of SMS hacks.  And as we said, for all the reasons I laid out first, it solves the problem of these public keys ever getting loose from them. All it can do is authenticate the challenge.  But what if you don't have your phone?  How do you do a recovery password?  They recognize that all of these systems one way or another have to have a, yeah, but I left my phone somewhere, it's not with me, blah blah blah.  So what they need is a backup code.



And this is where I have to say this is very cool.  Back in 1996 - so what is that, 27 years ago? - Northwestern University published an idea, and this is back in, like in UNIX login days before the Internet, published a nifty concept that they called S/KEY, for Secure Key.  And it was a one-time password solution that, for whatever reason, no one ever adopted.  But it's nifty.  So this system based on S/KEY is also in the new Twitter app for iOS and Android.  And here is how it works:  A separate - during this initial enrollment period, this enrollment and configuration with the new Twitter - I got myself distracted, sorry.  The new Twitter iOS and Android app, when you're setting it up, a separate 64-bit random seed is hashed 10,000 times.



LEO:  Wow.



STEVE:  Yeah, through SHA-256, so a state-of-the-art secure hash.  It's hashed 10,000 times and turned into a 60-bit, 12-character string using something called Base32.  And I think it was before we began recording, Leo, I mentioned that one of the first things I'm going to talk about when we start talking about email security is the whole...



LEO:  ASCIIfication.



STEVE:  ASCIIfication, thanks, yes.  Yes.



LEO:  I just made that up.  Turning stuff into ASCII.



STEVE:  And binaforcation [ph]...



LEO:  Yeah, which is the opposite.



STEVE:  The process of going - you want reversible.  You need to be able to turn binary into ASCII when it's necessary to transmit this over a channel that has limited - that isn't a binary-capable channel, and to turn it back into ASCII at the other end.  We see that all the time in crypto with certificates because they're all binary.  And we're going to be seeing it a lot with S/MIME and PGP and GPG and all those things.  You see these blocks of what looks like gibberish in a piece of email.  So I want to demystify what that is and get people comfortable with this whole process as we begin to plow into this.  But this takes - so we do 10,000 hashes; reduce the result to a 60-bit string, binary; turn that into a 12-character ASCII string.  That string is stored by Twitter on their servers.  Okay?



Then the phone does the whole thing again, but stops one short.  It does 9,999 hashes, does the same process, and gives you that 12-character string, saying write it down.  This is your emergency recovery key.  And so what's clever about this is you have the one preceding the one the server has.  And we know hashing is one way.  So if you ever need to log onto Twitter, and your phone is not available to you, but you wrote down this 12-character string and stuck it on a post-it note in your wallet, for example, then you go, oh, I don't have my phone with me, but I need to log on.  So you type in the 12-character string and submit it.



LEO:  Save it in your LastPass so it's secure.



STEVE:  That goes to - yes.



LEO:  Right?



STEVE:  That goes to Twitter, that converts it back into binary, hashes it one more time to take it from 9,999 to 10,000,  and it verifies that it matches the 10,000th string that you gave it.  And then, when you ask your phone for another one, because you can only use it one time - oh, I forgot to say, after doing that, Twitter stores the 9,999th one because your next emergency code will be the 9,998th one.



So basically, as you use these over time, you're walking backwards through a chain of one-way functions, a chain of one-way hashes.  As we know, it's always possible to go from the current one to the next one.  It's impossible to go from - to predict what the predecessor was of the output of a hash.  And so Twitter - so when you authenticate using your backup codes, you always give Twitter the one before, which it can verify is the one before the one it has, and then it stores that one as the one it has, and you'll give it the one before that next time.



LEO:  Perfect.



STEVE:  Which is really cool, yeah.



LEO:  I think, you know, it's something different, but it's a similar idea to what Apple and Microsoft do with the whole disk encryption built into the OS.  They give you a way out if you lose the password.  Right?



STEVE:  Right.



LEO:  Yeah.



STEVE:  Right.  And again, this also solves the problem of Twitter never having something that can compromise you.



LEO:  Yes, that is clever.



STEVE:  All that can do is verify that you gave it the proper preceding passcode, and then it says, yes, you are you, logs you in, and then it keeps that one you gave it as the next succeeding passcode for the one that you're going to give it, which will precede it.  So I thought that was okay.  It's all new.  They invented their own system.  It would be nice...



LEO:  And that's the shame, I mean, they didn't really need to reinvent the wheel.



STEVE:  Yeah, they wanted to own it themselves.  And it would be nice, for example - oh, by the way, SMS is still supported.  So if you don't want to do any of this, you can still use the existing SMS system.  I think it would be nice if they also supported OATH that everybody else supports.



LEO:  Yes, because I have my Google Authenticator.



STEVE:  Yes.



LEO:  Works for LastPass, works for Google, works for Outlook.com.  So, come on.  If it's good enough for Microsoft and Google, do it.  Seems...



STEVE:  Yeah.  Give it to us as an option.



LEO:  But, you know, Blizzard does that, too.  They have - Blizzard's worse because they have their own authenticator.



STEVE:  Yup.  They're like VeriSign, where you need to use their server in order to authenticate.



LEO:  Yeah.



STEVE:  So, not surprisingly, we talked about this a week or two ago when DEFCON officially - was it DEFCON or Black Hat?  Now I'm confusing myself because I wrote DEFCON...



LEO:  Black Hat is the official formal conference, and then the hackers stick around for DEFCON.



STEVE:  Okay.  So I'm...



LEO:  And that's where they get crazy on it.



STEVE:  So what I wrote here was that NSA director Keith Alexander did not have a pleasant time.



LEO:  That would be the Black Hat because he wasn't allowed to go to DEFCON.  They uninvited the feds, yeah.



STEVE:  Correct.  My notes confused me.  Yes.  So he was uninvited by DEFCON, saying, eh, you know - well, I mean, actually he wasn't, but all of the federal government was discouraged from going, with the argument that we need a little time to cool off here and so forth.  So it was at Black Hat that he was, on July 31st, the opening keynote speaker.  And so anyway, the crowd listening to his opening keynote was initially quiet and attentive and polite.  But as he went on, basically trying to explain the how and why of the NSA's surveillance being both legal and effective, the crowd got increasingly restless, hostile, and heckling.



LEO:  As am I, right now, just thinking about it.



STEVE:  Yeah.  So that by the end it was, I mean, he did make it through his speech, but it was somewhat questionable whether he was going to be able to or not.



And then, on the Sunday show, I hope there's some follow-up to this because I would like to - and I ought to have done some more research.  But it was just a comment in passing on ABC's "This Week" show with George Stephanopoulis where it came out that in 2011, so two years ago, the secret FISA Court produced a report themselves stating that what was being done was both unconstitutional and unlawful, and the report was classified and suppressed.



LEO:  Oh, I just - this is endless.  I don't know how it can get any worse.



STEVE:  So it's like, okay.  So here's the FISA Court, being this court that operates already in secret, and then the judges themselves produce a report stating that what they're being asked to do, that is, that what they are overseeing and is being done is unconstitutional and unlawful, and that report...



LEO:  Classified.



STEVE:  ...is suppressed, is classified and suppressed.



LEO:  Holy cow.



STEVE:  That's really wrong, Leo.



LEO:  We are rapidly approach 1984.  I am very depressed.  It's one thing if you can justify it and say, well, we're fighting terrorism.  But doing something like that, where your own secret court condemns you, being suppressed, that's viciously illegal at this point.



STEVE:  And we have lawmakers, Congressmen, who cannot speak because the information they have is classified.  And so they're unable to say this is wrong.  Ugh, yeah.



LEO:  Or they aren't being told, I mean, we're learning that, as well, that they are not being told everything...



STEVE:  In some cases they haven't been.  But there are other...



LEO:  There's vast illegalities going on, being perpetrated by the federal government, and not by the legislative branch, but by the executive branch and the law enforcement bureaus, vast illegalities, and no one is stopping it.



STEVE:  I tweeted a link, using bit.ly again, and I would be - I need to start using my own system.  I have the URL GRC.sc, for shortcut, so I could do my own little shortcuts.  But nothing is going to interrupt SpinRite.  I mean, I did, I did allow sci-fi to interrupt my work on SpinRite; but that stopped, and so I'm back.  Anyway, so for now I'm using bit.ly.  This is section215, all lowercase, is the tag:  bit.ly/section215.  This is the best, most succinct summary.  Ars Technica just published this, which is a very good explanation for how this mass surveillance legislation was basically silently fudged.



And what you will see in there, Leo, you should read it sometime if you can, the lawmakers who watched this happen, who objected to it, who knew what was happening from the initial authorization, when it came up for reauthorization, some language was subtly changed that fundamentally changed what could be done.  So, yeah.  I mean, it's really, as you said, it's not good.



Now, in something that is sort of - I don't quite understand.  This, for me, this is a tempest in a teapot.  But Twitter doesn't think so, and the media doesn't think so.  So 9to5Mac, their headline:  "Security flaw in Chrome browser reveals plaintext passwords without authentication."



LEO:  I was hoping you'd cover this because I'm very curious about this.  And of course you need an expert to tell you.



STEVE:  And I thought, wow, okay, what is that?



LEO:  Yeah.  That's not good.



STEVE:  And so then they quote, they say:  "The Guardian reports that a security flaw in Chrome allows anyone with access to a computer to view..."



LEO:  Well, at least there are some requirements.



STEVE:  You've got to have a computer.



LEO:  You could leave that whole clause out.



STEVE:  I know, "...to view all of the saved logins without requiring any form of authentication."  And so then I go, what?  So I switched over to the Guardian:  "Google Chrome security flaw allows unrestricted password access."  And then their subheader:  "Plain text logon details for email, social networks, and company systems stored in the browser's settings panel."  And I thought, well, yeah, okay.  So the Guardian - and this sort of, this explains both sides of this, and some sort of, like, this sets it up, so I'm just going to share this Guardian story.



"A serious flaw in the security of Google's Chrome browser lets anyone with access to a user's computer see all the passwords stored for email, social media and other sites, directly from the settings panel."



LEO:  What?



STEVE:  "No password is needed to view them."  Okay.  "Besides personal accounts, sensitive company login details would be compromised if someone who used Chrome left their computer unattended with the screen active.  Seeing the passwords is achieved simply by clicking on the Settings icon" - and Leo, you can follow along.



LEO:  I'm doing it right now, yes, terrified.



STEVE:  Oh, yeah.  Are you sitting down?  Are you on your ball?  Are you centered on your ball?



LEO:  Okay.  I am centered because this is horrible, yes, yes.



STEVE:  Good, yeah, because if you were off-center on your ball, you might lose it.



LEO:  Yes, okay.



STEVE:  Okay, "...choosing 'Show advanced settings.'"



LEO:  Show advanced, oh, that's way at the bottom here.  Okay, good.



STEVE:  Oh, yeah.  Go all the way, Leo, it's a long scroll to the bottom.



LEO:  Passwords and forms?



STEVE:  Yes, yes, that's where you want to go.



LEO:  Yeah, yeah, yeah.



STEVE:  And "Manage saved passwords..."



LEO:  Okay, let's click that.



STEVE:  "...in the 'Passwords and forms' section."



LEO:  I'm going to take the camera off of it because I don't want to reveal anything.



STEVE:  No.  "A list of obscured passwords is then revealed for sites."



LEO:  Yeah, they're obscured.



STEVE:  They're little black dots, Leo.



LEO:  Yeah, little black dots, yeah.



STEVE:  And they're all the same length, aren't they.



LEO:  No, they're different lengths.



STEVE:  Oh, oh, there's some information leakage right there.



LEO:  Yeah, that's not good, yeah.



STEVE:  No.  "But clicking beside them..."



LEO:  Okay.  I'm going to hide this again.  Clicking beside it...



STEVE:  "...reveals the plain text..."



LEO:  Oh, the Show button, yeah.



STEVE:  Leo, there's a Show button.  Oh, my god.



LEO:  And it does.  It shows it.



STEVE:  Who put that there?  Oh, my, that's a serious security flaw.



LEO:  Yes, yes.



STEVE:  Yes.  And now there for anyone to see is your password.



LEO:  Yes.



STEVE:  That could be copied, Leo.



LEO:  It could be.



STEVE:  It could be sent via a screenshot.



LEO:  Yes.



STEVE:  To an outside site.



LEO:  It sure could.



STEVE:  My god, it means pandemonium.



LEO:  But you have to be logged in as me, on my version of Chrome.



STEVE:  And, and, and, and...



LEO:  And have access to my computer.



STEVE:  But get this, Leo.  But the head of Google's Chrome development team, Justin...



LEO:  If I can't look at my passwords, that could be a problem, folks.  I want to be able to look at my passwords.



STEVE:  And get this.  This is where it just goes.



LEO:  I could do that with LastPass, too.



STEVE:  The head of Google - yeah, I know - Google's Chrome developer team said he was aware of this.



LEO:  Yeah, I'm aware of it.  What of it?



STEVE:  Uh-huh, and there are no plans, Leo...



LEO:  No, no, no plans.



STEVE:  ...to change the system.



LEO:  No, no plans at all.



STEVE:  Now, however, now, the Guardian took a little - in the middle of generating a great story here with a fabulous headline, he goes on to say:  "That response was described by Sir Tim Berners-Lee..."



LEO:  The guy, yeah, the man.



STEVE:  "...the British inventor of the whole web..."



LEO:  The whole thing, he invented it.



STEVE:  "...as 'disappointing.'"



LEO:  Come on, Tim.



STEVE:  Sir Tim is disappointed.



LEO:  Tim obviously didn't really look into it.



STEVE:  "He characterized the flaw" - Leo, you have just demonstrated a flaw of Chrome security - "as 'how to get all your big sister's passwords,'" says Tim.



LEO:  Yes, that's right.  If your big sister's stupid enough not to log off.



STEVE:  Just to give you some background here:  "Chrome is one of the three most widely used browsers."  I'm still quoting the Guardian.



LEO:  No, really?



STEVE:  Yes, from the Guardian.  The Guardian says:  "...the three most widely used browsers on desktops worldwide, along with Microsoft's Internet Explorer and Mozilla's Firefox.  It has millions, Leo, of users and is seen" - the Guardian didn't say "Leo," I added that - "is seen by some as crucial to Google's future efforts to monetize web use."



LEO:  It's crucial.  I mean, I'm just curious, because if I go to LastPass in my browser, and then I look at a password - here's let's pick something - and I say let's edit that password...



STEVE:  I did that yesterday, Leo.



LEO:  And then - ooh, let's not show that.  Oh, that was a mistake.  I just showed my credit card number.  I'm going to have to change that.  This is what happens when we start doing this stuff.  It had my credit card number in the clear.  How dare they?



STEVE:  After you asked it to show it to you.



LEO:  How dare they?  Yes.  Yeah, it had the whole thing.  I guess I'm going to have to change that.  Oh, well.



STEVE:  So, folks, there you have it.  If you want to know what your passwords are, Google will show them to you.



LEO:  Did you get the screenshot, those of you at home?  Okay.



STEVE:  Now, what Firefox does is offers you the option which Google has left out, and this seems to be the focus of this whole tempest in a teapot.  Firefox will allow you to create a master password to protect all of your mini passwords, your non-master, your slave passwords.  Chrome doesn't do that.  Everybody would be happy, apparently, if Chrome allowed you the option of creating a master password.  But this Justin, Chrome's head of - he's the head of Chrome's developer team, wrote on Hacker News that, quote:  "We've also been repeatedly asked why we don't just support a master password or something similar, even if we don't believe it works.  We've debated it over and over again" - so, folks, this was not left out by oversight - "but the conclusion we've always come to is that we don't want to provide users with a false sense of security and encourage risky behavior.  We want to be very clear that, when you grant someone access to your OS user account, they can get everything."



And what I loved was this article finishes with an unnamed security manager at a publishing company, who said:  "The fact you can view the passwords means they are stored in reversible form, which means that the dark coders out there will be writing a Trojan to steal that password store as we speak."  Now, this is not a very smart security manager, unnamed, thankfully, at a publishing company, because of course they're reversible.  They're stored in your browser so that your browser can send them to the website, as if you had typed them.



LEO:  If it didn't do that, you'd - okay.



STEVE:  Okay.



LEO:  So, by the way, don't use that credit card I just put out over the air because I've replaced it, so - I can't believe I did that.  So, now, the same thing happens with LastPass.  But you have to be logged in in both cases.  You have to be logged in to Chrome, too.



STEVE:  Browsers want to - browsers have always offered you, would you like me to save the password of this page?



LEO:  Right.  And Firefox will password protect that.  Actually, Firefox did used to store that without - in a file without encryption.  But that was a while ago.



STEVE:  Yes.  This has been resolved quite a while ago.  But mostly, I mean, the lesson we - our listeners know, yes, you are a privileged user of your computer, which is why I hope you have a logon password for your computer.  What that means is you should shut it down or lock the system if you're going to be away.  Someone sitting at your computer is presumed to be you, at a level of granularity you can control.  Under LastPass you can say "Prompt me for my master password" every time LastPass is going to decrypt your local store in order to send a password off to a website.  Or you can say, no, I'm the only one around.  Ask me only when I fire up Firefox.  Or make that, even that, make that more persistent.  So you can control that level.  And so what Google's position is, our feeling is none of that is really very useful.  We don't want to pretend that it is.  So, yes, we'll show you your password if you ask us.  And of course...



LEO:  Yeah.  If you have physical access to a computer in general...



STEVE:  Yeah, you're god of that machine.



LEO:  Yeah.  I mean, come on.  That's just moronic.



STEVE:  Yeah.  Yeah.



LEO:  Yeah.  And speaking of moronic, that was really stupid, to show my - all that information.  God.



STEVE:  So one of the other Black Hat presentations was a disturbing analysis of the current academic research in factoring.  And essentially a group of guys at a firm, iSEC Partners, did a very chilling presentation showing the advances just in the last six months on edge cases of factoring.  They don't fully apply today, so it's not like a linear scale where we're linearly getting better.  But the mathematicians are really intrigued by the idea.  And when you get a whole bunch of mathematicians really intrigued, and you allow them to talk to each other and publish papers and go, oh, look what happened, we realized that this little subdomain over here has a recurring modulo in the field of something or other, then other researchers go, hey, hmm, that kind of fits in with what I was doing, and they end up whittling away at this.  This is the way it's going to happen.



So right now the Diffie-Hellman key exchange, which relies on the so-called "discrete logarithm problem," which we've discussed, that was released in '76.  And RSA encryption, which relies on the hardness of factoring problem, that happened in '77.  So that's more than 30 years ago.  So 30 years ago, I mean, 30 years from then was 2007.  And that's around the time that Elliptic Curve Crypto, ECC, began to happen.  So, really, 30 years is a good run.  That's, I mean, that's a successful lifetime for anything in the security arena.



And these guys argue that the problem is we are not prepared to move as quickly as we should.  RSA and Diffie-Hellman are too well entrenched in the crypto ecosystem such that, if factoring fell tomorrow - and they're not saying it's going to, but Bruce Schneier's famous quote was "Attacks never get worse, they only get better."  And one of our big topics for today is BREACH, a new attack on SSL encryption, HTTPS sessions, where we're going to see exactly that.  So they ended their presentation showing timelines and exponential graphs and charts, and they really made a strong case for the fact that we need to move.



Now, there is something interesting holding us back, and that is that BlackBerry, of all people, own the patents on ECC.  And the NSA has even licensed the patents for some domains of use from BlackBerry.  But ECC is somewhat patent encumbered.  And so in general the industry doesn't like freely using and relying on patent-encumbered crypto.  I mean, that's always been a concern, the issue of intellectual property.  So they made a plea for BlackBerry to consider doing what's right and allowing some use of their patents.  And one wishes that BlackBerry were in better shape right now because they're probably looking at their elliptic curve crypto patents covetously and thinking, oh, how much money can we get for these?  Which is not good.



But so just it was an interesting presentation, saying, you know, keep an eye on RSA.  The problem is making the keys bigger, the RSA keys.  We're talking now about 2048 bits.  Google famously is retiring its 1024-bit keys, moving to 2048.  Our own backend credit card processing merchant gateway recently sent out email saying that their test gateway is now running 2048.  By a couple months from now, they're going to be switching over.  So anyone relying on, anyone who might have SSL crypto which is sensitive, and my implementation is not, but so there's another instance of everyone beginning to have to move to 2048 as their 1024-bit certificates are expiring.



So the problem is that elliptic curve crypto is much faster and uses much shorter keys.  You get about the equivalent, with only twice the key length, of elliptic curve crypto, which is a public key - it's an asymmetric key technology.  You only need to go, to get about the equivalent security of a 256-bit key in symmetric, you only need about a 512-bit key in elliptic curve; whereas you need about a 16,000-bit key using prime factorization RSA.  And, boy, things really slow down.  That's the problem is RSA does not scale well in key length and performance in order to maintain security, whereas elliptic curve crypto scales much better, much more efficiently.



I did also note, just in passing, that even Wikimedia is responding to the NSA spying news, and they are hastening their move to HTTPS Everywhere.  They're going to be switching to a full secure mode just so that - to make it less easy to have the users of Wikipedia and other Wikimedia properties surveilled. 



And then, lastly, before we get into our other technology stuff, I noted, and many people brought it to my attention, that the other agencies, almost predictably, the other government agencies are now complaining that the NSA has access to information they would like to have because it would make their...



LEO:  Well, of course.



STEVE:  ...discoveries and cases.  I know.  The New York Times said:  "The National Security Agency's dominant role as the nation's spy warehouse has spurred frequent tensions and turf fights with other federal intelligence agencies that want to use its surveillance tools for their own investigations, officials say.  Agencies working to curb drug trafficking, cyberattacks, money laundering, counterfeiting, and even copyright infringement..." - we know who they are.



LEO:  Yeah.



STEVE:  Uh-huh, "...complain that their attempts to exploit the security agency's vast resources have often been turned down because their own investigations are not considered a high enough priority, current and former government officials have said.  Intelligence officials say they have been careful to limit the use of the security agency's troves of data and eavesdropping spyware for fear that they could be misused in ways that violate Americans' privacy rights."  Uh-huh.



LEO:  What a surprise, yeah.



STEVE:  We've got it, and you guys don't get it.



LEO:  Except that I don't buy it.



STEVE:  No.



LEO:  I'm sure everybody gets it.



STEVE:  So two brief notes.  I did, as I mentioned at the top of the show, finish The Void Trilogy last week, loved it.  And I would recommend "Fallen Dragon" as anyone's first dip into Peter Hamilton, followed by the "Pandora's Star" and "Judas Unchained" pair of books.  "Elysium," Matt Damon stars, and opens on Friday.



LEO:  I can't wait.  That might actually be good.



STEVE:  Looks great, from what I've seen.  And "Oblivion," the only movie that I've seen twice this summer, was released on disk.



LEO:  I thought you didn't like it.



STEVE:  Oh, I loved it.



LEO:  Oh, you liked it.  That's the Tom Cruise one.



STEVE:  Yeah, thought it was great.



LEO:  Oh, okay.



STEVE:  I really enjoyed it.  And then just totally random, but I got a chuckle out of this, I got a note from Amazon telling me that the extended version of "The Hobbit" was just out on DVD.



LEO:  In case it wasn't long enough.



STEVE:  And I'm thinking, what?  They extended the extended movie?  Because, I mean, everybody was complaining.



LEO:  It was already three hours or something.



STEVE:  Because the movie was ridiculously long.  But, no, we didn't see it all, Leo.  There was some that was left on the cutting room floor.  So they've pieced it back together, and the extended version...



LEO:  Waste no furry toe.  So that's annoying because of course I bought the deluxe Blu-ray of "The Hobbit" when it came out, and now - that's probably why.  They want me to buy it again.



STEVE:  And did you watch it yet?



LEO:  Yeah, several times.  I liked it.



STEVE:  Yeah.  I enjoyed the movie also.



LEO:  I didn't dislike it.  I mean, it was nothing like the book, but I didn't dislike it.



STEVE:  I didn't think it was too long.



LEO:  New one comes out in December.



STEVE:  You can get more if you want.  It's extended now.



LEO:  I can only imagine.



STEVE:  And I am back working on SpinRite.



LEO:  Yay.



STEVE:  I'm working now on the low-level driver for the hardware, which will give us the access to huge buffers and was going to just really make SpinRite, going to be a huge performance benefit for SpinRite.  What I did so far, there's a bunch of very delicate timing in the so-called ATA specification, where, for example, if you change the drive you're selecting, where you've got two drives on a traditional flat cable, the IDE-style drive with master and slave, you have to wait 400 nanoseconds for the newly selected drive to put its status on the bus, and the drive that was selected to release its status from the bus.



LEO:  400 billionths of a second?



STEVE:  Yeah.



LEO:  Oh, dear.



STEVE:  Yeah.  And the problem is it's not easy to know when that amount of time has passed.



LEO:  I don't think you can count it, really.



STEVE:  Well, and so it's, like, easy to know if much more time has passed.  But if I did that, then I wouldn't be running as fast as I could.  And my whole, as is always the case for me, I want to write this code once and have it last forever.  So I've seen - and when I've looked around at how other people have solved the problem, I have been disappointed because even on really good websites they say, "Issue five output instructions and only use the" - or "five input instructions sampling the status, and only use the results from the last one."  And it's like, what?  Well, how do you know how long each output instruction's going to be?  Because that keeps changing and getting faster.  And it varies whether you're on an old-style motherboard or a fancy fast chipset and so forth.  So I've been very disappointed with what I've seen.



Anyway, what I wrote and nailed down after I got back to SpinRite was a system that gives me accuracy on the test platform I have, and it will generally be the case, down to 323 picoseconds of timing so that the 500-nanosecond, I'm going to give it an extra hundred just because that's wise, the 500-nanosecond delay requires 1,549 of those 323-picosecond intervals.  So I've got that nailed down.  I have a general purpose, highly accurate, high-resolution time base which establishes itself in 3.5 seconds on anyone's machine.  And then that will be driving all of the access where software's involved and waiting for things to happen on the hardware bus.  So it's going to be good.  That's going to work.



LEO:  How fun.



STEVE:  Oh, yeah.



LEO:  It's fun to be solving problems like this.  That's why you do it.



STEVE:  Yup.  It is exactly why I do it, because I want to - it's stuff I haven't done before, and then I come up with exactly the right solution that nobody else seems to have taken the time to do right.



LEO:  Gibson [indiscernible].



STEVE:  So everybody who has SpinRite 6 gets the new one.



LEO:  Yay.  Leo Laporte, Steve Gibson, and there's still lots more to talk about.



STEVE:  Actually two major issues, which I think will fit nicely into this final 20 minutes.  So responding to an arrest warrant and U.S. extradition request, an arguably slimy guy, Eric Eoin Marques, M-a-r-q-u-e-s, was arrested in Ireland last Thursday.  And a paper over in Ireland, the Irish Independent, reported that Marques is wanted for distributing child pornography in a federal case filed in Maryland, in the U.S., and quotes an FBI special agent describing Marques as, quote, "the largest facilitator of child pornography on the planet."



And elsewhere, I don't remember now where - oh, here it is, in an article by Wired.  I was going to follow into this.  Wired magazine then picked up the news, which was just about coincident with this event, and so as a consequence it's not believed to be coincidental:  Freedom Hosting, which was the facility that Eric was operating, began having, well, it put up a notice saying that the sites it was hosting were temporarily down for maintenance, and spyware was being injected.



Freedom Hosting is in the Tor network using the Tor hidden services that we have talked about.  In fact, we did a podcast on using the distributed hash tables and how the use of hidden services was sort of an inversion of what Tor was originally designed to anonymize.  Tor initially was anonymizing users who would use the Tor client to access the Internet through multiple Tor nodes, hopping around with the onion layers being peeled each time, decrypting their traffic, so that no - where no node needed to be trusted.  Very clever system.  Then they added a second facility such that, rather than having your traffic eventually go out onto the Internet, where then it would be public, it was possible to similarly conceal servers such that they would have name.onion, so they used the .onion top-level domain, and the server itself could be hidden within the Tor network.



Now, it's very valuable, of course, for many good purposes.  And unfortunately, it can also, as all of these technologies can, just like cryptography itself, can be used for bad purposes.  And there were - apparently Freedom Hosting was hosting websites that were offering a great deal of child pornography.



So Wired's reporting said:  "Freedom Hosting has long been notorious for allowing child porn to live on its servers.  In 2011, the hactivist collective Anonymous singled out Freedom Hosting for denial-of-service attacks after allegedly finding the firm hosted 95% of the child pornography hidden services on the Tor network.  Freedom Hosting is a provider of turnkey" - this is Wired, continuing - "Freedom Hosting is a provider of turnkey 'Tor hidden service' sites  special sites with addresses ending in .onion  that hide their geographic location behind layers of routing and can be reached only over the Tor anonymity network.  Tor hidden services are ideal for websites that need to evade surveillance or protect users' privacy to an extraordinary degree - which can include human rights groups and journalists.  But it also naturally appeals to serious criminal elements.



"Shortly after" - this is still Wired.  "Shortly after Marques's arrest last week, all of the hidden service sites hosted by Freedom Hosting began displaying a 'Down for Maintenance' message.  That included websites that had nothing to do with child pornography, such as the secure email provider Tor Mail."  And that's been one of the aspects of controversy here is that, as has happened before, this was a bit of a blunt instrument that it turns out U.S. law enforcement was using.  We'll get to the technology of that in a second.



"Some visitors," says Wired, "looking at the source code of the maintenance page, realized that it included a hidden iFrame tag" - and here we go back to what I was saying last week about iFrames just being fundamentally a bad idea, or dangerous - "that loaded a mysterious clump of JavaScript code from a Verizon Business Internet address located in Virginia."



So first off, remember that what iFrames do is they're like a web page within a web page.  They are a frame that has a URL, and they will induce the browser to go load that page with whatever the page contains, in this case JavaScript from a Verizon Business Internet address.  Now, there's many layers to this, and I alluded to one earlier.  One problem was that the Tor Browser Bundle, which is the TBB, the Tor browser bundle is what most people use for accessing Tor, including these hidden servers, had switched its policy sometime in the past from disabling JavaScript to enabling it, specifically because sites weren't working.  So the first part of this vulnerability was JavaScript was enabled.  And there was a known vulnerability, since patched, which was not propagated into the Tor browser bundle because this was a down version, v17 of Firefox, and this was the extended service release, the ESR version, which did not do automatic updates.  So it wasn't getting updated.



So, "By midday on Sunday," so this is like three days later, "the code was being circulated and dissected all over the 'Net.  Mozilla confirmed the code exploits a critical memory management vulnerability in Firefox that was publicly reported back in June, on the 25th, and is fixed in the latest version of the browser."



The Tor Project wrote in a blog post Sunday:  "The malware payload could be trying to exploit potential bugs in Firefox 17 ESR, on which our Tor browser is based.  We're investigating these bugs and will fix them if we can."



And so Wired concludes, saying:  "The inevitable conclusion is that the malware is designed specifically to attack the Tor browser."  I agree.  "The strongest clue that the culprit is the FBI, beyond the circumstantial timing of Eric Marques's arrest, is that the malware does nothing but identify the target."  And so some people have reverse-engineered the code.  I have looked at it.  It is Windows shellcode, essentially.  The JavaScript has a variable called "Magneto" which contains the Windows executable shellcode.  It uses a memory management flaw in JavaScript to inject this Windows shellcode into memory and then execute it.



What it does is it connects to an IP address, 65.222.202.54 over port 80, which is to say a web port.  And then it assembles and issues a simple HTTP query to that IP address providing the system's hostname and the local network adapter's MAC address.  And what's clever about that is, as we have often discussed and have explicitly talked about when we've been talking about the Ethernet protocol, which is where the MAC address lives, unless they are manually changed, they are globally unique.  So what is collected by a server, an HTTP server at that IP, is the user's IP address, because that's where the non-spoofable TCP connection comes from, the system's hostname, and the probably globally unique, or if nothing else, the current MAC address of that machine.



So I've seen all kinds of misreporting about this.  There was some - some reports believed that this was part of the CIPAV, which is a well-known, for about a decade now, FBI spyware tool.  CIPAV stands for Computer and Internet Protocol Address Verifier.  The reason I think that's misreported is that that is a much more comprehensive piece of spyware.  It collects the IP address, the MAC address, the list of open TCP and UDP ports, the list of running programs, the OS type, version number and serial number, the default Internet browser and version, the current user of the system, the current logged-in username, and the last visited URL.  So it's a much bigger blob.  This exploit was much more tightly written and much smaller, and it doesn't leave any kind of backdoor or any other modification behind.  And actually it cleans itself up and hangs the system so that, essentially when it's restarted...



LEO:  This is a reboot.



STEVE:  ...it forces a reboot.  It cleans itself out.  So it seems very minimal.  And back, oh, I can't think of now when it was, but the Ninth Circuit Court of Appeals did rule that this minimal level of identification did not meet the level of privacy that a user on the Internet could reasonably expect to have, and it was constitutional to collect this without first having a search warrant.



LEO:  I think so.  I mean, your IP address is exposed.



STEVE:  Yeah, and your MAC address and...



LEO:  And your MAC address.  It's just that you've been trying to prevent that using Tor.



STEVE:  That, and so - exactly.



LEO:  And this is through the Tor.



STEVE:  Exactly.  And so that's the key here is, remember that you're using Tor, and this client, and there's a tremendous amount of technology involved in hiding you.  You've got all these wrappers of onion layers, and your data is bouncing around among Tor browsers, and onions are being pooled and so forth.  And then your computer does a straight hot beeline connection to the FBI.  And in fact there were early reports that this was an NSA IP.  They didn't turn out to be true.  There were reports that it was an SIAC, which is a major government contractor.  That's not the case.  Nobody knows where this goes.  It turns out that it's been the IP address, 65.222.202.54, has been traced to a small block of eight so-called "ghost IPs."  It's just a, quote, "unallocated block" at the Verizon Business Datacenter in Ashburn, Virginia.  So...



LEO:  So nobody's using it.



STEVE:  Yeah.



LEO:  Nobody's using that.



STEVE:  There is a server.  There's a server that accepts, happily accepts your TCP connection, Leo.  And so essentially what this - the whole takeaway is that this bad guy, arguably bad guy, providing a huge amount, presumably for money, I mean, he's charging, I would imagine, I mean, this is a profit basis for him, selling kiddie porn, is extradited and arrested.  The FBI figures out where his machines are, immediately puts up a "sites are down" message, but inserts spyware such that anybody receiving those pages, anybody seeing those pages will essentially completely de-anonymize themselves, connecting to the server in Virginia with their IP, their MAC address, their machine's name, and now they're in trouble.  So as well they should be, although people using Tor Mail, again, this did cut a large swath.  Basically everyone using this Freedom Hosting who visited - oh, by the way, had to be on Windows.  If you were on a Mac, the shellcode would just explode and do nothing.



LEO:  Clever.



STEVE:  So, yeah, clever.



LEO:  Yeah.  Can't really complain about it, since it was...



STEVE:  No.  I don't - I would say this was - if nothing else, our takeaway here is that the FBI's got some smart people, too, and they are on the ball, and they are using this technology, and they're going to where law allows them to.  And this did not cross a boundary.  This was only getting people who were going to these sites, de-anonymizing them, and then allowing the FBI to then get a search warrant to get the person's machine and verify that in fact they were doing this, they had this behavior in their recent history.



LEO:  Very interesting.



STEVE:  And lastly, wrapping this up, we discussed at some length in the past Thai Duong and Juliano Rizzo, one of whom was at the beach looking at bikinis, everyone will remember...



LEO:  Oh, yes [laughing].



STEVE:  ...when they came up with their so-called CRIME, C-R-I-M-E is the acronym, for their very clever approach for using compression, essentially using compression variation, the variation in the amount that plaintext would be compressed to determine what browser query headers were.  What we know of compression is the more redundancy you have, the greater the compression.  So the theory was, and what they did was they created an absolutely robust attack.  The theory was we should be able to inject different things and then look at how the SSL/TLS compression compresses our stuff plus the stuff we want to know.  If our stuff matches the stuff we want to know, the compressor will compress it well because there's not much entropy there.  If our stuff doesn't match what we want to know, it will expand it and not compress it.



So they turned this into the CRIME attack, where shortly afterwards everyone stopped using SSL/TLS compression.  Now, that was easy to do.  No one uses it anymore because of these guys back last year.  But nobody was really using it the first place.  It was in the spec.  Some people had it on.  Newer browsers used it or offered it.  Newer servers offered it.  You had to have it.  It was one of those things where you had to have it at both ends so that both ends would negotiate.  And if they both supported it, then they would turn on.  But it was no big deal.  Why?  Because most of the traffic is going the other direction.  You send a URL to the website, and wham, back comes the page.  The page is where all the data is.  And CRIME was only an attack on the query headers.  What they got was, and they demonstrated this, they got the session cookie.  So that was certainly valuable.  But that's where their attack ended.



BREACH, B-R-E-A-C-H, Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext - nice acronym, BREACH - was revealed last week at Black Hat.  BreachAttack.com has all the details, if you want more than you get here.  And basically these guys figured out how to go the other direction.  And the bad news is everybody uses compression coming from the server.  What CRIME did - remember that we're all sort of talking about layers.  In communications technology we've got, like, Ethernet at the bottom, and below that is, like, ARP, for example, for the Ethernet packets to route.  And then we've got the IP layer, then we've got the TCP layer, then we have the SSL layer, and then we have on top of that HTTPS, essentially.  So the SSL/TLS layer really didn't matter because all it was was query headers, essentially, going in that direction.



But these guys have figured out how to do the same thing in a relatively short time to crack critical data, state data, being sent in the response headers, which often contains cookie setting material, or it can offer redundantly contained session-based material.  That stuff is going in the other direction.  Everybody compresses their responses.  The reason is, as we've talked about this before, HTML is incredibly redundant.  It's a markup language, hypertext markup language, HTML, which has so much, not only is it often in whatever language the text is written in, and language is inherently redundant, but all of this markup stuff, you know, tags are used with great abandon.  And they can all be compressed.



Consequently, you get, for example, you can take a typical HTML page and squeeze it down to 20 to 25% of its original size.  So that's huge in terms of performance, in terms of minimizing delivery bandwidth, and also improving the whole response time system of the web ecosystem because that means that the page gets to you in one quarter to one fifth the time.  That contains links that allow the browser to ask for all the other assets of the page much faster and get them all coming to you.  So the idea that we can no longer use HTTP compression is horrifying.



And what these guys demonstrated was an attack on - I can't remember now whether it was IE or Chrome.  Both were cited as being readily vulnerable because they're very fast.  And in the summary of their talk it said:  "In this hands-on talk, we will introduce new targeted techniques and research that allow an attacker to reliably retrieve encrypted secrets - session identifiers, tokens, OAuth tokens, email addresses, view state hidden fields, et cetera - from an HTTPS channel.  We will demonstrate this new browser vector is real and practical by executing a Proof of Concept (PoC) against a major enterprise product in under 30 seconds."  The title of their talk was "SSL,  Gone in 30 Seconds, a BREACH Beyond CRIME."



LEO:  That's better than stealing a car.



STEVE:  And they said:  "We will describe the algorithm behind the attack, how the usage of basic statistical analysis can be applied to extract data from dynamic pages, as well as practical mitigations you can implement today.  We will also describe the posture of different Software as a Service (SaaS) vendors vis--vis this attack.  Finally, to provide the community with ability to build on our research, determine levels of exposure, and deploy appropriate protection, we will release the BREACH tool."



LEO:  Oh.



STEVE:  Yes.



LEO:  Wow.



STEVE:  Yes.  So that has happened.  For mitigation, they don't offer much.  No. 1, disable HTTP compression.  Ouch.  Nobody can afford to do that today.  Disconnect secrets from user input.  Somehow keep them, like minimize the exposure.  They suggest masking the secrets.  For example, randomizing them with XOR and something else which you provide so that the idea is you don't want something static to be sent from the server over and over and over.  So, for example, don't redundantly provide the session token over and over and over and over because that's the kind of thing that's vulnerable.  And so essentially we've all - all web browser developers have assumed that, if they enforce HTTPS, that is, SSL sessions, on the delivery of a secure page, then nothing else matters.  They can just - they can send cookies.  They can have headers that they would not ever want anyone else to see.  They don't have to worry.  That's gone now.



Now, any webmasters should immediately take a look, who are concerned about this, take a look at what they're sending out in the response headers, and do what they need to to obscure them - rearrange them, pad them, add pseudorandom noise as the first header, append random varying length junk before the actual secret content.  It's really, from this point on, it's going to be necessary to deliberately obscure the response headers with stuff that will defeat this kind of a multiple query - this is using compression, the same concept as CRIME, where that's why turning off compression saves you is these guys are injecting stuff and seeing how the compression changes based on what they inject.  That allows them to essentially infer what was already there being compressed.



And maybe we could have an evolution of compression so that it's not as deterministic.  Maybe there could be some change to HTTP compression to thwart this kind of attack.  Absent that, and until then, it's going to be necessary to do something to obscure these headers.  So a word of warning to all webmasters out there.  And there's our podcast.



LEO:  And a lovely one it was indeed.  Well, you've given me great reason to be depressed.  But thank you anyway.



STEVE:  Yup.  Lots of news from Black Hat and lots of security stuff.



LEO:  Wow.  Steve Gibson does this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC.  That's at TWiT.tv.  I hope you'll join us live.  If you can't, well, you can always get audio or video on demand.  There's several ways to do that.  GRC.com has 16Kb audio and the smallest form of all, the text transcriptions by Elaine.  GRC.com, that's Steve's site.  Or you have, at TWiT.tv, high-quality audio and video, or wherever finer podcasts are available.  Do you make a feed available of the 16Kb?



STEVE:  No, don't do a feed.



LEO:  No.  So you just have to download that directly.



STEVE:  Yeah.



LEO:  Good.  You won't get sued.  And that's - forget I said that.  We'll talk another time.  What else is there?  Well, of course, last - not LastPass, SpinRite.  Another two-syllable, must-have utility.



STEVE:  What else is there?



LEO:  What else is there?



STEVE:  Ah, yeah.



LEO:  SpinRite, the world's finest hard drive maintenance and recovery utility.  And a lot of freebies, too.  So go over there and visit:  GRC.com.  Will you do questions next week, you think?



STEVE:  Yeah, let's do Q&A next week, and I'll probably have some more really interesting SpinRite news, too.



LEO:  Ooh, how exciting.



STEVE:  Yup.



LEO:  Thank god that novel was no longer.



STEVE:  Only took me 10 days of furious reading.  Believe me, I got it out of my system.  I'm having...



LEO:  I just bought the two that you mentioned on Audible.



STEVE:  Yeah, the Greg Mandel series, they are really - they're easier and really fun.  They're sort of like Hamilton getting warmed up.



LEO:  I can't wait.  I'm so excited.  But if you have questions for Steve, GRC.com/feedback is the place to go.



STEVE:  Yes.



LEO:  Don't email him.  You can't.  GRC.com/feedback.  And we will do a PGP, I hope a PGP episode soon.



STEVE:  Yes, well, we're going to do a series.



LEO:  Yeah.



STEVE:  Because there's a lot of foundation I want to lay down.



LEO:  A lot of questions.  And I'm getting a lot of emails from people who have installed it and got it working, but there's still lots of questions.  In fact, I will forward you an email I got from somebody who said, "You're doing it wrong, Leo."  And you should have multiple keys.  You should have a different key for encryption, a different key for signing.  You shouldn't be using RSA, et cetera, et cetera, et cetera.  So I'll pass that along to you.  I guess this is the pro tips for PGP.



STEVE:  Wow, cool.



LEO:  Yeah.  I mean, I've been perfectly happy with the old way, but if you really wanted to make it breach-proof, I guess...



STEVE:  Yeah, when you're just saying "Mom, what's for dinner..."



LEO:  Yeah.  There's nothing in there.  But I liked it.  I just like the tweak the NSA as long as I can, till I'm in jail.  What else?  I guess that's it.  We will see you next week right here.



STEVE:  Perfect.



LEO:  Thanks, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#417

DATE:		August 14, 2013

TITLE:		Listener Feedback #173

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-417.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  Time for Security Now!.  Yes, there's another update from Microsoft.  There's problems on the 'Net.  There's no need to fear.  Steve Gibson is here, protecting your security for eight solid years.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 417, recorded August 14th, 2013:  Your questions, Steve's answers, #173.



It's time for Security Now!, the show that covers your security, your privacy, your deep, most darkest fears and needs.  And here he is, Mr. Fears & Needs himself, Steven "Tiberius" Gibson.  Hello, Mister....



STEVE GIBSON:  If you weren't sure what you had to be worried about at the beginning...



LEO:  We'll find it.



STEVE:  ...you'll have all the details by the end.



LEO:  We'll find something for you to worry about before this show is over.  I worry about that.  Actually, that's what I worry about.  I don't want to make this show be something that people go, "Oh, what new, what fresh hell is this?"



STEVE:  No, I actually think we do a good job.  And I hear from listeners who confirm their feelings that we do a good job of keeping this balanced.  We're not the Hysteria Now! show.



LEO:  No, no.



STEVE:  I mean, I'm often very skeptical about some of these early things.  Like I was the last one to agree, okay, maybe Stuxnet really did come from the government.  It was like, I don't know, let's just wait.  We're still grasping, we're still guessing, blah blah blah.  And as it finally began to come out, it was like, well, it does really seem like a little joint effort between the U.S. and Israel, so maybe.  But, so, yeah, I think, I mean, our anchor is technology.



LEO:  Yes.



STEVE:  And so, yes, we will talk about the consequences of the technology.  But that's not what this show is about.



LEO:  No.



STEVE:  It's about technology.



LEO:  And Leo revealing his credit card numbers.



STEVE:  That's our focus.



LEO:  You know I did that.



STEVE:  And speaking - I know, last - yeah.  Well, let's remind everyone again, Leo, so they can go back and scroll...



LEO:  Well, no, I already canceled the card.



STEVE:  Okay.



LEO:  In fact, I should have a new one by now, shouldn't I.



STEVE:  It's a great number to use now because it's invalid, and it's not all fives or something really lame like that.



LEO:  Oh, you mean, like, when I have to give a credit card on the air.  Yeah.



STEVE:  Yeah.



LEO:  From now on I'll use that.



STEVE:  In fact, show it, and everyone's going to go [gasp].  But, you know, it's safe now.



LEO:  It's safe.



STEVE:  I hope.  I hope the cancellation order was well propagated through the entire system.



LEO:  Yes.  I hope so, too.



STEVE:  This is a special podcast.



LEO:  Well, it's always been a special podcast.



STEVE:  Well, this is a particular one.  How's that?



LEO:  Okay.



STEVE:  Sharp-eyed Elaine noted a couple weeks ago that August 18th of 2005 was the date of Podcast No. 1.



LEO:  Holy cow.  That long ago.



STEVE:  Here we are, on the 14th of August.  So between this podcast and the next podcast we celebrate an anniversary.



LEO:  That's cool.



STEVE:  Meaning this is the final podcast - I can't even pronounce it anymore, padcast - the final podcast of our...



LEO:  Well, you didn't get the memo that we don't call it "podcast."  That went out in 2006.  But that's okay.



STEVE:  Yeah.  I'm-I'm-I'm old.



LEO:  [Laughing] No, no.  Call it a podcast.



STEVE:  Year Eight now.



LEO:  Year Eight.



STEVE:  So next week starts our ninth year.  Yeah.



LEO:  When we started this show, Steve had hair, and mine was brown.



STEVE:  He didn't even have a ball.



LEO:  We didn't even have a wall.



STEVE:  You didn't even have a ball to bounce on.



LEO:  Oh, a ball, no.  I barely had a microphone.



STEVE:  You were upstairs, crouched over, where the attic was...



LEO:  That's right.  I had to sit like this with my head tilted the whole time because the roof was coming down on me.



STEVE:  And you'd sort of crowd people into your little den and say, okay, talk now.



LEO:  You know what's gratifying, sometimes shows, superannuated shows like this start to wear out.  This show has not - far from worn out, it has grown consistently.



STEVE:  I'm an expert on that phenomenon because, for example, "Dexter," I'm dragging myself through this final season.  It just - it's dead.  So it's uninteresting, it's just like, oh...



LEO:  And that's, what Season 6, 7?  It's not even that far along.



STEVE:  No.  And, but I mean, many - well, and "Galactica."  Wow, kickass couple first years.  Then they just kind of went, I mean, they were literally adrift with the writing because, you know, there's very much often an arc.  And you see this, where the show takes off.  It's successful.  Now it's collected a huge audience and a huge advertising base.  They can't stop.  They just - they're unable to.  One of the things I appreciate, somehow, for some reason, "Star Trek" always stops before it becomes really bad.  Even the "Next Generation."



LEO:  Well, that's the tradition.  It got canceled before it was even born, practically.



STEVE:  Yeah, but "Next Generation," seven seasons, thank you very much.  And that's like, wait, I mean, and we don't have anything like that now.  There's, like, nothing like a really good sci-fi series on.  We've got a bunch of low-budget, walking around in the weeds shows, with every so often something flies overhead.  It's like, okay.



LEO:  Well, I'm happy to say this show, far from it, has grown in audience.  It grows very consistently.  In fact, the last two years have been the most growth, I guess because of interest in what's going on in security, but also because of your excellent reporting on things like PRISM, where people really are hearing the straight story, and sometimes the story no one else is saying.



STEVE:  In fact, one of our, I can't remember how he described himself, anonymous and hiding from the government or something, in our mailbag that I ran across this morning was someone saying, how could you be so right about this stuff?  And again, it's not that I am prescient, it's that it comes from technology.  It was always clear we should not put unencrypted data in the cloud.  And so that's where TNO came from, and PIE.  I mean, these are just - it's come from the technology, and that's what we allow to, I mean, that's our main driver.



LEO:  Well, just to show you, the show "State of Surveillance" that you did, where you talked about what PRISM must be - and, by the way, in time have proven very accurate - is the most downloaded show of Security Now!, I think, with well over a hundred thousand downloads.



STEVE:  Wow.



LEO:  And I don't - that's not including your downloads or YouTube or any of the other sources.  So that's...



STEVE:  Wow, so just from you guys.



LEO:  Just from TWiT.



STEVE:  Wow.



LEO:  So that's pretty good.  Congratulations.  And I have a feeling we're on a roll.  Year Nine is going to be even more interesting.



STEVE:  Well, I think we've got the right mix.  I have had some complaints from people who say, oh, it just turned into a gossip podcast.  And it's like, whoa, whoa, wait a minute.  I think it's far from that.  I think that maybe we were a little too tech-y and not enough conversation.  And so in the last couple years we have, I think, evolved this into a little more discussion.  And I think, when I look at the listenership that your main TWiT podcast has, and what technical details it brings...



LEO:  No, it's more of a gabfest, yeah.



STEVE:  Yeah.  And I think people want entertainment, Leo.  I mean, yes, technology, that'll never - because that's who I am.



LEO:  Gotta have both.  Well, we've got to have both.



STEVE:  That's what interests me.



LEO:  It's informed entertainment.  How about that?



STEVE:  Yeah.



LEO:  And in your case, really, you are easily - this is easily the geekiest show we do.  And should be.



STEVE:  Oh, and baby, get ready, because we're about to dive into email encryption.  And there's a reason no one's using it.  So we're going to tackle that in the coming weeks.  And as an example...



LEO:  Good, good.  But a Q&A this week, yes.



STEVE:  Yes, Q&A this week.  So here we are on the 14th, the Second Tuesday of the Month, Patch Tuesday.  No huge news.  But as always, it's get your machines updated.  It's probably more important now than ever because the bad guys are getting smarter about reverse-engineering what's happened.  Brian Krebs did some nice reporting about this month's patches, so I'm just, rather than duplicating his research, I'm going to share the top of his blog posting from a day ago.



He said:  "Microsoft has issued security updates to fix at least 23 distinct vulnerabilities in its Windows operating systems and other software.  Three of the patch bundles released today," so, yeah, he did this, he did blog yesterday, "address flaws rated 'critical,' meaning that malware or miscreants can use them to break into Windows PCs without any help from users.



"Leading the critical updates is a cumulative patch for Internet Explorer that affects every version of the browser on nearly all supported versions of Windows."  So all versions of IE.  "In its advisory, Microsoft warns it is highly likely that attackers will soon develop exploit code to attack the flaws addressed in the patch."  So even Microsoft gets it now, that when they patch something, it's possible to figure out what they changed and then look at the unpatched versions and go, oh, we know how to leverage that.  So, unfortunately, that's a cat-and-mouse game there's nothing we can do to fix.



"Indeed, according to Ross Barrett," continuing to quote Brian, "manager of security engineering at Rapid7, the IE patch addresses a vulnerability first demonstrated at the Pwn2Own contest at the CanSecWest conference in March of this year."  So this was responsibly disclosed.  The guys who came up with this got a Pwn2Own award.  Microsoft then, that was March, here we are in July or August.  So it's like, okay, well, they weren't in a big hurry to fix this, but they have.  Now it's possible to reverse-engineer it from Microsoft's fix.  So, important to do.



Second most important critical update is a so-called "browse-and-get-owned font vulnerability."  And we've talked about that already.  This affects users on Windows XP and Server 2003.  And this is, you know, we were discussing this just in the last couple weeks, Leo, where the fact that the rendering engine isn't bulletproof, you can even have something as passive as a font file, which a browser will dutifully load in order to properly render the font that your web page asks for.  That can take over your machine with you not having to deliberately do anything.  And final, and then the final of the three, tackles several flaws in Microsoft Exchange that stem from a third-party component from Oracle called Outside In."



So Microsoft's fixing those three critical ones.  And then the important ones are your typical local privilege elevation where somebody at the machine who did not, for example, have administrative rights, could elevate themselves to do so.  And that's not good because you could have, like, locally installed software that is malicious, and the nave user doesn't realize that's happening.  So, as always, update Windows.  When I fired up my Win7 machine in order to run Skype to do the podcast, I got, oh, you have updates.  It's like, yes, that's correct.



We seem to always have these news breaks on Thursday, the day after the podcast has been recorded.  So we're reporting things which are, well, technically as stale as they could be.  Or I guess if they happened Wednesday afternoon, that would be worse.  But anyway, this still is the big story because it directly impinges on topics we've covered in the last couple weeks.  And we've already been discussing the companies that this happened to.  And the repercussions throughout the industry were amazing.



We were discussing just last week the company Lavabit because I brought it up in the context of the rumors, and I never actually saw confirmation.  Now I have actually heard the guy himself, Ladar Levison, say that he did have an email account with the name Edward Snowden on it.  So the owner of the ex, as in no longer, Lavabit service did confirm that there was such an account.  But I'm getting ahead of myself.



Last week Ladar Levison, who is the founder and has been running Lavabit for 10 years, shut it down without warning, just blanked it out.  And when this happened I actually - I realized this was too big for a tweet, so I created a blog entry on steve.grc.com, it's the first blog I've done in a long time, because I thought this was really significant.  So if anyone hasn't seen my blog, it was quite well retweeted and blogged, and I think there are 69 comments following it, and a lot of people thought this was significant.  What's significant is his reason for doing so.  Right now, if you go to Lavabit.com, and I would urge our listeners to, there's nothing but a page that says, I'm sorry, I've shut the service down because, due to - and he's extremely encumbered by, unfortunately, our government, the U.S. government.



LEO:  Even on his Democracy Now! interview, he had his lawyer sitting there to make sure he didn't say anything.



STEVE:  Yes.  And there was a lot of interchange where he'd come to something, and he'd say, he'd look at him and say, can I say.... And his attorney would say, uh, no, you can't, let's go in a different direction.



LEO:  So depressing.



STEVE:  So Ladar shut his service down because he said to do otherwise would make him complicit in crimes against U.S. citizens.  And he refused to do that.  He said, unfortunately, I can't tell you anything more than that.  I can't even - I am forbidden to tell you what it was that I said no to.  He can't even say that.  And, I mean, it is - so yesterday, when I saw the Democracy Now! interview, I tweeted, "Feel like being depressed?  Watch this 15-minute interview, and that ought to do it to you."  And I got a lot of feedback from people saying, oh, my Lord.  Anyway, it's a great interview.  I would really commend our listeners - I didn't want - it's 15 minutes.  I don't want to fill the podcast with it.  Everyone who's interested can find it.  But it's worth watching if this topic interests you.  It is really pathetic what has been done.  And, well, so the next day, Silent Circle announced that they were also preemptively - actually they announced they had canceled their Silent Mail service.  Now, Leo...



LEO:  We talked about Silent Circle.  This is Phil Zimmermann of PGP fame.



STEVE:  We did.  But more than that, Leo, they have Navy SEALs.



LEO:  Oh, yeah, that's the one.  And they're still scared.  Although they were quick to say we haven't received a government subpoena yet.



STEVE:  Well, and their concern was, see - okay.  So first of all, understand that both of these companies ran not really secure mail.



LEO:  Right.



STEVE:  And that's the crux of the problem.  In fact, that's what my blog posting made clear.  That's the point I had made the week before.  When we heard that Ed Snowden was using them, I thought - and that they were, oh, oh, secure mail, I thought, okay, what are they doing?  I went over, and as I reported on the podcast the week before, I was unimpressed.  They were doing mail at rest, they were doing, I'm sorry, encryption at rest storage, so that the email that they received unencrypted was then encrypted with the account's public key, and they only had access to the private key when the accountholder logged in.  But the fact was, when the accountholder logged in, then they would use the password to decrypt the private key, which would allow them to decrypt their mailbox, essentially, and then send it to them either secure or not.  Probably secure.  One would hope that the links to their server would be secure if they were promoting security.



But the point was, this was not actually secure mail.  This was encrypted storage.  But the nature of current email technology - and again, the point I made in my podcast was email is resistant to encryption.  We're going to be talking about overcoming that resistance in coming weeks here, as soon as, I mean, starting with next week when we talk about PGP and S/MIME and GnuPG and so forth, technologies for encrypting email.  But it is not easy.  Email resists it.  Which really is why it hasn't happened.  I mean, HTTP web browsing, that's all encrypted now, largely.  That's - the problem's been solved.  Not so for email, and we'll go into why.  But neither of these services were truly secure.  I mean, and so, unfortunately, I think Ladar painted a bull's-eye on himself for the NSA.



LEO:  Although he'd already been subpoenaed or something.  He couldn't say what, but he'd received, I would guess, a national...



STEVE:  About 10.



LEO:  Oh, he said 10.  And were they NSLs?  Did he say what they were?



STEVE:  Through the years he has responded to regular standard court orders.  And because, he says, I'm going to obey the law.



LEO:  I have to, yeah.



STEVE:  And if I'm given a court order for this data, I'm going to turn it over.



LEO:  Oh, so something different happened, then?



STEVE:  Yes, yes, yes.  This was probably overly broad, or maybe they wanted to install, like, now, see, his technology didn't allow him to decrypt what was there.  They may have come looking - oh, and by the way, this is about two weeks, wait, so two weeks or four weeks.  This had been going on for some time.  So this may very well have been related specifically to Snowden and that, where someone said we want this data.  And so whatever it was, he was made to feel uncomfortable at a level where previous court orders have never been a problem for him, but this caused him to say, I give up.  I cannot be complicit.



LEO:  Do you want to speculate?



STEVE:  I really can't.



LEO:  It would be rank speculation.  But...



STEVE:  Yeah, I can't.  I mean, we just...



LEO:  Okay.  So what we know is that the feds, it wasn't real security because the feds could just watch incoming and outgoing, and it would be unencrypted.



STEVE:  Correct.  And even - yes.  Well, and even there's one other little glitch here, and that is they could have said, when someone logs in, we want their decryption key.  Because when they log in, you get their decryption key.



LEO:  Oh.  You do?  Is that true?



STEVE:  Yes.  And that's the problem.



LEO:  Oh, they'd have to because otherwise he couldn't send the mail.



STEVE:  Right, right.



LEO:  Okay.



STEVE:  And so this was the weakness.  And this is why I said it wasn't - I think at the top of my blog posting I said something like - I put "nearly secure" or something in quotes.



LEO:  Yeah, and you told me that.  I told you last week, oh, I bought 10 years' worth of Lavabit.  And you said, well...



STEVE:  Yeah.



LEO:  Nice, but...



STEVE:  Okay.



LEO:  I also use GNU Privacy Tool, as we're going to talk about at some point, to protect...



STEVE:  So here was the problem.  Both of these organizations - email is store-and-forward, which means - and both of these, both Lavabit and Silent Circle had hundreds of thousands of customers.  I mean, they were ongoing, successful operations.  And but the fact that it's store-and-forward means that mail is coming in and being stored encrypted.  Then, when you connect up using POP or IMAP, your client is able to get this, decrypt the mail, for it to be sent to you.



The fact that both companies preemptively shut down, what that did was that meant they were in receipt of email that had not been picked up, and all they could do was say we're sorry.  And the Silent Circle people, they put their Navy SEALs on either side of the door, and they said, look, here's the problem.  If we were to announce that we are going to be shutting down, that window of opportunity would allow the federal government to come in and get our stuff.  They destroyed their servers at Silent Circle.  And so their customers have been inconvenienced and are complaining.  It's like, wait a minute, there was email that I had not picked up.  And they said, we know.



LEO:  That's the point.



STEVE:  Yes.  Yes, because if we had given...



LEO:  You and the NSA hadn't picked it up yet, yeah.



STEVE:  Exactly.  Exactly.



LEO:  Wow.



STEVE:  So, yeah.  Now, I thought about this.  I cogitated and ruminated for a while.  And I tweeted something that has been more retweeted than anything I have tweeted for a long time.  What I tweeted, and this might have been over the weekend, I said, "We can no longer safely delegate our security because our delegates may be compelled to secretly violate our trust."  Which I think very succinctly states the problem.  We can no longer safely delegate our security because our delegates may be compelled to secretly violate our trust.  I mean, and this is the problem with this whole situation we find ourselves in.



And this is what every, I mean, commercial companies are very upset.  I mean, Google is feeling this.  Microsoft and Yahoo! and these companies named in the PRISM slides are feeling really put upon.  And we discussed this last week because there was some commentary, I don't remember who it was, might have been Micro- was it Microsoft, where they were explaining how they're begging the federal government to let them say something, and the federal government says no.



Now, Bruce Schneier, our favorite cryptographer and smart guy, weighed in on this with - he covered, in his blog, the news of Lavabit's decision and had a nice little summary.  He said:  "This illustrates the difference between a business owned by a person, and a public corporation owned by shareholders.  Ladar Levison can decide to shutter Lavabit - a move that will personally cost him money - because he believes it's the right thing to do.  I applaud that decision," says Bruce, "but it's one he's only able to make because he doesn't have to answer to public shareholders.  Could you imagine what would happen if Mark Zuckerberg or Larry Page decided to shut down Facebook or Google rather than answer National Security Letters?  They couldn't."



LEO:  They can't.



STEVE:  "They would be fired."  He said:  "When small companies can no longer operate, it's another step in the consolidation of the surveillance society."  So, oh, and I want to make sure I don't fail to mention that Silent Circle itself is still an ongoing enterprise.  They have Silent Talk and Silent Chat.  It's only Silent Mail that they shuttered and that they shut down.  Lavabit's gone completely because all they offered was not-really-secure email.  Silent Circle also offered not-really-secure email, but their main two products, their main two offerings are end-to-end secure, TNO, PIE, all the good acronyms.  That stuff they did absolutely right because it's not - because they were able to build a standalone, truly secure solution.  This is the problem with email is it's got a huge compatibility problem because we're trying to add security to a fundamentally unsecure protocol.  They were able to, and anyone can, I mean, it's not difficult to do security right.



So I wanted to make sure we don't - I didn't miscommunicate that Silent Circle themselves are gone.  It's only their not-really-secure email solution.  And they were never really happy with it either.  They did it because people wanted it.  And they said, well, we really can't.  We can't.  And people said, yeah, well, do what you can.  And so do what you can is gone, and only the endpoint-to-endpoint correctly done solution is still up.  And they're in no danger at all.  Notice these guys shut this down preemptively.  They haven't needed to shut down the others because they absolutely know that it doesn't matter if the NSA comes knocking.  That's the way, if you design the system correctly, it doesn't matter.  And they did.



LEO:  I should, I mean, they had less to lose than Mr. Lavabit.  I mean, their main business was not this.  It was encrypted email, or IM and phone calls.



STEVE:  Yes.  His was entirely that.



LEO:  And they also said, unless they've said something since, that they had not received a government subpoena yet.  They were doing this preemptively.



STEVE:  Correct.  That's absolutely right.



LEO:  And I might point out it's excellent marketing.



STEVE:  Yes.



LEO:  Without much cost because this wasn't...



STEVE:  With or without...



LEO:  ...much of a business to begin with.



STEVE:  Now, I will also point out, Leo, as far as we know, Ladar...



LEO:  He's out of business.



STEVE:  He had no Navy SEALs, Leo.



LEO:  No.  And Ladar - and I respect Ladar because he - this wasn't a big business.  He said he was making something like 50 to 100,000 a year.  But it was his livelihood for 10 years.  And he's basically quitting the job and saying I can't do this job properly, thanks to the U.S. government, so I'm not going to do it at all.  And he's now going to have to find a job.  So that's a significant thing to do, and props to him.  And I at first was like, wait a minute, I just paid you for 10 years.  And then I said, well, you know, that's cool.  In fact, he has raised, what was it, $90,000 for his defense fund and needs more, I'm sure.



STEVE:  Yeah.  And they also said, well, you could do this somewhere else, as in a different country.  And he says, well, I live in Texas.  I like Texas.  I don't want to move.



LEO:  Yeah.  Real respect to him.  I'm not sure about the Silent Circle thing.  Their marketing has always been a little weird.  It does seem a little self-serving to say, hey, nobody's asked us, but just in case, we're going to shut this down.  And it's not a primary part of their business at all.  Right?



STEVE:  No.



LEO:  So, I mean, but the real message to everybody is that store-and-forward email is not - didn't Google just say don't expect privacy if you use Gmail?  They just said that.



STEVE:  Yeah.  And...



LEO:  And they're being honest because there isn't - it isn't private.



STEVE:  The other point that I will be making when we discuss email encryption is that, even then, you are encrypting what's in the envelope.  There is no way to encrypt the envelope itself.



LEO:  Right.  If you can't see the address, it's not going to get delivered.



STEVE:  Correct.  Which says that there will always be...



LEO:  Metadata there.



STEVE:  ...metadata leakage.  That's why Bitmessage is very interesting.  So don't any of our listeners think I'm not aware of Bitmessage.



LEO:  Oh, okay.



STEVE:  Bitmessage does not leak metadata.  It's a peer-to-peer network where you can send things to each other.  It is absolutely secure.  And there's no metadata leakage.  Now, I almost considered aborting the encrypted email discussion for this reason, because Bitmessage is interesting.  It looks very solid.  But I don't think that's practical, either.  I think we need to talk about the standards because there are, I mean, basically what PGP is and what S/MIME is, is a standard for encrypting email.  And it's certainly useful to understand it and have that as a tool in your toolbox.



But never fail to remember that it's just your - the fact that you're sending encrypted email will always be known.  There's no way to hide that.  But with Bitmessage, everybody gets everything.  It uses the Bitcoin blockchain technology.  So basically you're receiving the entire community's sendings, and your local client, in the privacy of your own computer, extracts that which is meant for you.  So nobody has any way of monitoring this.  It's very clever.  So we will of course be talking about that, as well.



LEO:  You know, I don't have anything to hide.  But I use PGP encryption.  I understand - I'm not sure how far I want to go.  I mean, so they get the metadata.  In my case it doesn't be a big deal.



STEVE:  Yeah, exactly.



LEO:  It's more a statement.  It's more a statement.



STEVE:  Yeah.  And I can certainly see, for example, between corporations and their law firms, corporations and their subcontractors, it's very - you could easily run across a situation where you need to send documents and files as email attachments encrypted to other people, not because you're planning anything nefarious, but because it's your company's private business.



LEO:  Privileged communications.  None of your business.



STEVE:  Yeah, and as I said, my favorite example that comes on this notion of people saying, well, why do you care about encryption if you have nothing to hide, is the webcam in the bathroom.  Somebody sent something, a tweet I saw that I appreciated.  He said, what I do in my email is boring and mundane.  And I said, yes, that's much like most people in the bathroom.  But still, who needs to see it?



LEO:  Exactly.  Exactly.



STEVE:  Not very interesting.



LEO:  Yeah, yeah.



STEVE:  So I mentioned, too, I mentioned last week that there had been a mention on ABC's "This Week With George Stephanopoulos" Sunday show that I had not had a chance by then to track down.  And that was the news that, in 2011, that the FISA Court itself had ruled that what it was being asked to do was unlawful and unconstitutional, and that that report had been suppressed.  Turns out...



LEO:  Yeah, this pissed me off.



STEVE:  That was on - yes, I remember it did.  This was October 3rd of 2011.  And David Corn, reporting for Mother Jones on June 11th, so just a couple months ago, in the wake of the Snowden revelations, he tracked this down.  His reporting said:  "In the midst of revelations that the government has conducted extensive top-secret surveillance operations to collect domestic phone records and Internet communications, the Justice Department was due to file a court motion Friday," so just recently, "in its effort to keep secret an 86-page court opinion" - this is the FISA Court opinion - "that determined that the government had violated the spirit of federal surveillance laws and engaged in unconstitutional spying."  So this is the Justice Department filing a court motion to keep this 86-page court opinion secret.



So David continues:  "This important case, all the more relevant in the wake of this week's disclosures" - oh, so this was just when this was happening - "was triggered after Sen. Ron Wyden, Oregon..."



LEO:  God bless him.



STEVE:  "...a member of the Senate Intelligence Committee, started crying foul in 2011 about U.S. government snooping.  As a member of the intelligence committee, he had learned about domestic surveillance activity affecting American citizens that he believed was improper.  He and Sen. Mark Udall of Colorado, another intelligence committee member, raised only vague warnings about this data collection because they could not reveal the details of the classified program that concerned them.  But in July 2012 Wyden was able to get the Office of the Director of National Intelligence to declassify two statements that he wanted to issue publicly.



They were, one, "On at least one occasion the Foreign Intelligence Surveillance Court held that some collection carried out pursuant to the Section 702 minimization procedures used by the government was unreasonable under the Fourth Amendment."  And, second, "I believe that the government's implementation of Section 702 of FISA [the Foreign Intelligence Surveillance Act] has sometimes circumvented the spirit of the law, and on at least one occasion the FISA Court has reached this same conclusion."  So at least that he was able to declassify last summer.  And that's different from and prior to this 86-page court opinion which apparently Justice is now trying to keep from having being made public.  So anyway, that's the details on what we heard two Sundays ago.  I just wanted to...



LEO:  I really don't understand why the government feels like this needs to be kept secret.  This doesn't need to be kept secret.  And frankly, in this case, secrecy is being used to hide incompetence, malfeasance.  There's no reason to keep this secret.  You're not - this doesn't protect us against terrorists, to keep this secret.



STEVE:  Yes.  Yes.  It's like them classifying the number, the integer number of plots that have been foiled.  They said, oh, that's classified.  What, because it's two?  Or because it's 200?



LEO:  It's embarrassing, probably.



STEVE:  It's ridic- probably is, yes, unfortunately.  But, yeah, you're right.



LEO:  I understand that there's some things you have to keep secret because you have to protect the means and methods so that the terrorists can't use counter methods.  That's understandable and fine.  That's not what this is.



STEVE:  Well, there's an old joke, Leo, in business.  Never ask your attorney if you can do something.



LEO:  Right, because they'll say no, yeah.



STEVE:  They say no.  I mean, that's the safe answer.  No.



LEO:  Yeah, no, it's a bunch of - use a bunch of attorneys, yeah.



STEVE:  Never ask your attorney.  Well, no, but my point is, why not just stamp everything with "Top Secret"?  Why, I mean, the point is, if you have the ability to declare things top secret, and you've got a big stamp...



LEO:  Might as well.



STEVE:  Why not?



LEO:  Why not?



STEVE:  Yeah, what's the danger?



LEO:  I'll tell you why not.  Because we live in a republic where it is important that the people who are governed have the right to weigh in on what we're doing because it's in our name.  It's in our name.



STEVE:  We're paying for it, yes.



LEO:  We're more than paying for it.  They're representing us.  And I have to point out, at least we can still talk about this freely and openly without consequence.



STEVE:  Yeah.



LEO:  Nobody's hauling you or me off to jail.  We are not in a gulag situation.  But nevertheless, the amount of secrecy that is being employed by our elected representatives and, worse, unelected bureaucrats, is not acceptable.  And I applaud Ron Wyden for doing what he can.  But we've got to go a lot farther here.  This is not okay.



STEVE:  Well, and the good news is it's been opened.  And a lot of people are now looking at this very closely.  And many people were surprised.  This was a rude awakening, not just to the public, but to our lawmakers.



LEO:  Yeah.  President Obama said, well, I wasn't going to do this so fast.  I was going to do it.  Sounds like a six year old.  No, really, I was going to do this.



STEVE:  That was an unimpressive - that was an unimpressive press conference.



LEO:  Well, there were things to be gained from it.  For instance, he acknowledged we have an unprecedented ability to collect this information.  That's a real acknowledgment.  That's saying...



STEVE:  Because the growth of technology has now created this facility.



LEO:  That's really, in a way, going farther than we've gone before, to admit we can do it.  And he said they're going to try - unfortunately, it's General Clapper that's choosing the members of the commission.



STEVE:  Oh.



LEO:  The last guy you'd want to do this since he lied to Congress last spring.



STEVE:  James Clapper, yup.



LEO:  But at least they're going to appoint a commission, and one hopes there'll be some work done in this direction.  It's very disappointing.



STEVE:  Well, bottom line is we know.  And we may have known or worried, I mean, it's funny, one of the questions, I think it was that same question, where someone said, Steve, how did you know?  It's like, I didn't really know.  I just knew that the idea - I was worried about bad guys, not our government.  And that's where TNO and PIE came from.  I wasn't worried about our government.  Now it's really worrisome.



So a little mistake surfaced in Android's random number generator.



LEO:  Oh, yeah.  Oh, yeah.  This is not the first time random number generators have been blamed.



STEVE:  Oh, and our listeners who have been following the podcast, any of you who've managed to survive eight years, how many times have we talked about this?  I mean, remember, this is why I spent all that time on the so-called "ultra high entropy pseudorandom number generator."  Remember that Netscape's first SSL implementation, SSL 1.0, it was immediately in trouble because it was generating bad random numbers.



Crypto absolutely needs randomness.  It absolutely does.  Anytime you have a communication, you are generating, you are encrypting that communication using symmetric encryption and a random key.  Then you're often using - you're either keeping that key secret, or you are encrypting the key, the hopefully random key, with asymmetric encryption because you can't afford asymmetric encryption, too slow to encrypt the whole thing.  So you absolutely have to have good random numbers.  And you absolutely never want to use the same one again because, if nothing else, bad guys could be capturing all the ones you've generated and just trying them.  That's better than trying them all.  Capture the ones that you've already used.  Maybe you'll use it again.



Well, guess what?  Android does.  It actually generates identical, not just weak, not just poor, not just not all 256 bits are random, but all of them are the same.  None of the bits are random.  So it turns out that a weakness was discovered quite a while ago, back in Christmas of 2012.  On December 25th, Nils Schneider discovered a problem which affected some implementations of Bitcoin.  And it's not exactly clear how this took eight months to sort of sift out and finally get attention.  But on the Bitcoin.org site, they blogged on the 11th, so three days ago:  "We recently learned that a component of Android responsible for generating secure random numbers contains critical weaknesses."



Okay, now, that's like saying, well, I don't know, I don't have a good analogy prepared.  But that's ridiculous.  It's actually generating duplicate random numbers.  Okay, "...contains critical weaknesses" - certainly that's true, at least - "that render all Android wallets generated to date vulnerable to theft."  And I'm going to explain exactly how vulnerable in a second.  But they say:  "Because the problem lies with Android itself, this problem will affect you if you have a wallet generated by any Android app."



LEO:  That's the sad thing.  Any.



STEVE:  Yes.



LEO:  None of them do it right.



STEVE:  Well, because they're all using...



LEO:  They're all dependent on the...



STEVE:  ...the Android, give me a random number please, function.



LEO:  Although that was a mistake, clearly.



STEVE:  It just gave them the same one.  "An incomplete list would be Bitcoin Wallet, blockchain.info wallet, BitcoinSpinner and Mycelium Wallet.  Apps where you don't control the private keys at all are not affected."  That is, where you've provided a private key from somewhere else, rather than it being something that the wallet generated.  "For example, exchange frontends like the Coinbase or Mt. Gox apps are not impacted by this issue because the private keys are not generated on your Android phone."



LEO:  Now, I'm using, I mean, we use Bitcoin wallets on Windows and Mac, which use their - I don't know what [indiscernible] they use.  Are those okay?



STEVE:  Yeah.  And the good news is those are so well vetted that, well, early, early Windows had some random number generator problems.  But Microsoft understood that and fixed it.  So, and Mac I don't think ever had any problems because they came from UNIX, and the UNIX guys figured this out a long time ago.  So Nils explains.  What's the problem?  Bitcoin uses Elliptic Curve DSA, Digital Signature Algorithm.  Elliptic Curve DSA, ECDSA, requires a random number for each signature.  If this random number is ever used twice with the same private key, that private key can be recovered.  So all it takes is the mistake of ever using the same random number twice.



He says in his blog, where he explains this:  "This transaction was generated by a hardware Bitcoin wallet using a pseudorandom number generator that was returning the same," and he has in quotes, "'random' number every time."  It's just - it was - it couldn't have been written into the code, here, this is a lot of random bits, just only ask for it once.  No.  Can't be the case.



So what Nils did was he examined the Bitcoin blockchain, and he discovered a few vulnerable Bitcoin addresses.  After some research, because we know that the blockchain has an anonymity problem, it's possible to de-anonymize in some instances, after some research he says he was able to contact the owner of those vulnerable addresses.  And he said, "He allowed me to spend the funds."  So back last Christmas Nils knew of this problem, analyzed the blockchain, found a weak wallet, tracked down the user, and with that owner's permission, took the money from his wallet.



LEO:  Wow.



STEVE:  So...



LEO:  Wow.



STEVE:  That cool?



LEO:  You know, I installed a Bitcoin wallet on Android when I first set up Bitcoin, and we have about seven - thank you to everybody anonymously who's donated bitcoin to TWiT.  We have a bitcoin donation QR code and number on the front page, and we've got about seven bitcoins, which is, what, 750 bucks, something like that.



STEVE:  Wow, cool.



LEO:  Yeah.  And I did set up a Bitcoin wallet on Android.  But fortunately it crashed.  It force closed so often, I just said, well, this isn't working, and I erased it.



STEVE:  Our first clue.



LEO:  Thank God I never got it tied into my account.  Yeah, that was a clue.  That was a good, you know, okay.



STEVE:  So it is possible now, you want to update Android to make sure that this problem is fixed.  So verify that you've got a version where it is.



LEO:  Oh, interesting.  So they have fixed it in later versions.



STEVE:  And you can rotate the keys, then.  And in fact this blog posting goes on to talk about specific implementations.  And you can just - you can regenerate keys, and then you'll be okay again.  So, although, really, I wouldn't put a lot of money in a mobile platform wallet.  Maybe have an account there where it's your play money.  But if you've got serious bitcoinage, you just don't want it on a mobile platform.  It's true, all of these platforms are at risk.  This podcast covers that constantly.  But mobile is really just more at risk.



LEO:  Yeah.



STEVE:  So I would be - I'd just put - don't have the keys to all of your coinage on a mobile platform.  I mean, really, just move over play money over there.



Okay, now, this was really interesting.  There are security experts who now believe, based on the statistics they are seeing - 236 days remaining until XP is no longer updated.  Hackers are believed to now be saving XP exploits for after that curtain drops because Microsoft will then no longer patch XP.  So what's happened is the cat-and-mouse game we were talking about, the find a problem - the value of an exploit is a function of how long it's able to be used before it's discovered and then patched and closed.  So there's this game of new vulnerability found.  You really want to keep a low profile.



It's like the FBI, who apparently have ways of getting spyware into people's machines.  But it's very rare that they will do something as high profile with that as they did with Tor recently, where they basically let something go that was quickly found, but there was a window of about three days during which anybody who got infected probably got a knock on the door from the FBI.  Normally you want to keep these things on the QT so that they're not widely exploited.  So they're using phishing attacks, limited attacks, rather than huge sprays.  So you can see the advantage if there are vulnerabilities in XP.  The fact is XP's deployment, I think we're still at 43% was the number I just saw.



LEO:  Isn't that amazing?



STEVE:  Corporations do not want to move because it's expensive.  Microsoft just doesn't give away Windows 7.



LEO:  And XP works.



STEVE:  And it works.  That's exactly the point.



LEO:  Why replace something that works?



STEVE:  Works just fine.  So the problem is that, come 236 days from now, I've got my little counter over on my Win7 machine telling me how many days left of XP, Microsoft won't fix these anymore.  And so the bad guys are now building up a stockpile because, at that point, I mean, and Microsoft really doesn't go back and fix anymore.



LEO:  So they're not - but, now, they'll have to be new flaws, not, I mean, they've fixed everything to date.



STEVE:  Yes, they are, well, they fix everything they...



LEO:  So it'll be newly discovered flaws.



STEVE:  Yes.  They fix what they know.  And, again, you can see Microsoft saying, well, that'll get them off of XP.  It gets...



LEO:  Yeah, that's too bad.



STEVE:  It keeps reminding people.  It is too bad.  But unfortunately it's not safe.  I wanted to quickly mention GRC's cookie forensics page.  Many people responded, too many for me to talk about in the Q&A, who never knew about my little cookie forensics.  And many of them thought, well, they were surprised by what their browsers were doing.



One person posted in the newsgroups, so I saw that.  He wrote, he said, "I deleted cookies using IE10," so he's on IE10, "the gear icon, safety, delete browsing history, and then checked delete cookies, and restarted IE10.  With first-party cookies accepted and third-party cookies blocked, the checkcookie page flags problems only for third-party session and third-party persistent cookies of type icon, embed, and object.  Checkcookie color codes these all blue as browser leakage bug."  And I responded to that posting, I said, "Wow, that's still there?  Amazing."  And I said, "I recall that it was due to IE that I added those tests."  It's impossible, it turns out, to keep Internet Explorer from transacting third-party cookies if they're added to those non-page items, which is easily done."  And I finished just by saying, "Incredible."



So this is IE, where you have explicitly turned off third-party cookies, and you haven't.  Because it turns out, remember that many things are fetched by the browser, not just JPGs and images and JavaScript and so forth, but the favicon is the little thing, the icon in your URL that many sites customize.  Google's got the little colorful thing.  GRC has got the little ruby G icon.  You probably have one, Leo, for TWiT.



LEO:  I do.  It's my head.  Well, TWiT is the TWiT logo and then on Leoville it's my head.



STEVE:  And it turns out that, since the browser is querying that, you can respond to that query for a favicon with a cookie, and IE will start sending that cookie back.



LEO:  Oh, that's good to know [laughing].



STEVE:  Well, yes.  And the embed, the embed tag and the object tag, all three of those you cannot shut down, no matter what you do.  And we discovered this years ago when I did the cookie forensics.  And I think I saw it somewhere, so I thought of everything possible that I could test cookies on, and then that's why there's, like, eight different little bubbles in the cookie forensics page.  Anyway, once again, if I've convinced people they ought to go check, I created a shortcut because I still don't have this linked on GRC's main menu:  bit.ly/checkcookie, all lowercase, c-h-e-c-k-c-o-o-k-i-e.  And our browsers are broken.  I mean, even today.  And my plan was to use these to force the vendors of browsers to clean up their acts, and I just never got around to it, so.



Okay, now, Leo, you've got a 15-second YouTube video.  This just surfaced while I was pulling things together.  I have not had a chance to test it scientifically.  People are skeptical.  It's just wacky.  But it's just too fun not to share.  And that's what this podcast is for.



LEO:  Here we go.  Is it supposed to look like that?



STEVE:  Yeah, in the beginning.



LEO:  Oh, okay.



[CLIP] MALE VOICE:  The best way to test it is with a meter.



LEO:  Oh, let me rewind so we can get the audio here.



[CLIP] MALE VOICE:  Everybody has batteries in many different kinds of devices.  And sometimes it's useful to know if a battery is good or bad.  Of course the best way to test it is with a meter.  But not everybody has a meter, and you don't always have one handy.  We're going to how you a simple test, in seconds, to determine if a battery is good or bad.



LEO:  Great Baltimore accent here, by the way.



[CLIP] MALE VOICE:  Here are two batteries.  The Energizer is good.  Alkaline batteries are rated for 1.5V, and this one is brand new.  It's showing 1.65.  That's excellent.  The Duracell is showing 1.2, and as soon as it gets any load on it, it goes less than that.  Believe me, it's beat.  Without a meter, how can we tell the difference?  With a simple bounce test.  A good battery will not bounce, and it will land with a thud and frequently stand up.  A bad battery will take several bounces and usually fall over.



LEO:  Huh.



[CLIP] MALE VOICE:  It works for all kinds of alkaline batteries...



LEO:  That's really interesting.



[CLIP] MALE VOICE:  ...AAA, AA, C, or D.  And we don't know exactly why it works, but it probably has to do with the chance of density of the material.  In any case, it always works, and it works like a charm.



LEO:  That is a great hack.



[CLIP] MALE VOICE:  Good luck testing your batteries.



LEO:  Oh, wow.



STEVE:  Isn't that fantastic? 



LEO:  That's bajarider1000, if you want to watch the video yourself, bajarider1000 on YouTube.  With a great Baltimore - Balmore accent there.  Nice mid-Atlantic accent.  That's really interesting.



STEVE:  Okay.  So, now, several people sent back to me, because I tweeted this, so if anyone wants to find it, you can also check @SGgrc's, my Twitter stream, and you'll see the link, and I go, WHAT?!?!?! and so forth.  They said, wait a minute.  He's got two different brands of battery.  Now, that's true.  So if you were to do this scientifically, you'd get a couple fresh of each, drain one of each, and then do bounce tests.  Although someone named Jesse Madonna sent back, he said, Steve, have you tried it?  I have access to a multimeter, and this bouncing test works.



LEO:  Wow.



STEVE:  So anyway, if it's true, fabulous hack.  And remember, the way you remember it is you want to - the battery that bounces, you bounce out of your remote control.



LEO:  Bounce the battery that bounces.



STEVE:  Bounce the battery that bounces.  So, wow.



LEO:  Wow.  That is really interesting.



STEVE:  I love it.  So, "Elysium."



LEO:  You saw it.



STEVE:  Disappointed.



LEO:  Aw.  Yeah, I think a lot of people were.



STEVE:  Yeah.  It's - and when I tweeted that, which I did yesterday, or, no, Monday, many people said, did you like "District 9"?  Because we all know that "Elysium" was made by the same guy.



LEO:  Neil Blomkamp, yeah.



STEVE:  Loved "District 9."



LEO:  As did I.



STEVE:  Oh, my god.  "District 9" was so fun and new and fresh and original, and also in some ways ridiculously over the top, like with the power of the alien guns.  It was fantastic.  "Elysium" had none of that.  It had a ridiculous cartoon character bad guy, Kruger, that just...



LEO:  I liked him.  He was really bad.



STEVE:  Oh, Leo.



LEO:  It's more of an action film than "District 9" was.



STEVE:  Okay, well, so you're welcome to like it.  I was very disappointed.



LEO:  I will tell you...



STEVE:  But I didn't have high hopes.



LEO:  ...my ratings I gave on NSFW last night, I thought an A for "District 9" and a B/B+ for "Elysium."  Not as good as, but not horrible.  Now, I saw it in the third row of an IMAX theater, so it was a big film.



STEVE:  Yeah.  I did want to mention that one of my favorite movies of the summer just came out on disk, and that's "Olympus Has Fallen."



LEO:  Really.  You liked that.



STEVE:  Yeah.  It may have been the first one that Jenny and I saw at the beginning of the summer movie season.



LEO:  That was the one about the White House being invaded or something, yeah.



STEVE:  Yes.  Yes, standard, straight-up action flick.  I thought it was fun.  And when I staggered from the theater, I immediately tweeted that I was still breathless after 10 minutes.  I mean, that was - I thought it was great.  And I do want to mention, finally, that I have discovered "Breaking Bad."



LEO:  Well, it's about time.



STEVE:  I know.  I know.



LEO:  Last season, dude.



STEVE:  There was so much noise about the start of Season 6.  And the gal that used to cut my hair was talking about it five years ago.  She said, oh, Steve, are you watching "Breaking Bad"?  So she induced me to, like, get the first season.  And I think I watched the first two episodes, and he was wandering around in his underwear in the desert, in his RV, and I thought, no, okay, I don't think this is for me.  But, oh, my goodness.  And so it's my - sort of my background when there's nothing else to watch.  And actually we're sort of in a dry spell at the moment before - the good stuff is over, and...



LEO:  "Homeland" is coming back, you know.



STEVE:  Oh, good, good, good.  So there are a few things.  I do like "The Network."  I know that you're not a fan of that.  But I do like that.  And as I said, I'm struggling to make myself keep watching "Dexter."



LEO:  You mean "Newsroom"?



STEVE:  I'm sorry, yes, "Newsroom."



LEO:  Okay.  It does harken back a little bit to "Network," the movie, where "I'm mad as hell, and I'm not going to take it anymore."



STEVE:  So anyway, "Breaking Bad," I just wanted to mention that, yeah, okay, I'm finally up to speed on it.



LEO:  How far - you watched all five previous seasons?



STEVE:  No, no, no, no, no.  I think I'm somewhere in the middle of, like, Season 3.  He's now struggling with his wife, who has found out.



LEO:  The dude gets wilder and wilder.



STEVE:  It's just - it's just - I finally understand that nothing, apparently nothing really big is going to happen.  It's just the story of these two...



LEO:  A few big things might happen.



STEVE:  Okay.



LEO:  Stay tuned.



STEVE:  Anyway, I'm really having fun.



LEO:  Stay tuned.



STEVE:  I'm really - I'm going - oh, and one thing that happened was, that had me thinking of this whole NSA nonsense, is I wanted - I was very curious to know about fulminate of mercury because I'd sort of heard...



LEO:  Right, contact explosive.



STEVE:  I was afraid to Google it.



LEO:  Yeah, you're right.



STEVE:  Because, you know?



LEO:  But you can.  And there's good recipes online.  We used to use it in college because it's a kind of nondestructive - by the way, there is an article I just read on the science of "Breaking Bad."  And the amount of fulminate of mercury that he got out of, what was it, I can't remember what he made it out of, was unrealistic.  The amount he had in his hand, unrealistic.  And it would have gone off in his pants long before he got to use it.  So it is, it's a contact explosive which, when wet, does not explode, but as soon as it's dry will explode on contact.  So we used to make it in college and paint it on the floor, and then ring a loud bell.  And when my roommate got up and put his feet on the floor, it'd go pow pow pow pow pow.  And he'd dance all the way out of the room.  Great fun.



STEVE:  You remember that, yeah.



LEO:  Easy to make.



STEVE:  I think ammonia's involved.



LEO:  Standard household chemicals.



STEVE:  And the ammonia dissolves, and it dries, and...



LEO:  Yeah.  I don't recommend, by the way, in any form or fashion.  I did not make it.  It was one of my roommates.  I just watched the results.



STEVE:  Those chemistry majors were fun to have around.



LEO:  They're fun to have around.  And I don't know what "MythBusters" did or did not do.  Apparently they tried it, it didn't work.  But you know what, it's real.



STEVE:  Oh, it definitely works.



LEO:  You don't want to carry it in your pants.



STEVE:  We were playing with it at Berkeley, Leo.  It, yeah...



LEO:  All right.  So, Burke, did you try this experiment?  And he bounced the batteries, and...



BURKE:  [Indiscernible].



LEO:  And you can tell whether they're good or bad based on the bouncing?  Now, you have to do it on a hard surface; right?  I'll do it on the clipboard.



STEVE:  Oh, cool.  So we have some initial anecdotal evidence.



LEO:  Well, I'm not very good at this.  Lower?  Okay, that's got to be bad because I could not get that to stand up.  It's like that high; right?  The bounce that counts.  That one's good.  Right?  Didn't stay standing up, but I don't know.



STEVE:  No, it's not - it doesn't have to stand up.  It's just the bounce.



LEO:  This bounced a lot; right?  So it's how much it bounces; right?  That's kind of more heavy.  I bet you could weigh these.  You think?  I don't - give up.  It's silly.  Okay.  On with the show.  We don't have time for this.



STEVE:  [Laughing] Okay.  So if you've got that PNG file, Leo...



LEO:  I do, indeed.  In a font I haven't seen in many moons.



STEVE:  The people who are looking at video are seeing a screen that many testers of the SpinRite research are seeing.  This is where we are at the moment.  We just discovered yesterday that I think four people or four machines out of maybe more than a hundred, in one particular point in the code, have interrupts disabled where they never should.  So I finally figured that out.  We solved a problem that had been dogging us.



That screen that you're looking at is where I am in sort of starting from first principles of a machine and figuring out what's on the PCI bus, what's the BIOS showing, what controllers do we have that we're able to talk to directly because SpinRite will be directly interacting with the hardware at a level much lower, at the lowest possible level, for the first time.  We've had some very hopeful results, by the way, with MacBook Air and Mac Minis because the older ones at least are running in the non-AHCI mode that SpinRite, the initial version of SpinRite, 6.1, is being developed to operate with.  So it's going to be screamingly fast.



People have been successfully booting SpinRite on their Mac, I'm sorry, booting the test code, because SpinRite still doesn't run, of course, because of the keyboard problem.  The older Macs that have optical disks, we're able to boot, not with USB because Apple didn't put USB BIOS support in those.  But they've got optical disks, so you can burn a disk and then boot SpinRite that way.  The ones without optical disks do have USB BIOS support, and we are booting all, you know, FreeDOS, the GRC version of FreeDOS 1.1, on USB sticks, like everybody's doing it now who is working in our test group.  So that problem's been solved at that level.  I'll be turning my attention to that as the next thing we do.



But the next piece of work, which I'll start after the podcast, since everything to date, we've just finished with the 10th release of SpinTest, and we now know what everybody's got.  We're detecting everybody's hard drives, no machines are hanging, and we're moving forward.  So anyway, it's coming along beautifully.



LEO:  I love that.  I love it when a plan comes together.  All right.  We do have questions.  We're also running out of time.  I should mention Bruce Schneier is joining us on TWiG, and he only has an hour, so we're going to get through as many questions as we can in the time left.  Steve, I have questions.



STEVE:  Yes.  Let's skip the first one because I've already referred to that throughout the show, essentially, and we've got 10 minutes before Bruce is going to be on the line.  And that still gives us an hour and a half podcast, so we'll do what we can.



LEO:  We'll get going here.  We'll get going.  No. 2 from Darren Mills, Albuquerque, New Mexico, home of "Breaking Bad."  He says he finally gets why Steve was spooked by the spooks:  Insert regular, but deeply sincere, podcast and SpinRite praise here.  That's what he says, with little brackets.  When the news broke of Lavabit's decision to throw in the towel and completely shut down after 10 years, my first thought was of your upsetting decision several years ago to suspend work on CryptoLink because you said you saw the handwriting on the wall.  I was and have continued to be upset that we weren't going to get a Gibsonian VPN solution because I knew it would be the best thing ever created and blow everything else away.  But now I get why you were spooked by the spooks.



You recently said you might create CryptoLink anyway, not as a commercial product, but as freeware, if you had the chance.  I guess you still want it, and I know I still want it.  I always will.  So please get what you need to get done on SpinRite.  Then I sincerely hope you will again think seriously about giving the world CryptoLink.  We need it more than ever.  I'd pay a lot to have it, even though I know maybe that's not why you would be doing it.



STEVE:  So I only - I saw this, and that triggered many similar comments that I've seen in Twitter and in the mailbag saying, okay, Steve, now I get it.  And CryptoLink would have been TNO.  It will be, if I ever get around to creating it.  So there isn't the concern that I could be forced to be complicit in spying.  My worry still is that the other shoe hasn't dropped, and that we might be seeing a regime where anyone selling an encryption product is forced to add a backdoor.  That I will never do.  But if it's not being sold, if it's freeware, then I don't think there's any such way of being compelled.  So...



LEO:  Would you do it in open source, as well?



STEVE:  Yeah.



LEO:  Yeah.  I think you have to.



STEVE:  Yeah.  I agree.



LEO:  That's the only way you can be sure there's no backdoor.



STEVE:  Yeah.  And I would just do it, always knowing that it's going to be free, that it's not going to be another commer- I was thinking of it as this will be the next thing I do after SpinRite.  It's like, eh, I'm getting old.  I'll just do CryptoLink.  I'll make it free.



LEO:  I'm getting old.  You know, you give away so much stuff.  I would never demand more free stuff from you.  But if you want to do it, I think it would be very valuable.



STEVE:  Yeah.  It was going to be so much - I did so much planning and early work on it, and I got very excited because it was just going to be so simple to use.  So...



LEO:  Oh, well.



STEVE:  We'll see how it goes.



LEO:  We'll see.  Dave Redekop, London, Ontario, Canada wonders about GRC and TLS in SMTP.  And if you've been listening to this show for any length of time, you know exactly what he's talking about.  I love this show.  Steve, your show has become so important in IT, I'm setting aside time weekly to listen LIVE.  I know this is what Leo wants, and it's working.  Quick question:  Why do you not support SMTP TLS (encrypted SMTP email) on your own server?  EOL.



STEVE:  You know that David was part of the core team, and probably still is, with our very early Security Now! sponsor, the group...



LEO:  I knew I knew that name.  Astaro.



STEVE:  Nerds on - Nerds on...



LEO:  Or Nerds On Site.



STEVE:  Nerds On Site up in Canada, yeah.



LEO:  I knew I knew that name.  David, nice to see you again.  That's great.



STEVE:  So GRC, absolutely - so what David is saying is that we're not supporting TLS in SMTP.  Meaning that our email server does not support encrypted connections to other email servers.  And he's right.  And I wish it did.  But it doesn't.  I'm using the product called hMailServer, which is extremely good.  When I went to choose a mail server, I did a lot of looking around because that was just this holiday season that I built the brand new Server 2008 machines and moved everything and fixed all the problems and so forth.  And I scrapped the old Ipswitch IMail Server and got this one.  But it does not support TLS in SMTP.  I hope someday they do.  When they do, I will definitely upgrade.



We do, however, support SSL connections for us.  So, for example, all GRC employees connect over SSL to that server.  So if I'm sending something to Sue, it is never in the clear.  Or if Greg and I are exchanging things, or Greg and Sue, or vice versa.  So for our own email, where it never leaves that server, we're a hundred percent encrypted.  And many, it turns out many SMTP servers offer SSL connections on alternative ports.  The whole idea with this negotiated encryption is you establish a non-encrypted connection over port 25; then, if the servers both agree, they bring up an encryption tunnel over the existing connection.  But, for example, SMTP defines port 465 for SSL and 995 for POP over SSL.  So there are alternative ports where you can connect to your mail servers using SSL for encryption there.  But the problem is, even if we did support STARTTLS, the other end would have to support it.  We know that that's rare.  Again, I would like to support it if we could.  And we will as soon as we can.



LEO:  I'm going to skip ahead a little bit to Will Farrell in Canada.  Not the Will Ferrell.  But also Tyler in Humble, Texas.  Both of them raise an issue that people keep raising with me.  And I want you to address this.  We've talked about Mailvelope, which is a Gmail extension for using PGP key signing and encryption.  And both of them point to Hak5 episodes.  They've done two of them in which they say that it's insecure, how Mailvelope stores your private key in plaintext in its plugin directory.  Since that episode it's been patched four times - this is Tyler in Humble, Texas writing - so one hopes it's safer now.  The first link gives a brief intro, blah blah blah.  He's pointing at the Hak5 shows on Revision 3.  Longtime listener, first-time writer.  So what do you think?  You've, I presumed, looked at those shows now.



STEVE:  Yes.  I chose this because it allows me to make the point that you still absolutely have to secure the endpoint.  So, yes, endpoint-to-endpoint security means that, from the moment it leaves, it is secure.  It is secure in transit.  It's secure if it's being stored any number of times.  It's secure if the NSA gets a copy of it.  And then it finally gets sent on to its destination.  Only when it gets there is it decrypted.  But it is decrypted at that end.  And it is not encrypted before it's encrypted at the sending end.



The point is the endpoints must remain secure.  That's why earlier I was saying I would not have bitcoin, all my bitcoinage on a mobile platform bitcoin wallet because the mobile platforms are still immature from a security standpoint, and they just have a great, a very high level of exposure to potential threats, just based on the history of the problems that we've seen them having.  So we'll end the podcast by just...



LEO:  We don't have to end it.  We don't have to end it.  We've got a few more minutes.  I want to go a little longer.  I do want to say, though, this is the issue of somebody has physical access to your computer, you've got a problem.  I store in fact my private keys on my computer, where if you had access to it, you could export it and take it home with you.  But the private key is further secured by a passphrase. 



STEVE:  Yes.  It is absolutely dumb that something that's all about security, like Mailvelope, would ever have not been storing those private keys encrypted in its own directory that it has control of.



LEO:  It doesn't matter.  It doesn't matter.  If you got to my computer, you could open my keychain and export an ASCII version of my private key.  You could also get it from my Dropbox.  Please, feel free to hack my Dropbox.  It's secured by my hand with a long, very random passphrase.  Of course you want to keep the private key secure.  But if somebody has access to your computer, it matters not...



STEVE:  Well, and that's my point.



LEO:  ...whether Mailvelope is storing it encrypted or not encrypted.  If you're using a keychain, it can be exported.



STEVE:  A good solution, which we discussed somewhere in here, is using the LastPass secure storage as opposed to Dropbox because you do have to provide encryption for your stuff if it's going to be in Dropbox because we know that Dropbox's encryption is not TNO.



LEO:  I just exported my secret key as ASCII in literally three seconds.  So if somebody had access to my computer, they could just open the keychain, export it out.



STEVE:  Yup.



LEO:  And put it on a USB key.  I don't worry about it because you have a good passphrase.  So I think this - I don't - I think this is BS.  This is another one of those, huh-huh-huh.  If somebody has physical access to your computer, you're screwed.



STEVE:  No.  Because there's no reason not to encrypt its private directory if you have to log into the plugin in order to use it.  You have to authenticate to the plugin.  So assuming that you could log out of the...



LEO:  Okay, but I'm just saying, GPG keychain access is an app you can run and export my key.  Is that broken?  Because that's what it does.  So does PGP, by the way.  You can export keys.  The point is...



STEVE:  Oh, I see the problem.  We're talking about different things, Leo.  Mailvelope maintains its own store, which is not part of the Mac keychain.



LEO:  No, I understand.  Yeah, but I'm...



STEVE:  And the Mac is protecting...



LEO:  No.  No Mac keychain is protecting PGP.  This is an app that runs normally.  It does not require a login.  You have to get into my computer, of course.



STEVE:  You're saying Mailvelope does not require a login?



LEO:  No, this is GPG, GNU Privacy Guard.



STEVE:  Okay, that's...



LEO:  Same thing with PGP.  You can always export an ASCII private key, which can then be put - mailed to somebody or saved.  You can always do that.  If you use PGP, this is something you can always do.  You've always been able to do this.  Just like Mailvelope does it, so does PGP, so does GNU Privacy Guard.  So if you have physical access to my computer - but that key is worthless without my passphrase.  You understand that; right?  It cannot unencrypt mail without my passphrase.  Do you see what I'm saying?



STEVE:  [Indiscernible].



LEO:  In other words, Mailvelope's doing it like every other PGP tool does it.  If you install PGP, you get a keychain program which has all your keys, private and public.  I can go to my secret key, export it as an ASCII file.  It's the same thing you're getting from Mailvelope.  But it's still no good because you need my passphrase to continue to unlock.  Is that not true?



STEVE:  Mailvelope has a private directory of keys.  And there's no reason for it not to encrypt that when...



LEO:  Okay.  It's the same - it's this Chrome story again. 



STEVE:  Precisely.



LEO:  No other PGP program does that.  And it's the same with Mailvelope.  You can have my private key.  Without my passphrase, it's no good to you.  Every time I use Mailvelope I have to enter my passphrase.  Right?



STEVE:  Right, right.



LEO:  So admittedly, you should secure your private key, and you have on your personal computer.  This is why you have to have a login, and that it's just not sitting in the open for people to use.



STEVE:  Right.



LEO:  But GPG and PGP both do the same thing.  And I don't think they're insecure.



STEVE:  As part of the protocol.



LEO:  Well...



STEVE:  No, no, no, I'm agreeing with you, Leo.  As part of the protocol...



LEO:  You need a passphrase.



STEVE:  ...in order to use the private key...



LEO:  That's right.



STEVE:  ...at the time you need to use the passphrase. 



LEO:  Yes.



STEVE:  So you don't want to spread your private keys around, but neither is it the end of the world if it gets loose.



LEO:  Exactly.  And it is kind of general practice with GPG tools that you can export your private key in an armored ASCII file or text file.  And that's because the - and you don't want to give it to people, obviously.  But if somebody has access to your machine, and you're using any PGP solution, they can do it easily.



STEVE:  Then, right.  But it does...



LEO:  And that's what Mailvelope does; right?



STEVE:  It doesn't give them anything because they still have to have access to your usage key.



LEO:  Exactly.  So that's it.



STEVE:  Yup.  We were talking about the same thing.



LEO:  Same thing.  It's much like the Chrome story.  And I agree that Chrome probably should password-protect the password storage just to make it - and if Mailvelope wanted to go the extra mile and password or encrypt their store, that would be a good thing.  But it all is presupposing that someone has physical access to your computer.  And as Google pointed out...



STEVE:  Which is where we began, is...



LEO:  You're screwed, if that's the case.



STEVE:  If you don't have that.  Now, I did want to mention, finally, that the most recent decision we have seen from the appellate courts, and I think this was the  Eleventh Circuit Court, I'm not sure, one of the appellate courts, and we talked about it at the time, and this is somewhere where the law is still really gray, and that is, can an individual be legally compelled to produce their password.  And the good news is, the most recent decision is no, that the courts have decided, they've ruled that that is tantamount to something you know.  It is in your brain.  And you cannot be compelled to testify against yourself.  That's Fifth Amendment protection.



So knowing the password, my point is that ultimately, if you want to protect your machine, you use TrueCrypt, and you may have a password that is where part of it is written down, but then you also know part of it.  The point is, it's got to be something that requires testimony from you, and the law cannot compel you, currently, to produce that.



LEO:  Right.  And you know, though, I'm sorry, I'm not heated with you, by the way.  I'm a little mad at Hak5 because I get this a lot, Mailvelope's not secure.



STEVE:  Right, no...



LEO:  And at first I said don't use it.  And then I looked into it, and it's BS, and Daren knows better than this.  This is link bait.



STEVE:  Right.  So your point is, and we were saying the same thing, but just using different terms, is that, because you have to have a password in order to use a private key, the private keys themselves don't reveal anything.



LEO:  They're an extra piece.  It's like two-factor authentication.  And so you should absolutely do everything you can to secure your private key.  And you should have a long - and this is important to people who want to use PGP.  You should have a very long, good passphrase.



STEVE:  Passphrase, in addition to your private key.



LEO:  So do the best you can to secure your private key, understanding that if somebody has physical access to your machine, they can, with every PGP tool I've ever used, easily export the secret key and save it.  Or mail it to themselves.  But that's not enough.  That's not sufficient.  So I don't think Mailvelope deserves any criticism.  They're doing what every other PGP tool is doing.  They're not storing it on their servers, are they?



STEVE:  No.  No, no, no, no, no.  No.



LEO:  Yeah.  I just - I think that it's misrepresenting the issue.  Maybe Daren doesn't understand it, but to make a big deal out of this is - and unfortunately, this has caused a lot of people not to use Mailvelope.



STEVE:  Yeah, which is unfortunate, as you say, because it provides very nice integration.



LEO:  Works.



STEVE:  Yes.



LEO:  And I've looked into it.  And as far as I can tell, it's not doing anything unusual.



STEVE:  Well, we will be going into - we will be looking at it closely in the future.  Yes.



LEO:  Let's do that, yeah.



STEVE:  There's nothing I want more than to be able to give this the Security Now! blessing, the way we did for LastPass.



LEO:  And so let's just be clear, leave it at this.  Mailvelope does what every other privacy guard, GNU Privacy Guard or PGP tool that I've ever seen does.  It is normal.  It is not insecure.  But it is a real security flaw to let somebody have unfettered access to your private computer. 



STEVE:  Because, yes, because the nature of the PGP protocol which Phil worked out all those years ago always, always protected your private keys with a passphrase.



LEO:  Right.  So you need - and it's good.  And I don't certainly give people my private key.



STEVE:  No.



LEO:  But I do store it in Dropbox.  And there's a reason.  That way, by the way, I can use PGP tools on the iPad, for instance, because I need to import my secret key into new installations of PGP.  So the way that you do that is you store your public and private key on a centralized server that you can access, a.k.a. Dropbox...



STEVE:  Well, or LastPass.  LastPass is also running on...



LEO:  LastPass would work, yeah.



STEVE:  Yeah.  And for people who aren't using Dropbox, LastPass gives you...



LEO:  LastPass is more complicated because the tool I've been using, which is, I think, called AP - I can't remember the...



STEVE:  Oh, pulls it directly from Dropbox?  Is it Dropbox support?



LEO:  It can get it from Dropbox; but, see, this is the problem with the iPad.  There's no file system that you have access to.



STEVE:  Right.



LEO:  So having it, yes, it's great to have it in LastPass.  And certainly in other installations when I'm on a desktop, that's fine.  But unfortunately, if you want to put PGP on an iPad, you need to use Dropbox.  Or...



STEVE:  We're going to have fun in the next few weeks, Leo.



LEO:  I have a lot of - I was looking back, and my oldest PGP key is from 1997.  I've been doing this for a while.



STEVE:  You know, I misspoke when I said that S/MIME predated PGP?  Turns out it's the other way around.  Phil was so early on this.  He reacted very badly to some congressional law that was being made, as I understand it.



LEO:  Yeah, he's come very close to prison many times.



STEVE:  Yeah [laughing].



LEO:  Anyway, I'm not - I didn't mean to be heated.  I was - and I'm not heated.  I just want to fervently have people understand...



STEVE:  You want to be clear.



LEO:  This is not a problem.  This is normal behavior.



STEVE:  Yup.



LEO:  It's not a weakness.  Steve, we are out of time.  Schneier, Bruce Schneier is coming up in just a moment, I'm very excited about that, to join us on This Week in Google.  We do Security Now!.  We have questions left over, if you want to do more next week or the week after.



STEVE:  Yep, we'll pick them up in two weeks because we're going to get on with the PGP protocol next week.



LEO:  Yeah.  Excited about that.  And again, I'll tell people, Leoville.com, I have my - I store my public key, not my private key.  You can download it and send me - and a lot of people, every day I get a few emails from people saying, "Did this work?"  And that's nice.  It's good.  We're slowly encrypting email, bit by bit.



Steve is at GRC.com.  That's his home, the Gibson Research Corporation.  That's where SpinRite is, world's best hard drive maintenance and recovery utility.  Don't fear that he's working on a new version.  He's already told us it'll be a free upgrade for all owners.  So buy it now, and you'll get the new version automatically.



STEVE:  Mo' betta.



LEO:  Mo' betta.  He also offers a lot of freebies, I mean, this is a place to go to just browse.  The cookie thing that you do, passphrases, GRC.com.  If you have questions, GRC.com/feedback, SSL encrypted.  And you can also find 16Kb versions of the show, SSL encrypted, and transcriptions by Elaine, SSL encrypted.  GRC.com.  We have the unencrypted, because I don't think we use SSL on TWiT, we have the unencrypted audio and video available at TWiT.tv/sn, or you can subscribe wherever you get your Internet shows because we're there.  We're everywhere.  Get it every week.  Help start Year Eight with a bang.  Next year is Year Eight, or we are we completing Year Eight?



STEVE:  We are finishing Year Eight.  Next is Year Nine.



LEO:  Wow.  There's only one show longer lived, and that's TWiT itself.  Amazing.  Thank you, Steve.  Thanks, everybody.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#418

DATE:		August 21, 2013

TITLE:		Considering PGP

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-418.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, Steve and Leo continue covering the consequences of the Snowden leaks and, with that in mind, they examine the Pretty Good Privacy (PGP) system for securely encrypting eMail and attachments.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson, our security guru, is here.  This is a show everybody has to watch.  In fact, share it with your friends, your neighbors, your colleagues:  Using PGP to protect your email.  Steve talks about it next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 418, recorded August 21st, 2013:  Considering PGP.



It's time for Security Now!, the show that covers your security, your privacy, your safety online with this man here, the 'Splainer in Chief, Steven Gibson at GRC.com.  Hey, Steverino.



STEVE GIBSON:  Hey, Leo.  Great to be with you for Show No. 1 of Year No. 9.



LEO:  Wow.



STEVE:  We begin our ninth year.



LEO:  Wow.  Episode 418, and you've only missed one, and that was because we made you.



STEVE:  Yeah.  So we're not going to do that again.  That was not pretty.  There was an uprising among the natives.



LEO:  Well, you've got to fight it out with Lisa because I don't - I never had the cojones to stop you, but she does.



STEVE:  We'll figure out something to do.  Oh, yeah, I got it.  No question.  There was, like, there will not be a podcast.  Oh.



LEO:  Well, start getting ready.  Here we are, we're almost at the end of August.  Christmas is just around the corner.  That's usually when we try to take a week off.  But if you want, we'll record ahead.  We'll do something for you.  You know what we're going to do...



STEVE:  We're here for our listeners, Leo.  Ultimately, they run - they rule the roost.



LEO:  There were here for you, that's right.  What we are going to do on, see, this might impact you because your show would be on New Year's Day.



STEVE:  [Strangled sound]



LEO:  And what we are going to do is this thing I've wanted to do for some time, the 24 hours of New Year's because we have listeners all over the world.  We're going to start, it'll be 4:00 a.m. our time New Year's Eve, and it's New Year's Eve in a tiny little island in the Pacific.  And what we're going to try to do, and I hope everybody listening will participate in this...



STEVE:  Get people to connect?



LEO:  ...is find somebody in every time zone.



STEVE:  Oh, neat.



LEO:  And get them on and say, okay, let's do the countdown.



STEVE:  Neat.



LEO:  And we'll actually have more than 24 countdowns because there are some areas that are on the half-hour and even the quarter-hour time zones.



STEVE:  There are, really?



LEO:  Yeah.



STEVE:  They're not all even hours?



LEO:  No, time zones being what they are, there are some odd ones.  So if you're in a time zone - what we're going to - we're putting up a page.  We're going to put up a page.  It'll be TWiT.tv/nye.  And we'll ask people to sign up in every time zone.  And I suspect there'll be a few like that very first one where nobody listens to us on this little island.  But maybe we can find somebody in a lighthouse or something and talk with them.



STEVE:  How about you get your rowboat girl to...



LEO:  Yeah, Roz can row out there, yeah.  Yeah, in fact, that's where she ended up when she did the Pacific was, I think, Tarawa, which is in the second time zone, second - the 5:00 a.m. time zone.  And we'll go all the way through from 4:00 a.m. New Year's Eve to 4:00 a.m. New Year's Day,  which will be, I think, Hawaii.



STEVE:  So you're going to sit there on your ball for 24 hours.



LEO:  Yes, and we're going to have...



STEVE:  You're going to put in a full cycle.



LEO:  A full cycle.  Every hour, sometimes even more, we'll have a countdown and fireworks and confetti.  And we're going to have guests; we're going to have music.  It'll be a lot of fun.  It's our New Year's Eve because we realize the people who listen to these shows really don't have a social life.  So we're going to give - myself included.  We're going to give you a little party here at the TWiT Brick House for New Year's Eve.  I think it'll be fun.  But...



STEVE:  Given some of what we hear from our listeners, Leo, we are providing a social life.



LEO:  Oh, yeah.



STEVE:  For some of our listeners.



LEO:  For me.  If it weren't for this, I'd be living in my - I'd be in my underwear at home watching TV.  So but...



STEVE:  Glad you're not.



LEO:  I know, there's an image, huh?  But you, my friend, would be six hours later, seven hours later on New Year's Day doing the show, if we do it live.  And I don't know if I'll be in any condition to do a show.



STEVE:  Oh, no, no.  I wasn't suggesting live.  I assumed that TWiT Land would do a hiatus, but I'd come up with something for us to fill...



LEO:  Christmas week is our Best Of week.  And so that Wednesday, which is Christmas Day...



STEVE:  Oh, I see.  We do have a problem, Leo.



LEO:  Yeah, you see, we have a little problem here.



BOTH:  But we'll figure it out.



LEO:  Yeah, we'll figure it out.  So, yeah, this is my social - I've created this entire network for my social life, so I'd have some friends.  I'm so lonely.



STEVE:  Well, and I remember, too, that when you and I first discussed this, it was in the studios of Rogers Cable...



LEO:  That's right, that's right.



STEVE:  ...up in Toronto.  And the problem was that the way they recorded was you would do four shows Monday, Tuesday, Wednesday, and was it Thursday?  And then when we...



LEO:  Yeah, it was the other way.  I would fly up - I would fly from San Francisco to Toronto on Monday, arrive in the evening on Monday.  We'd do 15 shows Tuesday, Wednesday, Thursday, Friday, and the 15th show I would collapse into a puddle, and the car would pick me up and take me to the airport, and I'd be home that night.



STEVE:  Well, and the key was...



LEO:  It was crazy.



STEVE:  ...you then had three weeks with nothing to do.



LEO:  With nothing to do.



STEVE:  Essentially you crammed a month's worth of programming material into one week.  And so you were kind of sitting around thinking, huh, you know?



LEO:  Anybody sensible would have just said, gosh, this is great.  I get three weeks off a month.  Work really hard for five days, and then take it easy.  But no.  No.  I said, oh, I think I'll start a whole 'nother business.



STEVE:  And Leo, we're...



LEO:  I'm glad I did.



STEVE:  Hundreds of thousands of people.



LEO:  And now nine years later, eight years later, beginning our ninth - I can't - that's so great, Steve.  That is amazing in any business.  But broadcasting especially.  But when a show is in its ninth year, that's a long time.



STEVE:  Yeah.



LEO:  That's a success.  So, and this show, I have to tell you, there's been zero attrition, and it's only grown over those nine years.



STEVE:  That's neat.



LEO:  It is larger now than it was when we started.  So, and I think that says something to, obviously, you and the content, but the people's need to know about security, as well.  In fact, that's what we're going to do today. We're going to tell you how to secure your email.



STEVE:  Well, yeah.  What I want to do, I'm - as promised, we're going to talk about PGP.  And I thought long and hard about the title.  And I decided I would - we would title this podcast "Considering PGP" because I definitely want to talk about what it is and how it works and the protocols and all of that.  But I still think it's fighting an uphill battle.  I still come away thinking, eh, you know, the Internet is full of protocols that clever people put together, that have niches, but just kind of never got off the ground.  I mean, they never got traction.  They never got critical mass.



And I'm afraid that I have to put PGP there, that it's, I mean, I want to say it absolutely does what it promises.  And it passes every test of serious security.  So, I mean, and Phil, right out of the gate, designed it beautifully.  He made one little mistake which is a typical mistake that's hard to avoid.  And that is, he did design his own cipher, which ended up not to be a good idea.



LEO:  Everybody does that.  I wish they would just use the stuff that...



STEVE:  Yeah.  And you could - back then you could argue that, okay, you weren't just like wading around in really good professionally designed ciphers.  And I have in my notes what he called it, and I can't - I'm blanking on it right now.



LEO:  I thought he was using Blowfish and 3DES.  But maybe I'm wrong.



STEVE:  Oh, no, no, those are all available.  I mean, this thing is...



LEO:  Well, now, yeah, now you can use RSA and everything.



STEVE:  Absolutely state of the art.  And there were problems with - oh, he called it BassOmatic.



LEO:  [Laughing] You know, I don't think that survived too long because I started using PGP in 1997 and I don't - and I've interviewed Phil many times.  And I don't remember BassOmatic.  So that quickly...



STEVE:  It was from Dan Aykroyd's "Saturday Night Live" skit.



LEO:  Yeah.  He was putting a bass in the blender.



STEVE:  In a blender.



LEO:  Yeah.



STEVE:  And he said that's basically what this does to your data is what the blender does to the bass.



LEO:  See, it's a good name.  It's a descriptive name.



STEVE:  So he called it BassOmatic.  Anyway, we're going to talk all about PGP.  But as is still happening, there's a bunch of news relative to the continuing blowback and consequences of the Snowden leaks.  And several things happened this week that were interesting and help to - this is a little bit of a thinking piece at the top of the show because there's this whole question of, if you don't have anything to hide, why do you need privacy?  There have been a couple events which have induced some smart people to make some comments that I want to share.  So I want to share some writing of a couple people.



And also, of course, we have the sad news that it has turned out for Ladar Levison - whom we discussed last week, who decided to close down Lavabit - it turns out that, shortly after his announcement, but enough afterwards that we didn't pick up on it last week, has come the news that he received essentially a threatening letter from the powers that be in the federal government for shutting down his service.  And this was reported by a very good reporter with NBC News, an investigative reporter whom I'm sure you know, Mike Isikoff.



LEO:  Yeah, who's very good.  Used to write at Newsweek.  Smart guy.



STEVE:  Yeah, yeah, yeah, I mean, this guy is top of his game.  So he wrote, and then Techdirt reported on it, saying:  "The saga of Lavabit founder Ladar Levison is getting even more ridiculous, as he explains that the government has threatened him with criminal charges for his decision to shut down the business..."



LEO:  But he can't have been surprised because the reason he shut it down, he wanted to erase the database, and that's what the government wanted.  So it's not that he shut down, it's that he erased the database, of course.



STEVE:  Well, apparently not, because he says:  "...the decision to shut down the business, rather than agree to some mysterious court order."  So what Isikoff has concluded is that they wanted continuing surveillance in the future.  And so if you read this this way, they're upset that they lost him as a resource.



LEO:  Right.  We're really excited about being able to tap into your ability.  But, you see, this is what you speculated is that they wanted ongoing keys.  You said this.



STEVE:  Oh, yeah.



LEO:  From Lavabit.  And so I think you're probably right, yeah.



STEVE:  Yeah.  So they said:  "The feds are apparently arguing that the act of shutting down the business itself was a violation of the order."  And then Isikoff says:  "A source familiar with the matter told NBC News that James Trump, a senior litigation counsel in the U.S. attorney's office in Alexandria, Virginia, sent email to Levison's lawyer last Thursday, the day Lavabit was shuttered" - so that's Thursday before last in our timeframe - "stating that Levison may have 'violated the court order,' a statement that was interpreted as a possible threat to charge Levison with contempt of court.  That same article suggests that the decision to shut down Lavabit was over something much bigger than just looking at one individual's information, since it appears that Lavabit has cooperated in the past on such cases," as we said last week.



"Instead, the suggestion now is that the government was seeking a tap on all accounts.  Levison stressed that he has complied with 'upwards of two dozen court orders' for information in the past that were targeted at 'specific users' and that," quoting him, "'I never had a problem with that.'  But without disclosing details, he suggested that the order he received more recently was markedly different, requiring him to cooperate in broadly based surveillance that would scoop up information about all the users of his service.  He likened the demands to a requirement to install a tap on his telephone."



And so - and we know what the architecture is because he was public with the architecture.  And the fact is he didn't have keys to his database.  He only acquired them as people connected in order to download the contents of their inbox.  And so that's what we - from a technology, purely technology standpoint last week, it was clear to me that they couldn't capture his database.  It wouldn't do them any good.  That part he got right.  That was useful, that he didn't have the keys to the data.  But the problem was he would always receive them at his end in order for the user to then decrypt the data on the server and download it.  So it must have been that, if he was upset with something, it was that he was going to be asked to provide this on an ongoing basis.  And now they're saying we're not happy with you for doing that, for, like, deciding not to be in that business.



LEO:  It's really getting bad.



STEVE:  It is.  And you know, Leo, there are - I've seen people say that, like, why are people getting upset?  We've all known this was going on.  And first of all, I think it's very clear we didn't all know this was going on, and also that...



LEO:  Only cynics knew it was going on.



STEVE:  Correct, correct.



LEO:  In some ways, this is what really pains me the most, is that the most cynical, conspiracy-minded people in this country have been proven right.  And that bothers me because I wanted to believe in the government.  I wanted to believe.



STEVE:  Yes, I did, too.  I mean, I've, you know, yes.  I was literally a Boy Scout, and we pledged to the flag.



LEO:  Yeah.  And we really need to get back to that, a government we can be proud of, that upholds the Constitution in this.



STEVE:  Yes.  And that's the other thing, too.  There is this sense now of our own government being adversarial.



LEO:  Yeah.



STEVE:  And that's really uncomfortable.



LEO:  And I'm sure you're going to talk about what happened to the Guardian and Glenn Greenwald's spouse.  And that is, now, that was the British government, but this is what we fear.



STEVE:  Yes.



LEO:  And it's coming true, I'm sorry to say.



STEVE:  That is what I have up next.  That is what I have up next because the second part of this is the government's response.  That is, it's one thing for them to be doing this, but they're really being very graceless in...



LEO:  Oh, they're insisting on their prerogative to break the law, essentially.



STEVE:  Yeah.  So the editor of the Guardian wrote a good piece.  I also - he also put together about a - it's six minutes and something, I think it's 45 seconds, so a little bit less than seven-minute video which I just tweeted the link to before the podcast.  So if anyone wants to see Alan Rusbridger in front of a camera, speaking and explaining himself, there's that, too [bit.ly/13RuIet].  But I want to share two pieces from a larger posting of his that he put up yesterday, discussing exactly what you were saying, Leo.



So jumping into the middle of what he wrote, he says:  "On Sunday morning David Miranda, the partner of Guardian columnist Glenn Greenwald, was detained as he was passing through Heathrow Airport on his way back to Rio de Janeiro, where the couple live.  Greenwald," of course, "is the reporter who has broken most of the stories about state surveillance based on the leaks from the former NSA contractor Edward Snowden."



LEO:  That word "reporter" is extremely important.



STEVE:  Yes, yes, because his partner David Miranda is not a journalist.  "Greenwald's work has undoubtedly been troublesome and embarrassing for western governments.  But, as the debate in America and Europe has shown, there is considerable public interest in what his stories have revealed about the right balance between security, civil liberties, freedom of speech, and privacy.  He has raised acutely disturbing questions about the oversight of intelligence; about the use of closed courts; about the cozy and secret relationship between government and vast corporations" - and of course just this morning The Wall Street Journal, Leo, disclosed, gave some numbers, put some numbers to the relationship the NSA has with major top-level telco providers.  And continuing, "...and about the extent to which millions of citizens now routinely have their communications intercepted, collected, analyzed and stored.



"In this work he is regularly helped by David Miranda.  Miranda is not a journalist, but he still plays a valuable role in helping his partner do his journalistic work.  Greenwald has his plate full reading and analyzing the Snowden material, writing, and handling media and social media requests from around the world.  He can certainly use this back-up.  That work is immensely complicated" - and this is really interesting, Leo, that this guy's writing this - "That work is immensely complicated by the certainty that it would be highly unadvisable for Greenwald (or any other journalist) to regard any electronic means of communication as safe.  The Guardian's work on the Snowden story has involved many individuals taking a huge number of flights in order to have face-to-face meetings.  Not good for the environment, but increasingly the only way to operate.  Soon we will be back to pen and paper.



"Miranda was held for nine hours under Schedule 7 of the U.K.'s terror laws, which give enormous discretion to stop, search and question people who have no connection with 'terror' as ordinarily understood.  Suspects have no right to legal representation and may have their property confiscated for up to seven days.  Under this measure - uniquely crafted for ports and airport transit areas - there are none of the checks and balances that apply once someone is in Britain proper.  There is no need to arrest or charge anyone, and there is no protection for journalists or their materials.  A transit lounge in Heathrow is a dangerous place to be."



LEO:  Unbelievable.



STEVE:  So, but I thought it was really interesting that he talks about the, as a consequence of what journalism now understands to be the case - and we'll talk about Groklaw here in a second, Leo.



LEO:  It's a huge chilling effect on what is a very important function of journalism, which is to keep an eye on government.



STEVE:  And to be able to guarantee your sources their own privacy and anonymity.  And how...



LEO:  Or we'll have no sources.  Which is what, frankly, the Obama administration wants.  It's why they're so aggressively pursuing whistleblowers.



STEVE:  I know.  Well, anyway, we have - there's a fabulous blog posting that I'm going to share in a second here, an open letter to Obama from an IT security expert in Silicon Valley who presents one of the most interesting analogies of pervasive surveillance that I've seen, that's also thought-provoking.  But I want to finish with this.  In the second part of what I wanted to excerpt from what Alan wrote, he says:  "A little over two months ago I was contacted by a very senior government official claiming to represent the views of the prime minister.  There followed two meetings in which he demanded the return or destruction of all the material we were working on.  The tone was steely, if cordial, but there was an implicit threat that others within government and Whitehall favored a far more draconian approach.



"The mood toughened just over a month ago, when I received a phone call from the center of government telling me:  'You've had your fun.  Now we want the stuff back.'"



LEO:  Ugh.



STEVE:  Oh, I know, it is just so bad.  "You've had your fun."  That's the way they're characterizing...



LEO:  It ain't fun.



STEVE:  ...what the Guardian is doing.



LEO:  It ain't fun.



STEVE:  "There followed further meetings with shadowy Whitehall figures.  The demand was the same:  Hand the Snowden material back or destroy it.  I explained that we could not research and report on this subject if we complied with this request.  The man from Whitehall looked mystified.  'You've had your debate.  There's no need to write any more.'"



LEO:  No, no, no.



STEVE:  Period.



LEO:  No, it's just beginning.  Got bad news for you, Whitehall.



STEVE:  Thank god.  "During one of these meetings I asked directly whether the government would move to close down the Guardian's reporting through a legal route - by going to court to force the surrender of the material on which we were working.  The official confirmed that, in the absence of handover or destruction, this was indeed the government's intention.  Prior restraint, near impossible in the U.S., was now explicitly and imminently on the table in the U.K.



But my experience over WikiLeaks - the thumb drive and the First Amendment - had already prepared me for this moment.  I explained to the man from Whitehall about the nature of international collaborations and the way in which, these days, media organizations could take advantage of the most permissive legal environments.  Bluntly, we did not have to do our reporting from London.  Already most of the NSA stories were being reported and edited out of New York.  And had it occurred to him that Greenwald lived in Brazil?  The man was unmoved."



LEO:  Which is, by the way, where his partner was headed.



STEVE:  Yes.



LEO:  He was transiting England.  He wasn't even in England.



STEVE:  Yup.  "The man was unmoved.  And so one of the more bizarre moments in the Guardian's long history occurred,  with two GCHQ security experts overseeing the destruction of hard drives in the Guardian's basement..."



LEO:  Morons.  Morons.  That's who's running this.



STEVE:  I know, "...just to make sure there was nothing in the mangled bits of metal which could possibly be of any interest to passing Chinese agents."  Then one of the guys jokes, "'We can call off the black helicopters,' joked one as we swept up the remains of a MacBook Pro."  Ha ha ha, yeah.



LEO:  They're just making it real.  Quite the contrary...



STEVE:  I know.  Leo, mark my words, there will be technological consequences that will take on the...



LEO:  Oh, absolutely.



STEVE:  There will be.  You heard it here.  I mean, we technologists, the people who get technology and the Internet, are not without recourse.  There will be - it's going to take months because these things take months to happen.  There will be a technological response that none of these agencies will view positively as a consequence, more than anything, of the fact of this kind of action and that they lie.  We cannot have, in a democracy, we cannot have our government lying to us.



LEO:  The response I was thinking of was the chilling effect it has, which your next story will talk about, on technology.  Already Germany's saying, well, you can't use Windows 8 because the TPM module gives a backdoor to the United States government.  So there's that chilling - that's the effect I was thinking of.  You're thinking of consequences, and I certainly don't want to be in a position where we're threatening consequences.  We have no control over that.  But I think...



STEVE:  No, no, no, all I mean is empowerment.



LEO:  Yeah.



STEVE:  There have been, and we've reported here, and I keep reading it, there has been a tremendous upsurge of interest in secure solutions.  And my point has always been, they exist.  You can do pre-Internet encryption, and you can do TNO.  I mean, we'll be talking about it later.



LEO:  Right.



STEVE:  PGP is absolutely bulletproof.



LEO:  Right.



STEVE:  I mean, but you have to use it in order to be protected.  But I predict that this puts pressure that we have never had before on the need for privacy, and all of the technology is there.  It just needs to get mobilized.



LEO:  Yeah, we've been talking about, I've been talking about PGP and putting my key on the front page of my website since literally 1997.  No uptake, never, nobody was ever interested in it.



STEVE:  No.



LEO:  All of a sudden there's a lot of interest.



STEVE:  Yeah.



LEO:  Which is good.



STEVE:  So in another piece of news earlier this week...



LEO:  This is depressing as hell.



STEVE:  It is, Leo.  I was so shocked.



LEO:  I think Pamela's overreacting, but I understand her - anyway, go ahead.



STEVE:  Yeah.  So anyway, this is about Groklaw, which we've touched on for years.



LEO:  Fabulous website.  Really good.



STEVE:  Yup.  And she's - Pamela Jones, P.J. as she goes, got very upset by this.  And from her...



LEO:  Groklaw, we should mention, is a site that discusses the law as it applies to technology, and it's hideously useful.  It's one of the resources I use all the time to understand lawsuits, patent issues.  She's really good.  DRM...



STEVE:  Really informed legal discussion.



LEO:  Yeah.



STEVE:  Yes.  So I'm not going to read her whole posting.  It's at Groklaw.net, G-r-o-k-l-a-w dotnet, for anyone who wants more.  But I excerpted a couple things because she, while I agree that she overreacted, Leo, she said a couple things and also quoted an author that I thought had some very interesting things to say.  So summarizing what came before, I put in brackets here, "[I feel betrayed]," so I could walk into the sentence I wanted to start at, saying "knowing that persons I don't know can paw through all my thoughts and hopes and plans in my emails with you."



So she's really disturbed, she writes, by the certainty now that - she maintains email with an international community.  And by definition international correspondence, email, is being captured.  We now know that.  So she says:  "They tell us that, if you send or receive an email from outside the U.S., it will be read.  If it's encrypted, they keep it for five years, presumably in the hopes of tech advancing to be able to decrypt it against your will and without your knowledge."  And of course we know, Leo, that since security certificates expire at most every three years, keeping encrypted content for five, if you get the expired keys, guarantees your ability to ultimately decrypt everything.



LEO:  Does perfect forward security prevent that?



STEVE:  Yes.



LEO:  Okay.



STEVE:  Yes.  So she says:  "Groklaw has readers all over the world."  She says:  "I'm not a political person, by choice, and I must say, researching the latest developments convinced me of one thing - I am right to avoid it."  And then she talks about her feelings after 9/11 and how hugely upset she was by the events of 9/11, the 9/11 attacks.  And so she says:  "Part of my anguish was that there were people in the world willing to do that to other people, fellow human beings, people they didn't even know, civilians uninvolved in any war.  I sound quaint, I suppose.  But I always tell you the truth, and that is what I was feeling.  So imagine how I feel now, imagining as I must, what kind of world we are living in if the governments of the world think total surveillance is an appropriate thing?"  And this was one of the sentences that really got me.  She said:  "What I do know is it's not possible to be fully human if you are being surveilled 24/7."



And then she quotes Janna Malamud Smith, the author of a book, "Privacy Matters."  And I guess Janna quotes Alan Westin in his book, "Privacy and Freedom," saying:  "In his landmark book, 'Privacy and Freedom,' Alan Westin names four states of privacy:  solitude, anonymity, reserve, and intimacy.  The reasons for valuing privacy become more apparent as we explore these states," reading from the book.  "The essence of solitude, and all privacy, is a sense of choice and control.  You control who watches or learns about you.  You choose to leave and return.  Intimacy is a private state because in it people relax their public front either physically or emotionally or, occasionally, both.  They tell personal stories, exchange looks, or touch....  They may ignore each other without offending....  They may speak frankly using words they do not use in front of others, expressing ideas and feelings, positive or negative, that are unacceptable in public.  When shielded from forced exposure, a person often feels more able to expose himself."



And anyway, so I really liked that.  I thought that helps to understand sort of the creepy feeling of wanting to send an email to someone with content that is really private, I mean, that you intend only to share with the other person, and the sort of sense of self-censorship which is now sort of pervading, or the idea of maybe needing to self-censor whenever you use the Internet because this - maybe, I mean, maybe we were wrong not to be cynical enough.  But now we know exactly what's going on, and I'm self-conscious about doing searches for things that interest me just intellectually because of the problem of false positives.



LEO:  Well, so there's a consequence.  We're losing one of the best law blogs out there, Groklaw, because she doesn't want to be exposed this way.  She's actually, it sounds like, trying to get off the Internet entirely.



STEVE:  Yes.  And unfortunately she did recommend a, quote, "secure email service."  For what it's worth, it's absolutely not.  So she mentions Kolab as, like, being the best secure email solution available.  Well, secure email is close to being an oxymoron.



LEO:  Yeah.  We're going to show you the most secure way to do it in this show.



STEVE:  Yes.  That is the content of the...



LEO:  There's no way to hide metadata.  And as we know now, metadata can be very, very revealing.



STEVE:  Well, but Kolab does nothing.  I mean, it's...



LEO:  She likes it because it's in Switzerland, so somehow that's magical, yeah.



STEVE:  Yes.  That's exactly why.  She said that she believes that they're in Switzerland, and doesn't understand that there's no encryption as it heads out to Switzerland, which is where the NSA has stationed their listening posts.  So, and Kolab's onsite.  I really got myself worked up when I looked at this.  I was like, oh, my god.  I mean, they say:  "We offer secure email accounts including calendars and address books that synchronize to all your devices.  The data is stored in our very own data center in Switzerland."



LEO:  Ooh.  Wow.



STEVE:  This is like...



LEO:  So is Google's.



STEVE:  ...Silent Circle has Navy SEALs.  It's like, oh, and we have our own datacenter in Switzerland.  BF - oh, excuse me.



LEO:  But, no, and so I feel like Pamela's overreacted, P.J.'s overreacted a little bit.  I understand her concern, and I don't know what it is that she's worried about people finding out.  I wish that Groklaw could continue because it's very useful.  But...



STEVE:  She did try to shut it down a few years ago and brought somebody in to help her out.



LEO:  Yeah.  There may be - there are other reasons in addition.  Might just be a good opportunity.  But it's a good protest.  It's sad.



STEVE:  Yeah.  Now, I want to share this open letter to the President.  And I don't know how to excerpt from it.  It's not very long, and I think it's worthwhile.  And this is where there's an analogy that I think is really interesting.  So this was posted day before yesterday, addressed to Dear President Obama:  "My name is Ben Adida (A-d-i-d-a).  I am 36, married, two kids, working in Silicon Valley as a software engineer with a strong background in security.  I've worked on the security of voting systems and health systems, on web browsers and payment systems.  I enthusiastically voted for you three times:  in the 2008 primary and in both presidential elections.



"When I wrote about my support for your campaign five years ago, I said:  'In his campaign, Obama has proposed opening up to the public all bill debates and negotiations with lobbyists, via TV and the Internet.  Why? Because he trusts that Americans, when given the tools to see and understand what their legislators are doing, will apply pressure to keep their government honest.'  I gushed about how you supported transparency as broadly as possible" - actually there was a funny tweet that I saw.  Someone said Obama's presidency is so transparent, now we can't see anything.



LEO:  Yeah.



STEVE:  And so anyway, it says:  "...transparency as broadly as possible to enable better decision-making, to empower individuals, and to build a better nation.  Now, I'm no stubborn idealist.  I know that change is hard and slow.  I know you cannot steer a ship as big as the United States as quickly as some would like.  I know tough compromises are the inevitable path to progress.  I also imagine that, once you're President, the enormity of the threat from those who would attack Americans must be overwhelming.  The responsibility you feel, the level of detail you now understand, must make prior principles sometimes feel quaint.  I cannot imagine what it's like to be in your shoes.



"I also remember that you called on us, your supporters, to stay active, to call you and Congress to task.  I want to believe that you asked for this because you knew that your perspective as Commander in Chief would inevitably become skewed.  So this is what I'm doing here:  I'm calling you to task.  You are failing hard on transparency and oversight when it comes to NSA surveillance.  This failure is not the pragmatic compromise of ObamaCare, which I strongly support.  It is not the sheer difficulty of closing Guantanamo, which I understand.  This failure is deep.  If you fail to fix it, you will be the President principally responsible for the effective death of the Fourth Amendment and worse."



He says, with his topic Mass Surveillance:  "The specific topic of concern, to be clear, is mass surveillance.  I am not concerned with targeted data requests, based on probable cause and reviewed individually by publicly accountable judges.  I can even live with secret data requests, provided they're very limited, finely targeted, and protect the free speech rights of service providers like Google and Facebook to release appropriately sanitized data about these requests as often as they would like.  What I'm concerned about is the broad, dragnet NSA signals intelligence recently revealed by Edward Snowden.  This kind of surveillance is a different beast, comparable to routine frisking of every individual simply for walking down the street.  It is repulsive to me.  It should be repulsive to you, too.



"If you're a hypochondriac, you might be tempted to ask your doctor for a full-body MRI or CT scan to catch health issues before detectable symptoms.  Unfortunately, because of two simple probabilistic principles, you're much worse off if you get the test.  First, it is relatively unlikely that a random person with no symptoms has a serious medical problem, i.e., the prior probability is low.  Second, it is quite possible  not likely, but possible  that a completely benign thing appears potentially dangerous on imaging, i.e., there is a noticeable chance of false positive.  Put those two things together, and you get this mind-bending outcome:  If the full-body MRI says you have something to worry about, you actually don't have anything to worry about.  But try convincing yourself of that if you get a scary MRI result.



"Mass surveillance to seek out terrorism is basically the same thing:  very low prior probability that any given person is a terrorist, quite possible that normal behavior appears suspicious.  Mass surveillance means wasting tremendous resources on dead ends.  And because we're human and we make mistakes when given bad data, mass surveillance sometimes means badly hurting innocent people."  And then he quotes the case of Jean-Charles de Menezes, who was shot seven times in the head in the U.K. after the bombings, just because of false identification.



"So what happens when a massively funded effort" - oh, and then, and this is another great point, he says:  "So what happens when a massively funded effort has frustratingly poor outcomes?  You get scope creep.  The surveillance apparatus gets redirected to other purposes.  The TSA starts overseeing sporting events.  The DEA and IRS dip into the NSA dataset.  Anti-terrorism laws with far-reaching powers are used to intimidate journalists and their loved ones."  And he was talking about what happened over the weekend.  "Where does it stop?  If we forgo due process for a certain category of investigation which, by design, will see its scope broaden to just about any type of investigation, is there any due process left?"



And then he adds something else that I thought was interesting.  Under Wrong on Principle, he says:  "I can imagine some people, maybe some of your trusted advisors, will say that what I've just described is simply a 'poor implementation' of surveillance, and that the NSA does a much better job.  So it's worth asking:  Assuming we can perfect a surveillance system with zero false positives, is it then okay to live in a society that implements such surveillance and detects any illegal act?  This has always felt wrong to me, but I couldn't express a simple, principled, ethical reason for this feeling until I spoke with a colleague recently who said it better than I ever could:



"'For society to progress, individuals must be able to experiment very close to the limit of the law and sometimes cross into illegality.  A society which perfectly enforces its laws is one that cannot make progress.'  What would have become of the civil rights movement if all of its initial transgressions had been perfectly detected and punished?  What about gay rights, or women's rights?  Is there even room for civil disobedience?  Though we want our laws to reflect morality, they are, at best, a very rough and sometimes completely broken approximation of morality.  Our ability as citizens to occasionally transgress the law is the force that brings our society's laws closer to our moral ideals.  We should reject mass surveillance, even the theoretically perfect kind, with all the strength and fury of a people striving to form a more perfect union."  So anyway, I thought there was some really...



LEO:  It's good.  It's really good, yeah.  I like the MRI analogy because I think that's exactly what's happened, and I think...



STEVE:  Yes.



LEO:  That's Ben Adida writing, and his blog is Benlog, B-e-n-l-o-g, dotcom.  Yeah.  I think - I don't know where you found that, but I think that that's kind of - those are words that I would have said, as well.



STEVE:  Yeah.  And it was that - that was what I meant when I talked about the analogy, the analogy to a scan.



LEO:  It's an excellent analogy, yeah.



STEVE:  It really is.  Because it is the probability, this low probability that has a high tendency for false positives.  I know from just my own eight years of doing a lot of medical research that scans are really frowned on for that reason.



LEO:  Right.



STEVE:  First of all, not the MRI...



LEO:  It's counterintuitive.  But these full-body scans which are - they're selling now, you know, there's these - this is a business.  And most doctors say don't do it.  It's a bad - it's a bad idea.  And it's not intuitive why it's a bad idea.  I think he described it quite well.  And it's precisely what's wrong with mass surveillance.  And we see it all the time.  I really...



STEVE:  Well, and Leo, yeah, and the fact that the Patriot Act has now allowed us to suspend habeas corpus, I mean, the idea that you can be, I mean, people make mistakes.  Government makes mistakes.  The idea that goons can show up at your door and take you away without recourse, without needing to explain themselves, simply saying "terrorism," just under the Patriot Act, essentially, we have unleashed and unbound agents of the government in a way that has never happened before.  I mean, and it's a fundamental principle of the country.



LEO:  Fortunately, we still have the right to debate this in public without fear of knocks coming on the door.  But I don't know how much longer that's going to go on.  When I see the kind of harassment that Glenn Greenwald is receiving...



STEVE:  Well, yes.



LEO:  ...I start to worry that in fact just speaking out will in fact make you a target.



STEVE:  And doesn't this feel like harassment?



LEO:  It is.



STEVE:  For his partner to go through nine hours of detainment?



LEO:  No, it's pure harassment.



STEVE:  Yes.



LEO:  And it's just the beginning, I think.  Now, it's always been a little worse in Britain.  I hope that, you know, we have, I think, a Constitution that is more protective of our individual rights.  I hope that that wins in the end.



STEVE:  Well, only if it's followed.  And when...



LEO:  I thought what he said is, that you don't want to be the President who goes down in history as the guy who overturned the Fourth Amendment, is right on.  And I hope that somebody's paying attention to this.



STEVE:  And I forgot.  I didn't want to keep reading because I know this was getting long.  But later on he comes back and makes it personal.  He says, Obama, Barack, if you were still a professor teaching constitutional law in Chicago, what would you be saying?  I mean...



LEO:  Yeah, well, as a senator he was very critical of this.



STEVE:  Yes.



LEO:  He was extremely critical as a senator.  I don't understand what happened.  I mean, I think that this is - the blog post is accurate.  And I think it's very generous to the President, frankly.  But we've got to do something.  This can't go on.  It really can't go on.



STEVE:  So I did want to mention that I was disappointed in Google.  And maybe I was more disappointed in the reporting.  I'm not sure.  But Google, since we last spoke, made a very big deal about now they are encrypting their drives.  And I - it caused me to coin a new acronym.  We have TNO.  We have PIE.  We now have ZVE.



LEO:  ZVE.



STEVE:  Zero-Value Encryption [laughter].



LEO:  I like it.



STEVE:  This is Google's very disappointing ZVE.



LEO:  It makes you feel better, though.  That's the importance.



STEVE:  Oh, don't we all need that, Leo.  We really - we need to feel better, yeah.  Anyway, they did a blogspot posting on the Google Cloud Platform, made a big deal about how they're now encrypting their data on their drives.  Now, it is true that it raises the bar for somebody physically stealing the drive.  I mean, they rotate keys.  I mean, they're doing the key management.  Oh, don't worry, we'll handle the keys.  You don't have to handle - well, it's like, hello.  ZVE.  It means nothing.  But the way the media covered it, my Twitter feed went crazy with people saying, hey, Google's encrypting their data.  It's like, yeah.  And decrypting it.  So...



LEO:  Yeah.



STEVE:  Big deal.  And so the bad news is, remember that about a month ago I picked up a rumor that this was happening, and I got excited, thinking maybe they were going to do some form of TNO encryption.



LEO:  They'd have to give us, let us determine the keys and  hold them.



STEVE:  Yeah.



LEO:  But you can always do that.  You use TrueCrypt on your end and store it on Google Drive.  It's TNO.



STEVE:  Precisely.  Or Boxcryptor is another great solution.  We've talked about those.  Oh, and, yeah.



LEO:  But you have to have the key.  They can't have the key or it's zero-value encryption.  I like it.



STEVE:  ZVE.



LEO:  ZVE, another ZVE.



STEVE:  Okay.  So a consequence of the April 8, 2014 discontinuance of XP's updates didn't really sink in last time I mentioned - I mentioned it last week that now we're at 229 days and counting, so there's time.  But remember I mentioned last week that Microsoft actually sent out a note saying, just want to make sure everyone understands that we're not going to be continuing to update XP SP3 after April 8th of next year.  Well, what's significant is - oh, and when I talked about it last week it was under the context of the security community beginning to wonder if maybe bad guys are not holding their exploits back, not using them, but waiting.



LEO:  Mmm.  That's what I'd do.



STEVE:  Yes, exactly.



LEO:  Wait'll after April 8th, and everyone's golden.



STEVE:  But here's the second part of this problem, and that is, almost all of these bad problems affect all supported versions of Windows.  We see that, I mean, not always.  Sometimes it'll just be Server 2008 or a Windows 7 thing.  But normally it's everything.  Because we know this is just one OS, and they keep putting different candy colors on the outside and give it a few more features.  But there's a core operating system that hails from NT that has had more crap glued onto it over time, but basically it's the Microsoft OS.  And they come up with new versions because they need us all to give them more money for upgrades.  The point being that, after April 8th, there will continue to be problems found in the remaining operating systems, Vista and 7 and Windows 8.  And those same problems will still be in XP.



So the other thing that we know happens is that bad guys reverse-engineer the patches.  Patches will continue coming out for all supported operating systems that should be coming out for XP, but Microsoft won't any longer.  So when those are reverse engineered, those newly discovered vulnerabilities, discovered by the act of patching the newer OSes, will give the bad guys vulnerabilities that will never be fixed in Windows XP.  So arguably, unfortunately, much as I hate to say this, because they're continuing to have - we're continuing to find fundamental problems with Windows even now, it's going to be important to really be careful about how you use XP after it is no longer the recipient of security patches.



LEO:  I'm sure Microsoft will have a page, as they did, remember, with IE6, saying stop using it.



STEVE:  Yeah.



LEO:  Stop using XP.



STEVE:  Okay.  So I just need to talk about this little Facebook bug and...



LEO:  Oh, this is a good story.



STEVE:  So, yes.  So a security researcher in Palestine by the name of Khalil Shreateh finds a problem that allows anyone - and he is anyone - to violate the security, I mean, a Facebook bug, to post onto anyone, any other Facebook member's private timeline and wall.  And so to verify this he posts something on Sarah Goodin's private wall.



LEO:  Does he know her?  I mean...



STEVE:  I don't know how he chose her.  The article I read said that she was the first woman ever to sign up for Facebook, so she's certainly an...



LEO:  Oh, she must work at Facebook, yeah.



STEVE:  Probably.  And I guess maybe a friend of Mark's.  But nothing happened.  So he does that.  Then he contacts Facebook security to report the problem and to collect his $500 bounty.  And he's told, sorry, this is not a bug.  And he thinks, what?  Well, okay.  So he posts to Mark Zuckerberg's timeline.



LEO:  It's a bug now, baby [laughter].  He was quite polite.



STEVE:  Within minutes, within minutes Facebook security engineer Ola Okelola contacts Khalil to request details of the exploit.  Khalil's Facebook account is frozen, later unfrozen.  Then Khalil is denied his $500 bounty on the grounds that he violated Facebook's terms of service.



LEO:  Oh, come on.



STEVE:  Which disqualifies him for receiving compensation.



LEO:  Oh, that's funny.



STEVE:  Then Facebook acknowledges that they should have asked for additional information initially.



LEO:  You think?



STEVE:  Now, anyway, that's the story.



LEO:  That's pretty funny.



STEVE:  And I can, I mean, probably the person on the frontline who Khalil first contacted, you can imagine how many false positives this poor person has to field.  And, I mean, especially when you offer money.  If it was free, then, eh, bogus people wouldn't bother.  But if it's a way to get a quick 500 bucks, you're just going to be trying to come up with all kinds of nonsense.  And so those poor guys on the frontline of Facebook security must just be like, I mean, "This is not a bug" must be something they, like, have nightmares that repeat in their heads at night.  So anyway...



LEO:  It's a feature.



STEVE:  Okay.  Now, listeners of this podcast...



LEO:  Yes.



STEVE:  You need to go listen to something Leo did last week [bit.ly/19kYAEh].



LEO:  Uh-oh.  Am I in trouble?



STEVE:  Triangulation with Esther Dyson.



LEO:  Oh, wasn't she great?  Yeah.



STEVE:  Oh, Leo.  I knew she was going to be good.  It did not disappoint.  She is...



LEO:  I didn't get a chance to say hi.  I'm sorry.  You were in the chatroom, and I apologize.



STEVE:  That's fine.  I've known Esther for about three decades.  I did a presentation for - there was a weird conference, Roger von Oech, who - the whack on the side of the head guy.



LEO:  Oh, yeah.



STEVE:  Sort of creative thinking and creativity and things.  Somehow he invited me to speak at his conference.  And at one point I dropped down onto my knees to pray to IBM.



LEO:  [Laughing] That I want to see.



STEVE:  I told the story, this was before the PC Junior was going to come out.  We knew that IBM was working on a home computer.  There was the IBM PC and XT and so forth, the industrial computers.  And IBM, who had launched the computer industry, I mean the PC industry, finally, after the first sort of sputtering prelaunch with the Apple II and the Ataris, now IBM had made it happen.  Clones were out, I mean, this was - we were moving forward.  So now they were going to do something for the home.  And so my point to this conference was that whatever IBM did was really, really important.  So I sort of set it all up, and I dropped to my knees, put my hands together and looked up at the sky and prayed to IBM.  I said - oh, I guess also beforehand I talked about how - oh, and you may remember the nickname for this thing was the Peanut, for some reason.



LEO:  Oh, yeah.



STEVE:  Remember?  It was the Peanut was like their code word.  Like Macintosh was supposed to be the code word at Apple, but it became the actual name of the machine.  This was the Peanut, the IBM Peanut.  That was their - and I guess because it was small and downscale and so forth.  And so at one point, as I'm talking behind the podium, I talk about the experience we've all had at the zoo, where we've got - we're feeding the animals.  Or I guess maybe we're feeding ourselves with peanuts because you crack open the shell and there's nothing there.  And so that ties in later, when I'm on my knees, praying to IBM, beseeching them to please give us - please do not give us a peanut shell with no nuts.  And anyway, so it was a bunch of craziness.  But Esther liked it a lot and so invited me to speak at her conference in Phoenix.



Anyway, the point is, Triangulation No. 115, listeners, go watch it.  Listen to it, watch it, whatever.  It's 45 minutes, and it is so full of just - I don't know what Esther has.  Esther has a way of distilling stuff.  I mean, it's sort of her job.  It's what she does.  But, and I love - I thought maybe I would go back through and try to find a lot of her little one-liners, but I didn't have time.  One thing that I did love was that she's explained that her goal in weightlessness was she decided I want to be weightless long enough to be bored.  Of weightlessness.  I thought that was perfect.



LEO:  She's been weightless seven or eight times.  I don't know if she has - I think she still enjoys it.  I don't know if she's bored yet.



STEVE:  But she's an avid swimmer.  And wherever she is, she swims.  And so I thought, well, I wonder, like, swimming and weightlessness.  But I love that concept.  Because, I mean, if I were weightless, oh, my god, there's all kinds of things.



LEO:  It's exciting, yeah.



STEVE:  I want to try spinning axially.  And I want to spin, like, I want to do all these different things.  But imagine getting to the point where you're bored with it.  That's like the perfect, I mean, like...



LEO:  Now we're talking.



STEVE:  Now we're talking, exactly.



LEO:  She wants to go to Mars.  You saw that.



STEVE:  She wants to end her life at Mars.



LEO:  Yeah, because there's no coming back, yeah.



STEVE:  Yeah.



LEO:  I would go.  I'll go.  Yeah.  I'm available.



STEVE:  Okay.  I did want to wrap up, because I had not caught up, with "Breaking Bad."  I saw a couple of tweets from people who said, Steve, you're a little slow on the uptake here.  To which I say yes.  Leo, it's the best thing I've ever seen [indiscernible].



LEO:  Aw.  It's really - it's a great show.  And the last season is fabulous, yeah.



STEVE:  Oh, my god.  It is, I mean, I'm not kidding, this is one, I was trying to think of this is something I will repurchase the box set.  We have six episodes left, and they're shutting it down.  I will purchase the box set and probably watch the whole thing through a few more times, in the same way that I can read Peter Hamilton novels after - with a spacing of a few years.  It is fabulously written and acted and assembled.  I'm just stunned.  It's up for 13 Emmys this time.  Bryan, the lead, Cranston, has won three times for Best Actor in a Dramatic Series.



And what's really interesting is how they evolve his character over six seasons from sort of basically a good guy who's in a bad situation, to somebody who can pretty much justify anything he does.  And I also love it that it's also got that whole - the whole Mafia don-esque thing happening because it's like an overriding theme with the Mafia types that their families come first.  Family is so important.  And that is exactly where Bryan always goes, or the character, Walt, always - Walter White - goes for his justification for things.



Anyway, for what it's worth, for those who didn't see the "Talking Bad" segment - it's an hour after the show airs on Sundays.  I watched them both because now I'm a serious fanboy.  And the creator is very happy with what they did.  I mean, everyone, huge tension now exists among the community of us, of which I now proudly count myself a member, of people watching "Breaking Bad," what is going to happen?  How are they going to wrap this up?  And the writers are tickled to death.  They are extremely happy with how this wraps up.  Sort of like every aspect of this apparently gets tied up.  So, and we don't know any more than that.



But anyway, it's just, wow.  I will say again, I tried to watch it once, and the first couple episodes just didn't get me.  I just thought, eh, I don't think this is for me.  If you've had that experience, push on.  Give it - the first season I think was only seven episodes.  Yes, the first season was seven because they probably weren't too sure.  AMC was like, eh, well, we'll give you a commitment of seven.  Then they had three seasons of full-length, full-season seasons.  So, wow.  Just wanted to say it rocks.



Speaking of that, I did make a faux pas, a minor one, last week where I mentioned Bitmessage and blockchain in the same sentence.  I only - I know that Bitmessage does not use the blockchain technology.  Someone said, "Steve, not the blockchain," because Bitmessage does not keep everything forever, whereas the blockchain is everything forever.  Bitmessage uses a variation where things expire after a couple weeks.  I did mention that last week, but I shouldn't have used the term "blockchain."  So for people who are watching that closely, I apologize for that and wanted to correct that.



SpinRite continues to run fabulously forward.  We are now beginning - yesterday I posted a test release that is beginning to transfer data.  We have found and killed the weirdest anomalies that people have found.  People have 133 MHz Pentiums, Leo, that we're testing this on because of course SpinRite needs to go all the way back to the dawn of time.



LEO:  Where did you find that?



STEVE:  Oh, I mean, they're there.



LEO:  That's fun.



STEVE:  And there was a subtle problem I had on a machine that had less than 16MB of RAM because it went looking down in conventional memory for an additional allocation, and I had forgotten to remove that from the allocation bitmap.  So we're finding all kinds of things.  It is looking like, with the first release of SpinRite, I'm going to at least look into incorporating the AHCI controller support, the advanced host controller interface, which I was thinking I was going to put off to 6.2, because I look at everything I've done so far, and it's all the perfect foundation for supporting that next-generation controller also.  And I would love to just have both of those bases covered.  So anyway, we're moving forward really well, doing lots of testing.  And now people - we're beginning to transfer data from drives.



LEO:  Very exciting.  All right.  We're going to learn about PGP, and I'm looking forward to this.  We should say, by the way, PGP is a commercial product created by Phil Zimmermann and sold by, now, by Symantec.  I presume you're going to talk, not about the commercial project, but the PGP protocol and its various implementations, including...



STEVE:  Right, and its history and so forth.



LEO:  History, yeah.  Because I use the open source GNU Privacy Guard and find that to be an excellent choice, a non-commercial choice.  So let's talk about PGP.



STEVE:  Okay.  I always wondered where the name came from because it sounded like modesty, you know, Pretty Good Privacy.



LEO:  Eh, it's okay.



STEVE:  And I thought, well, can I have better than that?



LEO:  I'd like Really Good Privacy, RGP.



STEVE:  I'd like RGP.



LEO:  Yeah.



STEVE:  Yeah.  It turns out that the wonderful fictional community of Garrison Keillor's Lake Wobegon sported, among many other memorable locations, a grocery store named Ralph's Pretty Good Grocery.  And apparently Phil Zimmermann was a fan of Lake Wobegon, and he drew his inspiration from Garrison's whimsy, calling his effort Pretty Good Privacy.



LEO:  You also know Phil was not the best namer of things.  But that's a - he was a good coder, though.



STEVE:  Yes.



LEO:  That's what really counts.



STEVE:  So the good news is the privacy is actually quite a bit better than just pretty good.  In fact, it's truly state of the art.  And we'll talk about some of those details here in a second.  There was one little mistake which hurt the privacy in the early days, before this really happened.  Actually this was at v1.0 that really didn't see much attention.  It wasn't until PGP 2.0 that it really took off.  But in v1.0, Phil made the mistake, which is always tempting for someone who's interested in cryptology, of doing his own cipher.  How many times on this podcast have we warned people.



LEO:  Yeah, please.



STEVE:  Do not write your own bit-mixing technique that you're sure is the best thing anyone has ever come up with, and your mother can't figure it out.  That's not the bar you will need to get past.



LEO:  No, no.



STEVE:  Phil did, unfortunately, invent his own symmetric cipher named BassOmatic in PGP 1.0, which was rather quickly and embarrassingly found to be insecure.  Over a discussion at the Crypto Conference in 1991, someone said, uh, you know, Phil, I was looking at BassOmatic.  Uh, maybe that's not such a good idea.  And in the source code Phil explains that BassOmatic got its name from an old Dan Aykroyd SNL ("Saturday Night Live") skit involving a blender and a whole fish.  Apparently the BassOmatic algorithm does to data what the original BassOmatic blender did to the fish.  Thus the name.



The good news is BassOmatic is no more the cipher.  And as is the case for all good state-of-the-art crypto systems, it is multi-algorithm completely.  What happened was initially it went with RSA and IDEA, which is - the IDEA is a very good symmetric cipher.  It was unfortunately intellectually encumbered, intellectual property encumbered, as was RSA, as we know.  Of course RSA had patents on it.  But patents have all finally expired.  There were non-encumbered alternatives that were available.  And so PGP was able to fall back and use those.



So the way to think of PGP, and thus really the reason for its success, is it isn't just by any means about email encryption.  That may be sort of like the plane on which most of us have some intersection with PGP.  But it is truly a generic, nicely designed, complete crypto system.  I spent some time, read the RFCs, dug into the format and semantics.  And I came away feeling very impressed.  Anybody could confidently use PGP for any application that it is intended for.  It's had, because it began back in '91, it's had a long history.  And we're now at PGP 5.0, sort of like in the formal versioning.  Leo, you mentioned GnuPG, which of course is GPG, which is that version.  There's also OpenPGP.  OpenPGP is sort of the standards body of which the other PGPs are then implementations.



LEO:  It is a standard.  It's RFC 4880.  So, yeah.



STEVE:  Right, right, and is embodied in a library of code so you can put command line frontends; you can put GUI frontends; you can use this block of code as your reference code for PGP.  So it supports multiple algorithms for signing, for authentication, for encryption.  It originally had a non-hierarchical flat keying system.  And I didn't realize until I read the spec, you can use a shared secret key...



LEO:  Hmm, I didn't know that.



STEVE:  ...or an asymmetric key, either way.



LEO:  Right, which is how most people do it.



STEVE:  Exactly.  And so here's, I mean, and what I like about this is the protocol is the kind of thing we've talked about often.  I will describe it to you, and I have described exactly the same sort of thing in, like, 10s, 20s, 30s, maybe not hundreds, but tons of different contexts. 



So you have text.  Now, because textual content is normally highly compressible, doing something like a deflate or a zip, doing compression is probably the first thing you want to do.  You cannot compress encrypted data because it's inherently pseudorandom, if it's good encryption.  So you need to compress it, if you're going to, beforehand.  And most PGP content is compressed because, once you encrypt it, it becomes binary.  And binary is often not safe to pass through email gateways if email is the conduit you want to use.  So that requires that the binary be inflated back into ASCII - and we'll talk about how that's done - making it larger.  So it makes sense to first make it smaller, then encrypt it, then ASCII-ize, it which is going to inherently make it larger.  The result, though, is going to still be smaller than if it was non-compressed because you're only making it a third larger.  And typically text compression generates huge levels of compression.



So you take the text and compress it.  Then, if you want to sign it, you hash that result and then encrypt the hash with your, that is, the sender's, your private key.  So what we have at this point is a hash of the text which is encrypted with your private key.  So obviously at the other end, if somebody wanted to verify that it hadn't been modified and that you were the sender, but if it wasn't encrypted, that is, you could sign without encrypting, then all they would have to do is they would hash what they receive and then decrypt the encrypted hash that you sent using your public key.



And because of, as we know, the nature of asymmetric keys, in order for it to properly decrypt, it had to have been encrypted with your private key.  So decrypting the hash with your, the sender's, public key guarantees that the hash was made with someone having your private key.  So, and then, if the results match, if the hash that was sent matches the hash that was computed right then, then we know that the document has not been altered.



So that's the signing side.  And again, nothing special about this.  I think one of the nice things about this is that Phil just stayed with standard, by-the-book protocol, doing nothing fancy.  So once that's done, if you do want to get - so that gives you authentication and verification that it hasn't been altered.  If you also want privacy, then you get privacy from encryption.  So then a pseudorandom number is pulled out of thin air, only meant to be used once, so nice and long.  And that is used as the key for symmetric encryption.



So a nonce, as the term is, n-o-n-c-e, is grabbed from a pseudorandom number generator that is a random one-time use string of bits.  That keys a symmetric cipher, and the cipher could be - the cipher is specified in the headers so that the recipient knows which cipher to use for decrypting.  And there's the standard range of ciphers.  AES is there.  There are some stream ciphers, and there's IDEA, 3DES, and a number of others.  So again, it is cipher-agnostic within the protocol, and the headers describe which ciphers were used, whether signing is there, whether privacy is present and so forth.



So a random number is generated.  That's used as the key to encrypt the document.  And then, much as with the hash, the random nonce is encrypted with the recipient's private key.  So you know where this is going to be sent to.  So you use their public key - did I just say "private" a second ago?  I might have said "private."  With emphasis.  Which made it extra wrong.  The recipient's public key.



LEO:  You can see why this is challenging for people.



STEVE:  Yes.  Yeah, you ought to be very careful with this.  So again, the nonce, which was chosen at random and used to encrypt the document, is encrypted with the recipient's public key, which is all the public, all anyone has.  So that protects the key while it's being sent.  So all of this is bundled together and shot off to the recipient.  The recipient receives this blob, and the PGP technology at his end looks at the headers, sees which ciphers are used, is it encrypted, is it signed and so forth, and basically reverses the process.  There, bound in, will be the key that was encrypted with their own public key.  So they use their private key, which only they have, to decrypt it.  And so what this is doing is this assures the sender that nobody but the valid recipient can view the contents.



So you're saying, I want to send something.  Yes, I want it to be encrypted.  But, whoa, I want to make sure only the person I'm sending it to can decrypt it.  Well, given, if it's true, that the recipient is the only one who has the private key that matches their public key, then you use the public key to encrypt the encryption key so that at the receiving end the recipient can use their public key to decrypt the encryption key.  That gets the nonce back at their end, and then they use that with the same symmetric cipher specified in the headers to turn it back into compressed text, assuming that it was compressed, and then they decompress that in order to get readable text.  And so that's it.  I mean, nothing, there's no other craziness.  It's just standard, by the book, this is the way the world has figured out how to do crypto.



Now, there were some extra challenges, though, in the use of email because email has traditionally been ASCII.  And if you start moving binary data through email, you quickly find out all the horrible things that the email channel does.  Gateways, for example, sometimes they'll just change the line endings from UNIX-style to DOS-style, or DOS-style to UNIX, meaning that UNIX just uses a linefeed; DOS uses famously a carriage-return linefeed.  And so the idea, well, we're UNIX here, so we're going to strip the CRs and just make them LFs.  Well, okay.  But if this is not readable, if this is encoded somehow, then you've just broken the signature, at the very least, and probably caused all kinds of havoc.



So in the OpenPGP spec which is now sort of the standard specification, as you said, Leo, enshrined in RFCs, they call it "ASCII armor."  They take this very seriously, the problems that email gateways present.  And so it's certainly well known that many of the links on the Internet traditionally were seven bits.  Many people may, old-timers among us, may remember that modems sometimes operated with, like, you had seven or eight bit of data, and then one or two bits of stock bits, and then sometimes parity.  And so actually you might even have a channel.  Your actual channel wasn't even a byte wide.  It was seven bits wide.  And so you could only send the first half of the 256-bit set.



And the good news is text, the ASCII character set, fits all within that first half.  The first 32 are all the control characters.  And then you've got special characters, uppercase ASCII, or uppercase alpha, lowercase alpha, and then the numerals, and then tildes and backslashes and so forth.  So what they do in order to convert something which is - by the time PGP is through with it, it is definitely binary.  I mean, you've taken this - you'll have readable headers.  You'll have ASCII headers.  But the actual content, the body that is described by what's inside has been turned into absolute pseudorandom noise that is binary.  So that cannot safely be moved.



I mean, if you were storing it in a file, if you were using it in a file system, it can remain that way.  Or, if you were uploading it somewhere for someone else over a channel which is inherently binary capable, again, you don't need to change it.  But if you're emailing it to someone, they're just, essentially, because email was designed for text, it will preserve case, we know that, and it will normally not mangle printable characters.  But unprintable characters, very much like white space of various sorts, tabs and spaces sometimes get transliterated.  Character terms can be removed, as I said.  So you just can't let that happen.



So this ASCII armor approach uses a well-known approach known as Radix-64, where we want to - what we're sending is essentially Radix-256, that is, they're 8-bit bytes of binary data.  We need to reduce those to six bits because six bits gives us a choice of 64 symbols that map into six bits.  And we can easily find 64 symbols that are printable that we know no email gateway will mess with.  And we use uppercase A through Z, lowercase A through Z, zero through nine, plus, and forward slash.  And so that gives us that, I've just described, that 64 symbols.



We know that email maintains case, so it's not going to change the case of things.  And so the way they convert this is sort of clever.  Imagine that you take three bytes together.  Well, three bytes of eight bits per byte is 24 bits.  So you can take that 24 bits and divide - which starts off as three sets of eight.  You can subdivide, you can re-divide that 24 bits as four sets of six because six times four is 24, just as three times eight is.  So now, simply by chopping that 24-bit string into four chunks of six bits, then we take each chunk of six bits and use a map to look up which of the 64 characters we want to translate it to.  And that allows us to take a binary blob, which is not safe to email to someone, turn it into text, essentially, and that's where I said it increased the size by a third because it's going to take every three bytes and turn that into four characters.  So that's a third larger than it starts out.  But it can move through email safely.



At the receiving end, the process is simply reversed.  Sets of four characters are then converted back into three bytes in binary.  That allows PGP to reconstitute the original binary.  And then it just reverses the process, as I described before, at the recipient end.



So as we said, there's flavors of PGP, OpenPGP, GnuPG.  Leo, you and I talked last week about Mailvelope, which is a plugin for Chrome and Firefox.  There is a nice OpenPGP compliant client for iOS called iPGMail.  Android has a number of apps, not surprisingly.  There's APG...



LEO:  Yeah, we use that one, yeah.



STEVE:  ...which is an OpenPGP implementation.



LEO:  Still not ideal on mobile, unfortunately.



STEVE:  No, agreed.  There's also OpenPGP Manager, and there is even a PGP-based secure messaging solution, an SMS that uses asymmetric encryption.



Now, stepping back from all of that, there's, like, the problem that we have with it is, my sense is, and I've articulated this before, is the fundamental problem that the world has, not just PGP, not just us here on the podcast, but the problem that the Internet has is authentication.  And it's one of the topics we talk about all the time.  That's where YubiKey came from, where all of our one-time passwords, the time-based passwords, the multifactor authentication, I mean, we're talking about authentication all the time because that is the problem.  We have the technology to establish between two people an absolutely secure channel.



But when the people are remote from each other, there's no way to prevent a man in the middle from bifurcating that agreement of, for example, a secure key by pretending to be the other end to each of the other ends, and creating two links with the so-called "man in the middle."  The only way to prevent that is if we mix in authentication because the man in the middle presumably cannot authenticate himself to each of the endpoints as being the people they think they're connecting to.  So this is, no matter what we do, we keep coming back to this problem.



Now, the novel approach which Phil took - because he understood about PKI, the standard Public Key Infrastructure, and there is now in the later versions of PGP the notion of a hierarchy of keys.  You can have a key which is like a certificate authority, which is able to sign other keys.  And then you could have a key above that.  They're called "levels," Levels 0, 1, and 2.  You can have a Level 2 which is able to create Level 1 keys, which is like, so it's able to create certificate authorities, which are then able to sign other keys.  So there is a notion of a hierarchy within the later versions of PGP.



LEO:  Which is generally not used.  It's really the Web Of Trust, or WOT.



STEVE:  Right.  I could see maybe in a corporate setting...



LEO:  Yes, yes.



STEVE:  ...where there you would want essentially to run your own certificate authority.  You'd use a key able to sign other keys in order to create the keys which your employees would all use.  And then they would all trust keys signed by the level - they would trust the Level 0 keys signed by the Level 1 authority, if it was like a corporate authority.



LEO:  I mean, my - what we do informally, and I've asked people to do that, is to sign my key.  And they ask me to sign their key.  You do some verification of some kind.  In fact, the signing process is interesting because you are asked how much verification you've done.



STEVE:  Yes.  In fact, that's formalized in the specification, Leo.



LEO:  Yeah, yeah.



STEVE:  There is a series of levels of how sure you are that this is the person who the identify assertion binds to.



LEO:  Your choices are:  I will not answer, I have not checked at all, I have done casual checking, I have done very careful checking.  And then you can look at people's signatures - on my key, for instance, I have 20 or 30 - and see how confident they are in that signature.  I think this is a good system, mainly because it eliminates this Hong Kong Post Office problem.



STEVE:  Yes, yes, exactly.  And therefore, I mean, that is the problem with the public key infrastructure, the formal PKI that we have where, exactly as you say, there are some certificate authority - I mean, there's many problems.  There's, like, you have to trust them.  You have to trust what they do.  You have to trust that no one is impersonating them and so forth.  So as you say, Leo, this Web Of Trust is essentially sort of a self-bootstrapping sort of community agreement.  Lots of people have made the assertion that you are you.  And so when someone looks at your key they go, wow, this seems reasonable.  But...



LEO:  You can see my current key if you - by the way, the other thing, and I get a lot of people sending me encrypted email, saying can you read this, and is it working, and will you sign it and send it back, et cetera, et cetera.  And I'm certainly open to doing that.  My key is public, as it should be, on my web page, Leoville.com.  But one thing I find people often forget to do, and all of these tools will let you do this, is upload your key to the key server.  It's easy.  You can attach it to an email.  But when you create a key, there's always a command, send key to server, public key to server, that is safe, in fact encouraged.  That's how other people can sign it, and it's how I can get it.



So if somebody sends me an email, and I want to see if I can talk to them securely, I can check for their key on the public server, add it to my keychain.  I have almost a hundred keys now from people who've sent me email in the last few weeks.  And I will continue to add names to that because I think we all ought to use it.  And of course every email we're encrypting is completely stupid and trivial.  That's not the point.  In this case, it's to use this system so that we have it.



STEVE:  So, yeah.  So I guess where I come back to is I wanted to absolutely give our listeners every confidence that PGP in all of its various flavors - now, that's, I mean, understanding that, as I said last week, a mobile platform is inherently a little scary.



LEO:  It is, yeah.



STEVE:  Because it's mobile.  We were talking about Bitcoin and keeping your whole Bitcoin fortune on your phone.  That's, eh, I don't know.  Mobile platforms are - they're just exposed to more danger.  And we know that exposure is unfortunately a concern for security because we don't have perfect security.  So, subject to implementation mistakes, the fundamentals of PGP are as good as any known.  I mean, it is serious, it's been seriously vetted.  It's mature.  It's old.  Real security people have looked at it and said this works.  And it has, there has been versioning evolution over time.  Subtle, small, and sometimes just theoretical mistakes in the definition have been found, have been fixed and eliminated, and PGP moves forward in versioning.  So it's everything that's there is absolutely solid.  So if somebody has a use for it, I would endorse it without reservation.



LEO:  Let me just show you, for those who are curious, this is what you see on encrypted email that has not been encrypted.  And the important point here is that the metadata, the to and from information and the subject, data, and time, along with all the other headers, are visible.  But the message itself is just gobbledygook.



STEVE:  Right.



LEO:  That Base64 gobbledygook that you were talking about.  All in ASCII, yeah.



STEVE:  Right.  So anyway, so that's really where I stand is the technology is solid; the spec exists.  Because it's been around for so long, it's cross-platform.  It's available with - a friend of mine was saying that he looked at IMail, and it's very easy to add PGP technology to the Mac platform.



LEO:  Yeah.  This is so simple.  GPG Mail is the easiest tool ever.  And there's GPG for Win, as well, that is very easy for Windows.  It's tougher on iOS and Android, unfortunately.



STEVE:  Yeah.  So I guess where I could - I've asked myself, okay, well, probably most of us are not using it.



LEO:  Nope.



STEVE:  And, like, why?  And it's like, well, okay, I'm - I do have instances where I'm feeling self-conscious about my mail going in the clear.  And so - and I have a couple very close friends who I communicate with.  And I'm sure that sometimes I'm writing things, and I find myself thinking, huh, when is this going to trip any false positives because I'm writing what I am?  So there, if I had my friends set up with PGP, and I were, then I could be corresponding with absolute comfort knowing that that wasn't happening, that there was absolutely no leakage of my mail.



Now, it is the case, as we discussed previously, that the fact of my communicating is public.  But that's a consequence of email.  We were talking about the metadata headers that route the mail from sender to recipient.  Well, that has to be visible.  So the fact that I'm communicating, of course, with a couple of my friends, that's - I'm doing that all the time.  Who cares?  So it's important to remember that that isn't being protected.  And we will be talking about, initially about Bitmessage because so many people who are listening want to know the details of Bitmessage.  But I'm absolutely certain that before long we're going to start seeing some solutions surface, just because I think unfortunately the climate has created a demand.



LEO:  Yup.



STEVE:  And we've got all the technology we need to fulfill that demand.



LEO:  Yeah, it exists.  In fact, in the early days of PGP, the government was very, very nervous about it, forbade its export and so forth, because they knew this is strong encryption. 



STEVE:  Well, and Phil famously printed the source code on pages of a book that the MIT Press published because the First Amendment protects the export of books.



LEO:  There you go.



STEVE:  And so he just thumbed his nose at the government and said...



LEO:  It leaked out, and it's everywhere.



STEVE:  ...here you go.



LEO:  And they gave up on those restrictions.  The other thing I would say I don't wait until it's just private stuff.  Use it all the time.  Otherwise...



STEVE:  It'll never get critical mass.



LEO:  Well, and when you use it, it's like saying, hey, by the way, this is the one you want to try to decrypt.



STEVE:  Oh, right.  Oh, exactly [laughing].



LEO:  The answer is not to only encrypt stuff that's private, but to encrypt everything.  And that's what I do.  If I have your key, you will only get encrypted mail from me.  The other thing that you didn't touch on but is also important, and one of the reasons I started using PGP 16 years ago, is it has as one of its features the ability to sign mail to verify its identity.  And because people from time to time impersonate me and so forth, I've used that for a long time.  It confuses the hell out of people when they see this signature.  But if you have PGP running, you can verify this came from Leo.  Otherwise, as you well know, it's very easy to spoof email.  So that was the main reason I started using it is merely - and it might be a good reason for everybody to use it - a cert, this is authenticated, this is me.  And there's also a certificate system, S/MIME, which I suppose one day we should do a story on, a show on, as well.



STEVE:  Yup.



LEO:  Because that's another way a lot of - it may be easier to use.



STEVE:  That's, well, yeah.  That is the - I know that many clients have that built in as opposed to needing it added on.  And it is a traditional PKI-style, public key infrastructure...



LEO:  With a signed certificate from VeriSign or...



STEVE:  Exactly.



LEO:  Or the like.



STEVE:  Oh, and I did forget to mention that PGP now also supports expirations on keys, so that you can get a time-limited key that will - like your corporation may issue it to you, just as, again, because it's good to keep them fresh.



LEO:  If you look at my keys, only use the most recent one, folks, because I didn't set a time limit on most of my keys.  There's many since 1997.  You can also now, and this is really good, this is new, create a revocation key.



STEVE:  Yup.  You can revoke them.



LEO:  So that's what I would suggest is perhaps not set an expiration date, but do make sure you get and save in LastPass or somewhere a revocation key.  That way you can from time to time revoke old keys.  Because all my keys are up on the key server.  And I do occasionally get email from people that is encrypted with an older key that I no longer have access to.  So use the most recent key.  Or just get it from my web page, Leoville.com.  And if you've got an old key for me, get a new one, update it.



STEVE:  Pushing back for a minute, I know we've got to go, but if we only had a solution for authentication.  And I don't know...



LEO:  Well, guess what?  All the strong rumors are going forward that September 10th Apple's going to announce a new iPhone with this AuthenTec fingerprint reader built into it.  And this is more than rumor, in my opinion.  I've heard it now from sources that are unimpeachable.  So that's going to be widely available is a strong authentication, we hope, a strong authentication system built into the phone.  Half the people who use smartphones use iPhones.  So that could change things.



STEVE:  Yeah. 



LEO:  That could change things.  I'd like to see Android, though, do that as well.  Apple's a little bit...



STEVE:  Oh, I agree.  And it has got to be - it's got to be universal.



LEO:  It's got to be universal.



STEVE:  It's got to be something.  For it to work, everybody needs it.



LEO:  Yeah.  Thanks, Steve.  Great show, as always.  Maybe one of the most important you've done.  I have a feeling this will be oft downloaded.  Encourage people to get a copy of it and share it with your friends.  Steve has transcriptions, text transcriptions by a human, so they're very good, on his website, as well as 16Kb audio for people who really have limited bandwidth.  That's GRC.com.  While you're there, get SpinRite, the world's best hard drive maintenance and recovery utility, getting better all the time.  And lots of other freebies there.  It's worth browsing around.



If you like Steve, if you like this show, visit GRC.com.  You'll find plenty to enjoy there.  And of course you can follow him on Twitter:  @Sggrc.  We also have high-quality audio and video of the show available for download on our site, TWiT.tv/sn.  Or you can watch us live.  Some people do.  They want the latest.  11:00 a.m. Pacific, 2:00 pm. Eastern time on Wednesdays.  That's 18:00 UTC on TWiT.tv.  Please stop by.  We love it if you watch live.  And if you can't, you can always get a version from us or Steve, or subscribe in your favorite podcatcher.  You'll get it downloaded.



STEVE:  And again, a strong urge to go see Triangulation Episode 115, Leo and Esther Dyson together.



LEO:  Thank you.  It was really fun.



STEVE:  It was just really delightful.



LEO:  Today we're going to interview Phil Rosedale, who founded Linden Labs, the creators of Second Life.  That's going to be - he's a very interesting person.  You know, Steve, I kind of want to close with this.  We talk a lot about engineering, computation and so forth.  There's a video going viral.  You know I sent my son off, Henry, to University of Colorado Boulder this morning, his freshman year in college.  And all over the country kids are going back to school.  This is a video that was posted on YouTube of a speech given by a senior engineering student to the incoming freshmen at Georgia Tech, one of our great schools.  And I think it's a great, inspiring way to end Security Now!.  Steve...



STEVE:  Cool, thank you.



LEO:  Thanks for the show.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



[Clip] We chose Georgia Tech because we want to do the impossible.  And this school is equipped with the resources and faculty to help us do just that.  And so, in the words of Sir Isaac Newton, if I have seen further, it is by standing on the shoulders of giants.  Georgia Tech is proud of its many traditions, but the one I find most exciting is our tradition of excellence.  Our mission as students is not to follow in the footsteps of the astronauts, Nobel Prize Laureates, and presidents who graduated before us, but to exceed their footsteps, crush the shoulders of the giants upon whom we stand.  We here are all such innovative people.  So I am telling you, if you want to change the world, you're at Georgia Tech.  You can do that.  If you want to build the Iron Man suit, you're at Georgia Tech.  You can do that.  If you want to play theme music during your convocation speech like a badass, we're at Georgia Tech.  We can do that.  I am doing that.



[Laughter]



LEO:  And that would be true of MIT, Cal Poly, Rensselaer, and all the great technology schools in this country.  If you're going to college right now, the world is yours to change.  We need a lot of help.



STEVE:  Yup.



LEO:  To do it.  Thank you, Steve.



STEVE:  Thanks, buddy.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#419

DATE:		August 28, 2013

TITLE:		Listener Feedback #174

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-419.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve has questions and answers, 10 of them.  He'll also talk about the latest security news.  Stand by.  Security Now! is next.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 419, recorded August 28th, 2013:  Your questions, Steve's answers, #174.



It's time for Security Now!, the show that protects you, your loved ones, your privacy online and off.  And I say "off" because we do some of that, too.  He's Mr. Steve Gibson, our Explainer in Chief here, from GRC.com, the man who created ShieldsUP!, SpinRite, the world's best hard drive maintenance utility, and of course first discovered spyware, coined the term, and wrote the first, believe it or not, antispyware program, lo these many years ago.



STEVE GIBSON:  Ah, yes.  I used to have hair back then, Leo.



LEO:  And here we are in year nine of the Security Now! show.  That's a long time for a show to be going.  That's great.



STEVE:  Now, the reason it continues, though, is that we don't take ourselves too seriously.



LEO:  No.



STEVE:  Which I'm going to prove with the first item here on our list to discuss.



LEO:  This is a Q&A episode.



STEVE:  It is.



LEO:  So we'll get a little news in.



STEVE:  We first need to discuss de-waxing ears.



LEO:  All yours, sir [laughing].  I actually have some stories to tell along those lines, but go ahead.



STEVE:  Well, that's why we're discussing it, because I heard you on TWiT talking about how you are - this was on Sunday - you had been declined for having your custom ear pieces fitted.



LEO:  My ear molds.  The audiologist said you've got to clean your ears first.  And she said, "I don't do earwax removal.  You've got to go to the doctors to do that."



STEVE:  Well, not true.  That's why I wanted to put this at the top of the show, Leo.



LEO:  Oh, good.  Thank you.



STEVE:  I have the solution for your earwax...



LEO:  Of course you do.



STEVE:  ...removal needs.



LEO:  No matter what it is, Steve will - this is what I like about geeks, particularly people like Steve.  They'll do the research.  They'll find the best.  Doesn't matter.  Could be a projection TV.  It could be earwax removal.  It doesn't...



STEVE:  And you can bring this up on the screen:  www.EarClear.com.



LEO:  You know, the Giz Wiz had some verkakte ear vacuum that he tested.  I couldn't do...



STEVE:  Yeah, those are ridiculous.  So this was maybe - this was after I had kicked in to my "let's take ourselves seriously" about health and supplements and all that stuff that I've been doing now for eight years.  And always, my entire life, my right ear tended to collect wax.



LEO:  Yeah.  It's a genetic thing.  It's actually a marker.  23andMe discusses this.  There are two markers for earwax.  There's wet and flaky, wet and dry.  And you and I probably have the wet marker.



STEVE:  I think that's probably true.  What I will tell you is the idea of using a syringe absolutely works.  It is doctor approved.  That's what the doctor does.



LEO:  Now, on this page it looks like you're shooting Coca Cola into your ear.  That's probably not the case.



STEVE:  No, he put the Coke can - he's an interesting guy.  He actually called me on the phone when I ordered some of these.  So I think it's a rather small operation.  I don't think he's - and I don't remember whether there was a PayPal button at the time.  His is very expensive.  His is, like, $40.  But there's one for $6.49, that first link in the show notes, HealthEnterprises.com, earwax removal syringe.  Anyway, the point is...



LEO:  Can't you just get a bulb or something to do that?  I mean...



STEVE:  Well, you want enough volume - so let me just get this out, Leo.



LEO:  Oh, get it out, get it out.



STEVE:  You do this in the shower.  You have your syringe there...



LEO:  It can be messy.



STEVE:  ...in the shower.  And so you pull the plunger out, fill the little tube up, put it in at the top, and just squirt a syringe worth of warm shower water into each ear.  I have turned several friends onto this, in addition to myself, and they cannot believe it.  I mean, they were doing Q-Tips and coat hangers and...



LEO:  Oh, don't do coat hangers.  Holy moly.



STEVE:  It was bad.



LEO:  That would be a bad idea.



STEVE:  It was bad.  And so this is, I mean, this is the way you solve the problem.  And so, if you do this just when you do your daily shower, you just squirt one syringe worth into each ear, in a couple days they are just - it's amazing how effective it is.  And I wouldn't be sharing this if it didn't absolutely work.



LEO:  Thank you.



STEVE:  And just solve the problem once and for all.



LEO:  Because of you, I'm going to get my in-ear molds made.



STEVE:  Yeah.



LEO:  That's pretty funny.  They also, by the way, the same company makes vinyl eye patches and pill box - pill splitters.  So it's a good company.  They're in the biz.



STEVE:  The EarClear.com folks?



LEO:  Yeah.  Acu-Life, yeah.  No, no, no, the Acu-Life - Health Enterprises.  The $6.49 one.



STEVE:  Okay, yeah.  I went for the $35 or $40...



LEO:  You went for the expensive one, huh?



STEVE:  Yeah, well, it's actually the first one that I saw.  I don't how because Amazon has, like, a million of them.  You put in, like, "ear syringe," you just get a bazillion of them.  Somehow I found this guy.



LEO:  The $40 one.



STEVE:  Yeah, he was - he took himself very seriously, too, on the phone.  He was like - and it comes with - well, in fact, here's mine.  I had mine...



LEO:  Holy cow.  That thing's got a lot of volume.



STEVE:  Yeah.  It's just, yeah, nice little pop.  And so you just fill it up and then squirt it into your ear.  And he talks about how it's got this little bent angle so that you can't go too deep.



LEO:  That's good.  You don't want to do that.  Yeah, you could injure yourself.



STEVE:  And he's got his little set of instructions it comes with.  And, yeah, anyway, all I'm saying is, that's the solution.  And it works perfectly.  It just ends the issue for anyone who has an issue with earwax.



LEO:  Okay. 



STEVE:  Okay.  Actually, we're going to do some security, Leo.



LEO:  Good.



STEVE:  Yeah.  On the subject, the category of "that didn't take long," we have a huge lineup of, like, everybody being shaken out of the rafters who have secure communication solutions to the NSA dilemma.



LEO:  Oh, god.  You know, I got some emails from people talking about nyms and all sorts of things.



STEVE:  Yeah.  And so the phase we're in at the moment is the everybody rushing to capitalize and cash in on the current frenzy over security.  That'll pass, and we'll end up with the right solution, or a couple of them.  At the moment, everybody's jumping in.  So of course Kim Dotcom...



LEO:  Of Mega fame, yeah.



STEVE:  ...of Mega fame, who's - he's in New Zealand; right?



LEO:  Yes.



STEVE:  And he's not happy with the New Zealand government because they're beginning to make some noises about changing regulations to thwart his ambitions.  Anyway, so his deal is he's going to fill in the - fill the shoes of Lavabit.



LEO:  Yes.  Of course he is.



STEVE:  Uh-huh.



LEO:  Being the humanitarian that he is.



STEVE:  Yes, exactly.  So Vikram Kumar, who is with Mega, told ZDNet that the company was being asked - was being asked - to deliver secure email and voice services.  We don't know who's asking, but somebody, apparently.  He says...



LEO:  Please, please, Mega.



STEVE:  You have to solve this problem.



LEO:  You, it's up to you.



STEVE:  In the wake of the closures, he expanded on his plans.  Kumar said work is in progress, building off the end-to-end encryption and contacts functionality already working for documents in Mega.  Quoting him:  "The biggest tech hurdle is providing email functionality that people expect, such as searching emails, that are trivial to provide if emails are stored in plaintext (or available in plaintext) on the server side," says Kumar.  Continuing to quote him:  "If all the server can see is encrypted text, as is the case with true end-to-end encryption, then all the functionality has to be built client-side.  [That's] not quite impossible, but very, very hard.  That's why even Silent Circle didn't go there.  A big issue is handling emails to and from non-encrypted contacts when Mega's core proposition is end-to-end encryption," says Kumar.  Of course, yes, that's what we've been talking about the last couple weeks.  So he says, "On this and other fronts, Mega is doing some hugely cutting-edge stuff," he says.  "There is probably no one in the world," Leo, "who takes the Mega approach..."



LEO:  No one.  No one.



STEVE:  Nope.  Nope.



LEO:  And that's because they're all so stupid.



STEVE:  "...of making true crypto work for the masses."



LEO:  True, true.



STEVE:  "Which is," says Kumar, "our core proposition."



LEO:  It's what we do.



STEVE:  So we don't know yet what he's up to.  He talked about Bloom filters, which is an interesting filtering technology.  Maybe it's going to provide searching of encrypted email.  I'm not sure why that's a big need, but we'll see.  So they're weighing in.  Also, Moxie Marlinspike has apparently come in off of his boat and...



LEO:  You know, it brings them out from all the corners, doesn't it.



STEVE:  Exactly.  [Indiscernible].  Wait, wait, we can solve this.  So Dan Goodin, our friend over at Ars Technica, reported.  And so we know about RedPhone.  RedPhone was the secure solution that Moxie was doing with ThoughtCrime.org.  Remember, ThoughtCrime is Moxie's site where he's working on this.  So now they've got something called TextSecure for Android and iOS.  And again, details are still unclear.  And I'm a little uncomfortable by the way they're trying to solve the problem.  The problem is, the problem with texting security is that the protocols like OTP that we've talked about, are that they're online protocols like SSL.  If you think about it, the whole idea of a handshake in SSL is real-time exchange of cryptographic content in order to do key agreement and obtain a secret which you share, which you then use to encrypt your interchange.



The problem with text messaging is it's not necessarily real-time, that is, I mean, by design.  It's like email.  It can be a store-and-forward sort of operation.  So the question is, how do you secure this?  And so I think what we're going to be seeing for the future, and what we'll be covering, are various attempts and approaches and ideas.  I'm interested to see where this goes.



I think long-term, once we get out of this all, sort of this reactionary, oh my god, we're the ones who have the solution, we'll probably come up with something that works because I really do believe that a consequence of all of this will be the development by the big boys, by the heavy guns, by the RFC committee kind of guys, of some next-generation solutions.  There will be pressure to create them that we really haven't seen before.



So the reason I'm a little uncomfortable with what Moxie's doing, aside from the fact we don't really have an understanding of it, is there's something called "prekeys" which they store on the server.  And that immediately makes me feel nervous.  Apparently, when you create an account for this TextSecure, at least for iOS - and there's some confusion between iOS and Android because, if your Android machine is on, Android is better than iOS is about allowing things to run in the background.  And so there can actually be a handshake in the background with Android that iOS just will not support.  It just - iOS is going to fight you on this.



So, again, details are very fuzzy.  But what I've seen is comments like a hundred keys are pregenerated and stored on the server.  So your phone - I'm making this up now.  I'm just, it's like, okay, well, how would this work?  Apparently a hundred keys get generated.  And the idea is that that's a way for you to receive a hundred text messages in a what I can only regard as semi-secure fashion because they have the keys.  But, I mean, maybe they're encrypted so that - we just don't know.  They could be encrypted so that something - it's just impossible to guess how this thing can be secure, where your phone is pregenerating some - your phone or the server is pregenerating keys, and then somehow that decouples you from needing to be online in real-time.  But Moxie's in the game, and with ThoughtCrime, and we'll maybe get more details as this thing matures.



LEO:  Now, I'm interested in remail, the idea of remailers.  And at some point I'd like you to look at that.  The Cypherpunks, who I really trust in all of this, have to do some remailing.  Which looks like the only real way to be completely anonymous and private.  Because when you send mail, it has to be, I mean, you've got to use PGP; right?  Well, anyway, we've talked about this before.  I don't want to...



STEVE:  Yeah.



LEO:  I don't understand how somebody could provide a service, unless it's software on your desktop.



STEVE:  I completely agree.  End-to-end encryption.  We have a great question...



LEO:  Somebody may do it.



STEVE:  We have a great question that we're going to get to later in the show about the notion of maybe, well, why not let the email server do that, rather than the client?  And it's an interesting sort of thought experiment in moving that one step back toward the server, which we'll talk about.  I want to cover a couple more of these things.  There's something called Wickr, again, another one of these, oh, we've got a solution for that, W-i-c-k-r.  Not clear where the name came from.  MyWickr.com is the company.  And these guys, okay, they sort of sound like - they're using a lot of the right words.  It's free.  And it's like, okay, well, it would be nice to understand why you're doing this and how we trust you.



So it's a free app.  They show it, I think for an iPhone.  I'm not sure how much platform cross-compatibility there is.  But there on their site:  "The Internet is forever.  Your private communications don't need to be."  And so deleting stuff is one of their benefits.  So they say:  "Wickr is a free app that provides military-grade encryption" - it's like, okay, well, I guess they have to say that for Mom and Dad - "of text, picture, audio, and video messages; sender-based control over who can read messages, where, and for how long; best available privacy, anonymity, and secure file-shredding features; security that is simple to use."  So, okay, that all sounds good.



Then they said:  "We have made this app with the best available security technology, but we strongly encourage you to only send private messages to people you trust."  What?  Oh, okay.



LEO:  Whatever.



STEVE:  So, you know...



LEO:  I don't know why they even say that.



STEVE:  I guess Anthony Weiner could use this, but he needs to trust the recipient, which actually does make sense.



LEO:  Sounds like more snake oil to me.



STEVE:  Well, that's - yes, exactly.  Then they said:  "Wickr uses AES-256 to protect data and ECDH-521," so we know that that's Elliptic Curve Diffie-Hellman key exchange...



LEO:  Why, that's military grade.



STEVE:  Oh, I know, Leo.



LEO:  Yeah.  Whoa.



STEVE:  Maybe they have Navy SEALs.  They haven't said that, but maybe - "for the key exchange.  RSA-4096 is also used as a backup and for legacy app versions.  So they used to use that, but they don't anymore.  They went to elliptic curve, which is shorter keys, and it's going to be faster and forth.  Wickr also uses SHA-256 for hashing" - which is the only thing you can use it for - "and Transport Layer Security.  Encryption keys are used only once, then destroyed by the sender's phone."  Okay, that stands out, I mean, that sounds good.  "Each message is encrypted with its own unique key, and no two users can have the same AES-256 or ECDH-521 keys ever.  Our servers do not have the decryption keys.  Only the intended recipients on the intended devices can decrypt the messages."  So that all sounds good.  And blah blah blah.  I wrote more here when I was making the show notes.



LEO:  Blah blah blah is good.  That's a good summation, a summary of all of it.



STEVE:  Yeah.  So, and...



LEO:  Yada yada yada.



STEVE:  "We can't see information you give us.  Your information is always disguised with multiple rounds of salted cryptographic hashing before (if) it is transmitted to our servers."  Okay, I don't know what that means, "if."  "Because of this..."



LEO:  Well, if you never mail it...



STEVE:  Yeah, you keep it to yourself.



LEO:  Keep it to yourself.  That's really trustworthy, then.  That's the most.



STEVE:  If you don't trust anyone, Leo, just don't send it.



LEO:  I don't send it.



STEVE:  Anyway, I don't know.  Another one of these things.  Then we have Cackle - secure, safe, private, and confidential.  I don't know where - it's Cackle-It.com.  And then this is a little disturbing.  Under the "How we do it" category is, I'm quoting them, "Explaining exactly which ciphers we use at which times and for what reason..."



LEO:  Oh, no, we shouldn't tell you that.



STEVE:  "...would be tantamount," Leo...



LEO:  Tantamount.



STEVE:  Good word, tantamount, "to giving away our company secrets."



LEO:  Oh.  Oh.



STEVE:  We wouldn't want that to happen.  However...



LEO:  Look, look, they put a key on an iPhone.  Wow.



STEVE:  "What we can divulge is an incomplete list of some of the cryptographic methods we make use of:  16,384 bits of ID-based encryption."  Leo, that's a lot of bits.



LEO:  That's a lot of bits.



STEVE:  "384-bit elliptic curve encryption; 256-bit and higher AES encryption; the Diffie-Hellman protocol for the handshake."  But that's all we'll say.



LEO:  Unh-unh, no more, unh-unh.



STEVE:  No, we don't want to give away any of our company secrets.



LEO:  They're in Cyprus, by the way, Cackle is.



STEVE:  I did see that.



LEO:  Yeah.  So I'm a big fan of open source.  So, you know, obscurity...



STEVE:  I know, I know.



LEO:  Security through obscurity is not...



STEVE:  And then, you know, and then I gave money to Hemlis.  We talked about Hemlis...



LEO:  Yeah, yeah.



STEVE:  ...some time ago.



LEO:  How'd that work out for you?



STEVE:  Eh, not very well.  Heml.is.  Unfortunately, apparently everyone has been asking them how their crypto works.  They're spending time on the pretty colors on their UI.  There's been a lot of focus.  In fact, on their second update blog posting, they have a spectrum of colors, and they show which letters of the alphabet each color corresponds to because that will help you see which conversation, to, like, follow the threading of conversations.  And this is, Leo, it's very pretty.  But unfortunately, in the third update, under the topic "The questions about encryption," they wrote - this is they:  "Most questions about Heml.is is about the encryption we're going to use."



LEO:  It is.  It is.



STEVE:  Yeah, no kidding.



LEO:  Most questions is about these.



STEVE:  Yes.  "How it's going to work and details about it.  For different reasons" - now, to be fair, English is not their first language, so their English is better than my Swedish.  But they said:  "For different reasons, we've stayed away from talking too much about the details.  It's not because we're arrogant, it's just that dealing with the crypto" - now, this is - I'm quoting them from their third update.  "But dealing with the crypto community is really time-consuming."  They don't have time to...



LEO:  Ohhhhhhhhhh, we've seen that happen before.  No time.



STEVE:  Then they said:  "Whatever solution we've decided on would be criticized..."



LEO:  Wouldn't want that.



STEVE:  "...and we aren't interested in the flame war that's inevitable."



LEO:  Right.



STEVE:  Right.  "We'd rather create and get things going.  Maybe a small lesson for the crypto geeks out there would be to be supportive instead of negative."  And it's like, uh, well...



LEO:  Steve, you're not being very supportive.



STEVE:  I thought these were security guys, Leo.



LEO:  No.



STEVE:  That's why I...



LEO:  You know, it's very obvious they're web designers.



STEVE:  Well, I gave them money.  Yeah.



LEO:  They're not security guys.



STEVE:  But they did say:  "After taking all things into careful consideration, we've decided exactly how the encryption will work."  Which is nice.  I guess they're not going to tell anybody because they're afraid they'll upset us, which is not really the right strategy.  However, they said:  "We've listened to all the comments and wishes from you guys, and we are now quite happy with the implementation we're going for."



LEO:  Thank goodness.  I'm glad they're happy.



STEVE:  "It's based on free and open source solutions, and we'll release the full source we create for the usage of it."



LEO:  Oh, good.  All right.



STEVE:  So that's neat.



LEO:  Yeah.



STEVE:  "More details will follow later, closer to release."  So that's hopeful.  We'll see what they come up with.



LEO:  Mm-hmm.



STEVE:  So that's sort of where we are right now.  We're, I mean, as I predicted last week, this essentially is what's happened, is everyone's gone, oh my god, look, everybody suddenly wants security.  Didn't you say that your mother was a security expert?  Well, let's [indiscernible].  Okay, so...



LEO:  She stores all her passports on the desktop in a file called Passports.doc.  That's secure.



STEVE:  Yeah.  So that's where we are.  We'll keep track of this.  I want to keep receiving people's findings.  Send me a little - a tweet or a note...



LEO:  You don't use PGP, do you.  You don't really use email, so you don't use...



STEVE:  No, I've just never had a need for secure mail.



LEO:  I am going to - I got a couple of very interesting emails, encrypted emails, from a guy who styles himself Demosthenes.  You may remember...



STEVE:  Yes.



LEO:  ...the character of Demosthenes from the "Ender's Cycle."  He gave me very specific instructions on how to use Cypherpunks' "nym," as in anoNYMous...



STEVE:  As in a pseudo...



LEO:  PseudoNYM servers.  Which is an interesting - and it still uses PGP, but it's about the metadata, hiding metadata, as well.  So an interesting idea.  But I'll pass those along to you, and you can enjoy.



STEVE:  Okay, cool.  So, okay.  The most tweeted, to me, topic of the week was the, unfortunately, the source of great hyperbole for members of the press, whose headlines were "No Passwords Are Safe Any Longer."



LEO:  What?



STEVE:  The end of secure passwords as we have known it.  Now, if you were using "monkey," Leo...



LEO:  Yes.



STEVE:  Maybe that's true.  All that happened, however, is that the well-known, high-performance, HashCat GPU-based brute-force cracking system...



LEO:  Yes, which has become very good...



STEVE:  It has become very good.  They had a password length limit of 15 characters.  Forever.  It's always been 15 characters.  And so all anybody had to do is to use a 16-character password, and HashCat couldn't handle it.  At the cost of rewriting half of their source code...



LEO:  And slowing it down a little bit, too.



STEVE:  Yes, it was, yes.  Essentially they lost 15% because the limiting the password length to 15 characters for all kinds of technical, just like the data path width requirements, there were optimizations they were able to apply at 15 characters or fewer.  Which is why, in the beginning, when this was first written, that's what they did.  That was their target.  But they realized that that couldn't stand.  So Jens Steube, who also go by the handle "Atom," wrote in the release notes for this upgrade:  "This was by far one of the most requested features.  We resisted adding this 'feature' as it would force us to remove several optimizations, resulting in a decrease in performance for most algorithms.  The actual performance loss depends on several factors - GPU, attack mode, et cetera - but typically averages around 15%."



Dan Goodin, who's a pretty good technical writer for Ars Technica, wrote:  "As leaked lists of real-world passwords proliferate, many people have turned to passwords and passphrases dozens of characters long in hopes of staying ahead of the latest cracking techniques.  Crackers have responded by expanding the dictionaries they maintain to include phrases and word combinations found in the Bible, in common literature, and in online discussions.  For instance, independent password researcher Kevin Young recently decoded one particularly stubborn hash as the cryptographic representation of 'thereisnofatebutwhatwemake.'"  Which if course we all know came from "Terminator 2."



LEO:  Oh, really.  I didn't know that.  But good.  Good on you for recognizing that.  No?



STEVE:  And so there is - "thereisnofatebutwhatwemake" is obviously a concatenation of a bunch of words.  So those of us who have thought about this a lot recognize that, yes, that's good...



LEO:  Not a good password.



STEVE:  ...but it doesn't have actually that much entropy because...



LEO:  Right.  Well, and did you see how they found it?  It was in - there's a Wikipedia entry with the quote in it.  So apparently they're hashing all the Wikipedia entries or something.



STEVE:  There may be that.  But I think maybe you're thinking of this second one.



LEO:  Oh, oh, okay.



STEVE:  Yiannis Chrysanthou...



LEO:  Yes, yes, that was that, yeah.



STEVE:  ...a security researcher who recently completed his master's of science thesis on modern password cracking, was able to crack the password.



LEO:  Skip this.  Skip this.



STEVE:  Now, this one is just ridiculous.



LEO:  Skip this.



STEVE:  I can't pronounce this.



LEO:  No.



STEVE:  Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn1.



LEO:  Which looks like random, but it's not.



STEVE:  No.  That's the fictional occult phrase from H.P. Lovecraft's short story "The Call of Cthulhu."



LEO:  Cthulhu, yeah, Cthulhu.



STEVE:  Cthulhu, ah.



LEO:  By the way, James Spawn [ph] said, oh, yeah, that's from "The Call of Cthulhu."  In our chatroom.  Right away recognized it.



STEVE:  That's why we have good people in the chatroom.  It would have been impossible to use a brute-force attack or even a combined dictionary to crack a phrase of that length.  But because the phrase was contained in this Wikipedia article, it wound up in a word list that allowed the security researcher to crack the phrase in a matter of minutes.  So this podcast, our listeners' takeaway is abandon anything but true random characters.  It's the only thing we have left is...



LEO:  If you used a random passphrase, but actual words, wouldn't that be okay?  Or no?



STEVE:  Well, there is...



LEO:  Not as good, of course.



STEVE:  ...[indiscernible] what we make.  That may have actually appeared because it appeared in "Terminator 2."  But...



LEO:  But somebody in the chatroom said, "My doorbell has cow mustard on top of its sticky side walls."  It's not - that's such a random phrase.  You could remember it.  Because that's the issue; right?  The best obviously is truly random.  The more entropy the better.



STEVE:  Yeah, I really think we're at the - we're in an era now where tools like LastPass, where they are long, truly random passwords, and you have given up, you are no longer remembering any of those, you've turned responsibility over to this technology, we're at that point now where you have one master password which also really needs to be good, but some - I'm a fan of using a keyboard-based algorithm and something to come up with something really screwy, and that's the way I remember my master password - something sort of semi-mechanical.  And then just give up and have a good random number generator or a random password generator make things up for you.



That's just the way I've been operating now ever since I found and vetted LastPass.  It's just like, okay, you know.  And the good news is that it's - LastPass is ubiquitous.  It's on all your platforms.  I've got it running on my iPad.  And so it'll, when I want to do something on my iPad, it's like, oh, I use LastPass Tab, which is the iOS-based browser, and it says, oh, yeah, here.  I'll it in for you.  It's like, oh, thank goodness.  So you need ubiquity if you're going to have passwords in your life that you absolutely don't know any longer.



LEO:  Yeah, the challenge is this master pass, which you have to remember.



STEVE:  You've got to have one.



LEO:  Yeah.  I'm going to try, you know, Chris somebody, somebody from YubiKey sent me a note saying that they have a new YubiKey.  One of their YubiKeys supports PGP passwords, passphrases.  So I'm going to try doing that.  Of course, if you lose the YubiKey, you're screwed.



STEVE:  Yup.  So don't do that.



LEO:  I still think it's best to have something that's in your mind that you can remember.



STEVE:  Yeah, well, and the YubiKey, great as it is for its purpose, is USB.  And so..



LEO:  That's not going to work on Android; right.



STEVE:  On your phone; right.



LEO:  You're going to have to do what Walt did and just memorize the GPS coordinates of his stash.



STEVE:  And then, did you see what he did?



LEO:  Yes, I thought that was brilliant.



STEVE:  Brilliant.



LEO:  Now, this is not a spoiler because it's not a plot point.



STEVE:  Very, very obscure.



LEO:  But he needed to remember a GPS coordinate, so he memorized it.  But of course he...



STEVE:  Short-term.



LEO:  Yeah, short-term, he didn't trust his long-term memory, so he bought a lotto ticket with a number of numbers.  It wasn't the number that he used, but the second number in with the number of numbers that he'd purchased, you know, he - worked.



STEVE:  Yes, basically he turned it into a lotto ticket so that there was a record on the refrigerator that no one would ever imagine was GPS coordinates.  Yeah, very clever.



Okay.  Now, this is bizarre.  This is - it's sort of fun and interesting.  People should not panic.  But it turns out that the Netscape Security Suite, NSS, which is the foundation for both Firefox and now Chrome, has an SSL logging feature.  If you create an environment variable, all capitals, SSLkeylogfile, and you set that environment variable to a filename, then you launch Firefox or Chrome and do anything with SSL and then look at that file, it has dumped all of the security keys that were negotiated.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Now, is that - that's, like, the key.  That's all you need.



STEVE:  It is, in fact, it is so much the key that if you also, even somewhere else, captured the traffic, Wireshark will decrypt the dialogue for you using the hex which has been logged in that keylog file.  So you can try it yourself:  SSLkeylogfile as an environment variable, set that to a filename - I set it to C:\herearemykeys.log - and fired up Chrome, went to GRC, looked in the file, and here was this beautiful log of all of the negotiation that had been done.



LEO:  Now, it doesn't do that unless you set that environment variable?  It doesn't do it by default.



STEVE:  Correct.



LEO:  Okay.  So it's a debugging feature. 



STEVE:  It's a debugging feature the developers use.  And it is handy if you yourself are a developer, and you don't have something like Fiddler or one of the ways of intercepting secure transactions because Wireshark will - you're able to decode this protocol, drop the hex in, and it's like, bink, there's all of your dialogue in the clear.  So you certainly - if you turn this on to play with it, remove it after you're done.



I mean, so this is not a huge issue because, remember, we have to understand what our security perimeter is.  Our own system is our own system.  We want to keep malware out of it.  We want to keep people out of it.  This is like Chrome that doesn't encrypt your website passwords, that sort of thing.  It's like, in RAM are all these keys all the time.  They have to be there to be used, to have dialogues.  Normally our browser doesn't write them to disk.  And these are keys relative to the server you visited, but that's only going to be the server's public key and the keys that you negotiated for a while.  But you don't want to have that happening.  So just I ran across this, actually just this morning, this SSLkeylogfile as an environment variable that will cause the local security suite, the NSS, Netscape Security Suite, to log what it does to a hard drive.



LEO:  Unbelievable.



STEVE:  Yeah.  And so I just wanted to mention, since all of your other podcasts had commented on Steve Ballmer's news that he was leaving, that he was one of my favorite people there, Leo.  I got to know Steve...



LEO:  Really.



STEVE:  Oh, yeah, back in the days when he and Gates were hanging out at Comdex.  Bill was always very focused and all about business.  And Steve was someone that would have a beer with you and remember your name.



LEO:  He seemed like a nice guy, actually, yeah.



STEVE:  Yeah, he was.  And, you know, at the same time, he could never have built Microsoft.



LEO:  Right.



STEVE:  I mean, he wasn't Bill Gates by any means.  And so he was a great person, I mean, he was a nice person to work with Bill, to sort of go to meetings when Bill was busy doing something else or couldn't be bothered.  And I thought he was - he kind of kept things going for a long time.  And I think this whole issue of Microsoft's sort of faltering is not surprising.  We've seen Microsoft faltering ever since PDAs first happened because they're a one-trick pony.  They've got an operating system that is massive, and it's never been able to run on batteries.  And so they've been having a problem with that ever since.  Initially it was PDAs.  Then it became telephones, as PDAs and phones sort of merged.



And I just - here they are now, there was a news blurb that was saying that, a year from now when XP stops getting security updates, it's expected that fully one third of PCs will still be running XP.  And it's like, yeah, because companies don't have money to burn right now, and Microsoft's, unfortunately, their model is one way or the other forcing you to move forward, even if XP works just fine.  And so new machines which are purchased will typically have, well, hopefully Windows 7, maybe Windows 8 at some point, God help you.  But so they won't have XP.  And so it'll just be XP will end up dying off because the machines that had it will end up dying themselves, and new machines will have a new version of Windows.  So anyway, I mean, I didn't think Ballmer was ever a genius, but I don't think he was ever expected to be.  He was just - he kept things going as well as he could.



LEO:  Yeah, yeah.  I mean, I think this was inevitable.  But, yeah, he's a nice guy.  That doesn't mean he should be running Microsoft, just he's a nice guy.  It's an important point to make.  It's kind of apparent when you read his quotes and so forth.  He's a fun guy.



STEVE:  I did want to share - I got a kick out of an xkcd carton, Leo:  xkcd.com.  This one is 1256.  So you can see it at xkcd.com/1256, or 1256/large, if you want the big version.  And what this is, this, again, is classic xkcd.  These are questions found in Google autocomplete.  And it really is wonderful.  It's where you begin to...



LEO:  It's hysterical.



STEVE:  It is fabulous.  You begin to type something, and then Google guesses, based on what other people have asked in the past, what you may be in the process of asking.  And so it's just a massive screen of sort of fun things.  But someone, I don't remember if it was through Twitter or GRC.com/feedback, noted that in the very far bottom left corner, you go to the bottom left corner, then you go to the right one column, so it's in the second column, and the third line up is "Why is there always a Java update?"



LEO:  [Laughing] It's right in between "Why don't boys like me?" and "Why are there red dots on my thighs?"



STEVE:  [Laughing] Why is there always a Java update?  Yes, a question for the times.



LEO:  Good question.  Good question, yeah.



STEVE:  Our friend Mr. Wizard, Bob Bosen at AskMrWizard.com, has continued producing his video versions of our prior podcasts that he thinks are core and important.  He sent me a note saying, "I have just completed new Episode 29 on 'Ethernet Insecurity,' where you covered 'ARP Cache Poisoning.'"  And he continues to say, "Your narration provided a fine addition to your 'How the Internet Works' and 'How LANs Work' episodes from back in February and March of 2006."  So he's continuing to work on those.  For listeners of ours who don't already know, Bob produces some videos that use the audio from the podcast along with his animations to sort of further embellish what we're doing at AskMrWizard.com.  So just wanted to give a note about that since he's continued to produce those.



And work on SpinRite continues.  I don't think I mentioned before that I have confirmed now that one thing that people have been asking for, kind of, the next release will be able to offer, and that is cooler operation.  One of the things that laptops have a problem with is getting rid of the heat that they produce.  They often have - there just isn't much room for air to move in a laptop, just because of the physical size of it.  And so many laptops, I know that all of my Lenovos have a little vent area, and you can feel, like, hot air being actively blown out of this thing as it's trying to cool off the CPU.  I've perfected the technology of completely halting the processor while SpinRite runs.  The processor will almost never be running.



LEO:  What?



STEVE:  Yes.



LEO:  Well, it's got to run a little bit.



STEVE:  It turns out that an interrupt, a hardware interrupt can take the processor out of halt, and does.  And so we've got the technology now proven for where I am already at one phase of the work that we're doing, halting a processor for three and a half seconds in order to make it absolutely quiet, to determine some aspects of the system's timing.



LEO:  That's a good idea.  That's a great idea.



STEVE:  So that nothing else is going on.  Well, it also dramatically lowers the power consumption, and thus the heat production, because the whole core, the processor clocks are just stopped.  And so what'll happen is 6.1, we've also confirmed, will be able to transfer in 32MB blocks, up from much like a 64K buffer to a 32MB buffer.  So we'll be transferring 65,535 sectors at a time.  That transfer is initiated, and then the processor is stopped.  And it will be sitting there doing nothing, just frozen, while all of that data flows into RAM.  And then it'll wake up, check to make sure everything worked, queue up and start the next transfer, and shut down again.



So its operational duty cycle will be, I'll end up measuring it because it'll be really fun just to know, but fractions of a percentage.  And so it'll do that, and we're also going to spin down any drives which are not in use.  So the drive SpinRite's running on, many people have machines with five or six hard drives in them.  It's amazing, the machines that we're testing were sometimes two drives, sometimes more.  SpinRite will shut any ones down that it's not working on, again, to further reduce power consumption and to dramatically run the system cooler while it's operating.



LEO:  Clever.



STEVE:  Yeah.  So, getting there.



LEO:  You may have noted The New York Times went down for a few hours this past week.  They now know that it was a spearphishing email, not attacking The New York Times, but a company called Melbourne IT, which is an Australian firm that buys addresses, domain names, and that was a domain name reseller, and hackers changed the DNS records once they got the logins from the domain resellers.  So it was a really good example of a spearphishing attack, sent specifically to staff at Melbourne IT.  And, boy, that's a...



STEVE:  And it was effective. yeah.



LEO:  Yeah.  It wasn't even Melbourne IT, it was a sales partner in the U.S., a partner of Melbourne IT.  So very indirect way to get at The New York Times.  They weren't actually, it looks like, going after The New York Times, but New York Times plus.  And they got quite a few credentials, I gather.



STEVE:  Wow.



LEO:  Yeah.  Hey, we're going to take a break.  We have questions from our audience.  Somebody in the chatroom  said, "Can I just come in the chatroom and ask?"  No, Steve likes to research his answers.  He doesn't like to answer off-the-cuff.  He takes it pretty seriously.  So what we do is we have a website, Steve's website, and a form there that you can ask questions.  If you want to ask questions now, go to GRC.com/feedback.  And Steve picks 10 or so questions every other week, twice a month, answers them.  And so, yeah, we don't take ad hoc questions because that's for the Tech Guy show.



STEVE:  I was going to say, I also do keep an eye on my Twitter feed.



LEO:  Ah, that's a way to do it, yeah.



STEVE:  And so if you mention, yeah, if you have something short, and you mention @SGgrc, if you tweet that out, by all means.  I normally keep current with everything happening in Twitter.



LEO:  Yeah.  Ten questions from our vast listening audience, starting with No. 1, Dan in the U.K.  He's @dansgalaxy on Twitter.  Is it possible, he asks on Twitter, for the NSA to identify a stream of VPN - well, this is very appropriate - VPNed data, and then match it based on variable bitrates to the VPN server outbound?  I don't know what he's asking.



STEVE:  Well, so, now, that's an interesting question because he's talking about traffic analysis.  And so if you had a VPN server, is there a way for someone, and in his example he's assuming the NSA would have an interest, in mapping the unencrypted public traffic back to the encrypted, tunneled traffic?  And so this is a concern because it's known as traffic analysis.  And, for example, one of the things that the Tor nodes deliberately do is introduce variable amounts of delay in their forwarding of the traffic when it comes in the node and leaves the node because they would like to break the association between packet coming in, packet leaving.  And so the feasibility of doing this is entirely a function of how busy that server is, whether it's a Tor node, for example, or a VPN server.  And also just, like, how closely someone is looking.



So, for example, say that you had a server that only one person was using.  Well, it's going to be very difficult to try to convince someone that your traffic that was encrypted going in is not related to the traffic coming out because there would be a burst of incoming traffic and immediately a burst of outgoing traffic.  There'll be a one-to-one relationship.  And so that makes it very obvious.  At the same time, if there were a thousand people all using the server, then to a much greater degree you're able to hide amid them.  But at the same time, if you remember also that normally people are going to a specific location out on the Internet, so there will be an IP address where their public stream out of the VPN is going, and then there's an IP address where the encrypted tunnel coming out the other side of the server is essentially going.



And so it's a hard problem to really hide from that kind of analysis because, even if there were a thousand people, one of the things that is characteristic of our use of the web is it tends to be extremely bursty.  That is, you click a link, and there's a flurry of activity where your browser requests the web page from the remote site.  Then, when the page comes in, your browser asks for all the resources, another burst of outgoing, and then typically it's quiet for a long time while you the human cogitate over what you just received and read it, scroll, and then maybe click something.  And then another furious burst of activity.



So the fact that the traffic is as bursty as it is really, I mean, it helps anyone who, even if you had a thousand very bursty individual users on a single server, here's a burst, there a burst, and then bursts come in, bursts come out, traffic analysis is a way of deanonymizing and associating the VPN user with the public user.  And this is a problem for which there's not a good solution.  That's one of the things, one of the benefits of Tor is that it's the reason Tor doesn't use just one node, for example.  If you just had a single Tor node, this would be - it would be easy to deanonymize.  It's by having it hop several times and the nodes deliberately introducing a delay, it's specifically to confound somebody trying to do traffic analysis.  So, great question, Dan.



LEO:  Yeah, wow.  All that in 140 characters.  Advait in India, I think, Kerala, India, he's a SpinRite user, and he wonders about Linux versus Windows:  Steve, when I browse the 'Net in Windows, I always use NoScript.  When I browse using my fully patched, up-to-date Ubuntu, I'm assuming I'm much safer, and I don't worry about using NoScript.  Am I putting myself at risk by not using NoScript in Ubuntu?  Is it true that almost all current web-based malware and threats will simply not execute in Ubuntu?  My understanding is Ubuntu is just a GUI shell around Linux.  Thanks, Advait, happy SpinRite owner.



STEVE:  So...



LEO:  His understanding of what Ubuntu is is mistaken, but that's okay.



STEVE:  Right.  The thing to, I think, appreciate here is that there are, unfortunately in this day and age, many different ways of getting yourself in trouble.  So, for example, if you are using Java, need I say any more?  So a Java exploit could be tied to the underlying operating system, but doesn't have to be.  It could be leaking your identity, leaking your session keys for things you're doing.  It could be causing a web-scale leakage of information, for example, logging what you're doing on your banking site, even when you're on Ubuntu Linux, not because of the Linux as a problem, but because the plugins and add-ons - like another, of course, frequent culprit is Adobe's PDF.  By the way, Leo, have you noticed how that sort of just - has that died down?



LEO:  We haven't heard a lot of that, yeah.



STEVE:  Yeah, that sandbox, it went from, like, a topic every week to, wow, we haven't heard of any more PDF problems for a long time.



LEO:  Interesting.



STEVE:  Because they really did, they finally got sandboxing.  They took it seriously and got sandboxing working, and that has really slowed these things down.  But so there's the potential problem of a web browser exploit.  Then sort of the next level is plugins, which the browser is bringing along to enhance your experience - JavaScript, Java, PDF reader and so forth.  And then finally at the lowest level is the OS itself.  And it is absolutely true that at the OS level, we're still seeing vastly more Windows exploitation than we are Mac.  I would say Mac is probably No. 2, and then Linux is a very distant third, just because the hackers are going where the people are.  And the majority of people are still using Windows.  And Windows seems to be giving no end of security opportunities for compromise.



LEO:  Jim Breen in Chicago notes the security implications of Yahoo!'s recycling its one-year dormant email accounts:  Steve, as you might be aware, Yahoo! began recycling email addresses this month.  I became aware of it as my employer, a large online eCommerce site, scrambles to figure out how to handle the fact that the email addresses associated with some of our user accounts could soon belong to someone else.  I wish - this is stupid.



STEVE:  Yes.



LEO:  Stupid.  As Yahoo! starts recycling the accounts.  So if you had leo@yahoo.com, didn't use it for, what is it, a few years?  What is it?



STEVE:  No, it's six months, I think.



LEO:  Six months?



STEVE:  Yeah.



LEO:  That they might give leo@yahoo.com to somebody else.  Who doesn't want it, trust me.  There are two big problems caused by Yahoo!'s decision to recycle email addresses which have been dormant for a year.  A year, I guess.



STEVE:  One year, yeah.



LEO:  The first, which seems to be getting the most attention based on Google searches, is that email senders with these Yahoo! addresses in their mailing lists risk sending email to people who didn't sign up for the list - who knows what kind of stuff, password resets - and having those people mark the email as spam, which then hurts the sender's email reputation with ISPs.  Well, that's a good point.



STEVE:  Yeah.



LEO:  This risk can be mitigated by removing the email address from the mailing list, if Yahoo! has been returning a "hard bounce" error for previous sends to those email addresses.  But will they hard bounce if they reassign it?  No.



STEVE:  Nope.



LEO:  The second problem is relevant to a security - I wonder if they're going to do, after a year we hard bounce for six weeks and then assign it.  Maybe they'll do that.



STEVE:  Yeah, actually what I read was that they were going to hard bounce for a month and then reassign it.



LEO:  Okay.  That would be better than nothing.  The second problem is relevant to a security audience.  It's harder to solve.  If the original owner of the Yahoo! email address associated it with an account on another site, then the new owner of the new email address will be able to take control of that account, of course, using the standard password reset functionality.  Since most websites base proof of ownership of an online identity on ownership of an email address...



STEVE:  Uh-huh.



LEO:  True - Yahoo!'s decision to recycle email addresses jeopardizes the accounts of those email addresses' former owners on sites across the Internet.  This seems like something the Security Now! audience should know about. Thanks for the great show.  Wow.  I didn't know about it.  That's terrible.



STEVE:  Yeah.



LEO:  Terrible.



STEVE:  It's caused - even our old friend Mat Honan has weighed in, saying, no no no no no, do not do this.



LEO:  Horrible.  Marissa Mayer ought to know better.



STEVE:  And actually she's been quoted as being the motivation behind this.



LEO:  Of course.



STEVE:  Yeah, saying, oh, well, we're going to spiff up Yahoo! and give it a facelift.  And, I mean, it's been around forever.  And what they're looking at is they're looking at all these email addresses that no one can use anymore that are, quote, "good email addresses," unquote, not BarneySmith3272653274897, but just Barney Smith.



LEO:  Hey, you didn't get an email address earlier, you missed the lottery.  Sorry, buddy.  You know what I mean?



STEVE:  I mean, it would make so much more sense to, like, do Yahoo2.com or, I mean, like change the - make a small change to the domain name or something, rather than take this huge, huge bulk of retired email addresses and make them available again.  They're still getting email into them, which are bouncing.  They're going to forever.  But more importantly, and there was some commentary that I appreciated, is that they look at - they decide that the account is dormant after some length of time.  If you're not logging in, even if you're getting email, if you're not logging in to receive it, they say, oh, well, it's dormant.  And so that's their reassignment basis.



Well, the problem is people often use a dormant account as their email security.  We've talked about have a separate account for your password recovery.  Don't use your normal high-traffic account for that.  Have password recovery go somewhere else so that it's extra secure.  And so now they're saying, oh, well, we're going to - if it's been dormant for a long time, we're going to free it up so people can get it.  And the point being made here is it is email, as we all know.  That's the way you authenticate.  That's the only thing we have for, like, proving who you are.  And so they're going to say, eh, no, we're going to let that happen.



LEO:  Baffling.



STEVE:  Bad idea.



LEO:  Baffling.  I guess one thing they could do that would be more sensible is to make a new TLD, Yahoo.me or Yahoomail.com or something like that.



STEVE:  Or I said Yahoo2.com or something.



LEO:  Yeah.  And then you've got the whole set again, fresh.  And the other thing, this is for anybody listening, and I think our audience would know this, but this is the very strong argument for buying a domain name of your very own and using it for your email address, so you have a permanent address.  And then if something like this happens, you don't have to worry about it, you just move it to some other service.  Just own your own damn email address.  It seems like nowadays that should be really the real answer to this.  Don't use somebody else's.



Pat Cho in Sacramento wonders whether files can be securely deleted - oh, this is a good one we get once in a while, you're the guy to answer - from flash drives?  Steve, is it possible to securely delete files from flash drives with the AxCrypt utility you recommended from a previous podcast or any other utility?  From what I have read, flash drives do writes differently for wear leveling, and so it may not be possible to overwrite a file.  Is this a cause for concern?  Pat Cho.



STEVE:  So, yes.  It's sort of related to hard drives, but even worse.  Hard drives will remove a sector from use when it becomes unsafe to store data there because of a defect in the magnetic storage surface.  So hard drives have a pool of spares, and they will "spare out," as it's called, spare out a sector and replace it with sort of a fresh good one only when there's a problem.  Flash drives work differently.  Flash, as we've discussed, the actual technology of writing to a flash drive involves fatiguing the material of the drive.  You use a high voltage to break through the insulation and sort of squirt electrons onto a little isolated pad, where they're stranded.  And that creates an electrostatic charge which can then be passively sensed.  So you read that there's that little charge there.  But the act of writing a one or writing a zero squirts or drains electrons through this insulation, which over time fatigues the insulation.  The insulative-ness breaks down.



So in order to solve that problem, because our operating systems tend to heavily use certain areas of the directory, the actual directory structure, the metadata, which contains filenames and the directory tree, many files tend to be written much more often than others.  So that would create hotspots where the regions of the flash drive containing those files would fatigue much more quickly than areas that weren't ever being used.  So flash drive controllers deliberately do this "wear leveling," as it's called, and it's exactly what it sounds like.  They level the wear so that there isn't undo wear occurring in one location.  And it's ongoing all the time.



So whereas for a hard drive it's only if there's a problem, it is fundamental to the way flash drives write is they have logic that is constantly remapping the surface so that the entire region of the flash drive is overall being written about the same amount.  What that means is prior versions of a file may exist on flash drives, and the work that the group down in San Diego has done on recovering from wear level drives, like essentially circumventing the controller to say, no, I don't want that sector, I want to look at the raw storage region, they've done that, and they have verified that this wear leveling means that all kinds of prior instances of data on the drive is there and is definitely available.  So what all of this means is, if you're concerned about security, you should never, ever, not once, write unencrypted data to a flash drive.



LEO:  Wow.



STEVE:  The first thing you need to do is, for example, install TrueCrypt.  TrueCrypt will do a beautiful job of encrypting the drive so that everything you write goes through TrueCrypt on the way to being stored, and then you absolutely don't have a problem.  Or use AxCrypt, which is a nice little freestanding utility.  Or even WinZip.  WinZip is now cross-platform.  I was looking at it the other day.  It uses very strong encryption.  And so you just use a good cryptographic key and then use AxCrypt or WinZip or some enciphering tool so that what you store on the flash drive is always encrypted.  Otherwise, to a much greater degree than for hard drives, if somebody really wanted to get at your data, they could.



LEO:  You'd have to physically destroy the SSD.  You'd have to smash it, and smash the chips.



STEVE:  You've got to crack it open and get to it.  But it turns out it's entirely possible to do that.  The guys in San Diego...



LEO:  Interesting.



STEVE:  There's a group of researchers who have been experimenting with this.



LEO:  Now, if I, after the fact - I have an SSD, external USB SSD.  If I, after the fact, apply full disk encryption, even though I've been writing to it unencrypted for a while, they'd have to have the key to the full-disk encryption to get down to the stuff; right?



STEVE:  If you - no.  If you...



LEO:  I turned on Apple's FileVault encryption, which is whole-disk encryption.



STEVE:  Right, or TrueCrypt.  If you add TrueCrypt later, then the problem is you'd have, I mean, over time of using it that way, it would tend to replace the less recently written regions with more recently written regions. 



LEO:  Which would be encrypted at that point.



STEVE:  Which would then be encrypted, exactly.  So over time the previously unencrypted data would kind of get pushed out of use by the wear leveling, which is what created the problem in the first place.



LEO:  So it sounds like, if you buy a new computer, and almost all laptops and many desktops come with SSDs, the first thing you should do is turn on full-disk encryption.  Otherwise you're just really...



STEVE:  Before you do anything else.



LEO:  Because it's going to be too late if you do anything else.



STEVE:  Exactly.



LEO:  And Windows comes with BitLocker, and Apple comes with FileVault.  These are, as we've spoken about before, I don't really trust any non-open source utility.  But that would be the easiest way to do it because you don't have to install it.



STEVE:  I just like TrueCrypt because it's portable.  I mean, it's been very well engineered.



LEO:  Yeah.  All right.  Okay.



STEVE:  But you're right.  There are native solutions, BitLocker and...



LEO:  Yeah, they're just operating system based.



STEVE:  Yup.



LEO:  Now, is there any way, after the fact now, to wipe the drive?  No.



STEVE:  No, there isn't.  No.  This is...



LEO:  It's too late.



STEVE:  This is done below the level of the API.  There are, in the latest specs, the so-called ATA and ATAPI, the AT attachment spec, this is where I've been living for the last couple of months, this is where SpinRite lives, there are commands, for example, a secure wipe.  But it's not exactly clear to me yet how that functions.  And the other thing I want to look at, and I will be, is the idea of the password on the drive, whether using the drive's own password, what level of security and where that could be bypassed.  But bottom line is I would - if it's a black box, it's a black box.  It's very much like the cloud, the Internet.  We say "pre-Internet encryption" because we don't know what that cloud is going to do.  Similarly, we don't know what that drive is going to do.  Much better not to be concerned about it.  TNO applies to your drive, too.  Encrypt it before it gets written on the drive.



LEO:  Wow.  And if you haven't, which most of us haven't, I mean, I have tons - all my computers have SSDs now.



STEVE:  Hmm.



LEO:  Too late.



STEVE:  Yup.  The good news is SpinRite will recover them when they have a problem.  But it is the case that you would want to add encryption immediately...



LEO:  Do it, turn it on right now and just keep using it.



STEVE:  Right now, and just keep using it.  And as it gets used, the wear leveling that caused the problem in the first place will also cause the solution because it'll still be wear leveling, but you'll be leveling - it'll be pushing the unencrypted stuff out into history, overwritten by encrypted data.



LEO:  Wow.  Mike in Philadelphia has some PGP worries:  Thanks for the PGP episode, Steve.  That was last week's, by the way.  I had already downloaded Mailvelope and generated keys a few weeks prior, so I was happy for some background.  Here's my worry, though.  Where do those PGP keys come from?  Are they generated by my browser, or are they auto-generated by some key server?  My worry is that these are generated by a key server, and I can choose to accept them or generate a new pair.  My concern, of course, is snooping while the - we can just skip this, because they're not.



STEVE:  Right.



LEO:  He's got all sorts of concerns.



STEVE:  But, yes.  So I wanted to make sure that nobody else was concerned.  The whole concept of PGP or even SSL keys that servers use is the private key, the keys to the kingdom, absolutely never leave your control.



LEO:  And they're created by the PGP program you're using, in his case Mailvelope.



STEVE:  Right.



LEO:  Locally.  They're not created by a key server anywhere or anything like that.



STEVE:  Correct.  So Mike's concern was that there seemed to be a server involved.  And because this was a web-based solution, he was uncomfortable with, well, I'm seeing things appear in the browser.  Did the browser make that, or did it get it from a server?  Which is a reasonable question because everything we see on a web page comes from a server somewhere.  But in this specific case, it is cryptographic code running in the browser that on the fly generates the key.  And it never - your private key never leaves your control.  And that's fundamental to the whole public/private key technology, which is one of the things that makes it really so fundamentally cool.



LEO:  And it's generated locally, by your local software.  And that's why we say use open source software, so that you make sure that there's no code in the software that generates the key, a good, secure key, and then emails it off to the NSA or something like that.



STEVE:  Exactly.



LEO:  Open source software, you or somebody can validate that it's fine.  And so that's a nice thing about PGP.  It is open source.  I'm sure Mailvelope is open source so you can see what's going on, generate secure keys.  And again, I've said this before, but even if you happen to lose control of your private key, there still needs to be a passphrase to use it, to unencrypt it.



STEVE:  Right.



LEO:  So this is why you should not use - what was that "Terminator 2" passphrase?  You should use a good - and passphrase might really be the wrong thing to say because it implies an English-language sentence.



STEVE:  It does, yes.



LEO:  And we really shouldn't be using that.  We should use long, random strings of letters.



STEVE:  Passcode, yup.



LEO:  Passcode would be much better, or password.  Even "word" isn't a good - yeah, passcode.  Random string of upper and lowercase letters, punctuation, and numbers.



STEVE:  GRC.com/passwords.



LEO:  He'll generate one for you of any arbitrary length.



STEVE:  Yup.



LEO:  And then do like Walter White does:  memorize, memorize.  It's good for your brain.  Buy a lotto ticket.  Steve Gibson, security guru; Leo Laporte.  A few more questions for you, Steve, starting with this one from a radio station, Dan Uff in Allentown, PA.  He writes:  I'm the owner of a small Internet radio station, WDMU Internet Radio.  I'm in the process of trying to fill my radio time with quality content.  I'd like to consider having your show as part of my station's lineup.  I think the show would be a great fit and help educate my listeners about Internet security at the same time.  I see the show is made once a week.  That's what I am looking for.  I'm also a big fan of Leo's and blah blah blah and would be honored to have him played on my small station.  Thank you for considering this request.  If you have questions, please feel free to contact me directly.  Thank you.



STEVE:  So what do you think?



LEO:  It's okay by me.



STEVE:  That's what I thought.



LEO:  So here's the deal, yeah, here's the deal.  And you should contact lisa@twit.tv to get formal approval; okay?  Lisa is our CEO at TWiT.tv.  But here's how it works.  If you look at our license, it's at the bottom of every web page at TWiT.tv.  We are Creative Commons licensed.  And you can read the details of that license.  We do ask that you adhere to our license, which has three requirements.  It's okay to play it freely for noncommercial purposes as long as you give full attribution, that's simple, TWiT.tv.  In fact, you don't even have to do anything because, unless you cut it off, it's at the beginning of every show.



STEVE:  It's all in there, yes.



LEO:  And the third thing is that it's a share-alike license.  Which means, if you make a mashup, which you're even allowed to do, that you have the same license on the mashup.  Now, I would ask personally that you leave our ads in because that's how we monetize.  But our license does not require - I probably shouldn't even mention this, but does not require you to do that.  If you're going to put it on a commercial radio station, if you have your own ads on there, then you need to get our permission.  And lisa@twit.tv is the email address.  But people do this all the time.  We're rebroadcast a lot of different ways.



STEVE:  And I don't think we'd ever talked about it, so I just wanted to...



LEO:  Yeah, I love it.  And you may add your own license.  I don't know, Steve.  But that's the...



STEVE:  No.



LEO:  ...license on all of our...



STEVE:  Creative Commons.



LEO:  Yup, CC, noncommercial attribution share-alike.  And you can click the link at the bottom of every web page at TWiT.tv if you want to see the specific verbiage.  As long as you adhere to license, you don't even have to ask our permission.  If you want to use it in a commercial environment, which this might be, then we're very - we're absolutely lenient.  But do email us, lisa@twit.tv.  What we don't want to do is have people, like, use it to make money, cut our ads out, put their ads in, things like that.  That's just rude.  Be polite.



STEVE:  That's creepy.



LEO:  Yeah.  John in Sacramento has an interesting thought experiment about PGP.  He's been listening since Episode 1, which is about as long as you can, nine years.  He was listening to our last episode [SN-418].  He had the thought, why not put PGP in the email server instead of the client?



As I understand it, we have SSL encryption between the user's email client and the server, whether it's using IMAP, POP, webmail, SSL.  And it works with mobile, as well.  With PGP on the server, the user connects securely to their email server in whatever way is most convenient to them, creates an email.  And then, as part of pressing the Send button, once the server gets it, the server will encrypt it with PGP before sending it out to the recipient's server.  Once there - by the way, there's the rub - the recipient's email server would handle the decryption when the recipient connects, again securely in whatever way is most convenient for them, and download the decrypted message.  All that's needed is a client capable of connecting to the server securely, which is much easier than trying to deal with plugins, et cetera, et cetera.  What do you think, Steverino?



STEVE:  Well, the problem is, well, there are several problems.  One is that the moment you step back from - and the right term is "end-to-end encryption."  That's one thing we're going to be hearing.  It's a term we haven't really spent that much time focusing on, but it's been implied in many of the things we're talking about.  SSL is end-to-end encryption.  You are encrypted where you are; it's decrypted where it's going.  And everywhere in between it's a pseudorandom stream of noise that has no meaning to anyone.  So that's the only way to be secure.  As soon as you step that encryption back even one stage from the end-user, you start having problems.



And so, for example, as you've alluded to even when you were reading this, Leo, John is right in that, if we have an encrypted link to our server, then our email is safe.  And if the server then encrypts it, and it's encrypted in flight to the other server, it's safe.  But notice that he said, "Once there, the recipient's email server would handle the decryption when the recipient connects."  So it's the weak link at the server where now we have vulnerability.  Whereas, if you do leave it encrypted all the way to the endpoint, you're not having that vulnerability.



But there are more problems.  For example, one of the beauties of the way PGP works - and Leo, you've alluded to this - is, if you've got PGP locally, and you've got a bunch of email addresses associated with the recipient's PGP keys, your client knows when to encrypt and when not to.  It knows whose keys it's able to encrypt your message for.  Or, if your client sees that you don't have a PGP key, it just sends it in the clear.  So you would be - you'd lose that level of control and feedback the moment you move encryption away from the client, away from the endpoint, which is really where it needs to be.



What you want is it's encrypted before it leaves the device.  It's not decrypted until it arrives at the recipient.  Anything else, I mean, and John's right that you would have secure links every step of the way.  But it does create a problem where, for example, the NSA could say to whoever it is running either your server or the destination server, oh, we want to take a look at that.



LEO:  Yeah.  I mean, there are solutions that do this.  HushMail does this.  But you're trusting HushMail.



STEVE:  Yup.



LEO:  And so it doesn't - so the problem with PGP is that you have to create a key and share the key.  And people find that complicated.  You can't send an encrypted email to somebody who's not shared his key with you or for whom you cannot find a key online.  And so that's the pain in the butt.



STEVE:  Well, okay.  In fact you are - this is the perfect segue into the next question, Leo.  I think you - go ahead.



LEO:  Here we go.  Question 8, Tim in Kansas, who really likes the idea of secure email, says:  I just thought I'd ask if you could go over the challenges of using PGP with Outlook - there are free options, but Gpg4win only supports older versions of Outlook - and those on Exchange servers.  As far as I know, only commercial options exist for Exchange, and I'm not certain if the flexibility is on par, say, with Thunderbird or GPG or Enigmail.  Thank you so much for covering this topic.  I hope to see greater adoption of it as, realistically, I've only been able to email myself and Leo.  Thanks for replying to my test, Leo.  No one else I know uses it, nor can they yet be convinced.  Best, Tim.  Yeah, I have now almost 200 keys in my keychain.



STEVE:  Yeah.  And this of course is the problem.  I mean, famously, this delayed Snowden's release...



LEO:  Yeah, he couldn't get Glenn Greenwald to do it.



STEVE:  Exactly.  Glenn refused.  He said, oh, I'm busy...



LEO:  I don't have time.



STEVE:  Yeah, I don't have time.  And...



LEO:  Now, I should say, once you exchange keys, or you figure - once you have that going on, it's really easy.  I just push a button and enter my passphrase in some cases.  In some cases, like on the Mac, the passphrase is stored in the secure Mac keychain, I don't even have to do that.  Once I'm logged in, I'm sending - any time I email these people, I can send them completely secure email, except for the metadata.



STEVE:  Yeah.  I just don't know.  It'll be fun as an observer to sort of watch and see where this goes.  My sense is people don't care that much.  They're like me.  It's like, well, you know, I'm just sending, you know...



LEO:  Just understand your email's a postcard.  If you don't care, it doesn't matter.



STEVE:  Yup.



LEO:  And I agree, this is more an exercise.  My first PGP key I created in 1997.  I've been...



STEVE:  Because you could.



LEO:  Because I could.  I've encouraged people to do it, and I have always published my public key on my website, Leoville.com.  I had an hysterical exchange with somebody who said, "I've looked everywhere.  It's not on your website."  Well, it is, it's on Leoville.com.  "Well, no, but when I Google you, the first result is Tech Guy Labs.  Why isn't it there?"  Well, it's not there.  It's on my personal website, Leoville.com.  "But it should be on all your websites."  No, it's on Leoville.com or on the key server.



STEVE:  It's where it is.



LEO:  It's where it is.



STEVE:  Not where it isn't.



LEO:  Yeah.  Sorry, dude.  Yeah, I should also put it in your pocket, but it's not [laughter].  Nevertheless, more than 200 people have - and I apologize.  I have actually been unfortunately swamped by people who want to exchange keys and test their setup.



STEVE:  Because you're the only one they know who...



LEO:  I know, me and Tim. 



STEVE:  Yeah, let's get - okay, Tim, maybe we can give out your email, and then you'll be part of a crowd of people.



LEO:  Well, what I do is I sign every email that goes out.  And people see this PGP block, maybe they start to get the message.  I don't know.  I've done it for years, and it's not - you're right, nobody wants to do it.



STEVE:  No.



LEO:  John O., Denton, Texas wonders about "Cookieless cookie tracking."  Steve, have you heard about - of course you have, Steve - about this cookieless track technology that cannot be blocked?  It doesn't rely on cookies, JavaScript, HTML5, localStorage, sessionStorage, globalStorage, Flash, Java or other plugins; nor on your IP address, your user agent string, or any methods employed by Panopticlick.  Can you tell us about it?



STEVE:  Yeah, this was also in the news.  I'm not sure why it sort of sputtered up to the top.  We've talked about it...



LEO:  It's nothing new.



STEVE:  Right.  It involves ETags.  One of the things - which has essentially, it's been referred to as a cache cookie, the idea being - and it's in use by websites right now.  When a website provides you with an asset, like the icon, the little favicon for the URL, or any of the embellishments that are standard on the site, as we know, browsers cache that, on the theory that it's much better to just save a bunch of this stuff locally - I mean, look how big our hard drives are, we can afford to save it locally - than going through the roundtrip of asking the remote server to send it to us again.  So it saves on the server resources.  It saves on time.  It makes the whole experience much better.



What happens is, though, browsers may want to verify that there's been no change.  So the server, when it provides an asset like an icon, for example, for the page, it will add a header, so-called metadata, to the resource, called an "ETag," which is - it's meant to be an opaque token, which is to say, the value is what's important, not what the value means.  That is, the value means something to the server.  It might be a hash.  It might be a CRC.  It might be a checksum.  It might just be an incrementing value that changes when the object changes.  But that's the key because the browser sends back when it's being - when the page is loaded, says I need to display this icon, the browser sends back the same ETag that it received, saying I have this icon that you provided me with this ETag.  If the ETag is different now, send it to me.



Well, that's tracking.  That's a way for the browser, I mean, it's exactly like a cookie.  Well, it's not exactly like a cookie.  It's cookie-esque, highly, because basically it's tracking your cache.  It's the way for the remote site to be issuing these tokens to all the things in your browser that the browser's going to cache.  And the browser sends them back to make sure they haven't changed.  Which identifies you, uniquely identifies you, if the ETags are unique.  So that's the key.  If the ETag was the same for every icon that it sent to everyone, then when they came back, the server wouldn't know who you were.



But ETag, again, is an opaque token.  So if it's something about the object plus something about you, then when it comes back it essentially contains uniquely identifying information so that your copy in the cache is different from somebody else's in their cache, even though they went to the same site.  So cookieless tracking via ETags, via the cache in your browser, is something, it's one more way that we're being deanonymized, or at least tracked, as we move around the Internet.



LEO:  Robert Osorio in Lady Lake, Florida wonders about the Trusted - what is TPM?  Trusted Program Module?



STEVE:  Platform.



LEO:  Platform Module.



STEVE:  Platform Module.



LEO:  And the German government's concerns.  We've been talking about this for a while.  The article about the German government says that the German government thinks Windows 8 is a trojan horse for the NSA and recommends people not use it:  A year ago I would have dismissed this as tinfoil nonsense, he goes on to write.  But now?  One has to at least admit it's possible.  After going to the Techno Security conference for a couple of years, I know that enterprise customers have to vet hardware for trojans embedded in firmware.



I'm not sure about TPM 2.0 being forced upon you in Windows 8, though.  Also, since it's a device, and any device can be disabled by some kind of hack, I would think you could bypass it.  If Windows doesn't have a driver for it, or if the driver is disabled, I don't see how it could be forced on you.  As I understand it, what TPM does right now is just provide a hardware crypto engine and a very good random number generator.  Vista, Windows 7, and Windows 8 will use it if it's available, but it is not required.  Love to hear your thoughts on this.



STEVE:  Well, so we've done an episode in the past on the Trusted Platform Module.  And it is as Robert suggests.  It is basically a crypto engine.  It's a physical chip by requirement, essentially, soldered onto the motherboard, that creates an identity for the machine and also a vault for secrets, for cryptographic secrets.  And the way the thing is designed is it is possible for you to ask it to validate things; but it is not possible, there is no API that will cause it to give out your secrets.  So as I understand it, Leo - and I have not researched this because I've been busy with SpinRite.  But as I understand it, all of this nonsense seems to me that the German government is complaining about is this notion of sort of a loss of sovereignty to, like, their own independent control of a Windows 8-based system which has secure boot technology and is locked to the Trusted Platform Module on the desktop or the laptop's board.



LEO:  Yeah, I don't - if you think about it, the logic of it is strained.  I mean, if you're using anybody's closed source code, it's difficult to know what it's doing.



STEVE:  Yeah, virtually impossible.



LEO:  Yeah.  And so the TPM module or not, I guess what they're saying is don't assume that TPM gives you some sort of security from Microsoft.



STEVE:  Well, one of the things that I've got on my short list of topics is the Windows 8 secure boot technology.  I want to look at it closely.



LEO:  Which, by the way, can be disabled.



STEVE:  Yes, yes.  And in fact has to be in order to run SpinRite.  A lot of the testers who've been playing with the testing code are booting their Windows 8 machines, and turning secure boot off is one of the things that people will need to do in order to - essentially the idea is that how do you ever know that a trojan or a rootkit didn't get into the system before Windows began?  That's the Achilles heel of ever being able to trust Windows once it's running, is was there a shim?  Was there any opportunity for running something untrusted?  And so it's really been carefully thought out, this notion of we're going to start from something we absolutely know, and every single step forward we're going to validate that we're only running - we're still in a trusted enclosure, essentially.  And so that's, I mean, it turns out it's a hard problem to solve.  And fascinating from an academic standpoint.



LEO:  And whoever wrote this article didn't really understand what's going on.  I mean, the German, whatever German government official said this.  If you're using it, you know, it's the same reason we don't use Chinese operating systems here in the U.S.  If somebody writes the operating system, and it's closed, has got any closed source code at all...



STEVE:  They have no idea what it's going to be doing.



LEO:  No idea what it's doing.



STEVE:  None.



LEO:  TPM or not.



STEVE:  Yup.



LEO:  And TPM does not secure you from the operating system by any means.  That's not a point of it.  Steve, we've come to the end of 10 fine questions from our lovely listening audience.  That means we're at the end of the show.  I thank you.  Encourage everybody to follow Steve on the Twitter.  He's @SGgrc.  He's also at GRC.com on the web.  If you go there, you can get SpinRite, world's best hard drive maintenance utility, a must-have.  But you can also get lots of other stuff, lots of freebies.  Steve really labors away to help you be safe, secure, and sound.  The passwords are great, all sorts of stuff.  GRC.com.  If you do have a question, that's the place to go to post your questions for future episodes:  GRC.com/feedback.



STEVE:  That's where these came from.



LEO:  Every one of them.



STEVE:  Yup.  Well, except for the one...



LEO:  Well, one on Twitter.



STEVE:  ...from Twitter, yup, exactly.



LEO:  And you can also, while you're there, you might want to get the 16Kb version if you're bandwidth impaired; or, even smaller, the text version.  We have full transcriptions at GRC.com.  The high-quality audio and video versions are at TWiT.tv/sn, for Security Now!, and wherever finer podcasts are aggregated.  Subscribe to your favorite version, or several.  That way you're sure never to miss it.  Steve, I thank you so much.



STEVE:  Always a pleasure, my friend.  And we'll talk to you next week.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#420

DATE:		September 4, 2013

TITLE:		Bitmessage

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-420.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a lot of interesting security news, Steve and Leo examine the operation and technology of the new Bitmessage secure and anonymous Internet messaging system.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Today he'll talk about Bitmessage.  Is it as secure as it's supposed to be?  He also talks about the USA and Brazil, another embarrassment.  Oracle, doing it all over again.  And he has a revelation to make about a new product he's going to be working on sometime soon.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 420, recorded September 4th, 2013:  Bitmessage.



It's time for Security Now!, the show where we cover your security, your privacy, all the good stuff that you need to know when you get online.  And there's nobody better to do it than our Explainer in Chief and coffee addict pro tem - no, that's wrong - Mr. Steven Gibson of GRC.com.  He's the creator of SpinRite, the guy who first discovered spyware, coined the term, wrote the first antispyware.  He's also the guy who told Microsoft, "You're crazy," when they did that raw sockets thing, and nobody believed him.  Everybody dissed him.  Microsoft mocked him until it became a big problem and they had to take it out.  I could go on and on.  This is a guy, he's been - he's been in the lead, the charge all along, and you've got to listen to him:  Steve Gibson.



STEVE GIBSON:  I think, Leo, we may be able to add before long that I came up with the solution for user login and web authentication.



LEO:  This would be huge. 



STEVE:  It would be huge.



LEO:  This would be huge.



STEVE:  And I think I've got it.



LEO:  All right.



STEVE:  And we'll talk about that later.



LEO:  Did you have this inspiration in the shower?



STEVE:  No, I was having coffee and reading my morning stuff when I was having some breakfast.  And it just kind of, I mean, my total focus is on SpinRite and working on the next release of SpinRite.  And this just came unbidden, like.  And I went, oh.



LEO:  Sometimes that happens.



STEVE:  And then I thought, wait a minute.  And then the more I thought of it, it's been six days now, and I - and I wanted to call it HIPS, which would be an acronym for Hiding In Plain Sight.  Because, I mean, it is so simple.



LEO:  I like it.  I like that acronym.



STEVE:  And so obvious.



LEO:  Yeah.  You're like Archimedes in his bathtub.  Eureka!



STEVE:  And as we were saying before, many times when, the way the human brain works, you focus on a problem, you really think about it, and then you just put it away, and other parts of your brain have been engaged.  And so when our listeners learn of this, it'll be like, oh, uh, yeah.



LEO:  Yeah.



STEVE:  So, yeah.



LEO:  Yeah.



STEVE:  And so I can't - it's so much better than anything we have now, I can't imagine...



LEO:  You're such a tease.  All right, stop teasing us.



STEVE:  ...that it won't - yes, okay.



LEO:  Let's get to the security news.  You can tease us later.  By the way, what is this show about?



STEVE:  Bitmessage.



LEO:  Okay.



STEVE:  Yes.  I want to cover Bitmessage to sort of get it out of the way.  It's got so many problems that it probably isn't going to survive, at least in its current form.  It could mutate.  But many of the people that have successfully attacked it for its shortcomings have also mentioned they're working on something of their own.  So, and I appreciate them disclosing that.  But so this is an example of what I have expected we would see post-NSA and Snowden revelation, which is a refocusing on this kind of stuff.  I think I read that Tor traffic is up 500%.  It's like five times more use of Tor.



LEO:  Good, good.



STEVE:  So Bitmessage, everyone wants to know what it is.  So this is - I didn't bother to spend the time to dissect the protocol at that level because I don't think it's - I think it's a waste of time.  But I want to explain - but my subtitle is "An idea worth learning from."  And so the concepts are interesting.  And so we're going to talk about it so that everyone's curiosity will be satisfied.  You'll sort of know what it is.  You could use it if you wanted to.  But it's probably better to wait for 2.0, or maybe even 1.0.  I think it's at 0.3.5 right now.



LEO:  That's usually a bad place to start, yeah.



STEVE:  Or wait for the one that succeeds it that, like, solves some of the fundamental problems.  So it's some interesting ideas that are definitely worth sharing.  And we've got a bunch of news this week, as well.



LEO:  Very exciting.  Very exciting.  Leo Laporte, Steve Gibson, Security Now! on the air.  And I like the headline of your first story.  It says, "NSA and the USA in the D-o-g-h-o-u-s-e."  What's going on?



STEVE:  Yeah.  Well, there continues to be international fallout from the incremental revelations as the Snowden documents continue to come out.  And I first learned of this from a tweet from a Brian S., is his name.  And he sent to @SGgrc, "NSA fallout:  Brazil's government seeks to create new surveillance-proof email system.  Aim:  an alternative to Gmail."  And he sent me a bit.ly link [bit.ly/1e6DJYn] which took me to the article in Portuguese which described this.  And a different friend of mine sent also that, but said - he noted that the Google Translate does a pretty good job.



Portuguese:  www1.folha.uol.com.br/fsp/mundo/127105-governo-brasileiro-quer-e-mail-nacional-contra-bisbilhotice.shtml



Google Translate:  translate.google.com/translate?sl=auto&tl=

en&js=n&prev=_t&hl=en&ie=UTF-8&u=http%3A%2F%2Fwww1.folha.uol.com.br

%2Ffsp%2Fmundo%2F127105-governo-brasileiro-quer-e-mail-nacional-contra-bisbilhotice.shtml



So looking at that and sort of pulling out keywords because it's still a machine translation, what it looks like is that the Brazilian government, in the wake of the Snowden NSA revelations, ordered their domestic postal system to expand an existing email facility which was previously targeted mostly for business into a national competitor to Hotmail and Gmail, specifically to avoid the problem of U.S. NSA surveillance.  So this is them saying, gee, now that the emperor's been shown to have no clothes at all, we need to do something about this.  So they're just uncomfortable with using domestic Hotmail and Gmail, U.S. services.  And I just shake my head.  I mean, it's certainly sad that this has happened.  But that's the consequence.



Secondly, the Indian government, this was a headline - this is covered by TheHackerNews.com.  So the Indian government may ban U.S. email services for official communications.  And I'll just share the top of the story.  They said:  "The Indian government is planning to ban the use of U.S.-based email services like Gmail for official communications to increase the security of confidential government information."  Well, one could argue it should have never been unencrypted, heading off to Gmail, for important Indian government work.



But, I mean, continuing:  "The recent disconcerting reports that India was being spied upon by American intelligence agencies has opened an all-new chapter in the cybersecurity space, as leaked by former U.S. National Security Agency contractor Edward Snowden, that the NSA was involved in widespread spying and surveillance activities across the globe.  The government" - the Indian government - "plans to send a formal notification to about 500,000 employees across [India], asking them to stick to the official email service provided by India's National Informatics Centre," said the Times of India.



"The fact [is] that several government officers in top positions use their Gmail IDs for official communications.  Several senior government officials in India, including ministers of state for communications [and a few others that are named in the article] have their Gmail IDs listed in government portals as their official email.  So last week India's IT minister revealed that the new policy will enforce rules such as the use of static IP addresses, virtual private networks, and one-time passwords for accessing Indian government email services on all Indian officials who are stationed abroad.  All Indian missions will use NIC servers which are directly linked to a server in India, and that will keep government information safe."



So in the past we were seeing rather lax security and not much focus and concern.  But governments are responding to what has been learned about what the NSA is doing.



LEO:  Of course, they're spying on us, too, so...



STEVE:  Yeah.



LEO:  I mean...



STEVE:  Yeah, but they're doing it more secretly, apparently.



LEO:  Right.  That's the big difference.



STEVE:  They're able to keep it quiet.



LEO:  Right.  There's no Snowdens working for them.



STEVE:  Okay.  So this next piece helped, I think, to explain a little bit about what we discussed last week with not only David Miranda being detained, but then that weird forced destruction of hard drives in the basement of the Guardian over in the U.K.  It turned out that David Miranda, who was, as we know, working as a courier for the Guardian's Glenn Greenwald, shuttling documents back and forth - are you sitting down, Leo?  I know you are.



LEO:  I'm sitting on my ball, yes.



STEVE:  Just wanted to make sure.



LEO:  I don't know if that's enough.  Maybe I need more support.



STEVE:  Are you well centered?  Center yourself.



LEO:  Yes, okay.



STEVE:  He was carrying the secure password for TrueCrypt-encrypted drives on a piece of paper.



LEO:  He wrote it down.



STEVE:  He wrote it down.  Now, we've discussed, obviously many times, proper password management.  And Bruce Schneier is famous for saying it is better to have a password you cannot remember and must write down than one that is easy to remember that you don't write down because, if it's easy to remember, it's easy to brute force. 



LEO:  Right.



STEVE:  But of course the right solution is to be a little more clever.  Leave off something that you...



LEO:  The Walter White solution.



STEVE:  Yes, exactly.  Leave off the ending seven characters, which you can remember, which you don't then tell anyone.  And then you're mystified why the password that was written down doesn't work.  It's like, well, that's what they gave me.



LEO:  That's supposed to work.



STEVE:  I don't know why.  I'm not technical.  Anyway, so the Register was apparently delighted in reporting this, that Miranda was carrying a hard drive encrypted with TrueCrypt.  So they said:  "It had been widely reported that Miranda disclosed some passwords to the police at Heathrow under threat of jail.  But many analysts had concluded that these were merely those of his social networking accounts and such."



LEO:  Here's my Twitter.  I'll give you my Twitter.



STEVE:  If you really want to log in with my Facebook account, then okay.  They said:  "...which it would be implausible to claim he did not know.  Naturally, it was considered unlikely that he would even know the keys to any top-secret encrypted data he might be carrying.  This was the view taken by security guru Bruce Schneier, for instance.  But now, in a court statement made this morning and tweeted live by Telegraph correspondent David Barrett, the government says that Miranda was actually carrying a piece of paper with a decryption password written on it.  This allowed the police to read at least some of the files he was carrying.  These include some 58,000 highly classified U.K. intelligence documents."



LEO:  Ooh.



STEVE:  Yes.  "In the government's view, this demonstrated 'very poor information security practice' on the part of Greenwald and the Guardian.  According to the Cabinet Office official making the statement..."



LEO:  Snowden was probably going, "God, I told them."  Oh.



STEVE:  I know, "...it was concern over this apparent amazingly lax security posture by the Guardian that had previously led the government to insist on destruction of any Snowden files it held, on U.K. territory, at least."  And now I have to say, who could blame them?  I mean, if you're given this kind of information, you absolutely have to treat it with respect.  And if they're traipsing around with encrypted drives and the password written down, not obfuscated, don't swap the first and second half, don't change anything about it, I mean, there's so many things you could do.  You could use haystacks.  Just add some stuff to it.  And then...



LEO:  But we knew, because Greenwald couldn't figure out how to use PGP, we knew he was not sophisticated.



STEVE:  Yeah.  But this is just a crime.  And, I mean, they've had WikiLeaks support and help.  And you'd think that somebody would have said, "Okay, look.  Here's the basics."  But no.  So anyway, I - you can imagine, I mean, we do know that the U.K., that part of what Snowden provided was documents the U.K. feels extremely unhappy about being disclosed.  And so it's one thing for someone, for the press to have them.  It's another thing for them to be flying around the world with - essentially in plaintext because that's what you have if you're using TrueCrypt and the password's tattooed to you.  So, yeah.



LEO:  That's really too bad, yeah.



STEVE:  There was, it was revealed, sort of an interesting iOS and OS X vulnerability.  This is, at this point, this is a crashing problem.  But we all know that that's the way exploits begin.  So Boy Genius reported:  "Android might be targeted by hackers and malware far more often than Apple's iOS platform, but that doesn't mean devices like the iPhone and iPad are immune to threats.  A post on Russian website Habrahabr.ru" - H-a-b-r-a-h-a-b-r dot r-u is how you spell it, that's for Elaine - "draws attention to a fairly serious vulnerability that allows nefarious users to remotely crash apps on iOS 6, or even render them unusable.  The vulnerability is seemingly due to a bug in Apple's CoreText font-rendering framework, and OS X Mountain Lion is affected, as well.



"According to the report, simply exposing various iOS or OS X apps to one of several possible strings of text is enough to trigger a crash.  What's more, sending one such string as an SMS or an iMessage to an iPhone, iPad, iPod Touch, or Mac computer can crash Apple's Messages app repeatedly, rendering it unusable.  Safari is also impacting by the bug, and naming a Wi-Fi network with one of those strings of text can cause an error while any Apple device is scanning for networks."



LEO:  Oh, that's bad.  Oh, that's really bad.  Oh, that's ugly.



STEVE:  That's nasty.  "The report claims that Apple has been aware of this vulnerability for six months and has yet to patch the exploit in any currently available operating system build.  The author does note, however, that beta versions of iOS 7 and Mac OS X Mavericks are seemingly not affected."  So for whatever reason...



LEO:  Well, that's how they plan to fix it, then, because those are both coming out soon.



STEVE:  Yes.  And what I would say, then, to people, is upgrade.  This is definitely - or, if your device begins doing something really suspicious every time you drive by a certain Starbucks, then now you know why, if it crashes when it comes within range of their network, or someone's network.  So I thought that was interesting.



And I picked this up also.  I thought this was interesting.  In what's being regarded as a historic vote, Ars Technica reported that New Zealand just banned software patents.



LEO:  Yay.



STEVE:  Yeah.  Big yay.



LEO:  Yay.



STEVE:  So Joe Mullin reporting for Ars Technica said:  "A major new patent bill, passed in a" - this was a landslide vote - "117-4 vote by New Zealand's Parliament after five years of debate" - they probably could have cut the debate somewhat shorter, given that it has that kind of majority - "has banned software patents.  The reluctant clause" - I'm sorry.  "The relevant clause of the patent bill actually states that a computer program is 'not an invention.'"



LEO:  Good.  It's not.



STEVE:  And people have argued that you cannot patent math, and computer programs are just math, so why can you patent computer programs?



LEO:  Yeah, good question.



STEVE:  "Some have suggested that was a way to get around the wording of the TRIPS intellectual property treaty, which requires patents to be 'available for any inventions, whether products or processes, in all fields of technology.'"  So instead they're just saying a computer program is not an invention.  So therefore it doesn't have to - we don't have a problem with this next clause of available for any inventions, whether products or processes.  If it's not an invention, then it doesn't matter.



"Processes may still be patentable if the computer program is merely a way of implementing a patentable process.  But patent claims that cover computer programs as such will not be allowed."  And that's interesting because I probably worked on one of my first patents, oh, 30 years ago?  And it was - it used one of the early 4-bit micros, and it was definitely a computer program.  But the attorneys I worked with said, okay, the way we do this, Steve, is we describe it as hardware.  And I said, but what?  It's software.  He says, I know, I know.  But you can't patent software.  Now this, again, this was like 30 years ago.



So the way we do this is, because a patent doesn't have to be - it doesn't have to always reflect what they call the "preferred embodiment."  So, but you can patent hardware.  You just at that time could not simply patent software.  So you'd patent the hardware implementation, but then you would do a software embodiment of the invention, and that's sort of the way you worked around it.  That was, 30 years ago, the way we did these things.



And of course over time it just became just sort of by agreement.  Nothing ever really happened, but it just - the patent and trademark office just began becoming more lax in their interpretation.  You know, under, I'm sure, plenty of political pressure for big U.S. companies to get patent protection for things that they want to cover with intellectual property law.



So continuing from this article in Ars Technica, it says:  "It seems there will be some leeway for computer programs directly tied to improved hardware.  The bill includes the example of a better washing machine.  Even if the improvements are implemented with a computer program, 'the actual contribution is a new and improved way of operating a washing machine that gets clothes cleaner and uses less electricity,' so a patent could be awarded."  So that seems sort of gray to me.



LEO:  Yeah, one of the things they're talking about is you have to build a model of it, a physical model.  That would be a good choice.  Yeah?



STEVE:  Yeah, that - yeah.  So anyway, this is - now, the question - oh, and they are saying they will continue to honor existing patents.  But they simply will not issue new ones.  So now the question is, here's New Zealand off by themselves with this.  What happens with the rest of the world?  And in fact they quote this Clare Curran:  "One Member of Parliament who was deeply involved in the debate, Clare Curran, quoted several heads of software firms complaining about how the patenting process allowed 'obvious things' to get patented and that, 'in general, software patents are counter-productive.'"



And that's, I mean, that's always been my argument is that there's - in the patent language, the test is supposed to be whether it would be obvious to someone trained in the art.  So, like, if you went through college, and you got your degree, and someone said "Solve this problem," that's called engineering, to use what you've learned to solve the problem.  And that's different from an invention, which is like, oh, my god.  Now, I don't know if what I will be revealing as the solution to web logon authentication should be an invention or not.  I'm going to claim no ownership of it because it needs to be free.  But maybe, I think it's obvious, but like there's a zipper, and there's Velcro.  And so some things are obvious in retrospect, but weren't obvious prospectively.



So it's difficult.  But it's certainly the case that what we see with software patents today is a company was just first.  And so, because they were facing problems others hadn't yet faced, they're claiming that they invented all these things which anyone else with that problem would have also done.  And I guess that's my argument.  I think that isn't an invention, if anyone being asked to solve the problem who is a knowledgeable expert in that knowledge domain would have, like, just simply done the work, written the code.  And that doesn't deserve protection.



So it is, unfortunately, our patent-granting system which is so broken.  They say, well, that seems new.  We'll let them battle it out in court.  And that's the problem is this litigation is incredibly expensive.  And in fact it's why I stopped volunteering to be an expert witness is that I was, for years.  It's sort of fun to be involved.  But I watched the court do the wrong thing so many times.  It's like, oh.  It just - it was more frustrating than it was gratifying to help people solve problems.



LEO:  Yeah.



STEVE:  So I don't know what that means.  But I think, if nothing else...



LEO:  It's a step in the right direction.



STEVE:  Yes.  It's progress.



LEO:  It means people are paying attention to it, whatever.



STEVE:  Now, we have a lack of progress from Oracle.



LEO:  Two steps forward, one step back.  That's the way life is.



STEVE:  Ohhh.



LEO:  I just hope it's not three steps back.



STEVE:  It turns out that Oracle is, like, they're reluctantly recognizing that they seem unable to control their own language, or at least the language that they inherited from Sun that is, of course, Java.  So now there is a new security warning which Oracle has added to Java, to pop up and warn you...



LEO:  Use of this software could be hazardous.



STEVE:  Yeah, it's like, no you know what.  No kidding.



LEO:  What does it say?  Does it actually say that?



STEVE:  No, yeah, it actually says that this is potentially dangerous.



LEO:  No.  That's the solution?



STEVE:  Well, here's what they did, though.  Two of the fields, the Name and the Location, where it came from and who created it, are not protected, and malware can change them.



LEO:  [Laughing] Oh, I get it.  So it warns you when you download a JAR file.



STEVE:  An applet cryptographically signed.  Yet you can change those fields in the warning.



LEO:  Well, they're just text strings [laughing].



STEVE:  Exactly.



LEO:  Holy moly.



STEVE:  It's unbelievable.  So Brian Krebs carried this.  He said:  "Faced with an onslaught of malware attacks that leverage vulnerabilities and design weaknesses in Java" - which puts it beautifully, Brian - "Oracle Corp. recently tweaked things so that Java now warns users about the security risks of running Java content. But new research suggests that the integrity and accuracy of these warning messages can be subverted easily in any number of ways, and that Oracle's new security scheme actually punishes Java application developers who adhere to it.



"Running a Java applet now pops up a security dialog box that presents users with information about the name, publisher, and source of the application.  Oracle says this pop-up is designed to warn users of potential security risks, such as using old versions of Java or running applet code that is not signed from a trusted Certificate Authority.  Security experts differ over whether regular users pay any mind whatsoever to these warnings.  But to make matters worse, new research suggests most of the information contained in the pop-ups can be forged by malware writers.



"In a series of scathing blog posts," writes Brian, "longtime Java developer Jerry Jongerius details the various ways that attackers can subvert the usefulness of these dialog boxes.  To illustrate his point, Jongerius uses an applet obtained from Oracle's own website, javadetection.jar, and shows that the information in two out of the three of its file descriptors, the Name and Location fields, can be changed, even if the applet is already cryptographically signed."



So, quoting from him, "'The bottom line in all of this is not the security risk of the errors but that Oracle made such incredibly basic errors in allowing "unsigned information" into their security dialogs,' Jongerius wrote in an email exchange. 'The magnitude of that fail is huge.'  Jongerius presents the following scenario in which an attacker might use the dialog boxes to trick users into running unsafe applets:  'Imagine a hacker taking a real signed Java application for remote desktop control and assistance and placing it on a gaming site, renaming it "Chess."  An unsuspecting end user would get a security pop-up from Java asking if they want to run "Chess" and, because they do, answers yes.  But behind the scenes, the end user's computer is now under the remote control of a hacker [who], maybe to throw off suspicion, implemented a basic "Chess" in HTML5 so it looks like the applet worked...'"



LEO:  Like this.



STEVE:  Exactly, "'all because Oracle allowed the Name in security dialogs to be forged to something innocent and incorrect.'  Oracle has not responded to requests for comment," said Brian, "but Jongerius is hardly the only software expert crying foul for the company's security prompts.  Will Dormann, writing for the Carnegie Mellon University's Software Engineering Institute, actually warns Java developers against adopting a key tenet of Oracle's new security guidelines.  Oracle recommends that all Java applets be cryptographically signed, regardless of the privileges required by the program."



But get this:  "Unsigned Java applets will run within a web page with a scary red warning that 'Running this application may be a security risk.'"  Okay.  So that's what the Java Runtime presents if you attempt to run an unsigned applet in a web browser.  Which is good.  Except, "One of Java's most-touted features is a 'sandbox' security mechanism that's supposed to prevent certain functions when the applet is sent as part of a web page.  But according to both of these developers, Jongerius and Dormann, Oracle made the default behavior for signed code to be full access to the computer..."



LEO:  Oh, come on.



STEVE:  "...essentially completely negating the usefulness of the sandbox."  It's just crazy.



LEO:  And it wasn't that way before Oracle?  I mean, that wasn't - that's something Oracle did, they added as a feature?



STEVE:  Yes.  These are things that have come along over time.  These are their responses.



LEO:  Thank you, Oracle.



STEVE:  In fact, they just - they cannot make it work right.  Unbelievable.



LEO:  We can't figure out how to do this, so we're just going to punt.  Oh, lord.



STEVE:  A bunch of people noted to me, so I wanted to share the information, that BitTorrent Sync now has an iOS client.  So it supports Android 2.2 and higher over on the Android side, and iOS 5.0 and higher over on the iOS platform.  Still no information from them on the protocol.  So we're still sort of in limbo.  It looks good.  They talk a lot about lots of bits of encryption and all that.  But they won't tell anybody how it works.



So, and every time - I'm on their PR list.  So I keep getting very nice updates from their PR guys saying, oh, Steve, it does this and it does that.  And I write back.  I say, that's nice.  Please, the only thing I want to know is have the white paper on the crypto.  We have to know how it works.  And he says, oh, okay.  But also it's pretty, and it has ribbons.  And I say, I know, I'm sure it is, but all I care about is the technical details.  When you have those, I will happily study it and then tell everyone that you guys did it right, assuming that they did.  But until then, we don't know.



Google Authenticator, I know you know this, Leo, made a huge mistake.



LEO:  Yeah.



STEVE:  Ouch.  And it's now pulled from iTunes.



LEO:  This was on iOS only, by the way.



STEVE:  Yes.  An update for iOS, when updated, wiped out the secure store of all of your Authenticator account.



LEO:  It just - it started over.



STEVE:  Yeah, yeah.



LEO:  But, you know, I have to say people should be saving their secret keys.  I save it in LastPass.  So it's very easy.  And the reason I do it, not because I was worried about that, although this is a benefit there, but just because I want to set up Authenticator on other platforms.



STEVE:  Yes.



LEO:  So I just - I save actually the image of the QR code into my LastPass, into my secure...



STEVE:  Yeah, it requires more steps.  And so not everyone was doing.  But, yes, you're right.  And it would be nice if there were some, like, good backup facility.



LEO:  Some automatic one, yeah.



STEVE:  So many people were getting hurt by this that Google yanked it immediately from iTunes.



LEO:  Well, and I think what happens is people - so let's say you're using Google's second factor authentication.  Google gives you a QR code.  You snap the picture in the - the QR code just has a long number, which is your ID, and so you don't have to enter it in by hand, just snap a picture of it, and Google Authenticator now has it.  Then people just delete it.  They go on - so there's no other place that it's stored.  That's just dumb, frankly.



STEVE:  Yeah.



LEO:  But they should tell you that.  They should say, "Store this QR code somewhere securely."



STEVE:  Yes, because you're going to need it.  Print it out on paper and stick it in a drawer.



LEO:  Right, right.  Now, you can always ask for another one.  So I don't know how big a deal it is.



STEVE:  Although I guess, obviously, you have to authenticate somehow through a different means.



LEO:  Right, right.  But everyone who uses this has some other means.  I just - Evernote uses this now, offers Google Authenticator, which is great.  More and more people are doing this.  I mean, I feel bad for anybody who's on iOS and lost them all.  I use it like crazy with LastPass, with Google, with Outlook.  Microsoft uses it with Evernote.



STEVE:  Yeah.  And just wait till I'm able to tell you how it should be done.



LEO:  Oh, I can't wait.



STEVE:  I know.  Okay.  So there was a hoax that upset a lot of people.  I wanted to let everyone know it is not the case that TrueCrypt has a backdoor.



LEO:  Oh.



STEVE:  This weird document suddenly was floating around the Internet that looked really authentic at first blush.  It appeared to be - and if you click that link, Leo, bring up the PDF in my notes there, you can put it on the screen - from the National District Attorneys Association.  Subtitle was National Center for Prosecution of Child Abuse.  And this was a presentation, a slide presentation  titled "Computer Forensics for Prosecutors," dated February 18th and 19th of this year, 2013, Portland, Oregon.  And it's a series of absolutely legitimate slides that would be part of a presentation being made to - sort of for law enforcement about computer forensics technology.  It talks about hard drives and encryption and hashing and is sort of a good grounder.



Toward the end of this really authentic-looking presentation there's a slide that is just labeled, "What's a Backdoor?"  And then underneath it says, answering the question, "A method to bypass data encryption or security."  And then as bullet points it says, "Does not require the password or passphrase to be known."  Next bullet point, "Saves time, cost, and effort to access encrypted or secured data."  Third bullet point, "Allows data to be accessed, copied, and even modified without tipping off the owner."  And then coming out a level of the outline, "Currently available for major encryption software:  Microsoft BitLocker, FileVault, BestCrypt, and TrueCrypt," and then it says, "et cetera.  Currently implemented by major cloud storage provider to comply with NCMEC requirements."  And it just sort of goes on.



So people see this and freak out, thinking, I mean, looking, thinking this is like an absolute legitimate presentation.  I mean, everything about it up to now, I mean, even through this, looks legitimate.  Except the last slide.  Down, if you look carefully at the last slide - this is the end of the first part of the presentation, so says "Part 2:  Detective Stu Pitt..."



LEO:  [Laughing]



STEVE:  "...will take over for Part 2.  And tomorrow Detective Laughlin Foo will conduct Part 3."  And the legitimate original document has also been found from which this spoofed one borrows heavily.  But the other one is much longer, and clearly many of the same slides were taken and so forth [cryptome.org/2013/09/computer-forensics-2012.pdf].  So this was just a hoax.  And Detective Stu Pitt and Detective Laughlin Foo will probably not be delivering Part 2 and Part 3 of the presentation.



LEO:  That is so funny.  There is one more little revelation somewhere, when I click this.  Oh, no, okay.  I guess the name of the PDF is "Hoax," but that was probably added after the fact [cryptome.org/2013/09/computer-forensics-2013-hoax.pdf].



STEVE:  That was added afterwards, yes.



LEO:  Oh, okay.  That would also give it away.



STEVE:  I got a bunch of tweets from people, oh, my god, there's a backdoor.  It's like...



LEO:  No.



STEVE:  I don't think so.  Okay.  So I had intended to cover this topic, Tor traffic analysis, so I printed out the 12-page, detailed, small print, two columns PDF and took it with me to a meal.  And only when I was sitting, I had sat down and was getting ready, I saw that my toner had just about run out on the printer.



LEO:  Oh, so you had a bunch of blank pages.



STEVE:  I got big huge empty stripes down the - so anyway, new toner is on order.  I will just say that this looks really interesting.  It was this research on Tor traffic analysis - and remember, we were talking about traffic analysis just recently because it is the Achilles heel, and it also feeds nicely into our discussion of Bitmessage.  This paper was put together by researchers at the U.S. Naval Research Lab, which of course was the original sponsor of Tor.  They did the original work on onion routing under the auspices of DARPA, and also some people at Georgetown University.  So this is - it's a beautiful piece of research.



And just reading from their abstract, they said in the abstract of this:  "We present the first analysis of the popular Tor anonymity network that indicates the security of typical users against reasonably realistic adversaries in the Tor network or in the underlying Internet.  Our results show that Tor users are far more susceptible to compromise than indicated by prior work.  Specific contributions..."



LEO:  No.



STEVE:  Yes.  "Specific contributions of the paper include   a model of various typical kinds of users; an adversary model that includes Tor network relays, autonomous systems, Internet exchange points, and groups of Internet exchange points drawn from empirical study; metrics that indicate how secure users are over a period of time; the most accurate topological model to date of the anonymous systems and Internet exchange points as they relate to Tor usage and network configuration; a novel realistic Tor path simulator; and analyses of security making use of all the above.  To show that our approach is useful to explore alternatives and not just Tor as currently deployed, we also analyze a published alternative path selection algorithm, Congestion-Aware Tor.  We create an empirical model of Tor congestion, identify novel attack vectors, and show that it, too, is more vulnerable than previously indicated."



So I will digest this study, figure out what it means, and we may just do a podcast on it because that's significant.  But basically it sounds like it's not good news.  I don't yet know how bad the news is.



LEO:  Yeah.



STEVE:  Okay.  So before we began recording, Leo, you and I had a lot of fun talking about one of our passions, which are TV shows.



LEO:  TV, yeah.



STEVE:  So in a weird - I haven't seen this from him before - blog, Paul Krugman, who is with the...



LEO:  Nobel Prize-winning economist.



STEVE:  Yeah, exactly, who blogs for The New York Times and is a regular columnist for The New York Times.  The title of his - and this is a good friend of mine sent this to me, otherwise - and I'm really glad from the description.  The title of his blog post was "Send in the Clones."  And then he said in parenthesis, "Unserious Entertainment Advice," except he's serious about it.  So I want to share this with - this is under - we're in Miscellany, obviously, now.



He wrote:  "Hey, if I can post music videos once a week, I guess I can recommend a TV show now and then.  Just finished watching our DVRed Season 1 of "Orphan Black," and wow.  If you haven't heard about it, it involves a number of women who discover that they are clones, products of an illegal experiment.  All of the clones are, of course, played by one amazing actress, Tatiana Maslany, who not only changes accents, but changes her whole body language when she shifts from London grifter to soccer mom to science geek to murderous religious fanatic."



LEO:  Wow.



STEVE:  "She even does the soccer mom impersonating the grifter and vice versa..."



LEO:  Wow.



STEVE:  "...and somehow makes it clear that that's what's going on.  Eat your heart out, Alec Guinness," writes Paul.  "And with the magic of modern technology, there are multiple scenes in which, say, three of the clones are talking to each other, and you really do forget that we're watching repeated takes of the same actress.  Oh, and Max Headroom appears to be the big villain, although in this show nothing is what it seems."  Then he concludes:  "I think they're rerunning Season 1 this fall, and there will be a Season 2 next year.  Highly recommended."  And that's a BBC production.  [Begins September 14, 2013 on BBC America.]



LEO:  And you can buy it on Google Play, which I'm about to do right now.



STEVE:  Yes.  It really sounds interesting.  I grabbed the Blu-ray, the first season on Blu-ray disk, and Amazon said they've sent it to me, so it's on the way.  And it is available in your other shadowy sources, as one would expect.



LEO:  Also Play Store, so you can get it for download.  I'm getting it right now from there.



STEVE:  I think it's 10 episodes of the first season, and really sounds intriguing.  So I'm not representing it one way or the other.  Haven't seen it.  But I...



LEO:  Chatroom agrees.  Some have seen it in the chatroom.  They say it's incredible.



STEVE:  Oh, fantastic.



LEO:  Yeah, can't wait to see it, yeah.  Buying it right now.



STEVE:  Okay.  So a couple days ago I posted something in the grc.spinrite.dev newsgroup, where I am hanging out full time, working on SpinRite.  And in a minute I will update everyone on that because I hit a major milestone yesterday.  What I posted was this.  Subject was "Something I cannot ignore any longer."



"Gang:  Three days ago" - so I guess this must have been Monday I posted this - "during breakfast last Thursday morning, I came up with what may well turn out to be the solution to the whole website authentication problem.  It requires no username or password.  It's 100% anonymous.  It gracefully supports multiple unlinked personas.  It's FAR" - in caps - "more secure, quick and easy to use than time- or sequence-based one-time passwords.  It inherently thwarts man-in-the-middle-style attacks, and it's comparatively safe to use in public settings where keystroke or other logging might be present.  The whole thing is so simple, and almost obvious in retrospect, that I can't believe that no one else has hit upon it before.  But I've searched, and apparently it's nowhere but in my head.



"It's inherently open, free, and TNO.  It can easily coexist with any other existing traditional authentication system, gradually taking over as it becomes more popular.  And it doesn't require any sort of third-party.  The interaction is just between the user and any supporting website that wants to offer this authentication alternative, and any website that wished to simply could.  There's no large startup cost, no critical mass needed.  There's really no way for anyone to make any money with it.  It needs to be free.



"I wasn't trying to come up with anything like this.  I wasn't even thinking about the topic.  I've been 100% saturated by this present work on SpinRite.  But, as you all know, I've also been living in that realm, thanks to the podcast, which keeps my attention focused weekly.  And you all know also what a passion I have for the problem with Perfect Passwords, Perfect Paper Passwords, Off The Grid, and Password Haystacks.  It's THE problem.



"So we'll get this present work on the ATA bus mastering DMA working, solidified, and finished.  Then I need to take a BRIEF" - and I put that in caps - "hiatus from the v6.1 work to create a web page describing and explaining my proposed solution.  Implementation is not something that I need or can do.  It's way bigger than me and would need an RFC-style standards body to ratify a single standard.  So I won't be away from here for long, only long enough to create a page carefully describing the idea.  Then I'll give it a podcast to launch it into the world and send it on its way.  Then we'll immediately plow into adding AHCI controller technology as a next step in this work."



So there were a couple responses from people.  One from a very security- and crypto-savvy guy who's also a very great contributor to the newsgroup said:  "Interesting.  Does it solve these problems, as well?"  And he said:  "One, can be backed up and restored easily."  Yes.  "Two, provides a key to the authenticator that can be used for encryption on the user's behalf."  And actually, as a matter of fact, it does that.  He said:  "Three, can be completely protected by something you know, i.e., a master password."  And the answer is yes, trivially.  And he said:  "Those are my three must-haves for any authentication system."  And I said, yup, it's got them all.  And then somebody else posted:  "Okay, I can't stand it any longer."  This was, like, two days later.  He said...



LEO:  You're such a tease.



STEVE:  "Have you given it a name?"  and I said:  "It has a name, a pretty good one.  But, if I share it, it's likely to set off a firestorm of speculation, which I would prefer to avoid for the time being.  I shared what happened last Thursday and what has been on my mind because it was the right thing to do when I found my own focus and concentration, though not my time, increasingly distracted by the idea because ultimately it will have some - likely modest - impact on this SpinRite work.



"Since then, pieces have been coming together, and the range of applications is expanding.  The patent landscape appears to be completely clear, with everything required either in the public domain or explicitly released from any usage encumbrance.  The world should look at and consider it sooner rather than later, so I don't want to wait long.  And, since there are interfaces among the pieces that need to be standardized to create a single universal interoperable solution, it would be better if my initial proposal was well thought out and fully specified so that interoperable endpoints could be immediately created from the initial disclosure.



"Because it's always possible to miss something, and because it's inherently impossible for me to adequately attack anything I have created, it needs to be reviewed by crypto-savvy third parties who can approach it from an adversarial perspective."  And then I said:  "If you think about it, that's exactly what this SpinTesting work really is that we do here, though it's other people's hardware that's taking an adversarial role."



So I will - SpinRite work is really going well, and I'm days away from - I'm probably later today releasing the next iteration of testing.  We are now able to transfer, all in assembler, at the hardware level, 32MB contiguous blocks up into extended memory.  So all of that - remember I talked about the real protected mode, of how with 16-bit code you can change, as a consequence of that weird fluke in the original implementation of the Intel system, you can actually get 32-bit addressing by sort of breaking the way segmentation is handled.  And that's all working.



So we have a 32MB transfer buffer, and we are now using Ultra DMA at the highest speed the drive can go to transfer 32MB at a time, so SpinRite will be screaming along.  We're doing that right now on the older style ATA specification.  And I want to - originally I was thinking I would do 6.1, and then I would hold off to do the AHCI controller.  But so many people have that now, and I'm right in the middle of all this.  So it's like, oh, let's just get it done while I'm in the middle of it.  So I do want to take a break and create a web page to explain this Eureka! Aha! event.  And when I tell everyone, they're just going to go, well, that's obvious.  I mean, it's so simple.  And it's just like, yeah, it is, like a zipper, or like Velcro.  But somehow no one has done it.  And it just - it solves every problem.  It's really cool.  So...



LEO:  Good, I can't wait.



STEVE:  The problem is I think you're going to be gone.



LEO:  Yeah, I am.  I'll miss it.  So I'll have to hear about it from a distance.



STEVE:  Oh, well, we'll see how the timing goes.  But, yeah.



LEO:  Yeah, I can't wait.



STEVE:  Yeah.  So that's where SpinRite is.  And we're coming along really well.  And it's looking like it's going to scream.



LEO:  Okay.  Okay.  And you don't want to say the name out loud of this thing.



STEVE:  Nope.



LEO:  Because people will do what they did, in fact, in the chatroom, when you did mention it before the show, speculate as to what it is and how it might work.



STEVE:  One other person in the world knows about it, because we had a three-hour conversation by phone yesterday, Mark Thompson.



LEO:  I figured you'd tell Mark.



STEVE:  I needed someone, I needed to bounce it off of somebody really smart.  And Mark is, similarly, he's, like, holy crap.  And I said, I know.  And he loves it.  I mean, it's like, so correct.



LEO:  Good.



STEVE:  And but there was a point I was going to make.  That's the reason I mentioned Mark.



LEO:  Well, that's the only person who knows what...



STEVE:  You were asking, you were...



LEO:  Well, just why you didn't want to say the name, because you didn't want to stimulate people to say what it might be.



STEVE:  I don't remember where I was going with that thought, unfortunately.  But anyway, so one person knows.  And, oh, I know what it was.  Mark felt that in order for this to succeed, I had to do everything.  I had to have the mobile app...



LEO:  Before you announce it, yeah.



STEVE:  And I had to have web-side stuff and everything.  I don't think so.  I mean, I understand Mark's position.  But this is so compelling, it will just - it will immediately kill one-time passwords.  They're dead.  They are, I mean, the reason - it's just, it's so much better than that.  And so I want to lay out the concept.  But it's crazy for me to - I just don't have the time.  And it doesn't make sense for me to, like, try to do the whole thing.  It's not necessary.  The concept will - it's so much better than anything we have ever seen that it will just happen.  It will acquire its own traction.



LEO:  Good.  I look forward to finding out more.  We don't have an ad.  You can go right into Bitmessage, our topic of the day.



STEVE:  Okay.  So, Bitmessage.  As I said at the top of the show, I'm not bothering to dissect the protocol because there are too many problems with it.  In time, when it gets to 1.0 - it's currently at 0.3.5 - then maybe these things will be figured out.  Or maybe it will have sort of been the first shot.  I think I was reading that Bitcoin - no, no, it wasn't.  It was the guy who did Litecoin.  This was not his first alternative to Bitcoin.  He did a first one, and there were a lot of problems with it.  And then he figured out how to do it right, and he learned from that and did Litecoin.  So similarly, this is sort of - this was just proposed in the wake of the surveillance that was assumed to be going on.  And this was even - this was back in 2012, late.  I think it was, like, maybe November of 2012 that the whitepaper was produced proposing it.  It's a little short six-page document just sort of laying out the concept.  And there's now code.



So one of the things it's getting is a little bit of credibility that it really doesn't deserve from Bitcoin because the reason I got so excited about Bitcoin when we did the podcast was that it was done so right.  So it's called "Bitmessage" sort of unfairly because the only thing it really has in common with Bitcoin is, first of all, the "Bit" prefix.  The fact that there is the concept of a partial hash collision, which was one of the things that was so cool about Bitcoin, the notion of a proof of work, the way the Bitcoin system slows down the generation of coins to keep them at a constant rate in the face of increasing amount of total work being done to create coinage by increasing proof of work.  Bitmessage uses that to thwart spamming because flooding of the network is an inherent problem.



And so the guy recognized that he needed to limit the way, to limit the ability to inject messages into the network.  And so there's a proof of work as part of this.  So that's something it borrowed from the Bitcoin concept.  And then the other thing is that the way Bitcoin works, as everyone knows, is that essentially everybody gets the block chain.  And so that is to say that you are - it's a peer-to-peer network where everything receives the current state of Bitcoin.  And Bitmessage has that same "everyone receives everything" model, although it isn't a chain, and the information is not kept forever.



So those are the only - that's all there is, really, to tie it to bitness relative to Bitcoin.  So I wanted to differentiate it from Bitcoin.  It's not like this is some messaging system written on top of Bitcoin or in any way related to it.  And so we shouldn't give it any props for being a relative of Bitcoin.  It isn't.  It just has that name.



LEO:  Can you just tell me what it does?



STEVE:  Yes.



LEO:  [Laughing] I mean, I can kind of infer from the name, but I'm curious.



STEVE:  Yes, yes.  So it is a peer-to-peer messaging system where everybody who wants to use it runs the Bitmessage client.  Which I think is a Python app.  I think it's written in Python.  And so it's multiplatform:  Windows, Linux, and Mac.  So they run this client, which connects into this peer-to-peer network.  And all users retain the most recent two days' worth of messages.  So when somebody new connects up, they connect into the peer-to-peer network, so they're adding their node to this, and they receive from the peers the most recent two days' worth of Bitmessages, which the entire network maintains.



So basically this is a bunch of peers that are passing messages around among each other.  Anyone who wants to send somebody else in the network a message can.  So everybody gets an asymmetric key pair, a public key and a private key.  The hash of your public key is obviously a much smaller token.  And the Bitmessage starts with a BM for Bitmessage, hyphen, and then it's a 36-character, we're used to seeing these pseudorandom strings, just looks like gobbledy-gook.  It's weird.  And I think it's like base58, which I've seen some people say, huh?  Why 58 and not 64?  It's like, okay, 58 for some reason.  Maybe it's to make - maybe they eliminated some of the visually confusing characters in case someone was going to type it in.  You could type in an address.  Hopefully you don't have to very often.



So everyone is known in the network only anonymously.  So there's no username.  There's no password.  In that way it's sort of also like Bitcoin.  You are just this string, this token, which is a hash of your public key.  So you could put that on your website.  You could email it to a friend.  You could do whatever you wanted to with it.  And there are four types of objects in the system.  There's a request for the public key.  So given the hash, you could ask the network for this user's full public key, which you would use to encrypt a message that only they can read.  So that's the way a person-to-person message is sent.  Then another object is the public key.  There's also a person-to-person message or a broadcast because what you could also do is a person could put onto the network something that they want multiple people to read.  And so rather than encrypting with a recipient's single public key, so that only they're able to receive it, you would instead encrypt with your private key so that anybody who wants to read what you have broadcast is able to do so.



So anyway, so basically it's a weird concept.  All these people are in this completely, this densely interconnected peer-to-peer network.  And anyone who sends a message, that message is received by everyone.  And the only way you know if a message has been put in, sort of like dropped into the network, where it propagates across the entire network, is if your private key can decrypt it.  So messages are coming in, and your client checks each one that comes in to see if it's able to decrypt it.  And if it is, then it must have been encrypted with your public key and thus bound for you.  And so, when you think about it, this defeats to some degree, but there are many - this has been around long enough, and enough people have looked at it, that there are people beginning to find little chinks in the armor here.



The concept was that, since everybody received all messages, there was no way to tell when a message was meant for someone.  Which is clever.  I mean, it defeats traffic analysis just by virtue of sending everybody everything.  It's like, uh, okay.  So that's essentially the concept.  There are - normally, messages are acknowledged.  And so some critics of this have said, wait a minute.  If messages are coming in, and they're being selectively decoded, and they're acknowledged when decoded, then a node, a user, could be seen sending an acknowledgment out, which would mean that that's acknowledging something they received.  So you can see where you could begin to chip away at this, at the opacity that the entire system was designed to have.



Also it feels very immature from a cryptographic standpoint.  Normally what you do, and we've talked about this often, is if you wanted to encrypt a message, you would use a pseudorandom number generator to generate a nonce, a one-time symmetric key.  You would use any of the well-established, proven, cipher-block chaining approaches to encrypt your message under that symmetric key.  Then you would only use your - either the private or the public key, the asymmetric key, to encrypt that symmetric key.  And you attach it, and off it goes.



As I understand it - and again, I didn't dig really deep, I'm just looking at comments from people who have been critical of it - the system uses the asymmetric key for the bulk encryption.  Now, part of their motivation was probably to slow down the creation of longer messages because there is this intention in the system for the bigger the message is, the harder it is to create it.  So they may have deliberate- I mean, it's hard to imagine that somebody who created this wouldn't have understood how basic PGP or SSL, I mean, all encryption uses the concept of a pseudorandom key that you use for symmetric encryption, and you use the much more slow asymmetric encryption only for the symmetric key.



Anyway, as I understand it, this system doesn't do this.  Also, there is no interblock connection.  And I've seen some people talking about that you could reuse already encrypted blocks and reorder them.  And allowing blocks to be reordered is never a good idea.  And you can also append additional information to the end of blocks.  Anyway, it's like the implementation really feels weak.  So again, it's receiving well-deserved criticism.  And I think maybe at some point it'll get off the ground.  It's not clear.  It is possible to tell people you are very concerned about privacy, so you will not respond with an acknowledgment.  Otherwise, the problem is, if somebody were sending a message to you, remember that messages only stay, in all, sort of are hosted by this network for two days.  So what if the recipient was offline for two days, and then the message that was bound for them they would never see?



So the idea is that you would need to check in every two days in order to get an update of all the messages that you're behind on so you can see if any of them are for you.  Oh, and when you receive it, you're supposed to acknowledge it to the sender so the sender can remove it from their sender's queue and essentially know that the recipient got it.  Otherwise the proper behavior, if the sender really wants to verify receipt, is an exponential back-off, where they'll wait two days, then they'll wait four days, then they'll wait eight days, then they'll wait 16 days, resending, each time doubling the length of time.  Then the logic on the receiver's side is you need to listen, if you've been away for some number of days, like 16 days, you need to listen for at least that length of time in order to create a window during which the sender will resend during the period of time you're looking.



So anyway, it's, as you can kind of hear, it's like, uh, okay.  It's kind of clunky.  People are really concerned about scaling.  The original author of the document addresses this.  And he comes up with a way of, like, forking the network through a series of binary decisions to create substreams, and then a sort of a complex way of managing parents and siblings of streams.  And anyway, it's just - it's interesting, but it just doesn't feel like it's there yet.  And I actually found myself being encouraged by looking at some of the very good criticisms of it.  And as I mentioned at the top of the show, people who are saying, eh, well, I'm working on something that I think is going to solve these problems, so I want to let everyone know that.  And but in the meantime here's what I think about Bitmessage.



So it's like, yeah, if you need - I think if you're curious about things, grab it, load it up, play with it.  People who have played with it say it's very cool.  They get this token which is their identity.  They send it to a friend.  And then they get their friend's token.  And then in the client you're able to, say, generate a person-to-person message or a broadcast.  So you choose which type of message you want to put out onto the network, and then you just type a message and send it.  So there's no support currently for files.  There's no support for formatted text and all those things.  Those things could come later, in this or in some other form.  So it's interesting.  But I don't think it's really there to be taken seriously.



LEO:  Yeah, I guess somebody said in the chatroom that Dvorak's using this on No Agenda.  So there.  If you're a fan, you might want to mention this.



STEVE:  Yeah, there was also, somebody did an experiment to de-anonymize Bitmessage users.  Because you can see the tokens of people on the network, this person collected thousands of current Bitmessage tokens, then requested their public keys so he could send them something, and then sent each person a customized message with a URL to a server.  And it made it look like it was an official Bitmessage announcement addressed to them.  And so it's like 15,000 people clicked the link and immediately lost their anonymity because, of course, not only did he have their IP, but the URL was customized so he knew which Bitmessage token was associated with which user coming in, and therefore what their browser query headers were and the IP where they were.



LEO:  Wow.



STEVE:  So that's, now, arguably that's an out-of-band attack.  It's clever.  And so it's the standard, well, don't click on links, please.  But it's an example of how the system could be abused.  So anyway, it's interesting.  It's like, eh, okay, we need something better.



LEO:  And Cryptocat still a good choice, do you think?



STEVE:  For, yes, I would say from point to point.  See, Cryptocat is real-time.  It requires you both be online in order to...





LEO:  A traditional IM system, yeah.



STEVE:  Yes, like a traditional IM system.  Whereas this is more of an asynchronous...



LEO:  Store it forward, yeah, yeah.



STEVE:  Yes, store-it-forward asynchronous messaging.



LEO:  Google Hangout says that, too. 



STEVE:  Yeah.  So for real-time interaction, the Cryptocat implementation of OTP is great.



LEO:  And you can still use PGP and encrypt any arbitrary bit of text.



STEVE:  Well, and remember that, when we talked about OTP, the protocol, of which Cryptocat is just one of many implementations, many existing, like Trillian, many existing IM clients already have OTP support.  And it's bulletproof technology, though it is real-time because you need to negotiate on the fly.  And so, I mean, there really are existing good solutions for this.  And this is just interesting.  And I liked - I think the real attraction was this concept of no one can tell when you're the recipient because everybody gets everything.  And it's like, okay, well, there's good and there's bad to that.  And scaling is one of the problems because you can see the problem with spamming.  Imagine if something injects spam into this, and now everybody, every single node has to store every single message for two days.  As this system gets bigger, it just - scalability is a real problem.



LEO:  Steve Gibson scales amazingly.  Yet still we must wait for his amazing revelation.  



STEVE:  Yeah, I'm sorry, I don't mean to tease, but I just - it hit me, and I just - I want to get it down, put it on...



LEO:  You don't scale.  You don't scale either, come to think of it.



STEVE:  No, I don't.



LEO:  One thing at a time.



STEVE:  That's the problem.  Several people have said we wish we had two Steves.



LEO:  He's single-threaded.  Even if his brain is multitasking, his abilities are single-threaded.  And that's as it should be.  You can go to GRC.com and see all the things he's cranked out one at a time.



STEVE:  One more, one more biggie very soon.



LEO:  Good.  I'm excited.



STEVE:  Yeah.



LEO:  That's where you get SpinRite, the world's finest hard drive maintenance and recovery utility.  You must have it, if you have a hard drive.  That's at GRC.com.  Steve's also got lots of other stuff, including his feedback form. This would be an opportunity for you to ask questions of Steve, GRC.com/feedback.  We'll be answering them next week, god willing.  God and the security environment willing.



STEVE:  If nothing horrible happens.



LEO:  If somebody doesn't leave his TrueCrypt password unencrypted.  What else?  Oh, 16Kb audio is there.  Transcriptions by Elaine Farris.  It's a great resource.  You can also follow Steve on the Twitter:  @SGgrc.  And if you want full audio or video versions of this show, we have those, too, at our website, TWiT.tv/sn.  And of course you can always subscribe to any version just by going to iTunes or wherever you subscribe to podcasts.



STEVE:  And Leo, I have agreed to come up and be with you for New Year's.



LEO:  Yay.  So that's something going to be exciting.  We're going to look for people who are in every time zone because we're going to do the 24 hours of New Year's.  I'm the only one who's going to stay up 24 hours.  You don't have to.



STEVE:  I don't plan to.



LEO:  But we're going to get a lot of people up here.  And I'm really thrilled you're going to do that.  And we're just going to have a party.  And every hour, and actually in some cases less than an hour because there are 26 time zones,  we will do a countdown to New Year, starting at 4:00 a.m. New Year's Eve.  That's what I calculated to be the beginning of this program.  Four in the morning, New Year's Eve.



STEVE:  Okay, now, and so the podcast is normally, let's see, where are we on the 2014...



LEO:  We'll do you at the normal time.



STEVE:  New Year's Day...



LEO:  Oh, yeah.



STEVE:  New Year's Day is Wednesday, January 1st.



LEO:  Right.  I'll be done by 4:00 a.m. New Year's Day.  But I'll stick around if you want to - you know, we should just do the show the day before.



STEVE:  Yeah, let's do it the day before.



LEO:  We'll do it New Year's Eve.



STEVE:  When you're still, like, able to put sentences together.



LEO:  Early.  In the first 12 hours of the show.  If we do it at the normal time a day early, that'll be fine.



STEVE:  Perfect, perfect.



LEO:  But we'll have to do it after the 11:00 a.m. countdown because it's New Year's, that's the beauty of this, it's New Year's Eve somewhere for 24 hours.



STEVE:  Leo, we can do it in four 15-minute segments.



LEO:  That's what we'll have to do.



STEVE:  I'm happy - I'll work with you.



LEO:  Oh, I'm so glad you're coming.  We're starting to line up people.  And it looks like it's going to be a great party.  I'm hoping we get some music and stuff.  Anybody who's listening who wants to be up here at the Brick House for that, please do.  New Year's Eve, we start at 4:00 a.m. New Year's Eve morning.  And then we go through 4:00 a.m. New Year's Day because we have to get Hawaii.  And then we're done.  Should be fun.  I haven't done 24 hours in a long time.



STEVE:  Yeah, not since you were...



LEO:  Not since the iPhone.



STEVE:  ...young, Leo.



LEO:  Well, no, no, not that long ago.



STEVE:  Oh!



LEO:  2008.  When the iPhone came out in 2008 we did a 24-hours of the iPhone.



STEVE:  Wow.



LEO:  I'm hoping I'm going to get a nurse to check my blood pressure.  I want to get a masseuse to give me backrubs.  I want to get a barber to come and give me a haircut and a shave.  We're going to - it's going to be an endurance.



STEVE:  Oh, my god.  You know what I'm going to do?



LEO:  What?



STEVE:  I'm going to bring my coffee for absolutely...



LEO:  I will need you to do that for me, yes.



STEVE:  Yes.  You have got to taste this coffee which everyone I expose it to says, "This is coffee?"



LEO:  You said you were going to send me a kit.  But we can hold off till New Year's Day.  That's fine.



STEVE:  We're holding off because I don't trust you to, like...



LEO:  No, no, no.  And we have to titrate - we have to titrate this every hour.



STEVE:  I have to oversee the production, the grinding and the production.  You have all the equipment.  I'm going to bring the raw materials.  And we'll hand you the cup of coffee and see what you think.



LEO:  Yes.  And I want 50 ml, 50 cc every hour.  I will slowly titrate this.



STEVE:  It's just fabulous coffee, Leo.



LEO:  Thank you, Stevie G.  We'll see you next week on Security Now!.



STEVE:  Bye.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#421

DATE:		September 11, 2013

TITLE:		The Perfect Accusation

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-421.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After covering this month's Patch Tuesday events and catching up with the past week's security news, Steve and Leo examine the week's most troubling and controversial revelations:  the NSA's reported ability to crack much of the Internet's encrypted traffic.  They explain how different the apparent reality is from the headlines, but why, also, this does form "The Perfect Accusation" to significantly strengthen all future cryptographic standards.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  And, yes, normally we would do a question-and-answer session on our odd-numbered episodes.  But today we've got a very important story.  We're going to talk about breaking news from last week about the NSA breaking all the encryption.  Is it true?  What does Steve say?  We'll talk about it next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 421, recorded September 11th, 2013:  The Perfect Accusation.



It's time for Security Now!, the show that covers you and your privacy and security online with the guy, the man, the myth, the legend, the one and only - he's holding up his spyglass - Steve Gibson of GRC.com, our Explainer in Chief.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  I was looking at the number, 421.  Now, of course that's a particularly special number for me because that's the first three digits of binary.  So 4, 2, and 1 are the first...



LEO:  Oh, wow.  You've got a mind that works in mysterious ways.



STEVE:  I see patterns in things.  But...



LEO:  I would not have noticed that.



STEVE:  ...that's a lot of episodes.  I mean, just...



LEO:  That I noticed.  Huh?



STEVE:  Yeah, it's like...



LEO:  Okay.  We have to explain because John Slanina, who's a very bright guy, says, "What?"  So the binary numbers are one...



JOHN:  And zero.



LEO:  Yeah, but...



STEVE:  1, 2, 4, 8...



LEO:  1, 2, 4...



STEVE:  ...16, 32, 64 and so forth.



LEO:  So 101...



STEVE:  And so, like, I've been doing a lot of work back in assembly language with the work on SpinRite.  And so I'm - and some of the screens that I'm putting up show hex dumps of registers.  And so the hex dump will show 05.  And so I have to decompose that into 101 to know which bits of the status the bus mastering controller has set and not.  And so I'm - so, like, when I look at 421, what I see is, oh, the binary values of the first three bits of - yeah.



LEO:  Right.  The first bit is 1, 01.  The second bit represents the twos.  You get it now?



JOHN:  He said it was the first three...



LEO:  It's reversed.  No, no.  Okay, got it.  He says you said it was the first three binary numbers, and obviously that's not - it's the decimal places on - it would be 010, a hundred thousand in decimal.  It's 0, 1, 2, 4, 8, 16 in... 



STEVE:  Right.  And the order of them, in this case 4, 2, and 1, is the binary value when it's in a hex representation of each of those digit places. 



LEO:  And that's what - and the truth is I should recognize it because 421 are the bits that you set with chmod when you're in Linux, when you change file permissions.



STEVE:  Precisely, exactly.  And so, yes, it's a 7.



LEO:  It's a 7.  Folks, if we haven't baffled you yet, you belong here.  This is your show.  You found the right show.



STEVE:  This was not a test to see whether you qualify for the balance of the podcast.



LEO:  Yeah, but it - yeah.



STEVE:  This was just a little diversion.



LEO:  [Sighing]



STEVE:  Now, we were supposed to do a Q&A.



LEO:  Yes, we were.  We're not, I see.



STEVE:  How could we?  You know?



LEO:  I know.  It's just endless, isn't it.



STEVE:  Once again, on the day after the podcast, it was last Thursday...



LEO:  We had you on the radio show to talk about it, it was such a big story.



STEVE:  And I came on with Tom on Tech News Today.



LEO:  That's right, yeah.



STEVE:  In order to talk a little bit about it.  Basically, to sort of calm people down.  And what I want to do today, we're going to talk about the most recent round of revelations, which, as we've seen before, unfortunately, the press goes crazy.



LEO:  Oh, yeah.



STEVE:  It's not the functions which are hyperbolic, it's the headlines.  And so I titled this "The Perfect Accusation" because, as we're going to see, what we actually know is that, like, where - and I've read all these press articles that talk about the NSE - I'm sorry.  The NSA has substantially, is substantially able to crack all of the Internet's cryptography and subvert it.  And they've been working behind the scenes to weaken it.  And there's a lot to be disturbed about.  So I've got - so we'll talk about the news.  But once again, the real meat here is where I want to focus the podcast because that's what this podcast is for.  And in '07 our friend Bruce Schneier wrote a beautiful summary of the one, the only thing that anyone has been able to point to that suggests that maybe the NSA was involved behind the scenes in weakening something that no one cares about.  I mean, it absolutely...



LEO:  This is the NIST standard.



STEVE:  Yes.  This is, well, this is one fourth of it that is the worst fourth, that is the - it's like the unloved stepchild random number generator.  I've never heard of anyone using it.  No one would ever use it.  It's slower than, like, orders of magnitude, than the other good ones.  And it's just - it's, like, bizarre.  But the key is, it is perfect because, even if it were cracked, and it isn't, we don't even know that there was influence behind the scenes.  But we really do, as an industry, need to be more vigilant.  So this accusation could not be more perfect because probably the crypto industry wasn't asking enough questions, wasn't saying, hey, now, wait a minute, where did you come up with these magic numbers in here?  And so something was allowed to happen.



And part of the reason it was allowed to happen is everyone knew, well, it doesn't matter.  But it's perfect because it serves as an object lesson.  The entire crypto industry is aware of this.  All of our listeners will be.  And everyone can at least breathe a sigh of relief because very much in the same way that I said I - the first day that we talked about the Snowden leaks, and I said, "I'm so glad," and the news was very fresh, and we weren't sure what it was going to come to, similarly, I am exactly so glad about this because this is a wakeup call that we needed.  The fact that this happened at all says, okay, we were getting too lax.  But it can never again be the case that anyone is accused of too much tinfoil because of essentially what did happen six years ago.  Shouldn't have, but it doesn't matter.  Anyway, we have...



LEO:  Yeah, that's what the professor at Johns Hopkins said in his blog post that Johns Hopkins forced him to pull down.



STEVE:  Well, yeah.  I'm going to talk about Matt.  Matt Green is a neat cryptographer.  And it's not actually that blog post but the one, I don't remember if it was after or before, but I'm going to share that in its entirety toward the end of this because, more than anyone else I've read, Matthew perfectly sort of lays out the terrain.  And our listeners will end up coming away from this podcast saying, okay, I understand exactly what happened, and I feel comfortable with it.  I mean, revelations were definitely part of this, with what we found out.



LEO:  Oh, yeah.  We do know new stuff.



STEVE:  These documents are creepy when you read them.  But I also think, eh, they feel to me like maybe this is how we get our budget pumped up a little bit.  Some of what they're saying is like, eh, okay.



LEO:  It's a little - they're overselling the case a little bit.



STEVE:  Exactly.  I think a real close analysis would come to that conclusion.



LEO:  Yeah.  Steve Gibson, Leo Laporte, Security Now!.  Let's get to security news.



STEVE:  Yeah, so again we are on this side of a Patch Tuesday.  So I feel a little bit of an obligation just to note that to our users.  When I fired up my Win7 machine that I use only for once a week, or sometimes a little more frequent Skype connections with you guys, I had five updates that it wanted to give me.  I'm not sure actually why it was so few because there were 14 - oh, I know why, it's because I don't have...



LEO:  You don't have those...



STEVE:  ...SharePoint Server...



LEO:  There you go.



STEVE:  ...on this machine.  So, yeah, so we are this side of Patch Tuesday.  Microsoft and Adobe had treats for us.  In Microsoft's case, four of their 14 patch bundles are rated critical, collectively fixing 47, at least 47 known security vulnerabilities.  And I thought it was interesting.  Microsoft is beginning to sense the friction against updates, especially when updates are messing things up.  So, I mean, that really hurts them.  So they're beginning to prioritize them.  And Microsoft recommended, and this is my phraseology, for "reluctant enterprise-class upgraders," that they prioritize and install the Outlook, the IE, and the SharePoint Server fixes with a higher priority because those are a bigger problem.  And at least one of the SharePoint vulnerabilities has been publicly disclosed, so it's ripe for exploitation.  And in a corporate setting, you don't want anybody getting into your servers that way.  So definitely worth doing that.



Adobe was a grand slam - Flash, Acrobat, Reader, Shockwave Player, and Adobe Air.  Everything.



LEO:  But Microsoft's updating those?  Or that's the Adobe Updater?



STEVE:  Well, Adobe has updated them.  Now, IE10 has auto-update now.  And of course Google Chrome was the leader of the pack in auto-updating browser technology.  OS X - I'm sorry, OS 10.  I keep writing "X," and that's why I say it - OS X will block older versions now, so it's aware of that, and tell you you need to update.  So it's really only Firefox and Opera users who still may need to deliberately go and get it.  And as always, if you do go to the site and grab a download update pack, make sure you disable the default-enabled McAfee Security Scan if you don't wish to have that installed in your machine.  It's just amazing that they think they can get away with that.  But I guess they get money from McAfee.



Yahoo! has joined some of the other very unhappy commercial providers named in the very early Edward Snowden links in suing the federal government and the FISA Court, essentially for the damages they're experiencing over loss of reputation.  Yahoo! said on Monday that they've joined other U.S. technology giants in launching legal action against the federal government over the NSA surveillance revealed by whistleblower Edward Snowden.  I'm reading from an article in the Guardian, which I thought was interesting because this article, I salute the Guardian, is being pretty rough on the Guardian.  It said:  "Yahoo! filed a suit in the Foreign Intelligence Surveillance (FISA) Court, which provides the legal framework for NSA surveillance," of course as we know, "to allow the company to make public the number" - so they're saying "to allow the company to make public the number of data requests it receives per year from the spy agency."



Now, again, that seems like a benign thing.  They're not saying we want to say who.  We just want to say how many.  And I think they...



LEO:  Google has asked for this, too.



STEVE:  Yes.



LEO:  And I think Facebook, as well.  And of course they've said no.



STEVE:  Yes, Google and Facebook.  Google and Facebook are the other.  And also Microsoft is in there, too.  And one of the Yahoo! guys said:  "Yahoo's inability to respond to news reports has harmed its reputation and has undermined its business, not only in the United States but worldwide. Yahoo! cannot respond to such reports with mere generalities."  And also it says: "Criticizing news coverage, specifically by the Guardian and the Washington Post, Yahoo! said media outlets were mistaken in claiming that the PRISM program allowed the U.S. government to tap directly into the servers to collect information.  It said that claim was 'false.'"



So we still have this cloud of we don't know the details.  And that cloud may never be lifted.  You'll remember, of course, everyone will remember my original theory was, if we take the denials of the reading that some looking at Snowden's slides gave, and take the position that the NSA has installed taps just upstream of the providers, that it very much solves the same problem, without actually requiring that these companies are complicit in this.  So again, we don't know.  But to me this is interesting because it is clearly the case that the domestic corporate interests are really being hurt by this notion that they're collaborating with the NSA and people who are upset by the idea that their privacy is being compromised.  So another one in the pile.



Also OpenID, or myOpenID, which is a service run by Janrain for, wow, seven years, announced that they were going to be closing on February 1st of 2014.  The CEO, Larry Drebes, explained.  He said:  "In '06, Janrain created myOpenID to fulfill our vision to make registration and login easier on the web for people.  Since that time, social networks and email providers such as Facebook, Google, Twitter, LinkedIn, and Yahoo! have embraced open identity standards.  And now, billions of people who have created accounts with these services can use their identities to easily register and log into sites across the web in the way myOpenID was intended.



"By '09 it had become obvious that the vast majority of consumers would prefer to utilize an existing identity from a recognized provider rather than create their own myOpenID account.  As a result, our business focus changed to address this desire, and we introduced social login technology.  While the technology is slightly different from where we were in '06, I'm confident that we are still delivering on our initial promise - that people should take control of their online identity and are empowered to carry those identities with them as they navigate the web.



"For those of you who still actively use myOpenID, I can understand your disappointment to hear this news and apologize if this causes you any inconvenience.  To reduce this inconvenience, we are delaying the end of life of the service until February 1st, 2014 to give you time to begin using other identities on those sites where you use myOpenID today."  And then he says:  "Speaking on behalf of Janrain, I truly appreciate your past support of myOpenID."  So we originally covered this.



LEO:  Yeah, I used it, frankly.



STEVE:  When it happened.  And, I mean, it had - I guess I would call this early first-generation, an early first-generation attempt.  To give our listeners a quick review, you logged in, kind of perversely, with a URL.  And it was a URL to a page that you controlled.  And so that was the concept, the idea being there's always this notion of something you control.  For example, using email to authenticate, you controlled your email account.  In this case, the idea was you controlled a web page.  And so you logged in with a URL to the web page, and then the site could go there to pick up your login credentials for authentication.  And anyway, it just sort of - it was interesting.  You could - sometimes you'd run across a website that would say, oh, log in with OpenID.



And so these guys were for people who didn't have their own website and web server and couldn't easily manage their own page.  This was a service to provide that identity sort of as a third-party provider.  So it was an interesting notion.  And what he's talking about, of course, when he refers to social login, is what we have since been covering, which people see as log in with your Facebook account, log in with your Twitter account.  And that's the  OAUTH approach, where the site you're attempting to authenticate to bounces you over to a site where you are already known.  You authenticate there, give permissions as required, and then behind the scenes that site authenticates you to the place you were trying to log in, and your browser is again bounced back to where you originally were, now authenticated.  And then behind the scenes is the plumbing to make that secure.  We did a podcast on OAUTH quite some time ago [SN-266].



At this point, Facebook accounts for 46% of OAUTH social login use.  So it's the leader at 46%.  Google is second at 34%.  Yahoo! a somewhat distant third at 7.  Twitter right behind it at 6.  Then a whole bunch of other sort of there, too, also-rans collectively have about 6%, and Microsoft is less than 1%.  So Facebook is the clear leader, with Google coming in in second place at 34.  And that's where we are.  And of course there's a lot of attention being given to login, and I teased everyone last week with the idea that I think I may have a really terrific solution that's better than all of that.  So I will be working on that soon.



Many people, as a consequence of the NSA revelations, have tweeted me and said, hey, Steve, what about LastPass?  You vetted it.  You use it.  Leo uses it.  Everybody likes it.  But where are they relative to the NSA?  Responding to that yesterday, Joe posted a blog that I'm going to share with our listeners.  He said:  "With news that the United States National Security Agency has deliberately inserted weakness into security products and attempted to modify NIST standards, questions have been raised about how these actions affect LastPass and our customers.  We want to directly address whether LastPass has been or could be weakened, and whether our users' data remains secure.



"In short, we have not weakened our product or introduced a backdoor, and haven't been asked to do so.  If we were forced by law to take these actions, we would fight it.  If we were unable to successfully fight it, we would consider shutting down the service.  We will not break our commitment to our customers.  Although we are not currently in the position of having to consider closing the service, it is important to note that, if LastPass had to be shut down, our users would be able to export their data or continue using LastPass in 'offline' mode, although online login and syncing would no longer be possible.



"We have consistently reiterated that LastPass cannot share what we cannot access.  Sensitive user data is encrypted and decrypted locally with a key that is never shared with LastPass.  As always, we encourage our users to create a strong master password to better protect themselves from brute-force attacks.  Given our technology and the lack of access to stored user data, it is more efficient for the NSA or others to try to circumnavigate LastPass and find other ways to obtain user information.



"Ultimately, when you use an online service, you are trusting the people behind that service to have your best interests at heart and to fight on your behalf.  We have built a tradition of being open and honest with our community, and continue to put the security and privacy of our customers first.  We will continue to monitor the situation and change course as needed, with updates to our community when necessary.  Thank you to our community for your ongoing use and support of LastPass."



LEO:  Now, this is the fundamental problem with any closed-source solution is, yes, they do everything right, but they could be coerced to put a backdoor in the closed source, the binary that you're required to use.  Right?



STEVE:  Well, remember that they're running JavaScript on our browser.



LEO:  Oh, all right.  So it is open source, then.



STEVE:  It is open.  No, it's open source.  And they even - and, I mean, this is why I'm so happy with them is everything that you could do, they have done.  It is truly TNO.  Otherwise I would never have recommended it as I have.  I wouldn't be using it myself.  As I said, I don't know any of my passwords anymore.  And no one needs to...



LEO:  I love LastPass.  But I'd be very sad to learn that it could have a backdoor.  But it couldn't, you're saying.



STEVE:  And here's the point.  Yes, it can't.  Here's the point is that the NSA did go after - I'm blanking now, the email company, the email provider who Snowden used.



LEO:  Yeah, yeah, yeah.  I'm blanking, too.  I've put it out of my mind.



STEVE:  Yeah.  Anyway, we know who we're talking about.  A couple weeks ago...



LEO:  And he shut down, much to the dismay of the NSA.  Lavabit.  Thank you, chatroom.  Lavabit.



STEVE:  Because he wasn't actually offering - yes, Lavabit.  They did go after Lavabit because he wasn't actually secure.  It was fake security.  It was completely vulnerable to him receiving a national security letter, which he would have to comply with, and he would have to violate his customers' privacy.  All LastPass is storing for us is a preencrypted blob.  They do not have the encryption key.  Only we do.  What they get is a multi-iterated hash of the encryption key and our account name, our email address in this case, and password, hashed a bunch of times, which serves as an opaque token with which to identify who the blob belongs to.



So our browser says, here's a blob and this cryptographic token which means nothing.  Save this for us.  And they do that.  And then when, over on our iPad, we log in, the iPad says, hey, are there any updates to this cryptographic token's blob?  And the LastPass server says, oh, I do have a newer blob for you.  Here's your new blob.  And so that's how synchronization works.  Only when the blob gets down to the client, which then has the email address and password, are those used, again, cryptographically multiple iteration hash, to generate a key which decrypts the blob there.



So there's - and this is the model for the future.  This is the only way these things can work.  That's what we've been talking about for years:  Pre-Internet Encryption and TNO, Trust No One.  There is no reason for the NSA to bother the LastPass folks because their system is secure.  Now, the danger that exists is that they would be compelled to insert in the currently secure system some insecure technology.  And we have to acknowledge the possibility.  I mean, if I don't say it, I'm going to get flooded with tweets that will say, Gibson, this is possible.  And it's like, yes, it's possible that - and unfortunately, one of the things that we know from this last week's revelations is the NSA is not happy that, like, LastPass exists and has done this in such a secure fashion.  [The NSA] would love to have access to all of a given user's login passwords for their entire identity.



One of the things that the protocol I will be shortly proposing solves is all of this.  There's no reliance on this kind of vulnerability, which is one of the things that makes it better.  But what Joe is saying is he won't do that.  He will, like Lavabit, just say, I'm sorry, we're pulling the plug.  He won't be able to tell us why.  He'll just say, "LastPass has decided we can no longer offer this service.  Good luck."  As opposed to breaking this trust.  Now, then you wonder if him doing that puts him in violation of a letter saying you need to give us access because that's one of the other things that Lavabit said was that there was an implication in the email that his attorney was receiving that shutting down the email system was preventing the government from getting what they wanted from him.  It's like, oh, lord.



LEO:  And I'm sure the law allows them to compel him in some form.  And it wouldn't be surprising if it compelled LastPass to do it secretly.



STEVE:  Yeah, I mean, so...



LEO:  Maybe the solution is to use the open source KeePass.  It's not as functional.



STEVE:  Yeah, and then not update it.



LEO:  Right.  Well, it's open source.



STEVE:  I mean, that's the problem, is the only - I guess what we could do is, if there was a way, for example, of freezing the LastPass code base so that it...



LEO:  But if it's JavaScript there isn't because you're loading it every single time; right?



STEVE:  Exactly.  You're getting an update from - and the LastPass plugin uses that in order to provide your form fill.  So anyway, we're in an interim awkward place right now, and I hope we can move past that quickly.



LEO:  Boy, it'd be really a big compromise to get LastPass because that would - then they'd have everything.



STEVE:  Yeah.  So Jenny and I saw "Riddick."  And I tweeted "FWIW," which is For What It's Worth, "Riddick was pretty much awful."  And I tweeted, "If you're sure you'll like it, then go with that.  But it was much less good than the two previous."



LEO:  Oh, you liked the other ones.



STEVE:  Oh, "Pitch Black" was great.  I thought that was innovative and new and fun and interesting.  And then the second one I thought was really fun, too.  This was just kind of a cartoon.  It's like, eh, okay.  So I just - and many people thanked me for the warning.  I mean, it'll be on disk next Tuesday, so - I'm kidding, but, I mean, soon it'll be out.  And spend $3 to get it on Apple TV or an Amazon download or something.  Don't spend $15 in the theater unless you really...



LEO:  I can't tell you how few sequels are any good.  Think about "The Matrix."



STEVE:  Yeah.



LEO:  "Star Wars."  Though people are going to yell at me for that one.  But...



STEVE:  So, and in response to this, David Busch tweeted from - his handle is @HappySlice.  He said:  "@SGgrc Riddick movies were always campy."  Can't argue that.  He said:  "I watched the first three episodes of 'Orphan Black' yesterday.  Fantastic show."



LEO:  Oh, wasn't that good.  Yeah, thank you for that recommendation, by the way.



STEVE:  Yes.  And so the reason I brought this up is that I've had a lot of feedback from people.  I haven't even poked into it yet.  But Jenny also watched it and loves it.  And Elaine, who read the, well, created the transcript last week, noted that Season 1, Episode 1 - remember I said that Paul had mentioned in The New York Times that he believed it was being re-aired.  It re-airs on BBC America starting September 14th.



LEO:  As they prepare for the new season.



STEVE:  Yeah.  So three days from now.  So for anyone who wants, it was 13 episodes.  Was it 13 or 10?  Can't remember now.  But anyway, so people are really liking it.  So that's good news.



LEO:  Good.



STEVE:  Okay.  So I did note, I watched Apple announce the new iPhone 5S.  And like everybody, it's like, okay, 64-bit processor, that sounds interesting, motion, or the M7 motion...



LEO:  Let me ask you, though, before you go jump on, okay, to the next thing, 64-bit processor.  It's hard to get the straight information on this.  You're a programmer.  You would understand the value or the non-value of 64 bits.  It's my understanding, certainly on a desktop, the clear advantage is you could address more memory, so you can break the 4GB RAM barrier.  This is not a problem on phones.  They don't say how much memory the iPhone has.  But I guarantee it's not 4GB.  It's much more likely a gig or two.  There's one phone that has 3GB.  Nothing has more than that.



STEVE:  The only - the place where 64-bit matters is where you're dealing with math of any kind that can't fit in 32 bits.  So the way a 32-bit processor handles it is in pieces.  So you add the two lower 32 bits, and maybe there's a carry from that.  So you then add with the carry the upper 32 bits.  So in terms of performance, and that also...



LEO:  For giant numbers, though, only; right?



STEVE:  Yes, yeah, exactly.  For, well, so crypto is giant numbers.



LEO:  Ah.



STEVE:  Graphics oftentimes uses giant numbers.  So it's just, I mean, my sense, you know, here I am programming in assembler.  I look at...



LEO:  Well, that's why I ask, because you know register sizes.  Most programmers aren't even aware of this.  And that's what 64-bit means; right?  It means it has registers of, instead of 8 or 16 or 32...



STEVE:  They are double the length.  They are...



LEO:  They're 64-bit registers.



STEVE:  Yeah.  And so...



LEO:  A lot of what you do does not require 64 bits.



STEVE:  Right, like character processing and so forth.



LEO:  Right, that's 8 bits.



STEVE:  Eight bits,  yeah.



LEO:  Maybe 16, if you're using...



STEVE:  Right.



LEO:  So my question is, is it a marketing term?  Or is there some real value to be gained on a mobile platform with 64 bits?



STEVE:  Oh, I see.  I...



LEO:  That's a value judgment.  I mean, I'm only asking you what are the technical advantages of 64 bits.  And you can access more memory, and you can work on giant chunks of - giant numbers.



STEVE:  Correct.



LEO:  I guess if you're doing - moving data, you can move bigger chunks at a time, which is nice.  That's why gaming would benefit.



STEVE:  Yeah.  Although, for example, what's happened with our processors is the processor speed has completely outstripped RAM speed.  RAM is stuck because of its physics to being relatively slow.  So we have a cache on the chip that reads in so-called "lines" of RAM.  It reads chunks of memory at a time because the notion is processors tend to stay sort of within their neighborhood as they're executing code.  So doubling the register size doesn't mean that the cache was doubled or that the cache line size was doubled.  It probably wasn't.  That's probably...



LEO:  No, I'm sure it wasn't, yeah.



STEVE:  Those things are probably all the same.  So I agree.  I think maybe it's a little bit of specsmanship, more than anything else.



LEO:  ExtremeTech, Joel Hruska says on ExtremeTech it's marketing fluff.  But I think that is a somewhat subjective judgment.  And the other thing I don't fully understand is the difference that ARM might - because we're using a RISC architecture with ARM, there may be a difference.  That's different - I'm thinking, 64-bit generally for me is on the Intel CISC stuff.  That I'm a little more familiar with.  I'm not sure if it changes things in the ARM architecture, the v8.



STEVE:  Yeah.  When we were talking about how processors work, we did our whole processor technology series years ago, one of the things that we made clear was that the reason the complex instruction set, the Intel-style instruction set is inherently difficult to run at low power is you've got all of this real estate taken up with very - with instructions which have very low utilization.  You have to have them because you want to be backward compatible to all the way back to an 8088 chip, which Intel to their credit is.  But, boy, they're dragging that legacy forward with every single generation.  They still have to have all of that old gunk that you just have to know they would love to be able to flush.  Whereas the ARM people were able to..



LEO:  To start from scratch, yeah...



STEVE:  ...start from scratch, yeah.



LEO:  They do, on the ARM page, talking about their x8 and 64-bit, they do say - or v8, I should say - they do say that - they do mention cryptography specifically.  And that does make sense, if you're dealing with giant primes.



STEVE:  Yeah.  I would say look at the phone we have now and what it's able to do with 32 bits.  It's like, that seems fine to me.  I mean, everything scrolls smoothly.  Nothing is jerky and hesitating.  I mean, clearly you could engineer the phone around 32 bits if that was what you needed.  I just think we're going to see RAM get larger and ROM get larger.  And the problem is, with 64 bits, it just in general is more hungry.  Even though they apparently have really got power consumption down, too, on this thing.



LEO:  Yeah.  Oh, I'm sorry, I didn't mean to interrupt, but I knew of all the people I could ask about 64-bit, I thought you'd be the best on that.



STEVE:  So fingerprints...



LEO:  The fingerprints, yeah.



STEVE:  ...is interesting to me.  I think it's 100% cool.  I love that it's round because that means it's orientation independent.  I sort of wish that it was a linear, drag your finger over it approach because then it's less easy to spoof it, I've always felt.  If you have to move your fingerprint over it, you can get a lot of linear resolution and a lot of temporal resolution as you drag your finger across it.  But then you certainly don't get rotation neutrality.  And it's clearly nice that you can put your finger down on any 360-degree orientation, and it spins it around and figures out what it's seeing.  And one of the things that I've been noticing in the buzz about this is people worrying about the security of it.



Well, what I would remind people is it is not its goal, like a fingerprint that you leave behind at a crime scene, to be able to identify you from the population of the world, where we see on all of the crazy TV shows where the fingerprint comes up, and the computer's going [vocalizing], like finding features, and then you see all these faces flashing by, and we find the person that that one fingerprint belongs to.  None of that is happening here.  All that's happening here is that we've trained the phone to recognize one or a very few, because you could have multiple people trained, fingerprints out of everybody else.  So that's a very different problem.  That's the problem of here's five fingerprints, or one, typically, if you just have just your phone, here's one fingerprint that we've seen over and over and over and over and over and over and over.  Now comes a new one.  Is it the same?  That's the question we're asking.  Is it the same?



And so the beauty of this, if they've done it well, is that every time you use it, it is refining its knowledge.  Notice that you may actually put your fingerprint down in a slightly different position.  So hopefully that gives it knowledge that it didn't have of a new region of your finger, whereas it has enough of the old, of the region it's seen before, to say, ah, same guy.  Look, it's moved over 17 pixels.  But we've got some more information here over on the right-hand side.  So it expands the map of the finger.  I mean, I trust them to have thought about this and to have done it right.



And so it's exciting to think how well this could work because the question it has to answer is same fingerprint or not?  And that's why, potentially, it can do a very good job of, eh, this doesn't look the same.  And it's going to be, no doubt, somewhere in the world are a collection of other people whose actual fingerprint looks enough like yours that it would say, oh, he's back, when in fact he's not.  But that's the same problem that you have - this is actually a weak analogy, but we've all talked about how door keys are not unique.  There are not enough combinations for door keys for them to be unique.  There are other people in the world whose door keys fit our doors, the front doors of our homes.  But they don't know that, and we don't know that.  So it's good enough.  But it's definitely the case that somebody who you actually encounter at Starbucks who picks up your phone, or someone who steals your phone, their particular fingerprint, none of their 10...



LEO:  Highly unlikely, yeah.



STEVE:  ...or anyone they know are going to fool this thing.  Yeah.  So anyway...



LEO:  Apple says that they're saving the fingerprint as a hash, and encrypted, to boot.



STEVE:  Perfect.  That's exactly what they should do.



LEO:  So it would be useless even if the NSA were to get the database.



STEVE:  Yes.  It would be absolutely possible to run the recognizer, determine a bunch of characteristics after derotating it and recentering it and so forth, and then you take those characteristics, and you hash them so that you get, unfortunately we'll reuse the term, you get a fingerprint of the fingerprint.  Or a signature of the fingerprint is a better way to put it.  And but you can't go backwards and figure out what those features were that generated that signature.  And I believe, see, that's one of the other really nice things about what Snowden has done for us, is it's the level of scrutiny was already high.  Now it's neurotic.



LEO:  Yeah.  Everybody's very paranoid, yeah.



STEVE:  It's good.  Thank you.



LEO:  Not bad.



STEVE:  Get some, you know, tinfoil sales is up, and I think that's just fine.



LEO:  And I have to point out, and perhaps people forget this, I don't know how many DMVs do it, but certainly in California, they fingerprint you when you get your license.  So California has built a massive database of every driver in the state, of their fingerprints.  So the NSA really doesn't have to work that hard.



STEVE:  And probably not encrypted.



LEO:  Not encrypted.  I'm sure shared with the NSA.  That's the reason they collect them.



STEVE:  Yup.  They're actually recording your entire fingerprint image.



LEO:  Right, right.



STEVE:  And of course that is why famously we've said, when you go to Disneyland, and they want to use your fingerprint for access, give them your knuckle instead.



LEO:  Right.  And then it's just a matter of time before they take a little bit of hair, and then they get your DNA.  And, you know, you can't knock it because every crime is solvable then.  All you need is a fingerprint or a strand of hair.  You could say you were there.  You were on the scene.



STEVE:  Oh, just put gloves on like Dexter, and then you're fine.  Okay.  So, shoot, there was one more thing.  Oh, I did want to say that this scanner is subject to spoofing.



LEO:  Ah.  Now, this is a good question because there were scanners that would look for an infrared heat signature, and then that would be - you'd have to be a live person.  There are some scanners you could use a Play-Doh thumb.



STEVE:  Now, there's a lot we don't know.  You can, for example, you can get someone's pulse from their thumb.  And so maybe Apple's doing that.  I mean, not a lot - there's a lot we don't know yet.  But as I understand it, it's a capacitive sensor which uses the ridge, the difference in capacitance...



LEO:  Oh, that's interesting.



STEVE:  ...between the ridges that are closer and the grooves that are further away.  And so it needs to be 3D.  But somebody, I guarantee you, they will take - they'll do an experiment.  They'll take a thumbprint off of a wineglass, lift it off or just dust it and then photograph it.  Then they'll use a 3D printer to make a 3D image of that thumb, and it will unlock the phone.  And it's like, okay.  So proof of concept, that's interesting.  We're going to see that.  And then, yeah, you could - so technically, if you've got somebody's fingerprint - I mean, if this works.  We don't know for sure that it works.  But if I had a lot of spare time on my hands, I would try it.  Maybe one of our listeners who gets one of these new phones will be industrious and give it a shot.  Somebody's going to post it up on YouTube, and we'll certainly carry it when we find out about it.  But maybe Apple's done something to defeat that, where it's got to be a live thumb.



LEO:  I'd be curious.  Here's the thing that I thought was most interesting.  If it's just to unlock the phone, big deal.  Then none of this is that important.  It's just unlocking the phone.



STEVE:  Oh, Leo.  I'm so - how long are you going to be gone?



LEO:  Three weeks.



STEVE:  Okay.  Maybe I can wait.



LEO:  Don't wait, don't wait, no, no, no, no, no.



STEVE:  I really - because one of the things that my solution needs is endpoint security because...



LEO:  Authentication is so vital for all this stuff.



STEVE:  Yes.  And so the power is that it's completely anonymous, and but the ease of use is that you would like it not to put you, not to have to have you remember a big long password.  So I'm loving that there's now this fingerprint scanner.  Doubtless they will export this to an API so that apps can say please put your thumb on the Home key in order so that we know you're here.  Well, an implementation...



LEO:  That would be so awesome.



STEVE:  ...of my code for my approach on the iPhone, absolutely will want to do that.



LEO:  And the thing I thought was telling is that Apple trusts it enough to use it not just for authentication on the phone, but for eCommerce.  And they're putting their - that's putting their money where their finger is because that means they're saying you can buy stuff on the app store just with your fingerprint, not with your password anymore.



STEVE:  As Sarah said, she apparently has so many apps that she loves the idea.  She can say, oh, I want this, and then...



LEO:  It's very frustrating.  Every time you update an iPad or an iPhone, you have to enter in your password.  It's extremely frustrating.



STEVE:  And if it's a good password, then it upgrades the frustration level.



LEO:  So this is, I think, encouraging.  I'm not going to run out and buy one until I see that API and third parties adopting it.  But that could make the iPhone 5S a must-have until others do the same thing.  And it may well be that Apple, because they bought AuthenTec, has the rights to do this that others don't.



STEVE:  Yeah.  I'm up for plan upgrade on my Apple track.  I've got a Blackberry and an iPhone.  So I'll be there.



LEO:  Yeah.



STEVE:  Okay.  So this is really cool, Leo.  Net Neutrality is a hard concept to explain.  If you don't know about this, make a note, Leo, to check this out.  The URL is TheInternetMustGo.com.  I tweeted it yesterday.  And what I said was "Terrific video that finally explains Net Neutrality.  Everyone you share this with will finally get it."  Anyway, it's a spoof of a guy who's hired by the ISPs, essentially to, like, sell why Net Neutrality is a bad idea.



LEO:  [Laughing] It says at the beginning, "This is for internal marketing purposes only."



STEVE:  Yes.



LEO:  I love it.



STEVE:  Anyway, it's really good.  I commend our entire audience, TheInternetMustGo.com.  Watch the video.  It's also on YouTube, so you can just watch it on YouTube if you're interested.  And, I mean, he covers the bases.  He, like, goes to privacy advocacy groups.  And, like, there's a bunch of hippie-like people around the table, and they're, like, looking at him like he's lost his mind as he tries to tell them why it's all good that you'll be able to pay extra, $5 to get these and $5 to get this plan.  And someone says, well, that's cable TV.  We don't want that.  And he goes, oh, yeah, you do.  So anyway, highly recommended.  TheInternetMustGo.com.



LEO:  Love it.  I'm sharing it on Facebook right now.



STEVE:  Good.  It's, I mean, because, again, it's a difficult concept to portray.  And I found out about this from the EFF that is promoting this video.  So they're behind this, too.



A little quick update on SpinRite.  We have nailed the high-speed technology.  We're generating benchmarks using the new low-level, all in assembler code, which is matching the manufacturer's absolute maximum sustained data throughput rates that they say their own drives can do.  So there was one that was reasonably old, I think it was 78MB/s on the outer diameter of the disk Seagate said this particular drive can do.  And we're measuring it at 77.4 and actually achieving the absolutely maximum that the drive is capable of.  So that's what SpinRite will be doing.  And we've got that technology nailed.  Everybody, like about a hundred people are playing with that.



We've also uncovered, as I knew we would, some weird boundary cases.  There's an older OCZ Vertex 2 SSD that turns out not to be ATA spec compliant.  We were telling it - it says it's able to handle transfers of 65536 sectors at a time, but it doesn't, even though everybody else's drives do.  We've run across a couple add-on controllers that misbehave and revector the hardware interrupt controller and sort of take it over.  So I'm now in the last few days here of, like, dealing with the fringe cases.  I've come up with solutions for all of that.



So anyway, it's going really well.  And of course I will remind everybody that anyone who has SpinRite now, SpinRite 6, will be able to get a free upgrade to this hot new version as soon as I have it ready.  And actually we'll make it available probably before it's officially released for people who want to beta test.



We are getting new people joining the process.  This is - it's so fun to work in this mode because GRC has a newsgroup server, an old-style newsgroup, NNTP, at news.grc.com.  But that's not a web browser.  You can't put news.grc.com into your web browser.  You need an NNTP client.  Thunderbird is one.  Outlook actually even has news capability.  I use Gravity, which is a nice free one that's been around forever on Windows.  And the Mac's got  a news reader.  iOS has one called NewsTap that I use.



But it's really interesting because, when we're in this mode, when I'm, like, there's people in the newsgroup, we're working on stuff, somebody will have a problem.  I'll say, oh, and I'll be back in two minutes with another attempt, and they'll run it, and it fixes the problem.  And people are just not used to, like, interactive software development, where it's a cycle of, like, a few minutes, and something is resolved.  And some guys will, like, come back after being gone for three days, and they'll go, oh, my god, I can't believe what's happened in the three days.  And it's because...



LEO:  How fun is that for you?  That must be great.



STEVE:  Oh, it's just incredible.  I mean, I'm dead by the end of the day.  But I can cycle so fast that way that people are able to say, okay, this didn't work, or it hung.  And I'll go, okay, hold on a second, and I'll put some code in where it apparently hung.  That person will run it, it'll spit out some diagnostics, I'll go, oh...



LEO:  This is such a...



STEVE:  ...shoot, okay.  And then I'll say, I'll bet that your BIOS is, like, leaving interrupts turned off.



LEO:  Awesome.  Awesome.



STEVE:  And so I just add - I turn interrupts back on, problem solved, okay, move on to the next thing.  And so it just allows us to move so fast.



LEO:  You should write this up because very few people are doing development in this - or have the luxury of doing development in this fashion.  You have a devoted group of people who are literate and smart, and you're interacting with your beta testers in real time.



STEVE:  Yes.  It is real-time development.



LEO:  That's awesome.



STEVE:  And it's just incredibly powerful.



LEO:  Write this up because this is something that other developers should pay attention to.  And yet again, another really important point proving the value of community.  Having an interactive real-time community as we do with the chatroom and so forth, so valuable.



STEVE:  Yeah.  Well, exactly.  You see exactly that.



LEO:  Yeah.  I'm doing interactive, iterative broadcasting.



STEVE:  Yup.



LEO:  Yeah.  It's really cool.  That's really cool.  All right, Steverino.  It's time to talk about a perfect accusation.



STEVE:  One thing I forgot to wrap up with is people have asked how they participate in that process I was just describing.



LEO:  Oh, oh, of course, yeah.  How can we do that?



STEVE:  GRC.com/discussions will take you to our page.  Or up under Services, I think, on the main menu is Discussions.  And so that's the page that lays out how to participate - the domain name of the news server, news server configuration in order to get there.  We have a test group, GRC.test, where people can attempt to do posts.  It has a five-day expiration, so we generally host little random dialogues there.  Everything is saved forever in the newsgroups.  And so I'm operating in GRC.SpinRite.dev, as in short for "development."  That's where I am.  But there's a SpinRite group.  There's a Security Now! newsgroup where there's the discussion of the podcast topics, sort of like for people who want to go much deeper.  There's all kinds of stuff going on.  I mean, it's a little-known bastion of no - it's like, there's no flaming, there's no spam, it's just serious people who are interested in this topic.  And so, if you're interested in participating, we'd love to have, you know, the more the merrier.  It ends up being fun for everybody.



LEO:  Oh, I'm going to learn Turkish.  I found the book I want.



STEVE:  Okay.  So the perfect accusation.  One of the things that annoys me, our listeners know, is when the headlines are clearly designed to attract readers.  Or as I said, when not only the algorithms are hyperbolic, but the headlines are.  CNBC had a headline, "Internet Experts Want Security Revamp After NSA Revelations."



LEO:  Okay.



STEVE:  And it's like, what?  And then, so it starts off - I won't bother everybody with the whole thing.  But "Internet security experts are calling for a campaign to rewrite web security" - what?  No, they're not - "in the wake of disclosures that the U.S. National Security Agency has developed the capability to break encryption protecting millions of sites."  Okay.  There are no such disclosures.  No one said that.  I mean, it's just like, okay.



LEO:  Just make up the news.  You'll get more hits that way.



STEVE:  "But they acknowledged the task won't be easy, in part because Internet security has relied heavily on brilliant government scientists who now appear suspect to many."



LEO:  Oh.



STEVE:  It's like, oh, gosh, just shoot me now.



LEO:  Where is that from?



STEVE:  CNBC.



LEO:  Oh, well, no wonder.



STEVE:  I know.



LEO:  Terrible.



STEVE:  Anyway...



LEO:  This is what happens when you have people who don't understand technology, which is most people, writing about highly technical subjects and trying to get links.



STEVE:  Now, unfortunately, The New York Times did, I mean, it's as if they took what scant information they have and read it the worst possible way, knowing nothing about the subject.  So, yes, it creates an interesting, inflammatory story which, as we were just saying, generates hits.  But, boy, I mean, it leaves the wrong impression.  At the same time, the raw data is also deeply disturbing because The New York Times story linked to secret documents which were - this was this next level of rollout.  And in the actual secret document release - and now I'm reading from the source material - there's weird acronym stuff that the intelligence community uses, TS/SI/NF, whatever that stands for.  Then we know that SIGINT is Signals Intelligence.



So this says:  "The SIGINT Enabling Project actively engages the U.S. and foreign IT industries to covertly influence and/or overtly leverage their commercial products' designs.  These design changes make the systems in question exploitable through SIGINT collection, e.g., Endpoint, Midpoint, et cetera, with foreknowledge of the modification.  To the consumer and other adversaries, however, the systems' security remains intact.  In this way, the SIGINT Enabling approach uses commercial technology and insight to manage the increasing cost and technical challenges of discovering and successfully exploiting systems of interest within the ever more integrated and security focused global communications environment."



Okay.  So that's political gobbledygook, but it also says - or, in fact, now, off to the side, The New York Times has summarized this, saying:  "The NSA's SIGINT Enabling Project is a $250 million-a-year program that works with Internet companies to weaken privacy by inserting backdoors into encryption products."  Now it's like, okay.  But no examples, no names, no companies, no, like, we found one of these.  No one's ever found one.  But that's what we're saying.  "This excerpt from a 2013 budget proposal outlines some methods the agency uses to undermine encryption used by the public."



So again, what I just read is what The New York Times summarizes that way.  And so it's true that what I read is unsettling.  But they're trying to get money.  And that's one of the things I would like to remind people is they talk about things coming online, or we're making progress on this.  So we need a new facility in Utah with lots of water to cool our supercomputers, and then we're going to rub our hands together, and magic is going to happen.  So, again, this is - there are no specifics anywhere.



Also, same document, different topic:  "Basic resources in this project are used to" - and there's two that are extra worrisome - "insert vulnerabilities into commercial encryption systems, IT systems, networks, and endpoint communication devices used by targets."  So they're saying that.  But, again, no specifics.  No other information.  Just that that's what they say they're doing.  And then the other one is "Influence policies, standards, and specification for commercial public key technologies."  So it's interesting that they say that because that's what sort of - that raised the alarm among the crypto community that remembered a controversy from seven years ago where it's like, oh, I kind of remember something about that.  And we're going to talk about that next.



And then also here, two more bullets is "Reach full operating capability for SIGINT access to a major Internet peer-to-peer voice and text communications system," and that's been suggested maybe to be Skype, that there was that reengineering of Skype that we know was specifically done so that they could - someone could respond to wiretap requests.  And then also "Complete enabling for" - and then it's blanked out here, redacted - "encryption chips used in Virtual Private Network and web encryption devices."  So it's like, again, no specifics, just strong and worrisome intent.



Okay.  So, now let's look at someone who understands this exactly to sort of get our bearings.  And this is Bruce Schneier, who back in '07 - so I'm going to read what he wrote.  But he's talking about this just happened, this is new.  So remember that this is then.  This is seven years ago, six years ago that he's talking about.  And so it's history.  So he says:  "Random numbers are critical for cryptography, for encryption keys, random authentication challenges, initialization vectors, nonces, key-agreement schemes, generating prime numbers and so on."  And those are, of course, things we've talked about on this podcast often.  We all understand we've got to have a source of really good random numbers and what happens when you don't.



Continuing, Bruce says:  "Break the random number generator, and most of the time you break the entire security system.  Which is why you should worry about a new random number standard" - remember, new in '07 - "that includes an algorithm that is slow, badly designed, and just might contain a backdoor for the National Security Agency."  So what I'm reading is the only thing anyone knows about.  And all of this has sort of bubbled up from this, what I'm reading.



"Generating random numbers isn't easy, and researchers have discovered lots of problems and attacks over the years.  A recent paper found a flaw in the Windows 2000 random number generator.  Another paper found flaws in the Linux random number generator.  Back in '96, an early version of SSL was broken because of flaws in its random number generator.  With John Kelsey and Niels Ferguson in 1999, I co-authored," says Bruce, "Yarrow, a random number generator based on our own cryptanalysis work.  I improved this design four years later and renamed it Fortuna in the book "Practical Cryptography," which I co-authored with Ferguson."  I'm afraid we've got a weed whacker going on outside.



LEO:  That's fine.  It's not loud.  But it's good to note it so that people don't think it's their...



STEVE:  Don't think it's, yes, their earphones are falling out.  "The U.S. government released a" - so here it comes.  "The U.S. government released a new" - back in '07 again - "official standard for random number generators this year, and it will likely be followed by software and hardware developers around the world.  Called NIST Special Publication 800-90, the [130]-page document contains four different approved techniques called DRBGs, 'Deterministic Random Bit Generators.'  All four are based on existing cryptographic primitives.  One is based on hash functions, one on HMAC, one on block ciphers, and one on elliptic curves.  It's smart cryptographic design to use only a few well-trusted cryptographic primitives, so building a random number generator out of existing parts is a good thing.



"But one of those generators, the one based on elliptic curves, is not like the others.  Called Dual_EC_DRBG" - that stands for Dual Elliptic Curve and then Deterministic Random Bit Generator - "not only is it a mouthful to say, it's also three orders of magnitude slower than its peers."



LEO:  Oh, that's good.  That's an improvement.



STEVE:  Yeah, so it's like, oh, let's hurry up and use that one.



LEO:  That's a thousand times slower.



STEVE:  Yes, yes.  Because the other ones are - they're hash functions, or they're a symmetric cipher that you run a counter through.



LEO:  That's terrible.



STEVE:  Yeah.  "It's in the standard only because it's been championed by the NSA, which first proposed it years ago in a related standardization project at the American National Standards Institute (ANSI).  The NSA has always been intimately involved in U.S. cryptography standards.  It is, after all, expert in making and breaking secret codes.  So the agency's participation in the NIST" - the NIST is the U.S. Commerce Department's National Institute of Standards and Technology - "standard is not sinister in itself.  It's only when you look under the hood at the NSA's contribution that questions arise."



Now, I should stop for one second, just to remind people that, for example, IBM many years ago developed DES, the Data Encryption Standard.  And IBM proposed it as a standard.  And it was a technology where there are these things called S-Boxes.  An S-Box is a sort of a - it's a pattern box.  You put in a byte, and a different byte comes out.  So there's a mapping inside between incoming and outgoing bytes.  And DES has a bunch of these, which the cryptographers at IBM specified and said this is really good.  The NSA changed the design of the S-Boxes and never said why, but they did that.  They just said, uh, this is better.  And that then got standardized.



Now, we know that DES is weak, but it wasn't as a consequence of that.  It was because the key length was 56 bits, which is no longer secure.  Thus 3DES uses three different keys, each of that length, and does the DES thing three times.  Much later, when our academic understanding of cryptography improved, people looked at what the NSA had done when we were at a position to understand it, and they had fixed it.  If the original design had been left alone, DES was already broken.  It was bad.  And so without saying anything, without giving away their secrets, the NSA said, uh, change it like this.  Just trust us.



And it turns out they fixed it.  They, the NSA secretly, without telling us why, fixed the broken crypto that was used universally.  DES was the banking crypto that was universally used for a long time, until we got up to modern times.  So certainly there are cryptographers and mathematicians and a lot of smart people at the NSA.  It would be wrong to assume that their only goal is to crack Internet crypto.  They are equally responsible for helping us to have strong crypto so that foreign governments and terrorists and bad guys are unable to crack the crypto.  So I just wanted to insert that here.



Continuing with Bruce, remember, because when you look under the hood, he was saying, this Dual_EC_DRBG is in the standard because of the NSA:  "Problems with Dual_EC_DRBG were first described" - okay, now, he's writing this in '07 - "first described in early 2006.  The math is complicated, but the general point is that the random numbers it produces have a small bias.  The problem isn't large enough to make the algorithm unusable, and Appendix E of the NIST standard describes an optional workaround to avoid the issue, but it's cause for concern.  Cryptographers," Bruce writes, "are a conservative bunch.  We don't like to use algorithms that have even a whiff of a problem.



"But today there's an even bigger stink brewing around Dual_EC_DRBG" - "today" meaning '07 still, remember.  So there were problems.  Two papers were published that raised some concerns.  Then in '07, so a year later:  "In an informal presentation at the CRYPTO 2007 conference in August, Dan Shumow and Niels Ferguson showed that the algorithm contains a weakness that can only be described as a backdoor.  This is how it works:  There are a bunch of constants - fixed numbers - in the standard used to define the algorithm's elliptic curve.  These constants are listed in Appendix A of the NIST publication, but nowhere is it explained where they came from.



"What Shumow and Ferguson showed is that these numbers have a relationship with a second secret set of numbers that can act as a kind of skeleton key.  If you know the secret numbers, you could predict the output of the random number generator after collecting just 32 bytes of its output.  To put that in real terms, you only need to monitor one TLS Internet connection" - now remember, if it was encrypted using this pseudorandom number generator that nobody has ever used ever.  But if it were, then you'd "only need to monitor one TLS Internet connection in order to crack the security of that protocol.  If you know the secret numbers, you can completely break any instantiation of Dual_EC_DRBG.



"The researchers don't know what the secret numbers are; but, because of the way the algorithm works, the person who produced those constants might know.  He had the mathematical opportunity to produce the constants and the secret numbers in tandem."  Now, think public/private key.  It's very much like that.  We understand that you produce a public key and a private key together, and the point is one doesn't expose the other.  Yet you need to use the other to undo the effect of the one.  So the analogy isn't perfect.



But imagine that we're using, essentially, a public key in the form of these constants, which actually are just - an elliptic curve is a parametric curve.  It's a curve described by y cubed equals x cubed plus x3, blah blah blah, that kind of thing, algebraic curve, where the specific instance of the curve matters.  So these numbers describe a single curve which is in the standard.  And so we could think of it like the public key.  Maybe what these researchers discovered is it's theoretically possible that there could be the equivalent of a private key matching those numbers which are in the standard, which are public, which would completely break the random number generator.  So it's, again, theory.



Now, I've looked at the standard.  I've also looked at the presentation that these guys gave.  And they specifically say in their conclusion, Slide No. 8 of 9, under "Conclusion," it says, all caps:  "WHAT WE ARE NOT SAYING:  NIST intentionally put a backdoor in this PRNG.  WHAT WE ARE SAYING:  The prediction resistance of this PRNG as presented in [the standard] is dependent on solving one instance of the elliptic curve discrete log problem.  And we do not know if the algorithm designer knew this beforehand."  So what they're being very careful in saying is there's a theoretical weakness we've discovered.  Maybe it's news to everybody, including the NSA.  Maybe it's not.  And so we're wondering more now about the behind-the-scenes politics of this, sort of, today.



So continuing with Bruce's post, he said:  "Of course, we have no way of knowing," Bruce writes, "whether the NSA knows the secret numbers that break Dual_EC_DRBG.  We have no way of knowing whether an NSA employee working on his own came up with the constants and has the secret numbers.  And we don't know if someone from NIST, or someone in the ANSI working group, has them.  Maybe nobody does."  Maybe they don't exist.  "We don't know where the constants came from in the first place.  We only know that whoever came up with them could have the key to this [theoretical] backdoor.  And we know there's no way for NIST - or anyone else - to prove otherwise.  This is scary stuff, indeed," writes Bruce.



"Even if no one knows the secret numbers, the fact that the backdoor is present [theoretically] makes Dual_EC_DRBG very fragile.  If someone were to solve just one instance of the algorithm's elliptic curve problem, he would effectively have the keys to the kingdom."  Remember, only if people ever used this.  But, "He could then use it for whatever nefarious purpose he wanted, or he could publish his result and render every implementation of the random number generator completely insecure.



"It's possible to implement Dual_EC_DRBG in such a way as to protect it against this backdoor, by generating new constants with another secure random number generator and then publishing the seed.  This" - now, get this.  "This method is even in the NIST document, in Appendix A.  But the procedure is optional, and my guess is that most implementations" - if there are any - "of the Dual_EC_DRBG won't bother.



"If this story leaves you confused, join the club," he says back in '07.  "I don't understand why the NSA was so insistent about including Dual_EC_DRBG in the standard.  It makes no sense as a trap door:  It's public and rather obvious.  It makes no sense from an engineering perspective:  It's too slow for anyone to willingly use it.  And it makes no sense from a backwards-compatibility perspective:  Swapping one random number generator for another is easy.



"My recommendation," says Bruce, concluding, "if you're in need of a random number generator, is not to use Dual_EC_DRBG under any circumstances.  If you have to use something in [this standard] SP 800-90, use [the counter] CTR_DRBG or [the hash] Hash_DRBG.  In the meantime, both NIST and the NSA have some 'splaining to do," says Lucy, or says Ricky.



LEO:  Says Lucy [laughing].



STEVE:  So that's the story.



LEO:  That's pretty funny, I have to say.



STEVE:  Yeah.  It's just - it's weird.  And so this is what people thought of, they remembered, when they read these assertions in the budget request for the way the NSA wants to spend their money.  And I want to - we've got about 15 minutes left before 1:00 o'clock, when you turn into a pumpkin, Leo.  So I want to share what Matthew Green said because he's a PhD, he's got his master's, he's at Johns Hopkins, a cryptographer.  He originally was thinking he wanted to write a book on cryptography, and instead he just took to blogging.  His blogs are excellent.  He blogs at blog.cryptographyengineering.com.  Or just CryptographyEngineering.com, and then you can see the link to his blog.



He weighed in on this, and I'm going to skip down a little bit, saying:  "All of this is a long way of saying that I was totally unprepared" - so this is he's just written this about the end of last week's revelations.  "All of this is a way..."



LEO:  This is the post, I should just mention, that Johns Hopkins initially forced him to take down.



STEVE:  I don't think it was this one, actually.



LEO:  Oh, it was the one prior to that.



STEVE:  Yes, yeah.



LEO:  Okay, yeah.  He left it on blogspot.  He didn't take it down there.  But the university compelled him, in a really shameful display of kowtowing to the NSA...



STEVE:  Of academic censorship, yes.



LEO:  Really horrible, yeah.



STEVE:  Yeah.  And I'm sort of ignoring that because it's like, okay, fine.  And but his take is compelling.  He said:  "All of this is a long way of saying that I was totally unprepared for today's bombshell revelations describing the NSA's efforts to defeat encryption.  Not only does the worst possible hypothetical I discussed appear to be true, but it's true on a scale I couldn't even imagine.  I'm no longer the crank.  I wasn't even close to cranky enough.  And since I never got a chance to see the documents that sourced the New York Times/ProPublica story," and, he says, "and I would give my right arm to see them, I'm determined to make up for this deficit with sheer speculation.  Which is exactly what this blog post will be."  So then he talks about Bullrun and Cheesy Name, which are two of the project names.  He says...



LEO:  [Laughing]



STEVE:  I know.  Cheesy Name, they named it.  "If you haven't read the ProPublica/New York Times or Guardian stories, you probably should.  The [takeaway] is that the NSA has been doing some very bad things.  At a combined cost of $250 million per year, they include:  Tampering with national standards (NIST is specifically mentioned) to promote weak, or otherwise vulnerable cryptography; influence standards committees to weaken protocols; working with hardware and software vendors to weaken encryption and random number generators; attacking the encryption used by 'the next generation of 4G phones'; obtaining cleartext access to 'a major Internet peer-to-peer voice and text communications system,'" and he writes in parens, "(Skype?); identifying and cracking vulnerable keys; establishing a Human Intelligence division" - the so-called HUMINT - "to infiltrate the global telecommunications industry; and, worst of all, to me, somehow decrypting SSL connections.



"All of these programs go by different code names, but the NSA's decryption program goes by the name Bullrun, so that's what we'll use here."  So he says, "How to break a cryptographic system:  There's almost too much here for a short blog post, so I'm going to start with a few general thoughts.  Readers of this blog should know that there are basically three ways to break a cryptographic system.  In no particular order, they are:  One, attack the cryptography.  This is difficult and unlikely to work against the standard algorithms we use..."



LEO:  As Schneier says, trust the math.



STEVE:  Trust the math.  He says:  "...though there are exceptions like RC4.  However, there are many complex protocols in cryptography, and sometimes they are vulnerable.  Two, go after the implementation.  Cryptography is almost always implemented in software, and software is a disaster.  Hardware isn't that much better.  Unfortunately, active software exploits only work if you have a target in mind.  If your goal is mass surveillance, you need to build insecurity in from the start.  That means working with vendors to add backdoors.  Three, access the human side.  Why hack someone's computer if you can get them to give you the key?"



And he says, he writes:  "Bruce Schneier, who has seen the documents, says that math is good, but that code has been subverted.  He also says that the NSA is cheating.  Which, assuming we can trust these documents, is a huge sigh of relief.  But it also means we're seeing a lot of two and three here."



So he says:  "So which code should we be concerned about, and which hardware?  This is probably the most relevant question.  If we're talking about commercial encryption code, the lion's share of it uses one of a small number of libraries.  The most common of these are probably the Microsoft CryptoAPI and [embodied in] Microsoft SChannel" - the so-called Secure Channel - "along with the OpenSSL library.  Of the libraries above, Microsoft is probably due for the most scrutiny.  While Microsoft employs good - and paranoid - people to vet their algorithms, their ecosystem is obviously deeply closed source.  You can view Microsoft's code if you sign enough licensing agreements, but you'll never build it yourself.  Moreover, they have the market share.  If any commercial vendor is weakening encryption systems, Microsoft is probably the most likely suspect.



"And this is a problem because Microsoft IIS powers around 20% of the web servers on the Internet, but nearly 40% percent of the SSL servers.  Moreover, even third-party encryption programs running on Windows often depend on the CAPI components" - which is the Microsoft secure API, the Crypto API - "including the random number generator.  That makes these programs somewhat dependent on Microsoft's honesty.



"Probably the second most likely candidate is OpenSSL. I know it seems like heresy to imply that OpenSSL, an open source and widely developed library, might be vulnerable.  But at the same time, it powers an enormous amount of secure traffic on the Internet, thanks not only to the dominance of Apache SSL, but also due to the fact that OpenSSL is used everywhere," he has in italics.  "You only have to glance at the FIPS validation lists to realize that many commercial encryption products are just thin wrappers around OpenSSL.  Unfortunately, while OpenSSL is open source, it periodically coughs up vulnerabilities."  I like that, like a fur ball.  "Part of this is due to the fact that..."



LEO:  [Coughing]



STEVE:  Yeah, "...that it's a patchwork nightmare originally developed by a programmer who thought it would be a fun way to learn bignum division."



LEO:  Isn't that funny.  He was studying C.



STEVE:  I know, yeah.  "Part of it is because crypto is unbelievably complicated.  Either way, there are very few people who really understand the whole codebase.



"On the hardware side, and while we're throwing out baseless accusations, it would be awfully nice to take another look at the Intel Secure Key integrated random number generators that most Intel processors will be getting shortly.  Even if there's no problem, it's going to be an awfully hard job selling these internationally after today's news."  Anyway, and he goes on - which standards, which people are involved, if it's HUMINT.  And finishing up, it says:  "So what does it all mean?  I honestly wish I knew.  Part of me worries that the whole security industry will talk about this for a few days.  Then we'll all go back to our normal lives without giving it a second thought."  I don't think that's the case, I'm saying.



And he says:  "I hope we don't, though.  Right now there are too many unanswered questions to just let things lie.  The most likely short-term effect is that there's going to be a lot less trust in the security industry, and a whole lot less trust for the U.S. and its software exports.  Maybe this is a good thing.  While we've been saying for years that you can't trust closed code and unsupported standards, now people will have to verify.



"Even better, these revelations may also help to spur a whole burst of new research and redesigns of cryptographic software.  We've ... been saying that even open code like OpenSSL needs more expert eyes.  Unfortunately, there's been little interest in this, since the clever researchers in our field view these problems as 'solved' and thus somewhat uninteresting."  They're not interested in, like, some stinky implementation of the algorithms they've created.  It's the math that turns them on.  "What we learned today is that they're solved, all right.  Just not exactly the way we thought."



So that's where we are.  My feeling is that this is great.  This, I mean, this brouhaha is, I mean, this is a perfect sort of second echo of the original Snowden shockwave that really hits the core of the crypto industry.  We now have absolute evidence that there was influence a long time ago by the NSA on the standards body, NIST, that got this standard introduced.  I also did read in all of the research that this particular standard got into Vista.  So apparently it's in Windows Vista and 7 and 8.  I haven't done any further research to track it down.  But again, nobody uses it.  In the same way that we've talked about how SSL, your browser has a whole bunch of possible security protocols that it knows, the server has a whole bunch, and they negotiate the best that they both know.



Similarly, this is - it's a random number generator that is weird and untrusted and a thousand times slower and nobody would choose to use it.  But it's sort of there.  So the point is, though, that as Bruce says, cryptography is ultraconservative.  Cryptographers are.  Never again will this be allowed to happen.  And that's why this is a good thing.  Elliptic curves themselves are fine.  I mean, there are many good elliptic curve algorithms.  We've moving towards them because they're faster; they use smaller keys.  So there's, like, there's nothing wrong with an elliptic curve.  It's just a - it's a way of implementing the discrete logarithm problem that we'll be talking about a little bit more in the future.  So that's not it.  It's when a standard says use this one particular curve from the family, and it needs to be in the standard.  And then Appendix A says, oh, but you could also use random values, if you wanted to, as long as you also use the one in the standard.



So, I mean, it is highly suspicious.  The good news is that's enough to be an object lesson for all time to never accept something like this and just shrug our shoulders.  I mean, we now wish we had put our foot down and said absolutely not.  Unless you can tell us where these numbers came from, we're not using them.  Again, so this is great for that reason.  I don't think this will ever happen again.



LEO:  Good.



STEVE:  And my feeling is, what we've seen is a lot of hyperbole, a lot of glaring headlines to draw readers, the scariest possible conclusions drawn from admittedly scary intent.  Certainly there is budgetary intent in, like, if you give us money, we're going to be able to do these things.  So Congress, open your checkbook.  So I think that creates some motivation for them overstating what they can do.  But again, if they can install a keystroke logger in someone's machine, you don't have to break the encryption of what's leaving their machine because you get it beforehand.



LEO:  Right.  It just, you know, this is exactly what you'd expect.  They're trying every method they can to get through the darknet.  And they've got, apparently, budgeted a quarter of a billion dollars a year to do it.  So, you know.  Hey, if they want to subvert me, give me a few million dollars a year, I'd do it.



STEVE:  Well, and again, the technologies we're actually relying on, this is not this wacky random number generator nobody uses.  So maybe...



LEO:  Not even ECC.  People keep saying ECC's using this elliptical curve RNG.



STEVE:  No, no, no.



LEO:  It's too slow.  Why would you use something a thousand times slower?



STEVE:  Correct.  Correct.



LEO:  There's no motivation to do that.



STEVE:  And I'm a little worried that people are going to misunderstand ECC.  Elliptic Curve Cryptography has nothing to do with this except it uses the term "elliptic curve."  And the idea is that...



LEO:  It's just the same name, I guess.



STEVE:  Right, it is.  And so, for example, you could take - there are many ways to generate random numbers.  You could take a hash function and take the output of the hash function and feed it back in.  And then you're going to get a different output.  And you feed that back in, you get a different output.  And you feed that back in, you get a different output.  Well, there's a random number generator using a hash function.  Similarly, you could take a cipher, and you feed its output back to its input.  Oh, look, now you've got random numbers.  Or you could use an elliptic curve in exactly the same way.  And that's what this does is it uses - it just sort of feeds it back to itself.  The question is why that particular one because there's an infinity of them.  And in Appendix A it says you could also use a really good random number and make up your own curve.  Except the standard supplies one, and that's the point.



LEO:  Right, that's a problem, yeah.



STEVE:  Yes.



LEO:  And if you use an OpenPGP implementation, when you generate your - one of the concerns somebody had is, if Intel does put a backdoor, let's say, into a chip that's in hardware, these hardware RNGs, every PGP, OpenPGP implementation I've used of course uses random number generators, but also gathers entropy from mouse moves and keystrokes.  Does that mean we don't have to worry, in that case?



STEVE:  Yes.  Yes.  For example, what I will be coming up with soon also needs random numbers because everything does.  I'm going to have the person wave their camera phone around and stream all of the data from the camera into a hash.  And so we'll take the random number that iOS gives, but then XOR it with one we make locally so we get the benefit of both.



LEO:  So even if the random number generator's flawed, and they're all - by the way, we should say pseudorandom number generators, that's the issue is it's...



STEVE:  Actually, no.  We've passed that now.



LEO:  Are we better at that?  Oh, good, okay.



STEVE:  Intel is true quantum random numbers.



LEO:  Got it.



STEVE:  It is not algorithmic.  And I've read several articles now about what Intel's doing.  And, I mean, it's wonderful.  It's great.  But again...



LEO:  But even if it were compromised, hashing it with chaotic information produces an unpredictable result.



STEVE:  Yes, just turn the microphone on and digitize the noise and mix that in.  And then even if there was some bias, you've washed that away.



LEO:  Right.  Okay.  So you can trust the math, and you can trust open source implementations of things like PGP.  I use GNU Privacy Guard, and I love it.



STEVE:  Yes.  It is - and that's the key.  Nothing actually mainstream, not SSL, TLS, nothing anyone is actually using has in any way been hurt.  Just this bizarre, weird, seven-year-old, one particular elliptic curve random number generator that nobody would ever choose.



LEO:  But it is a smoking gun that says, look, they are trying to subvert.



STEVE:  It's a lesson, yes, exactly.  It's a fabulous object lesson.  And that's why I named this podcast whatever I named it.



LEO:  A Perfect Accusation.



STEVE:  The Perfect Accusation.  Because, okay, you fooled us once.  We're not accepting numbers that we don't know where they came from ever again.



LEO:  No, no, no.  And one can presume that they are attempting to subvert Microsoft and Google individual engineers or corporately or with NSLs.  There is a constant assault on corporations.  That's, by the way, the damage that this does.



STEVE:  Yes.



LEO:  It makes us not trust anybody.



STEVE:  You heard me last week saying I have a problem with using Bit whatever it is, Microsoft's encryption.



LEO:  BitLocker.



STEVE:  BitLocker.  I just, like...



LEO:  Because we don't know.



STEVE:  How could I trust that?



LEO:  It's a binary blob, and it could be compromised. 



STEVE:  Yes.  Whereas we've got stories of people using TrueCrypt and Brazil sending drives to the FBI because they just...



LEO:  They can't figure out what's in there.



STEVE:  They can't crack it, yeah.



LEO:  Right.



STEVE:  Oh, and I forgot to mention also, I should have, because so many people tweeted, I said last week that Greenwald's partner Miranda had the password written down on paper.  I'm sure you remember, Leo, that Greenwald is absolutely denying that.  He's saying, whoa...



LEO:  Oh, good.



STEVE:  It was not written down.  That was made up.  And, by the way, they have not decrypted the documents.  Apparently there was some small cache maybe that weren't encrypted in the first place.  So, again, I wanted to make sure that I just said that all I was relating was the news that we had at the time.  But Greenwald has said, absolutely believe me, we were - this was not written down on paper.  So that sounds like GCHQ or whatever they're called, trying to excuse themselves for forcing, being able to claim poor...



LEO:  See, we found a Post-it note; right.



STEVE:  ...security, yeah, claim poor security, and thus we're going to trash all your hard drives in the basement.



LEO:  Sad.



STEVE:  Never a dull moment in security, Leo.



LEO:  It is fascinating.  And if you are interested, this is the show for you, every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 18:00 UTC on TWiT.tv, if you want to watch live.  Steve offers 16Kb audio, for those who are bandwidth impaired but would like to still listen, on his site, GRC.com.  You'll also find full English language transcriptions, thanks to Elaine Farris and Steve, who makes those available.  GRC.com.  When you get there you might want to buy SpinRite the world's finest hard drive maintenance and utility.



STEVE:  Pays my bills.  Thank you.



LEO:  Yeah.  Thank Steve by buying SpinRite.  And you'll get the benefit of this great tool.  He's also got a lot of freebies, and you can check them all out.  In fact, are we going to do questions next week?  I guess so, huh.



STEVE:  Yeah.



LEO:  Barring breaking news.  You can leave your questions there, too:  GRC.com/feedback.  Steve does not do email.  Don't try.  People keep saying, what's Steve's key?  I say, I don't know.  He doesn't do email, dude.  You can get full bandwidth audio and video of the show at our site, TWiT.tv/sn, or subscribe to any of our feeds on your favorite podcatcher, like iTunes, et cetera, et cetera.  And you'll get it each week automatically.  Steve, thanks so much.  I guess...



STEVE:  Do we have you, or are you gone now?



LEO:  I guess this is farewell, my friend.



STEVE:  For three weeks; right?  So three...



LEO:  I will be in Venice a week from today.



STEVE:  And do I know, are we going to have Iyaz?  Or is Tom going to do it from his lair?  Or who's going to...



LEO:  Who's hosting next week?  Tom Merritt will be hosting from the...



STEVE:  Okay.



LEO:  From the Merritt lair.



STEVE:  Cool.  I think that'll be fun, from one Skype to the next.



LEO:  Yes, from one Skype to another.  Yeah, so I'll be back October 9th, three weeks hence.  But don't hold back, dude.  Do it, man.  I'll listen.  I'll be listening to the shows.  I'll be listening.



STEVE:  Okay.



LEO:  All right?



STEVE:  Okay.  I'll - okay.



LEO:  You do what you want.  You always do.  I mean, I can't...



STEVE:  I expect that I'm a few days away from being able to put the work that we've got on data throughput aside.  Then I need to work on communicating this.



LEO:  Yeah, I'm sure...



STEVE:  And so we will just see how it goes.



LEO:  It all takes longer than one expects.



STEVE:  It always takes longer.  It's why I don't do schedules.



LEO:  Yes.



STEVE:  I just show up here every week.



LEO:  That's the schedule.  And just a heads-up, we are looking at moving, I think, to Thursday; right?  What did we...



STEVE:  Tuesday at 1:00 was the last I heard from Liz.



LEO:  We're working on our next, our new schedule, which will debut next year, after the Christmas breaks.  And some shows will be moved, including, I believe, this one.  So I just want to warn people because I know everybody hates change.  But it will help me because I will then get two consecutive days off instead of the doughnut that I get right now.



STEVE:  Okay.  So have a great trip the next three weeks, and we'll be talking then when you get back.



LEO:  I've got my Venice guidebook.  I've got my Istanbul guidebook.  I got my Turkish language lessons at Audible.



STEVE:  You got Audible, exactly.



LEO:  I'm ready.  I know enough Italian to be dangerous, so I'm - you know, it's fun, you can actually ask Google Now, you can ask, you know, you can say, "How do you say where's the bathroom in Italian?" and it'll tell you.  It's kind of cool.



STEVE:  No kidding.



LEO:  Yeah, you want to see?  Okay, Google Now.  Oh, it's locked.  Is it locked?  Yeah, let me unlock it first.  Okay, Google Now.  How do you say "Where is the bathroom" in Italian?



FEMALE VOICE:  "Dov' il bagno?"



LEO:  Did you hear it?



STEVE:  Uh-huh.



LEO:  Dov' il bagno?  That, see, that's the future, right now.  Right here, right now.  I love that.  All right, Steve.  We'll see you in a month.



STEVE:  Yes.



LEO:  On Security Now!.



STEVE:  Thanks, Leo.



LEO:  Bye-bye.   



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#422

DATE:		September 18, 2013

TITLE:		Listener Feedback #175

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-422.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Tom discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  Hey, coming up on Security Now!, Leo Laporte's on vacation, so I get the pleasure of hanging out with Steve Gibson and talking security.  Yeah, we're going to talk about the NSA.  Yeah, we're going to talk about a zero-day vulnerability from IE.  But there is hope in the future, not just from a good television show, but apparently about stronger encryption.  All of that and more coming up.



TOM MERRITT:  This is Security Now! with Steve Gibson, Episode 422, recorded September 18th, 2013:  Your questions, Steve's answers, #175.



It's time for Security Now!, the show that helps you stay safe online.  I'm Tom Merritt, filling in for the vacationing Leo Laporte, and very happy to be back doing it with the man himself, Mr. Steve Gibson, the man behind GRC.com, the man I turn to when I want to know what's up in security.  ShieldsUP!, SpinRite, been using those things for years.  They've saved my bacon.  Steve, good to be back on the show with you again.



STEVE GIBSON:  Hey, Tom, you were saying that it was not since last November that we had been doing this, and it was also for a Q&A episode last year.



TOM:  That was - right.  It was 20 Q&A episodes ago.



STEVE:  Great to have you back.



TOM:  Well, thank you.  It's good to be here.



STEVE:  And has anyone heard from Leo?  Did he get there?  Is he safe?  Has there been any communication?  Or has he just disappeared?



TOM:  We haven't heard otherwise, so that's good.



STEVE:  Yeah.



TOM:  Yeah, hopefully he doesn't spend too much time.  Hopefully he just relaxes and enjoys himself.



STEVE:  Good, well, that was the whole idea.



TOM:  Absolutely.  We've got some interesting stuff today, huh, Steve.



STEVE:  Yeah, not a big news week.  It's weird.  Sometimes we're like - well, in fact sometimes there's so much to talk about that we just, like, it pushes any other end-of-show content off the end.  I've got some interesting stuff always, and some great comments and thoughts, a couple really long pieces.  But they were so interesting, I thought, well, we'll have time.  So, yeah, I think we'll have a good show.



TOM:  There's always something to say about the NSA these days.  So we've got something about...



STEVE:  Ah, yes.



TOM:  And thankfully, well, not thankfully, but for our purposes there is a zero-day vulnerability for IE we can talk about.  Thank you, hackers, for doing that.  All right, Steve.  Let's start off talking about that zero-day vulnerability.  Is it for everyone?  How bad is it?



STEVE:  Well, it's bad enough that anyone - the way I tweeted it this morning when - I got email from Microsoft last night, or I guess actually late in the morning yesterday, and finally got around to checking it out.  So what I said was, in my tweet, "New IE 0-day Vulnerability being exploited in the wild.  If you must use IE you can apply temporary Fix-It," and then I gave a little bit.ly link [bit.ly/1gyQ31T].  So anyone who's interested, if you check my Twitter feed, Twitter.com/SGgrc, and you'll see my most recent stuff.  There is a Fixit which they describe as a "shim," which will solve the problem.  They're reporting...



TOM:  Not a shiv, a shim.



STEVE:  Is it shiv?



TOM:  No, no.  That would be the opposite, I think.



STEVE:  Yeah, the vulnerability would be a shiv.



TOM:  That's right.  The shim protects you from the shiv.





STEVE:  Yeah.  So they're seeing, Microsoft has acknowledged the exploitation of IE8 and 9, although this does affect all versions of IE, 6 through - and they even list 11, even though it's like, not out of the box yet.



TOM:  Oh, wow.  Yeah, that's just a preview.



STEVE:  So I love this Microsoft speak, the way they write these things.  I mean, clearly it's boilerplate.  But of this they wrote:  "Microsoft is investigating public reports of a vulnerability in all supported versions of Internet Explorer."  Is IE6 still supported?



TOM:  I didn't think it was.



STEVE:  I don't think it is anymore.  But anyway, it is on their list of, like, vulnerable OSes.



TOM:  They know so many people still use it, they probably just put it on there, yeah.



STEVE:  All vulnerable products.  Anyway, so they said:  "Microsoft is aware of targeted attacks that attempt to exploit this vulnerability in Internet Explorer 8 and Internet Explorer 9.  Applying the Microsoft Fix it solution" - and they give the CVE number, so it's MSHTML, it's an MSHTML code, MSHTML Shim Workaround - "prevents the exploitation of this issue.  See the Suggested Actions section of this advisory for more information.  The vulnerability is a remote code execution vulnerability.  The vulnerability exists in the way that Internet Explorer accesses an object in memory that has been deleted or has not been properly allocated.  The vulnerability may corrupt memory in a way that could allow an attacker to execute arbitrary code" - again, I get a chuckle out of this because they previously said it does allow an attacker to do this, and attackers are doing this.



Anyway, so they said, "in the context of the current user within Internet Explorer.  An attacker could host a specially crafted website that is designed to exploit this vulnerability through Internet Explorer and then convince a user to view the website.  On completion of this investigation, Microsoft will take the appropriate action to protect our customers..."



TOM:  Thank you.



STEVE:  As opposed to not having written the code in the first place, which would have always had them protected.  "Which may include," they continue, "providing a solution through our monthly security update release process, or an out-of-cycle security update, depending on customer needs."  So we don't have - you can't go to Windows Update for this.  So you do have to go get this deliberately, a Fixit solution, the little "1," you know, click on the "1" button, and then it turns something off in the registry or installs a quick patch or something.



So, again, if you're - when I tweeted this I got some responses from people saying that they had to use IE in their corporate settings, so they appreciated the heads-up.  They had passed this on to IT to get the IT blessing before they did it, which is what you should do in a corporate setting.  And if for some reason you're still using it at home - that is, IE - or on your own, then it's probably good to do.  It's funny, too, because they have, like, mitigating factors that they list.  It's like, okay, things that make this not a problem.  And the first one is, like, the Server versions of IE use their so-called "protected mode"?  Well, you might as well just unplug from the Internet if you try to use IE in that mode.  When I...



TOM:  It's kind of for browsing manual files, isn't it?  I mean, yeah.



STEVE:  It's incredible how restrictive it is.  I can't figure out what it's useful for, and obviously you are protected when you do that.  The fourth mitigating factor, though, the last one, they said, "In a web-based attack scenario, an attacker could host a website that contains a webpage that is used to exploit this vulnerability.  In addition, compromised websites and websites that accept or host user-provided content or advertisements" - okay, well, what website doesn't have user-provided content or advertisements?



TOM:  These days.



STEVE:  And that was my point, is that...



TOM:  Yeah, Geocities is gone, so, yeah.



STEVE:  Yeah.  What we're seeing is that the way these exploits are getting to people now is not necessarily that you go to some dark corner, off-the-path site where you probably ought to know better.  It's you're at The New York Times or the Wall Street Journal or some Yahoo! page that you would expect to be perfectly safe.  And somehow that page has been made vulnerable to exploitation, and something gets stuck on the page.  So there's really, you know, it's not like if you are surfing safely, you're safe now.  The problem is, if you're surfing with IE, you're more than likely not safe.



TOM:  Yeah.  One of the fixes for me is to not use IE unless I have to.  But some people have to; right?



STEVE:  Yeah.  I did note in the news coverage today of Google's new tracking alternative to third-party cookies, AdID, it think they call it?



TOM:  Yeah.



STEVE:  I didn't realize that Chrome is now the No. 1 browser and has surpassed IE and Firefox and the others.



TOM:  Depends on who you ask.  But in lots of those surveys they have, that's true.



STEVE:  I just wish it were smaller, I mean, lighter weight.  I've talked to Leo about this.  When I launch Firefox, I get a bump in memory.  When I launch Chrome, I, like, lose a quarter of my machine.



TOM:  It used to be the opposite.  The reason I switched to Chrome years ago was because Firefox was so big back then.  So I guess when you become popular you start to become a memory hog.  But the thing about Firefox and Chrome, I use NoScript and NotScript in them, which would help prevent this sort of thing from happening.  But is there a NoScript equivalent for IE where you can say, like, turn off all the scripts on these websites so that third-party stuff doesn't execute?



STEVE:  You can absolutely disable scripting globally.  But I've never seen an add-on that allows you to do it dynamically.  It may be that the add-on interface doesn't provide the hooks necessary in order to do that.  But, boy, I mean, that would be a great solution.  But the only thing I know if is, like, disable JavaScript completely.  And then, unfortunately, too much of the web is broken.



TOM:  Because the brilliance of NoScript is I can say, oh, yeah, I'm on The New York Times.  Let The New York Times scripts work so that the site works well.  But don't let any of that other stuff from outside run because I don't know what that is.



STEVE:  Yeah, and in fact in whatever they're on now, I think it's 23, 22 or 23 of Firefox, we were commenting a couple weeks ago that they had somewhat controversially removed the setting from the UI to allow users to disable JavaScript.  And when you updated, because it might cause so much trouble, they silently reenabled it as they were removing the checkbox from the UI.  And so Leo and I discussed it, and I was curious how they thought they could get away with this.  So I pursued the dialogue, like down in the forums where this was argued, and their position was scripting is so necessary now that only experts know not to run with it or to run with it conditionally.  And anybody who wants conditional scripting needs to use NoScript.  So they're sort of like - they were, like, taking themselves out of this all-or-nothing mode, very much the way IE has, actually.  But at least Firefox has NoScript, and Google has NotScript that gives you per-site control back, which is useful.



TOM:  This next story we talked about on TNT.  And we had a lot of differing opinions about...



STEVE:  Yeah, it's interesting.  I had the TV on, I think it might have been Monday morning.  And it's like I was watching "Morning Joe" on MSNBC just sort of babbling on in the background.  But this, so it was like, just yanked my attention when Joe was holding up the L.A. Times with a story because I thought, whoa.  Maybe this is going overboard.  So the L.A. Times covered this.  The headline was "Glendale School District to Monitor Students' Social Media Posts."  Kelly Corrigan, reporter for the L.A. Times, wrote:  "Glendale school officials have hired a Hermosa Beach company to monitor and analyze public social media posts, saying the service will help them step in when students are in danger of harming themselves or others.



"After collecting information from students' posts on social media platforms such as Facebook, Instagram, YouTube and Twitter, Geo Listening" - which is the name of this Hermosa Beach company - "will provide Glendale school officials with a daily report that categorizes posts by their frequency and how they relate to cyber-bullying, harm, hate, despair, substance abuse, vandalism and truancy.  Glendale Unified, which piloted the service at Hoover, Glendale and Crescenta Valley high schools last year, pays the company $40,500 to monitor posts made by about 13,000 middle school and high school students at eight Glendale schools.  



"According to a district-wide report, Geo Listening gives school officials 'critical information as early as possible,' allowing school employees 'to disrupt negative pathways and make any intervention more effective.'"



TOM:  Wrong thinking?  Is that - yeah.



STEVE:  "Glendale Unified Superintendent Dick Sheehan said the service gives the district another opportunity to 'go above and beyond' when dealing with students' safety.  'People are always looking to see what we're doing to ensure that their kids are safe.  This just gives us another opportunity to ensure the kids are safe at all times'" - whether they're at school or not, I add that - "he said.  Yalda Uhls, a researcher at the Children's Digital Media Center at UCLA and a parent of two, said students should be made aware that their posts are being monitored.  'As a parent, I find it very big brother-ish,' Uhls said, adding that students could lose trust in adults once they find out their posts are being tracked.



"However, she also admires schools' efforts in trying to attack the problem of cyber-bullying.  'This could be one piece in a school's tool kit to combat that problem, and it should be a very small piece,' she said.  School board member Christine Walters said that as Glendale educators have become increasingly aware of how much bullying occurs online, officials have become more 'proactive to find ways to protect our students from ongoing harm,' she said.  'Similar to other safety measures we employ at our schools, we want to identify when our students are engaged in harmful behavior.'"



TOM:  Right.  That's why the schools are always putting microphones up and recording all the conversations in the halls, and they're following students home to see where they go in public.  Those are sort of the analogs I came up with when I heard the story because it is important to realize that they're not spying on the students by, like, finding their emails or anything.  They're looking at public posts.  If their Facebook posts are private, then they're not going to see them.  But the Twitter posts are always public.  So there isn't the invasion of privacy that you might think of.  But there are other things that students do publicly that schools don't try to monitor.



STEVE:  And thinking in terms of execution I wonder if there is then - is there a form that students fill out of the account names?  Like what's your Twitter handle?  What's your YouTube account?  What's your Instagram account?  What's your Facebook?



TOM:  Oh, that's interesting, yeah.  How do they find out who the students are?  Yeah.



STEVE:  Yeah.  I mean, so, and, I mean, I completely agree that this ought to be done with students' awareness that their school is listening.  On the other hand, the way actual social media works, I'm sure this thing has been known from the second it was deployed that your school is monitoring what you're doing.  So my sense is all this does is push that kind of stuff further underground, if somebody wants to communicate that way.  I don't know. 



TOM:  Well, in a way I could almost see it as a positive in that it teaches kids, hey, everything you do on the Internet's public; right?



STEVE:  Yes.  I had the exact same...



TOM:  If you don't want people to know about it, be careful.



STEVE:  Yup, exactly.  It's like, hey, get used to the new connected world, kiddies, because everyone is watching what you post.  And there has been a lot of dialogue about the consequences of oversharing on Facebook, the fact that now headhunters and employment agencies and employers are very much doing a deep dig into what would-be employees have posted publicly in order to get a better sense.  The reading is you can better gauge who somebody is from that than sitting across from them at a table and asking them a series of canned questions for which they're going to look like an angel.



TOM:  It is a really interesting debate because of the fact that they're public posts; right?  And everyone's reacting as if they're spying on the kids' private interactions.



STEVE:  Yeah, you're right.



TOM:  And they're not.  And I'm not saying that I think it's a good idea, either.  I think it does go over the line.  It's a little bit overreaching.  It's a little bit of a nanny state type of thing, if some people like to categorize it that way, because you can't protect kids from every kind of harm.  But at the same time, children are doing these things in public.  Anybody can see this stuff.



STEVE:  And I guess you could also argue that this is - the proper role may be parents, but parents aren't doing this.  So the school, sort of being a little bit of a nanny state mode, is stepping in to take responsibility.  And it's interesting that there is a big service that is making $40,000 a year, no doubt automating this in some way and doing, like, keyword searches.  I mean, certainly there aren't any - there's no one who's reading 13,000 students' individual, you know, every posting everywhere.  So this is like a small version of what the NSA is doing on a local scale.



TOM:  I kind of wish Oracle was a little more of a nanny state, to be honest.



STEVE:  [Laughing] Yeah.  This is kind of creepy.  We've talked about the fact that Oracle, that Java 6 is no longer being updated, and the problem that represents.  But exploring the logical consequences of that a little bit further is extra chilling.  Dan Goodin, writing for Ars Technica, reported on some studies, I think it was Trend Micro that sort of brought this to his attention.  He wrote:  "The security of Oracle's Java software framework, installed on some three billion devices" - which of course it brags every time you update it, we used to see that all the time when we were updating it frequently - "is taking a turn for the worse, thanks to an uptick in attacks targeting vulnerabilities that will never be patched" - and that's the key, so we're seeing an uptick in attacks on vulnerabilities that will never be patched - "and increasingly sophisticated exploits.  The most visible sign of deterioration is in-the-wild attacks exploiting unpatched vulnerabilities in Java version 6," said Christopher Budd, threat communications manager, oh, yeah, at antivirus provider Trend Micro.



"The version, which Oracle stopped supporting in February" - that is, the whole line of v6 - "is still used by about half of the Java user base.  Malware developers have responded by reverse" - and here's the key, sort of like extensions of what you might expect actually happening.  "Malware developers have responded by reverse-engineering security patches issued for Java 7 and using the insights to craft exploits for the older version.  Because Java 6 is no longer supported, those same flaws will never be fixed."  So, Budd adds, "This is a large pool of vulnerable users who will never be protected with security fixes, so [they're] viable targets for attack."  Anyway, so...



TOM:  Yeah, I mean, just don't use Java if you can help it.



STEVE:  Yeah, exactly.  Don't use it unless you have to.



TOM:  And some people have to.  That's the problem.



STEVE:  Yeah.  And if you do - see, now, the problem is that many corporations have old software that won't run on Java 7.  So their employees and their systems are stuck with Java 6.  They look at the burden of updating the software to run on 7, and it's like, uh, we have other things to do.  It works.  Let's leave it alone.  And the problem is it's just - it's waiting to be exploited.  So hopefully those are non-browser-hosted instances.  Or, I mean, if a company wanted to be secure, they could install Java that they have to use on IE, but don't let IE talk to the Internet.  Just use Java as an application runtime locally, and host it in a browser if it has to be.  But then on your browser that you use for the Internet, Chrome or Firefox, for example, there you want to use Java 7 or no Java at all.  Probably no Java at all.  I can't really think of any contemporary site that requires that you have Java itself installed. 



TOM:  No, it's usually an application, yeah.



STEVE:  I guess I've heard - whenever I say this I get tweets from people in the Scandinavian countries saying, oh, my bank requires that I use Java.  But then I'm also seeing that they're rapidly moving away from that.  They're probably, unfortunately, going to JavaScript.  But that's better than Java.



TOM:  And so you're saying browse globally, execute Java locally.



STEVE:  Yeah.  Well, yes.  Because the great benefit of Java was its platform neutrality.  You could run Java - a corporation could write some proprietary system, maybe it's for access to their backend servers or who knows what, some big glue that pulls things together.  And it would run on Macs, and it would run on PCs, because Java was the virtual machine, the so-called JVM.  You'd install that on whatever computer you wanted, and then that one application, it was write once, run everywhere.  So that was a reason that Java had so much uptake sort of early on.  But that's not a browser-based approach.  In my opinion, the whole notion of making Java run in a browser was, in retrospect, which obviously is hindsight and easy to do, it was a disaster because it's caused so much grief for people.  So it made sense to run it as a local virtual machine in a write once, run everywhere mode.  Never was it a good idea as a browser plug-in because it's just been a catastrophe.



TOM:  It is kind of sad.  I wish it had been - I wish it had fulfilled the write once, run everywhere.  But we kind of moved past that with HTML5 and web apps and such.



STEVE:  Exactly.  I think we're really seeing - well, in fact, for example, we're even seeing now, with the new communications stuff, we're beginning to see like real-time audio and video leaving individual chat apps and moving into the browser.  I think the browser as a dynamic container clearly is getting powerful enough to write and to run these kinds of things.



TOM:  Okay.  It's NSA time.  We need kind of a regular bumper or radio stinger for this, huh.



STEVE:  Yeah, yeah.  We can't get away from these things.  And there are a couple interesting notes from our users that we'll share here in the second half of today's podcast.  But this one sort of caught my eye because the person who was quoted, John Gilmore, is a famous co-founder of the EFF, very involved in what's happening on the Internet.  And this was in Infosecurity magazine.  The title of this piece was "Did the NSA subvert the security of IPv6?"  And I'm just going to share this little piece, it's pretty short, in its entirety.



TOM:  That's frightening, yeah.



STEVE:  They wrote:  "Following the Snowden leaks revealing Bullrun," which we talked about last week, the whole notion of the extent and the level and the budget of the NSA's overt - now it's overt, no longer covert - intent to essentially keep the Internet from going dark for them, "there is an emerging consensus that users can no longer automatically trust security.  Cryptographer and EFF board member Bruce Schneier" - who's been a recent guest of Leo's, and of course we speak of Bruce all the time - "has given advice on how to be as secure as possible.  'Trust the math,' he says.  'Encryption is your friend.  Use it well, and do your best to ensure that nothing can compromise it.  That's how you can remain secure even in the face of the NSA.'"  Unquote from Bruce.



TOM:  I like that "trust the math."



STEVE:  Trust the math.



TOM:  I like that as a slogan, yeah.



STEVE:  Yes.  Because he's absolutely right.  That, and, I mean, as far as anyone knows, that is still the case.  The actual math, the actual technology of cryptography is sound.  Unfortunately, the actual delivery of security uses cryptography as only one component.  And nothing else except the math is sound.  And so the NSA, they can bribe people.  They can use national security letters.  So they can use arguably abusive authority and basically everything but the actual crypto.  The crypto we can depend upon.  So the story continues.  



"He confirms the growing consensus that Bullrun's greatest success is in subverting the implementations of encryption rather than in the ability to crack the encryption algorithms themselves.  The general belief is that the NSA has persuaded, forced, or possibly even tricked individual companies into building weaknesses or backdoors into their products that can be exploited later."  And I've gone on the record to say, okay, I need evidence.  It's like, yes, we need to be skeptical because we've always had to be skeptical.  And I think what has happened in the wake of these revelations is that the tinfoil factor has gone up by an order of magnitude.  But it was always there, so...



TOM:  Yeah.  In a way, the NSA is just a very large and powerful group of hackers.  And so you need, I mean, they're big; right?  And there's political implications.  But as far as, like, what they can do, they can do all the same things anybody else can.



STEVE:  Yeah.  Now, and we talked for example about BitLocker, Microsoft's proprietary hard drive encryption.  I'm not going to use it.  I'm going to use TrueCrypt because I know that TrueCrypt came from an international group of developers where the security of the product was their goal.  I don't know anything about Microsoft's goals for BitLocker, nor any influence.  I have no reason to believe there was any.  I actually, again, I would need proof rather than just this sort of, like, conjecture and suspicion.  But still, given a choice, hey, we have a choice.  TrueCrypt is free.  Why not use that one?



Anyway, continuing:  "The bottom line, however, is that the fabric of the Internet can no longer be trusted.  Meanwhile, John Gilmore, co-founder of EFF and a proponent of free open source software, has raised a tricky question:  Has NSA involvement in IPv6 and IPSEC" - the IP security layer - "effectively downgraded its security?  IPSEC is the technology that would make IP communications secure."  So just let's stop again here for a second to remind people.



The way we get security over TCP connections now is we establish a point-to-point connection, and then we run a protocol SSL/TLS on top of that lower level physical connection, or point-to-point connection.  So HTTPS, for example, brings SSL to the HTTP connection as an add-on, as a layer on top of the underlying protocol.  One of the best things, in my opinion, about IPv6, which almost makes it worthwhile, was that IPSEC, which again has been an existing technology, IPSEC has been around for a long time, you can get IPSEC routers, you can set up tunnels and so forth.  So that's been all in place.  But the proposal has been that it would be integrated into IPv6 from the beginning.  So that was one of the cool advances was that IPv6 would have security as part of, like, bound into the protocol.  IPv4, that we're using now, doesn't.  You need to add that layer.  IPv6 would.



So John says:  "Gilmore notes that he had been involved in trying to make IPSEC 'so usable that it would be used by default throughout the Internet.'  But 'NSA employees participated throughout the process and occupied leadership roles in the committees and among the editors of the documents.'  The result was 'so complex that every real cryptographer who tried to analyze it threw their hands up and said, "We can't even begin to evaluate its security unless you simplify it radically."'"



TOM:  Hmm, that's worrying.



STEVE:  Which never happened.  So, I mean, so this, everything we know, this reads true because, if you wanted to kill something, you'd just keep adding crap to it until it is so huge and lumbering and burdensome that, first of all, nobody wants to code it because it's just a nightmare to, like, support it all.  And with that complexity, as we know, complexity is the enemy of security.  So you can imagine - and again, pure speculation.  But even if hidden in that complexity wasn't some way around it, the point was that real cryptographers understood that, if they couldn't understand it, they couldn't ever vouch for its security.  So even if it was secure, you just make it impossible to implement, and nobody will.



So continuing, Gilmore says, or the article says:  "Gilmore doesn't explicitly say that the NSA sabotaged IPSEC, but the fact remains that in December 2011, IPSEC in IPv6 was downgraded from 'must include' to 'should include.' He does, however, make very clear his belief in NSA involvement in other security standards.  Discussing cell phone encryption, he says, 'NSA employees explicitly lied to standards committees' leading to 'encryption designed by a clueless Motorola employee.'"



TOM:  Poor employee.



STEVE:  "To this day, he adds, 'no mobile telephone standards committee has considered or adopted any end-to-end, phone-to-phone privacy protocol.  This is because the big companies involved, the huge telcos, are all in bed with NSA to make damn sure,'" the article says, "'that working end-to-end encryption never becomes the default on mobile phones.'"



TOM:  And this makes perfect sense when you think of all those stories we've heard over the years of somebody tapping in on cell phone conversations, showing how easy it is to listen in on cell phone conversations, and everyone reacting, going why don't they do something about this?  Why don't they fix it?  And the best cover story of all was that we're like, agh, the telcos, they just don't care, they're greedy, and they're incompetent.  And probably several people out there jumped to the conclusion that it was some kind of cooperation with the government.  But that seems 100% the most likely explanation now.



STEVE:  Yeah, unfortunately.  And again, that demonstrates this has been going on for quite a while.  I mean, and again, the NSA's charter is to know what's going on to the greatest degree possible.  So it is the case that our lives have moved online, what we do is moving over wires, and so I used to buy things driving around in my car.  Now I go to Amazon to do it.  And so if somebody, I mean, so Amazon has all my records.  Amazon knows more about me than any other single entity on the planet, based on what I buy.



So, I mean, the world has changed as we've gone online.  And I think what's interesting is that it probably got really good for a while for the NSA.  But I've said on the podcast, talking to Leo about the Snowden effect, that it's going to get really bad in the future.  I mean, this will end up having been the worst thing that has ever happened to our intelligence collecting ability because, as Bruce says, trust the math.  The math is good.  And so the point is that the math will stay good, but people who care about offering more security have the ability to do so, in all the ways other than the math.  And that's there.  So, which is a long-winded way of saying we're going to fix a lot of this.



TOM:  Yeah.



STEVE:  And it's going to be because we now know somebody is actually listening, and we'd rather not be listened to.



TOM:  The implications of this are not going to be known in full, any more than the Pentagon Papers coming out at the time did we know in full what that was going to do to how we conduct business and how we think of privacy and how we think of the government.  It's still being worked out right now.  But for sure it's going to keep coming.  It does seem like there's more leaks to come, too.  I don't know if we're at the end of them yet, or not.  



STEVE:  Yeah.



TOM:  Let's cheer up.  Let's talk about "Orphan Black."



STEVE:  Well, I just wanted to say I mentioned it a couple weeks ago.  A good friend of mine sent me a review from Paul Krugman, of all people, a well-known columnist for The New York Times, who raved about it.  I've still not seen it.  In fact, oh, here it is, thanks to Amazon.



TOM:  Wow, that was quick.



STEVE:  There's my "Orphan Black" DVD.  I'm still catching up on "Mad Men," having figured, okay, everyone's raving about it, I need to find out what's going on, after catching up with "Breaking Bad."  So I'll get to "Orphan Black."  But I'm getting a ton of feedback from people making me very glad that, even sight unseen, I shared this with our listeners.  Will Pearce, and I saw this in the mailbag I was going through today for today's Q&A, Will Pearce in Raleigh, North Carolina had the subject line "Orphan Black," so that just kind of caught my eye.  He just said, very quickly, two lines, "Addicting and bingeing."  Or, I'm sorry, he said, "Addicted and bingeing.  Thanks a lot, Steve.  I really needed another time sink."  Which is obviously a backhanded compliment.



Then also Dale Francisco in Fresno, California, subject was "Orphan Black Nightmares."  He said, "Steve, based on your critique," which actually wasn't that, it was not even a review, just awareness, "in Episode 420, I decided to see what about 'Orphan Black' could be so special.  Dang it.  I usually watch the History Channel, Discovery, Military Channel, and PBS.  Argh.  Now I will have to burn up more hours of my day with 'Orphan Black.'  I fully expect to spend nearly all day tomorrow watching/catching up with 'Orphan Black.'  Thankfully, I just retired.  I have a few more hours each day available to devote to my personal interests."



So again, for what it's worth, I've still not seen it; but the people who, our fellow listeners who have, have been raving about it.  I haven't seen a single negative comment.



TOM:  Oh, yeah, no.  I can back them up.  I watched the entire season on BBC America.



STEVE:  Oh, cool.



TOM:  And it was fascinating.  And they're airing it on the BBC in the U.K. now because it was actually made over here.



STEVE:  Oh, so I know that they're rerunning first season.  Are they...



TOM:  On BBC America they're rerunning first season.  In the U.K. they're getting it for the first time.



STEVE:  Ooh, which means people who have [clearing throat] ways can no doubt get it, too.



TOM:  Oh, of course, yeah, absolutely.  And I'm excited about the second season and what they're going to do there.  We're going to meet more clones.  I don't want to say too much, if you haven't watched it yet.  But, yeah, it's good.



STEVE:  Cool.  So a little SpinRite update, and then we'll get into our Q&A.  Yesterday I finished the work that was, like, the whole first phase of development.  The major feature that SpinRite 6.1 will offer is freedom from the BIOS.  The BIOS has been an increasing problem for SpinRite.



TOM:  That figures.  That's great.



STEVE:  Unfortunately, yeah, the BIOS hasn't been able to keep up with the size of drives.  And so sometimes people report divide-by-zero errors when they give it - when a particular motherboard and a particular drive don't like each other, SpinRite comes along and says, oh, let's go, and the BIOS collapses.  So what we have now is a rock-solid implementation, our own direct memory access, bus mastering, native-level drivers for every system that the hundred people in the newsgroup, I think there's 175 drives I saw.  Somebody pulled the information together and posted a table.  It's really a fabulous development environment to work with these guys.  And it's working perfectly.  It's really interesting, too, because what I ended up creating was a benchmark which is perfect.



SpinRite now has, or I should say - it's funny, too, because I have to be careful because people have been writing to GRC saying, hey, where's the beta that Steve's talking about?  We're not - I don't have a SpinRite beta.  Actually we have something called SpinTest, which is sort of the core, the new core communications structure, which I will then merge into SpinRite once that's finished.  So it's a freestanding application that anyone who is interested with could play with, and it's freely downloadable.  What we're seeing is - oh, I'm sorry, what I was going to say was that I ended up producing a benchmark just because that was a nice way to demonstrate what my goal was, was performance.



So SpinRite has an integrated extended memory manager that we created from scratch.  I talked about how in real mode I'm able to tweak the Intel architecture to get access to 4GB of memory.  We only really need 32MB.  32MB is the maximum size that a disk could transfer at once.  That's 16 bits' worth of sector count, which is 65536, which is 32MB of data.  So what we're seeing is we're able to demonstrate data transfer rates that match the specs from the companies making the drives.  Obviously, they're going to quote the highest possible data rate their drive can achieve.  This benchmark gets the same number.  And, for example, on the faster drives that we're seeing, we're getting, like we're seeing 157MB - I think it's 57.  I didn't go back and check.  It's either 57 or 75.  157, something like that, MB/sec, which equates to, in terms of like a SpinRite Level 2 read and recover when necessary scan, 93 minutes per terabyte.



So we've really achieved what I was hoping for, was the ability to test large drives in a short amount of time.  93 minutes per terabyte means a little over an hour and a half per terabyte.  So you can do 1, 2, and 3TB drives just in a matter of a couple hours.  So it's going to be - so at this point the technology is in place for the older style standard, the ATA IDE standard.  There's a newer type of controller, so-called AHCI, the Advanced Host Controller Interface.  That I'm going to do next.  But first I'm going to take a break, as I've mentioned before, to document the idea that I had for website authentication.  I think I have a way of obsoleting usernames and passwords completely.  I've been thinking about it in the background for a couple weeks, since this hit me on a Thursday morning during breakfast.  I can't find a problem with it.  So I'm going to - so I wrapped up SpinRite work yesterday.  I'm going to get this concept for authentication documented.  Then I'll talk about it here on the podcast, and then I'm going to get back to SpinRite.



TOM:  That's impressive stuff, Steve, that being able to operate outside of the BIOS.  And I for one am one of the many who hope you fix that username/password thing, too.  That would be amazing.



STEVE:  Yeah.  It's funny because, well, I've seen people talk about like the additional complexity of one-time passwords and how the problem with its adoption is that it hasn't removed anything.  It's added more complexity in return for the assumption of more security.  And but the problem is - so there's a problem because you're just - you're adding more stuff.  And yes, okay, maybe it makes you more secure.  I mean, obviously I've been a fan of one-time passwords.  If that's all you can do, it makes you more secure.  I think I have a solution which completely replaces the whole username password model.  It can run side by side.  And so a website could offer traditional authentication or new style.  And the motivation for new style would be it's much easier to use.  It's, for example, safe in a public setting.  You could safely log on in a library, where a system might be crawling with malware.  And the reason it would be, one of the many reasons it might get adopted is the website then doesn't have the problem of user credentials escaping from them, either.  It's safe against that, as well.



So anyway, I don't mean to keep teasing people.  I've been teasing myself for weeks because I haven't let myself sit down and really focus on it until I finished this phase of SpinRite, which as of yesterday is done.



TOM:  It sounds great.  And people in the chatroom are like, ask him this, ask him that.  I'm like, let's let him document it, get the ideas down.  Then we can start pressing him for details.



STEVE:  Yup.  And I want it attacked.  I absolutely need more eyes on it in order to say, what about this, and what about that.



TOM:  Yeah, for sure.



STEVE:  So we'll be doing that for sure.



TOM:  Time now for a Listener-Driven Potpourri #175.  I love doing these.  These are fun, Steve.



STEVE:  Well, we got a bunch of really interesting thoughts and observations and questions.  So I think we're going to have fun with them.



TOM:  Let's start off with listener Greg, writing from an undisclosed location because he's probably protecting his geolocation.  He wonders what Bruce Schneier meant:  Hi, Steve.  Could you briefly explain what Bruce Schneier meant when he said that he preferred conventional discrete-log-based systems over elliptic-curve systems because the latter, referring to elliptic-curve, have constants that the NSA influences when they can.



STEVE:  Yeah.  I'm a little concerned that elliptic-curve systems are going to be - are going to have their reputations needlessly damaged by being lumped in, as with, like, all elliptic-curve systems.  The point is that, where the traditional RSA-style public key technology, as we've talked about often, uses the difficulty of factoring a really large number into the two primes of which it is the product.  So there it's, like, very easy to understand what that does.  A whole different class of problems, where factoring is the hard thing that no one knows how to do quickly.  The so-called discrete-log problem, is the fact that we don't know how, similarly, to find the discrete log of a large number.



Now, there are different systems that use the logarithm problem, one being elliptic curves.  Elliptic curves are an equation, x^3 equals x^2 plus x times 3 plus b or something.  I mean, so it's basically an algebraic curve.  But it is parametric in nature.  The specific elliptic curve that you choose bears on the performance.  So, and cryptographers understand that there are dumb ones that no one would use, and then there are lots of good ones that people can use.  So what's happened is - but inherently there are, like, curve families.  You are able to plug these variables in and choose an elliptic curve.  So for interoperability of systems, in the same way that we have, like, clients and servers that need to be able to have an agreed-upon protocol for establishing a handshake, you'd like to agree on specific elliptic curve parameters so that you could then write protocols that use those curves.



So here's where Bruce's concern and the NSA influence comes in.  We talked about this a little bit last week with regard to a wacky random number generator that the NSA had a hand apparently in influencing.  Specific elliptic curves have been standardized by the NIST, and the parameters are known.  The problem is we don't know where the parameters came from in many cases.  And it's been shown that it's theoretically possible to choose parameters that effectively give a specific curve a backdoor.  So essentially, if you know where the parameters come from, if you know who created them and why they created them, then an elliptic curve is not only as good as RSA - and this is the point - it's arguably much better.



The reason people are looking at this, and in fact considering elliptic curves and discrete-log problems as the generation beyond RSA, is that, from everything that we know, the discrete log problem is much more difficult to solve for a given size of problem, for a given bit length, than factoring.  So, for example, we know how to - say that you had a number that was small, like it was no larger than 50 bits.  Well, we know how to factor 50-bit numbers.  I mean, that's easy to do.  But doing a discrete log of 50 bits, even that is much harder than factoring.  So the point is that equal difficulty, discrete logs versus factoring, the discrete-log problem is much harder at a given bit length.  Consequently, you can use much smaller keys in elliptic curve discrete-log systems than in the RSA factoring problem system, and much smaller keys means much faster algorithms.



So in terms of difficulty, elliptic curve systems appear to have a much stronger future because they are vastly faster today for the same level of security.  And it looks like they will scale very well in the future as we decide we need more security by creating greater bit lengths.  So there's nothing wrong with them at all.  I'm a fan of elliptic curve systems.  You just have to understand why you're using the curve you're using.  And I agree, unfortunately, all the standard curves are, I think, poison at this point.  The NIST standard where, like, these are the curves we're all going to use, it's like, uh, no, thank you.



TOM:  So in other words, trust the math, but not the mathematician.



STEVE:  Well, again, it's like, unfortunately this particular system, a prime factorization is not parametric.  There's no parameters to be used at all in factoring a number.  There's the number.  Factor it.  That's all you can do.  Elliptic curves, by their nature, are a family of curves.  There's an infinite number of them.  And so somebody chose the particular parameters for a specific curve that you could then agree to use for your system.  The question is, who chose those, and why?



TOM:  Yeah, what family?  Whose family?  And everything we've been saying, which is there's nothing wrong with the math of elliptic curves, but there's these endpoints of, like, here, use this set, use this family.  Who's saying?



STEVE:  We'd like you to standardize on this.  It's like, uh...



TOM:  Yeah, exactly.  Richard Warriner in Bedford, U.K. offers some sci-fi feedback:  Steve, I just wanted to thank you for introducing me to the Antares trilogy by Michael McCollum.  It has been some time since I have read a complete trilogy back to back and couldn't put it down.  For me, it has just the right balance between the sci-fi element and the main narrative of the lives of the characters - something that I struggle with sometimes with Peter Hamilton books.  I certainly won't be able to wait many squared heartbeats before I read another of his books.  Richard.



STEVE:  So I just wanted to, you know, we've talked about Michael McCollum often.  And I wanted to say to Richard, well, if you liked the Antares trilogy, don't forget the Gibraltar trilogy.  There's another trilogy:  Gibraltar Earth, Gibraltar Sun, Gibraltar Stars.  Same author, and I recommend it similarly without reservation.  And to any of our listeners who have heard me talk about this in the past, but haven't made the move, if your life gives you some time to read, either the Antares trilogy or the Gibraltar trilogy by Michael McCollum are fabulous.  That's M-c-C-o-l-l-u-m.



TOM:  And mentioning Peter Hamilton, I'm reading "The Great North Road," which is his latest one right now.



STEVE:  Cool.  I've not yet started.



TOM:  Definitely a balance of characters and sci-fi in that one going on.  Which I know what Richard's talking about sometimes.  But this one I think has a really good balance.  So that's another one.



STEVE:  Cool.  How far are you?



TOM:  About, well, it feels like I should be at the end, but I think I'm about a quarter of the way through, yeah.  They're long.



STEVE:  They are.



TOM:  Daniel in Oslo wonders whether we're living in the post-encryption world already.  He says:  I guess I've lost faith.  With the latest revelations that the NSA can crack pretty much anything on the market these days, I am even skeptical of the news today of breakthroughs in quantum encryption.  Is this a new attempt at sneaking in backdoors and getting everyone to jump over to a new, even more easily circumvented standard?  I seriously considered unplugging myself entirely for the first time today.  Is there any hope, Steve?



STEVE:  So this question and the next one are pretty much on this topic.  I guess what I want to reiterate is that I believe there is hope.  I think that, as Bruce says, trust the math.  We also, as we've seen, have to trust the system.  And it's the system, not the encryption, not the math, which has, because it is a system, and it's complex, and it involves lots of moving pieces, we realize now it can be abused.  The system can be tightened up.  The system can be fixed.  And I think what's going to happen, a year from now, this doesn't happen fast, but there is tremendous pressure now on improving the system.



And that's why I think that ultimately what happened with Edward Snowden is going to end up really improving security because now we know there's a reason to tighten things up, and there's a reason, for example, to update protocols.  Protocols are not easy to update.  There's inertia, huge inertia to updating them.  And so it's like, well, they seem to be fine right now.  Well, no one thinks that today.  So they can be updated.  They can be fixed.  And I really think we're going to see a technical response which is going to go a long way to bringing back the faith that Daniel has lost.  It's worth - it's going to take a while, but I believe it's going to happen.



TOM:  Well, and things, when you take the historical perspective, are better now than they have been.  And I'm saying the historical perspective.  I'm not talking about last year or the year before or even 10 years ago.  But people actually have the ability to buy a computer and use encryption and not just slave away in a field somewhere for a subsistence agriculture, at least in large parts of the world they do.



STEVE:  And look at the appreciation that really has - it took a long time.  But people now understand not to use "password" as their password.



TOM:  Right.  Even on a smaller scale, that's a big advance, you're right.



STEVE:  Yeah.  It was inertia.  It took a long time.  But people get it now.  So this kind of change isn't instantaneous.  I would say we're at the low ebb at this instant because there hasn't been time to react yet, technically.  Yet at the same time we've been hit by the political, the social side.  The technology's going to come.



TOM:  Yeah.  We actually have a concept of privacy that has not always existed.  In fact, that's a very new thing in human history.  And so we have to work it out.  And this is it being worked out.  This is the sausage being made.  At least that's my opinion.



We've got a similar one here.  Lynwood Wright in Tampa, Florida wonders whether privacy exists at all:  Steve, I've been an IT professional for 17 years, longtime listener, and longtime user of SpinRite.  I can't count how many times it's recovered data.  Genius product.



I've been following all of our government domestic spying news, and I can't think of any possible way to maintain privacy, short of abandoning all electronics and moving to a northern Canadian deserted mountaintop.  Like most Americans, I have nothing to hide, but firmly believe in privacy.  Without it, freedom is lost.  I've been self-censoring my communications more and more every day, trying to think if what I'm writing will trigger anything at the various agencies monitoring my every thought.  This is not freedom.  For instance, "trigger" and "freedom" in the same paragraph is probably not a smart thing to do.



Just a list of things in my head that are insecure.  Please tell me I'm wrong:  Phone calls:  intercepted, and access to stored metadata.  Emails: intercepted, and access to stored metadata.  Texts: intercepted, and access to stored metadata.  He goes on.  HTTP/HTTPS:  broken, and they have a key database.  VPNs:  broken.  They have a key database to use.  Cloud:  captured in transit, and they likely have access to the datacenter.  Computers, files, video, audio, Stuxnet.  Smartphones:  everything in and out is intercepted, and access to stored metadata.  Standalone GPS units might be safe, eh?  [Sigh].



STEVE:  Yeah.  I was moved to put both of these in mostly because there's so much of the incoming email reads like this.  I mean, and I recognize that the listeners of this podcast, the people who care about security and privacy, who don't just say, oh, whatever, and don't just say, oh, well, it's always been like this, I mean, this is what the listeners of this podcast are thinking about.  Certainly we provide, we have been providing, tools for years to begin to work against this.  I coined the acronym TNO for Trust No One.  And in fact, in talking about Google's ridiculous encryption of their Google Drive, which they can decrypt, we also recently coined ZVE, Zero Value Encryption, as an acronym.



So again, this is still what people want to talk about.  We'll talk about it.  Soon we'll be talking about the improvements, essentially coming back from where we are using new technological solutions to begin to restore privacy.  I don't think what will ever change, though, is that everything he itemized there is a consequence of the connectivity that we have.  It is a huge productivity boost.  Anything I want to know, I can Google and know.  I mean, that's just - that's amazing.  But with it comes some compromise to the fact that somebody monitoring what I'm doing is able to see what I'm interested in.  And there certainly is a chilling factor.



I've often talked to Leo about how I'm self-censoring a little bit.  Like in Google searches I think, oh, you know, whose attention is this going to come to?  Just the other day I was curious about, what was it, the gas that was used in Syria.  It wasn't ricin, it was sarin.  And so I remembered, though, that Wikipedia was going to be switching over to HTTPS.  So rather than just Googling "sarin," which would obviously maybe be seen, I established a secure connection to Wikipedia first, and then I searched for sarin in Wikipedia, that is, with a secure connection, trusting Wikipedia more than I trust Google to keep my interests safe.



I mean, I have no interest other than just I was curious what it was, what was that that sarin gas did?  Unfortunately, I found out.  But that's the consequence of this sense of being watched at all the time.  And this next question by Robert Sutton is just - or actually statement.  He talks about privacy in a way I think is really interesting.



TOM:  Yeah, he's got a bit about the philosophy of privacy.  He's in Brigantine, New Jersey:  I can tell that Steve is interested in the philosophy behind the importance of privacy, so I figured I would share a bit of the philosophical basis I use to explain why privacy is necessary:  The 20th-century existential philosopher Jean-Paul Sartre asserted that privacy was necessary to make the most out of our lives.  This is apparent in his play "No Exit."  In this play, a group of people have their eyelids removed and are trapped in a room together.  It turns out this room is hell.  This is where the quote "Hell is other people" comes from, he says.  Their eyelids being removed is so that they can't even close their eyes and imagine that they are alone.



In Sartre's version of existentialism, he claims that humans have two modes of being:  being-for-itself and being-for-others.  Imagine you're alone in the woods or going for a stroll in the park with no one else around.  You look at all the trees, the park benches, and leaves on the ground, and just enjoy the nice scenery.  Since you're alone, you almost get the feeling that all these things are there just for you.  You perceive these things as objects in your universe.  This is being-for-itself.



Then suddenly, you notice someone else in the distance walking towards you, though they don't see you yet.  Seeing someone else and realizing they are about to approach you, you now perceive yourself as an object in someone else's universe.  So what do you do?  You suddenly become conscious of your appearance.  You make sure your shirt is buttoned, you fix your hair, you straighten your posture so you look presentable and mentally prepare yourself for an interaction with another person.  Then, when the person finally approaches you, you put on a smile, claim you're happy to see the person, and extend your hand for a handshake.  In this mode of being, you are viewing yourself as an object in someone else's universe.  You're not just behaving as your true self, but you're also behaving how you believe the other person expects you to behave.  Viewing yourself as an object in someone else's universe is being-for-others.



Sartre believes that being-for-itself is the mode where humans can be the highest form of themselves and make the most out of their lives.  Being-for-others is the source of all shame, embarrassment, and guilt.  People who live through the expectations of others and always behave how they believe others want them to behave is what Sartre refers to as being in bad faith.  The philosophy is somewhat derived from Friedrich Nietzsche's concept of "bermensch," which is German for "Superman."  An bermensch is someone who is the highest form of themselves with minimal influence from society.  An bermensch is always living inside their own head, and they don't view themselves through the eyes of others.  An bermensch also doesn't follow any rules or social norms that they don't understand, and make the most of their existence before they croak.



Ever since the whole NSA surveillance fiasco, I realize I'm always considering how I appear to others.  Whenever I am talking with a friend, I have trouble getting the feeling of flow, in which I feel like I can be my true self, because I always know someone else is watching.  It's like I'm always viewing myself through the eyes of a third party.  Before every sentence I speak or write, I enter being-for-others in which I consider how I would appear to someone else listening in on the conversation.  It's like I'm always behaving how the government would expect me to behave as the perfect citizen.  I even find myself afraid to say inside jokes I have with my friends because I'm afraid someone listening in would take them out of context.  I find myself constantly restrained from being my true self.



When the whole PRISM thing got leaked, I could hear Sartre and Nietzsche rolling in their graves.  This news made me realize that existentialism is now more relevant than ever.  If we believe we are always being watched, we will lose our ability to maintain being-for-itself, and we'll all be living through being-for-others in which we spend our short lives as robots behaving through other people's expectations.  This is why in the opening chapter of "1984," Winston Smith sat in the corner of the room as he wrote in his journal, outside of the view of the cameras. He needed to escape the view of others in a desperate attempt to retain his humanity.



I know this is long, but I just thought you would be interested.  I'm a computer security grad student, and I started listening to your podcast just to stay informed in current security affairs.  But now I find myself looking forward to every Wednesday at 2:00 p.m.  Thanks for the great podcast.



STEVE:  I thought that was interesting.  An interesting case.



TOM:  You know, I was a philosophy minor, big fan of Sartre, and loved that play "No Exit."  There is an alternate take on that.  And this doesn't discount anything Rob said.  Rob did a great explanation of one view on this.  But the alternate take could be that what Sartre was trying to encourage you to do was to be that being for yourself, even in the view of others.  I supposed you could take that...



STEVE:  Ah, be strong enough.



TOM:  ...yeah, take that to the logical extent, that something like this actually strengthens us because it forces us to confront that being-for-others and try to resist it.



STEVE:  It's like gazing around and seeing cameras pointed at you and saying, eh, okay, so what?



TOM:  Yeah, exactly.  And not feeling like, oh, I have to, you know, some other people are around, so I have to behave differently than who I am.  It's being true to yourself.  I think we'd all like to choose to put ourselves in that situation, rather than to be thrust into that situation.  But the reason this is so applicable, I believe, is Sartre wrote a lot of this stuff based on his experience in France during the German occupation, where he went through exactly the worst form.  I mean, we think we've got it bad.  They had a much worse form of a surveillance state.



STEVE:  Yeah.



TOM:  Just without the technology.



STEVE:  Yeah.



TOM:  Shall we go to Paul Durham in Port Elizabeth, South Africa, suggesting an SMTP protocol improvement?  He says:  Hi, Steve.  On Security Now! you have discussed privacy issues relating to email.  I have an idea that I think could be applied to SMTP that could improve privacy.  Currently when a user sends an email, the email headers show who it is from, who it is going to, and the content of the email is typically visible as well.  The mail content can be encrypted by applying PGP.  Privacy is still leaked by the header containing the "from" and "to" details.



Suppose each email domain had a PGP key pair.  When the email is created by the sender, the recipient is defined in the email as normal, and the email content is encrypted with the recipient's PGP key, as normal.  In order to protect the recipient's email address from being viewed in the metadata, the email and the recipient's details should be encrypted with the receiving domain's PGP key.  This way the email can get as far as the receiving domain's SMTP servers without the recipient being identified, and only then would the recipient become identifiable to the receiving domain in order to deliver the email to the recipient.  Since the domain decrypting the recipient information is the same domain the recipient is in, there would be little, if any, risk of loss of information.



In order to protect the sender's information, the email created by the sender, after it has been encrypted by the recipient's PGP key and thereafter by the recipient's domain's PGP key, can be encrypted by the sender's domain's PGP key.  This would protect the email sender's metadata from being intercepted until it is received by the sender's mail server for further delivery.  Since the server's domain is the same as the sender's domain, there is little, if any, loss of information at this point.



So to summarize, encrypt an email with the recipient's PGP key, then the receiving domain's PGP key, then the sender's domain's PGP key.  This would seem to protect the privacy of an email from the source to the destination, with the exception of the sender's domain knowing the sender, and the recipient's domain knowing the recipient.  Does this make sense, and would it work as Paul envisages it? 



STEVE:  Well, first of all, yes.  And I got a kick out of this as I was reading it because essentially what Paul has done is create a mini onion router.  This is essentially what the onion router does.  When you want to send something anonymously out on the Internet, you choose a series of nodes, and then you encrypt from the farthest away one sequentially towards you, successively encrypting, creating these so-called layers of the onion.  And then you send this to the first node that's only able to decrypt the outer layer.  It sends it to the next node that, because the packet is moving in the same direction that you added these layers, it's able to hop back through, each node decrypting what is then the outermost layer when it receives it.



That's exactly what Paul has suggested here with SMTP.  The idea would be that you first encrypt with the recipient's email, then you encrypt with the recipient's domain, then you encrypt with your domain.  So then you hand this, that's got three layers of encryption wrapping, to your domain.  It's able to decrypt it to find out where it goes.  It then sends it to where it's going, the recipient's domain.  That domain can decrypt that layer.  Now it knows who it's bound for.  It then transfers it to that person.  And then that person takes the last layer, the innermost layer off, by decrypting that.  So essentially it's onion routing.  And we know that the concept is strong and viable, and this essentially applies that to email.



Now, of course, going from the theory, which is sound, to practice is a problem because we all have a protocol which doesn't use much encryption right now.  I think that probably email is as ripe, when I was talking about the pressure the notion of surveillance puts on the adoption of protocols, email is probably among the most ripe for this kind of upgrade, switching in general to more security.  Initially the optional servers will then be replaced that understand some sort of email privacy, and then we'll begin to get it over time.  Because right now it's just almost all of email is completely unencrypted in the clear.



TOM:  Do you think email's worth saving?



STEVE:  That's a good question.



TOM:  Or will we just move on to something entirely different?



STEVE:  It's a good question.  I love the store-and-forward nature of it.  I love that it's asynchronous.  We can do things in the middle of the night.  We can answer things when we choose to.  Like switching everything to real-time would make us all neurotic, I think.



TOM:  Yeah, I suppose that's true.  Speaking of neurotic, when I was growing up we all talked about neurotic people going to the mental hospital in Alton, Illinois.  But that has nothing to do with Steve, who I imagine is perfectly sane, and from Alton, Illinois.  A bunch of my family is over there, too, Steve.  Don't worry about it.  On this topic of Steve's coffee recipe:  Steve, thanks for the great security show.  Listener for years.  I've heard you talk about this amazing coffee recipe you have.  Will you please open source the coffee recipe so the rest of us can get addicted, as well.  I'm with Steve.  What is this coffee recipe?



STEVE:  And go ahead and do No. 8 at the same time.



TOM:  Okay, yeah.  John Hughan also asks about your magical coffee.  He says:  When you're done working on the far more important webpage that describes the solution to user and web authentication, assuming this isn't something you want to keep as your secret recipe, I'm wondering if you could post your "Guide to 'This is Coffee?' Coffee," including raw materials, hardware, and methods.  I have to say I'm very intrigued by your description because I tend to drink coffee only in more elaborate drinks because I've always found black coffee too bitter.  But I also hate the number of calories those types of drinks have.  So if there is in fact a way to get great-tasting black coffee, I'm all ears, as I would suspect many of our listeners will be, as well.  Thanks for a great show.



STEVE:  Well, I don't want to keep everyone in suspense.  I have promised Leo that the next time I come up to Petaluma I'm going to specifically arrange to make him a cup of coffee using my formula so that we have another person's opinion.  Because so far, as I have said before, this is the coffee I drink.  I mean, I've got it right here, and I've been drinking it.  And when I've shared it with people, I've said, here, like, taste this, they're like, is this coffee?  They can't even believe how smooth and perfect it is.



But so here's the deal.  I mean, it's not a big mystery.  I did search for it for a while.  The way I got to here was I was making what Starbucks calls Americanas, or Americanos, at home.  I have a commercial espresso machine.  And so I would nuke a large mug of water, making it hot water, and then drop the espresso directly into the hot water.  I'm big on not having the espresso go into a little shot glass because it immediately starts to oxidize and goes from, like, light brown to black and then becomes very bitter.  I don't know how anybody would want to just drink espresso that's been sitting around in a cup for a while.  But by having it drop immediately from the filter holder into the coffee, it gets diluted, and it's protected from the oxygen.



And so I was making a very nice cup of coffee.  The problem was it only makes one cup.  And so then you're going back, if you want to have five cups over the course of the day, you're going back there all the time.  So what I ended up evolving to was to use Starbucks espresso bean and drip brew that.  So my formula is pretty simple.  I have a burr grinder, and I've got the one that I told Leo about.  I don't remember the model number now.  But I chose it because it has no reservoir.  The beans drop right through it down into the coffee filter.



So I take, I think it's one ounce, I don't remember the amount, but I have a measuring deal, essentially for about five cups of coffee.  And so I take the beans, grind them through this, so they grind and drop right into the filter, and then it's just do a drip brew, a sort of a small, sort of like a half pot.  It's a - and it's also the drip brewer that I've talked to Leo about, the little simple coffee percolator.  And it uses the little Melitta disposable, I use the brown filters because I don't want the bleach, and drops right through into the pot.  And then I transfer it to something that keeps it hot for hours at a time.  And that's it.  So anyone who's interested, you need a good grinder.  You can't use one of those little spinning blade things that just fractures the beans.



TOM:  It hurts me just thinking about that, yeah.  Don't use that.



STEVE:  I know, it's horrible.  So you need that so you get a consistent grind.  I've got mine set to 3, whatever that means, which is sort of large, I think, because you don't also want it to be ground too fine, or you get a more bitter result.  So anyway, I will do all this the next time I'm with Leo, hand him a cup, and see what he thinks.  And in the meantime, anyone who wants to experiment, just buy a bag, you can get a one-pound bag of espresso bean, you don't want it pre-ground, espresso bean.  Unless you don't have a grinder, in which case they could grind it, then you could run home and give it a try and see what you think.



TOM:  Sprint home, yeah.



STEVE:  Yeah.



TOM:  I like this idea of the grinder that goes right into the filter.  Because I have a burr grinder, as well, and I've been meaning to replace it because it's old, and it's also really loud.  And it goes into this plastic thing that you dump the coffee out, it's not good.  So I love that.  If you remember what brand that is, I'd be curious.



STEVE:  I will.



TOM:  Simon Comeau-Martel in Montreal, Quebec, Canada wonders about Touch ID on the new iPhone 5S.  There were definitely people earlier in the chatroom wanting to know this, too:  What's your take on the new Touch ID technology by Apple, Steve?  What's its impact on the device disk encryption?  Historically, the PIN/password was used to protect the encryption key.  How can we fit a fingerprint reader in the equation?  It will never scan exactly the same thing twice.  Also, should we worry about someone lifting prints from a desk, or from the phone itself, to try unlocking it?  



STEVE:  Okay.  So at this point all we have is conjecture.  I'm looking for and have not yet found, so I'd like to enlist the entire listenership of the podcast as a dragnet for information.  I'm really curious to know exactly what Apple has done.  Simon is right that certainly every time we put our finger on the scanner, it's going to be a different image.  We seem to know that it uses detail extraction.  So it's not actually using the image.  It's using the well-known fingerprint details, loops and whorls and breaks in the ridges of fingerprints which are uniform over time.



So the idea is that you train it by putting your finger on the scanner many times, giving it the same fingerprint over and over and over.  It so-called "learns" that.  So what it's doing is it's not memorizing the image.  It's memorizing the features.  And then it decides that your fingerprint has the following features in a certain topology.  That's what it memorizes, and then that's what it no doubt uses to match with in the future in order to unlock your disk encryption.



So it can't, I would be very skeptical if it used that as the key directly because, for example, you would never be able to retrain it with a different one.  There's got to be an intermediate step where it says, is this the same one I've been taught to accept?  And if the answer is yes, then it uses that.  And maybe it turns those features into a hash, and then it uses the hash.  We don't have enough details yet.  But it certainly is the case that it goes through some iteration of, like, feature recognition.  I'm sorry, go ahead.



TOM:  No, no.  Am I right that - I thought I remembered them saying that, even though you have the fingerprint, you still set a normal password as sort of a backup...



STEVE:  Yes.



TOM:  ...to the fingerprint not working.  So could that be what it's relying on for the consistent behavior, and just working the way it's always worked?



STEVE:  Well, yeah.  So the idea would be it has a template for what it has seen.  I was glad to see that from day one Apple recognized the privacy concerns.  So, and I hope they will, like, put all of our minds at ease by just telling us what they've done.  They probably have some patent stuff they may have to wait for.  But we need to know.  But, for example, if you had a means of representing the topology of the features, so that loops and whorls and gaps are mapped, and that's invariant over time, then you could hash that to create a hash key that was invariant over time.  So at this point we just sort of have to make things up and wait till we hear exactly what they've done.  I love that they've done this because, I mean, I watched Leo and Sarah reacting to the news as it was happening, and Sarah talked about how she hates having to enter her long, complex, secure password every single time she wants to buy something.  She just wants to put her finger on the phone, which I do, too.



TOM:  Java678 in the chatroom gave us a link to one of the Apple patents...



STEVE:  Ooh.



TOM:  ...that they have used for fingerprint identification.  We still don't know if that's what they implemented, though, because it shows things like near-field communication and stuff involved which are not in the iPhone 5S.



STEVE:  Right.



TOM:  We've got one last question here.  Macarthur in Virginia shares some thoughts about the randomness of Intel's RNG:  Intel claims that it's purely random, but they haven't proven that it isn't "not random."  They've only shown that it appears to be random enough.  You can never prove that something is random.  All you can do is prove that something isn't.  So all they've shown is that it doesn't break down and lose to the tests that we currently have.  Thus, they've shown that it seems to be random.  They've shown that it is enough random that it doesn't show bias and seems to be random.  Any RNG can't be proven to be random.  It can only be proven to not be random. Now, while I do think that Intel's fab is probably the best in the world, they can't verify every single one.  That's the words of our writer, Macarthur here.  They can't prove every single one.  That's why the Linux kernel doesn't rely solely on Intel's RNG.  They mix in Intel's RNG products with its own internal pool of random data.



The kernel gets it from network traffic latency, all of them; HDD access times; temperature from the various parts and a few other places.  So they currently mix that data from Intel's RNG with that data to make it stronger and more random.  So even if Intel put a backdoor in it, it'd never result in completely unrandom data since the kernel stores that data in RAM.  And the CPU could go through and try to turn the data to all zeroes, but the kernel would likely reject that result as it tries to keep that data as random as possible.



The last I remember reading, the kernel held about 4 to 16Kb of random data on the /dev/random device.  I believe that the BSD kernels use a similar approach.  The Linux kernel, and as far as I know the various BSD kernels, don't just accept what intel feeds them.  They use it as an additional source of random data.  So all Intel is doing is making that data more random; and, at worst, they're keeping it as strong as it was before.



STEVE:  We've talked a lot about randomness because it's crucial for cryptography.  And one of the - in fact, we highlighted it last week when we were looking at the accusations that the NSA, through the NIST, may have deliberately subverted an almost never used, and no one really cares about it anyway, random number generator.  But the idea that you might have something nonrandom is a huge concern.



I love this notion of mixing random sources.  I've used it myself.  Listeners with a really good memory will remember when I was messing with the Off The Grid paper-based encryption system [SN-315].  I needed an ultrahigh entropy pseudorandom number generator.  Not that 256 bits wasn't enough, except that there are so many possible Latin squares of that size, I mean, just a phenomenal number of possible ones, that if I used a random number generator with a small amount of entropy, it couldn't have that many states, and it couldn't give me nearly as many Latin squares as possible.



Anyway, the point is that I have GRC provide entropy, whatever it was, 256 or 512 bits, and I have JavaScript in the user's machine provide it, and mix them together.  It's one of the coolest things about randomness is that - and it's sort of what we see with the XOR feature.  It's sort of one way to think of it is you can't unscramble an egg.  Once you've got something random with a lot of entropy, there's no way, nothing you can do to it can lower the level of entropy it has.  It's got it.  And all you can do as you add more is increase the level that it already has.  Which is why the idea that the kernels would take sources that they already maintain, things like packet arrival times, hard disk completion events, use high-resolution timers to watch things happen.  And that's going to, I mean, technically they aren't absolutely random.  But what they are is absolutely unknowable to an attacker.



So you take all those different sources.  And by all means, if the Intel chip wants to throw some bits at you, take it in.  It can't hurt you in any way,.  Even if it sent all zeroes, you'd still have all the other random sources that are pooling their randomness.  And this whole notion of, when he talks about the kernel having 4 to 16K, that talks about the total entropy in a so-called "entropy pool."  And as you pull randomness out of the pool, it diminishes the pool size.  And then, as other events happen in real time, it begins to replenish the pool size.



So it's funny how far we've come in our understanding of what a good random number generator is.  Back not that long ago, really, we were using a simple equation, like a linear, what's called a linear congruential pseudorandom number generator, which just was an addition and a multiplication and produced an absolutely deterministic series of numbers.  I mean, just an awful source of random numbers.  But that's what people used.  Today, we've gone from much more sophisticated pseudorandom numbers to this notion of a pool of entropy that has a known size that we are pulling from and adding to as the entropy is being needed and being replenished.  So anyway, just the whole notion of entropy is key to cryptography because ultimately we are protecting secrets, and it's a random number that is the secret that we don't know.



TOM:  Yeah, and as somebody pointed out in the chatroom, it takes something like a black hole if you want to unscramble an egg.  So that's pretty good security.  For now, anyway.  For the foreseeable future.  I want to go take a dip in the pool of entropy now.  Be more safe.



STEVE:  I wonder what color it is.  Probably is.



TOM:  Yeah.  I wonder what kind of swimsuit I should wear.



STEVE:  Maybe it's 17% gray.  It probably is.



TOM:  It probably changes.  I guess.  Just fluctuates.  Well, Steve, that brings us to the end of a great episode of Security Now!.  I'm so glad I get to do a couple more of these with you.



STEVE:  It's going to be really fun, yeah.



TOM:  Yeah, I will be here for two more weeks.  Leo is on vacation.  He'll be back in a couple of weeks.  Meanwhile, folks, if you have not, I can't imagine you haven't, but if you have not gone to GRC.com and checked out all of the amazing things, you were talking about the Haystacks thing that you were doing, you were talking about the password thing, the new version of SpinRite, ShieldsUP! still going on there, you've got to go check that out, folks.  Any last thing to mention before we head out of here?



STEVE:  Only that I do keep asking people to send your thoughts and questions to GRC.com/feedback.  And also I will say again, what we don't have is a beta of SpinRite 6.1.  What we do have is a very active group that's been playing with the code that I've been writing over the last couple months.  I get email from people saying how do I join that?  GRC.com/discussions will explain how you participate in our forums.  We don't have web-based forums.  We're old school NNTP newsgroups.  The whole population of people really prefer that.  I like it.  It just seems, I don't know, more hardcore, and it's more about being down to business.  Also very high quality posts and people hang out there.



So you'll have to go to GRC.com/discussions in order to understand how to hook up to our NNTP server.  You can't go to news.grc.com with a web browser.  There's no web server there.  You have to have - I think Thunderbird has one.  I use Gravity on Windows.  I know that there's NNTP news readers for Apple.  I use something called NewsTap on my iOS devices, on my various iPads and iPhone.  I like it a lot.  So anyway, we'd love to have people show up.  The more testers we have, the merrier.  And it's a lot of fun to participate in nailing down this code.



TOM:  Absolutely.  Go check it out, folks.  And don't forget about our show notes, too, at TWiT.tv/sn.  We'll see you next time.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#423

DATE:		September 25, 2013

TITLE:		Fingerprint Biometrics

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-423.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's news, and following the news that Apple's new iPhone Touch ID system was spoofed within days of its release, Steve and Tom take a much closer look at the technology and application of Apple's Touch ID system, examining the reports of its early demise.



SHOW TEASE:  Coming up on Security Now!, I'm filling in for Leo again.  And Steve Gibson and I have got some great stuff to talk about.  There's more NSA news, seems like there's more every week.  We've got some of that.  Also we'll find out what about iOS7 is really frustrating Steve, and it's not the fingerprint sensor.  In fact, we've got a whole explanation of what's good and what's bad about fingerprint biometrics.  All that and more coming up.



TOM MERRITT:  This is Security Now! with Steve Gibson, Episode 423, recorded September 25th, 2013:  Fingerprint Biometrics.



It's time for Security Now!, the show that attempts to keep you informed about the safety hazards of the Internet, and sometimes the wider world, to help you stay safe online.  I'm Tom Merritt, filling in for the vacationing Leo Laporte.  He's gone for two more weeks, so I get to do this show one more time.  I'm excited about that because I get to do the show with this guy, Steve Gibson, the man behind GRC.com, ShieldsUP!, SpinRite, and so much more.  Steve, it's a pleasure to do this show with you.  Thanks for letting me co-host.



STEVE GIBSON:  Oh, likewise, Tom.  It's great.  We get along well.



TOM:  We've got some fingerprint biometrics to talk about today, amongst other news.



STEVE:  Well, yeah.  As soon as the news of the fingerprint reader came out, our listeners will remember me saying, well, let's see how long it takes before the reader is spoofed.  And I'm finding myself reacting to the fact that people are saying it was hacked.  To me, it was spoofed, it wasn't hacked.  A hack would be something that circumvented the need for it.  But spoofing is, I mean, that's the right term.  Fake fingerprints were made.  And we talked a little bit about the technology.  The fact that it was a capacitive technology as opposed to a photographic technology meant that inherently you would need a 3D finger.  And of course it didn't last a week.



So I figured it'd be a great topic for today since it's obviously very topical.  It's in the news.  And I wanted to also put it into perspective because one of the groups that performed the hack said, see, nanny nanny nanny, we told you fingerprints were no good.  But a different guy who did it says, you know, the topic of his posting was "How I hacked Apple's Touch ID, and why I still think fingerprints are great."  And both of these really - the reason I think I want to share them mostly is they really take us into the technology that had to be developed in order to do this, which is also sort of interesting.  And of course we've got a whole bunch of news of the week.  So a great podcast.



TOM:  Yeah, it's a great - I'm really interested in talking about this, too, because what these - you can use "hack" in sort of the broad sense of messing with stuff to apply to it here.  I know what you mean.  It's not actually changing the sensor or getting in there.  But these ways of going after it, they show the limits of it.  Nothing is a hundred percent secure ever.  So to me what these show is not that, oh, see, fingerprints are bad.  It's that, if you're going to use a fingerprint sensor, you should know that these are the limits to what it's going to be effective at and what it won't be.



STEVE:  Exactly.  What I want to do is I want to bring back some perspective of - and in fact, even in this context I think a week or two ago I talked about front door keys that are also not - that are not unique.  But they're in the physical world, and they're good enough to do the job.  And a fingerprint and what you have to go through to spoof it and the fact that it's a real-world, physical attack that involves proximity, in that sense it's completely different than anything that can be done to us from China or Russia, purely electronically, with a zero-day sort of thing.  So it does really put us, I think, in a different class of security.  So I want to just take a really good overview of what this means in the context of security and convenience because really those are the two terms that apply.



TOM:  Yeah.  Watch out for those boxes of fingers being shipped over from other countries.  Okay, Steve.  Let's get into some of the security news, starting with - oh, yeah.



STEVE:  Yeah, now...



TOM:  With the NSA.  Back again.



STEVE:  We can't get away from it.



TOM:  NSA and RSA.  We've got two different SA's.



STEVE:  Yes, we do.  We shouldn't be away from it until it sort of dies down...



TOM:  Sure, of course.



STEVE:  ...of its own accord.  Now, many people apparently misunderstood what I was saying in the last couple weeks about this so-called backdoored dual elliptic curve programmable random number generator, or deterministic random bit generator, I think is what - DR, whatever it was - when I was saying that nobody would use it.  I wasn't saying nobody has ever used it.  I said anyone who knew anything would be crazy to use it.  So that was my point, was that in this collection of four pseudorandom number generators that the NIST had standardized on, it was, like, it was ridiculously bad.  It was hundreds of times slower.  It was questionable from even before the ink was dry on the standard.  And it was sitting next to three others that were faster and clearly secure, where from day one this stepchild was just wrong.  And then we find out that it's the default random number generator used by RSA's suite of security libraries.



[Silence]



TOM:  It just kind of leaves you speechless, doesn't it.



STEVE:  Okay.  Let me say that again.  The RSA, the arguably sort of premier commercial provider of security technology and software, the inventors of standard factorial-based public key encryption, the designers of all these technologies, they, in commercializing this, they created a suite of libraries.  There's Crypto-C, Micro Edition Suite, Crypto-J, Cert-J, SSL-J, Crypto-C, Cert-C, SSL-C, all these packages.  There's something called the BSAFE Toolkits, they call them.  And what we learned from a letter that RSA sent to their major clients and customers is that they needed to change the default pseudorandom number generator used in all of this for, I think it was like 2007 or 2008, I mean, for like many years, because the default was this last orphan child random number generator.  That's what the BSAFE Toolkit suites used by default.  They had other PRNGs in there.  But if you didn't explicitly select and tell the package to use a different one, this is what you got.  And it is impossible to explain this.  I mean, this is just - the security industry was stunned.  I mean, arguably, we should have known.  But it was just - you just - RSA would be the last person you would expect to do this.



TOM:  RSA is synon- I mean, I know most of the audience knows that they're synonymous with encryption.  In an episode of "Agents of SHIELD" that premiered yesterday, they throw out RSA in there as sort of like, yeah, we're using RSA, like...



STEVE:  The guys, yeah.



TOM:  If Joss Whedon writes that in the script, that means that this is permeated into the consciousness of the culture; right?



STEVE:  Okay.  So Matthew Green, whom we've spoken of recently, the Johns Hopkins cryptographer, he wrote - and I'll just quote the top of his posting.  He said:  "In today's news of the weird, RSA," and he says in parens "(a division of EMC)" because they got bought by a bigger fish, "has recommended that developers desist from using the" - and he says in parentheses "(allegedly)," and then in quotes, "backdoored" - and that's the other thing, too, is that our listeners understand, because we covered this in detail, what we know about this.  And we don't know anything.  But there's every reason to be as suspicious as we should be.  And that's all the reason anyone needs never to use it.  I mean, because it's not like it's the only choice.  It's like the worst choice, in terms of performance.  Oh, and in fact, in trying to defend it, the CTO of RSA said, well, you know, there are purposes for having slow algorithms.  It's like, what?



TOM:  Like what?



STEVE:  Well, for example, when you want to strengthen a password, you run it through a hash many, many, many hundreds of thousands of times.  But that's slow hashing functions.



TOM:  Yeah, that's not the same thing.



STEVE:  It's completely distinct, yes, from a slow random number generator.  Normally you need those at very high speed and very high quantity.  We were talking about how entropy gets drained from operating systems that maintain entropy pools and that - so operating systems are thirsty for new entropy because the random number generator is taking up the entropy in order to do a really good job.  So this is just - this is unbelievable.



But anyway, so continuing what Matt Green said, he said:  "...developers desist from using the (allegedly) 'backdoored,'" in quotes, "Dual_EC_DRBG random number generator, which happens to be the default in RSA's BSAFE cryptographic toolkits."  And then Matt writes:  "Youch."  He said:  "In case you're missing the story here, Dual_EC_DRBG (which I wrote about yesterday)," he says, "is the random number generator voted most likely to be backdoored by the NSA."  And of course he doesn't mean voted literally.  No vote was taken.  But we all agree.



He says:  "The story here is that, despite many valid concerns about this generator, RSA went ahead and made it the default generator used for all cryptography in its flagship cryptography library.  The implications for RSA and RSA-based products are staggering," writes Matt.  "In the worst case, a modestly bad but by no means worst case," he says, "the NSA may be able to intercept SSL/TLS connections made by products implemented with BSAFE."



TOM:  B-UN-SAFE.



STEVE:  Oh, goodness, yeah.  "So why would RSA pick Dual-EC as the default?  You got me," he says.  "Not only is Dual_EC hilariously slow, which has real performance implications, it was shown to be a just plain bad random number generator all the way back in 2006.  By 2007, when Shumow and Ferguson raised the possibility of a backdoor in the specification, no sensible cryptographer would go near the thing.  And the killer is that RSA employs a number of highly distinguished cryptographers.  It's unlikely that they'd all miss the news about Dual_EC.  We can only speculate about the past."  So, I mean...



TOM:  Can you make a stab at why?



STEVE:  Well, NSA.  Again, we will never know.  We don't actually positively know there's even a problem.  But there's certainly grounds - there's grounds for concern.  The magic numbers used in this particular elliptic curve, remember I said elliptic curves are fine, but specific ones, because there's an infinitude of them, specific ones are chosen for various reasons.  So the researchers, Shumow and Ferguson, verified that it was possible to have a backdoor such that getting a few random numbers from this generator would allow you to get the entire future, to essentially capture its state.  And once you have the whole state of a random number generator, because it is deterministic, you can simply project that state forward into the future.



So it's impossible to excuse this.  No one would have chosen this.  Someone did.  And, I mean, there's, like, there's no better place to plant a trojan than in RSA's toolkit, which is used pervasively as a building block because no one wants to write all this complex crypto stuff themselves.  It's used pervasively in commercial products as a building block for everything.  So, I mean, this is the nightmare scenario.  And we know how crucial random numbers are.  It's the basis for secrecy is that you choose a random number which is unpredictable by your adversary, and then you encrypt it in order so the other side can decrypt the random number, then they have it, and then you both use that for the actual - to run the cipher.  So anyway, the incredible good news, I mean, this is another example of the positive fallout that Edward Snowden created.  None of this would be happening if he hadn't sacrificed his way of life.



TOM:  You mean no one would know about it.



STEVE:  Correct, I'm sorry.  None of the revelations would be occurring.  And, I mean, this has now been killed.  This may have been the coup that the NSA has had, and it's dead.  Well, it will be as soon as they root this out of all the products that have it.



TOM:  Sure.  Well, this seems to be the smoking gun that goes along with the story that said NSA had broken encryption, and everyone was saying, well, they can't have broken encryption.  Bruce Schneier was saying, "Trust the math."  This could be the explanation of it.  They didn't have to have broken anything.  They had something that was already broken, essentially.



STEVE:  There could very well be people back in Langley who are just not happy today.



TOM:  Oh, I'm sure.



STEVE:  Because their big feather that they had managed to insinuate out into the industry - and, I mean, also, the problem with this is that it is not just the NSA.  There are other smart people in the world.  And especially when you aim them at something, and you give them a place to go dig, they can find answers.  So if other people, not the government, I mean, you could argue that the U.S. government, the NSA having this is bad enough.  But this has always been the argument against allowing any kind of security vulnerability, even one that seems to be asymmetric in nature, where only if you had a secret would it be vulnerable.  The problem is, those secrets cannot be kept.  The fact that Edward Snowden happened demonstrates the NSA could not keep their own secrets.



TOM:  Right.  And what the NSA would like to say is, yes, but if Snowden had kept his mouth shut like he should, this wouldn't be happening.  That he didn't is a fact.  And the fact is, if he didn't keep his mouth shut, if he did keep his mouth shut, somebody else might not have kept their mouth shut, just proving the point that you can't keep the secret.



STEVE:  And the fact that there are other smart people implies that, if we allow known weak crypto with suspected backdoors to go into heavy use, then it may very well be that there are other people far from Langley, Virginia who are also not happy because who's to say that they haven't independently cracked this.  And that's the danger.  It's not just, I mean, if there is a crack, and it requires keeping a secret, the huge breakthrough in our understanding of how to secure privacy is that algorithms must be public.  The idea that you have - and even RSA is guilty of this.  They had some, RC6 may still be, but RC4 was for a long time, and then it kind of - it got loose from their control.  The idea is that you want to have the algorithms be open and then - but be secretly keyed.  Here we have an algorithm that is inherently flawed because it's based on some keying material no one knows the providence of.  We don't know where it came from.  It just, ooh, magic numbers.  You know, trust us.  And, no.  We can't do that.



TOM:  TNO, yeah.



STEVE:  Yeah.  So...



TOM:  I was just going to say, I think the lesson here - because I'm sure there are people in our audience even who say, well, you know what, I want the NSA to have an advantage; I'm not one of these people who is against them.  And that's fine.  I probably disagree with you, but that's fine, to be on that side of the argument.  However, it's not necessarily, as Steve is saying, about just the NSA.  You don't know who else has the ability, or has had the ability for a long time now, to take advantage of this same backdoor.



STEVE:  Yeah, and they're not going to tell you.  They don't want to disclose - they don't want to disclose that.  It's probably, if it exists, it is a super-secretly guarded secret.  And they're chortling around with their ability to capture some random numbers and then know the future.  Which is the end, which kills crypto.



TOM:  And even The New York Times now understands that backdoors are bad.



STEVE:  I was impressed by this, actually.  This meant something to me because it was the Sunday review section.  It was put up in the paper by The New York Times Editorial Board.  So not just one random crank, I mean, but this was their formal statement.  They said:  "In 2006 a federal agency, the National Institute of Standards and Technology" - NIST we've talked about - "helped build an international encryption system to help countries and industries fend off computer hacking and theft.  Unbeknown" - unbeknown?  Well, that's what it says.  Unbeknown.  I guess I can put a "st" in, unbeknownst.



"Unbeknownst to the many users of the system, a different government arm, the National Security Agency, secretly inserted a 'backdoor' into the system that allowed federal spies to crack open any data that was encoded using its technology."  Now, again, we don't know that.  So this is dumbed down for the general population.  Unfortunately, it's also a little overblown.  But our listeners understand suspicion is enough, and we've got plenty of suspicion, when there doesn't need to be any.



So going on it says:  "Documents leaked by Edward Snowden, the former NSA contractor, make clear that the agency has never met an encryption system that it has not tried to penetrate."  Well, that's probably true.  "And it frequently tries to take the easy way out.  Because modern cryptography can be so hard to break, even using the brute force of the agency's powerful supercomputers, the agency prefers to collaborate with big software companies and cipher authors, getting hidden access built right into their systems.



"The New York Times, The Guardian and ProPublica recently reported that the agency now has" - meaning the NSA agency - "now has access to the codes that protect commerce and banking systems, trade secrets and medical records, and everyone's email and Internet chat messages, including virtual private networks."  Again, that's a little overstated, but okay.  "In some cases, the agency pressured companies to give it access."  Now, that we do know.  "As The Guardian reported earlier this year, Microsoft provided access to Hotmail, Outlook.com, SkyDrive, and Skype. According to some of the Snowden documents given to Der Spiegel, the NSA also has access to the encryption protecting data on iPhones, Android and BlackBerry phones.



"These back doors and special access routes are a terrible idea, another example of the intelligence community's overreach.  Companies and individuals are increasingly putting their most confidential data on cloud storage services and need to rely on assurances their data will be secure.  Knowing that encryption has been deliberately weakened will undermine confidence in these systems and interfere with commerce.  The backdoors also strip away the expectations of privacy that individuals, businesses, and governments have in ordinary communications.  If backdoors are built into systems by the NSA, who is to say that other countries' spy agencies  or hackers, pirates and terrorists  won't discover and exploit them?"



TOM:  And we've been saying they probably already have, yeah.



STEVE:  Oh, yes.  The government can get a warrant and break into the communications or data of any individual or company suspected of breaking the law.  But crippling everyone's ability to use encryption is going too far, just as the NSA has exceeded its boundaries in collecting everyone's phone records rather than limiting its focus to actual suspects.  Representative Rush Holt, Democrat of New Jersey, has introduced a bill that would, among other provisions, bar the government from requiring software makers to insert built-in ways to bypass encryption.  It deserves full Congressional support.  In the meantime, several Internet companies, including Google and Facebook, are building encryption systems that will be much more difficult for the NSA to penetrate, forced to assure their customers that they are not a secret partner with the dark side of their own government."  Wow.



TOM:  Good on them for pressuring Congress, yeah.



STEVE:  Yes, yes.  And the idea, I love the idea that we could see some legislation that forbids the government from asking for this because then any companies approached are completely free to say, first of all, no; and also to say, hey, guess what the NSA just asked us to do illegally?  So this is a step forward. 



TOM:  Yeah, absolutely.



STEVE:  Yeah.  I was pleased and impressed.



TOM:  I'm not sure how much I feel Google and Facebook are the folks I want leading the charge on building new encryption standards.  I don't think it's bad to have them in there.  I prefer distributed open source solutions to that.  That's why this next story both scares me and heartens me.  What does Torvalds have to say about inserting backdoors?



STEVE:  I know.  I just got a big kick out of this.  And this, of course, came out last week.  He was - well, anyway.  So I'm stuck on his name because I know he pronounces it apparently Linus [Lee-nus].



TOM:  You can say Linus [Lie-nus].  I say Linus [Lin-nus], which is probably...



STEVE:  Sort of a compromise, yeah.



TOM:  Yeah.



STEVE:  Anyway, so Linus or Linus or Linus, who created the open source Linux operating system...



TOM:  LT.



STEVE:  ...22 years ago, of course we all know, "took the keynote stage at the LinuxCon conference, along with fellow kernel developers, to talk about the state of Linux kernel development.  Throughout the hour-long session, which occurred on September 18th, the panel was peppered with a barrage of questions on a wide variety of topics, with the outspoken Torvalds providing all manner of colorful comments.  Torvalds was also asked if he had ever been approached by the U.S. government to insert a backdoor into Linux.  Torvalds responded 'no' while nodding his head 'yes,' as the audience broke into spontaneous laughter."



TOM:  Classic.  It's classic Torvalds.  He's hilarious, if you've never actually heard him speak.



STEVE:  And the problem is I wouldn't have been laughing.



TOM:  Well, it's not funny.  It's funny the way he delivered the answer.



STEVE:  Correct.



TOM:  The actual answer is no laughing matter, you're right about that.



STEVE:  It's funny, have you tried saying no and nodding?  It's amazingly difficult.



TOM:  It's hard.  Yeah, it's like patting your head and rubbing your tummy at the same time.  No.  You have to think about it.



STEVE:  Yeah, it requires a lot of deliberate override of what's natural.  Anyway, I loved that.  And here's another piece of information.  So he says no while he's nodding.  So, yikes.  At least...



TOM:  It's an elegant way to deliver a complex piece of information, which is usually in these cases, if you have been approached, the government then says you can't tell anybody we approached you.



STEVE:  Of course, yes.  And this was brilliant.  So hats off to him.  And further evidence of the pressure that manufacturers of pervasive systems, even something like this, I mean, the much-heralded open source, I mean, I don't know how he would do it if he chose to.  But of course he never would, so...



TOM:  No.  Good man.  I hope.



STEVE:  Changing the topic...



TOM:  Yeah, I was going to say, hopefully we've got one iOS7 security thing to talk about when we get to fingerprints later on in the show.  But there's other flaws.  Whenever there's an iOS update, there's always going to be flaws that surface.  And hopefully none of these have to do with the NSA.  What are they?



STEVE:  So, okay.  What intrigued me about these, I found three different problems that have been reported.  But from the standpoint of being a developer, and just sort of - problems have a feel.  It's one thing to have, like, an obscure buffer overrun in some library that was written 10 years ago, that if you dance in a full moon in the dark with touching your nose and send in a certain thing, this will happen.  That's one thing.  These feel different.  These feel like they are characteristic of a system which is getting overly complicated and is beginning to show its age.  And that's sort of sad.  I mean, these are mistakes that are a consequence of complexity.  And as we know, security and complexity are enemies of each other.  It is difficult for anything really complicated to also be secure.



And what unfortunately Apple has done is they have added feature on feature on feature on feature.  There are little pathways, little cracks through the system that they obviously didn't foresee.  So the first one is just kind of a - I get a kick out of, reported by a number of different people.  The Find My Phone feature, much heralded in iOS7, can be disabled by putting the device into Airplane mode.  Okay, well, that's not surprising because Airplane mode, of course, shuts down all communications because otherwise we're told we're going to crash.  Okay.  So the problem is in iOS7 this can be done when the phone is locked with a passcode, meaning not by its owner, but by a thief, as the voice-activated assistant, Siri, which is available by default while the phone is locked, can be verbally instructed to put the phone into Airplane mode.



TOM:  That's just one of those ones where they weren't - they thought, oh, well, putting it in Airplane mode, you should be able to do that.  That's not a security flaw.  Oh, wait a minute.  Yes, it is.



STEVE:  And then the problem is Siri is still accessible, as we will hear in the third one, which is another Siri accessibility problem.  She's accessible while the phone's locked.  So first thing the thief does is have Siri put the phone in Airplane mode for him, and now he doesn't have to worry.  Now he can attack the phone and not have to worry about Find My Phone being activated remotely.  It can't be, because it's disconnected.  Wow.



Now, this one, apparently there was a soldier who had a lot of time on his hands, and he was bored.  Maybe he was on guard duty.  Jose Rodriguez in the Canary Islands somehow worked his way through this little gem.  Anyone can exploit the bug by swiping up on the lock screen to access the phone's control center.  We'll be coming back to the control center later because I have a peeve of my own about that.



TOM:  I'm going to do this along with you.



STEVE:  So you swipe up on the lock screen to access the phone's control center.  And then opening the alarm clock, holding the phone's sleep button brings up the option to power it off with a swipe.  Instead, the intruder can tap Cancel and double-click the Home button to enter the phone's multitasking screen.



TOM:  So far so good.  It's working.



STEVE:  That offers access to its camera and stored photos, along with the ability to share those photos from the user's various accounts, essentially allowing anyone who grabs the phone to hijack the user's email, Twitter, or Flickr account.  And then people who wrote about this said:  "The far-reaching nature of this breach through the steps described above offer unfettered access to a user's photos and the sharing functions of those photos.  That includes access to social media accounts and emails.  And by selecting the option to send a photo by iMessage, it also allows complete access to the user's contacts, and all information stored therein."  So, I mean, this is just a classic mistake and then a wedge that pries open access to other parts that are needed in order for the first phase to function.



TOM:  I got into my App Store, too.



STEVE:  "Apple has reportedly acknowledged the mistake and pledged to rectify it in a later software update.  Until this gap is patched, users can prevent this from happening to them by disabling access to the Control Center on the lock screen. Go to Settings, then Control Center, then swipe the option to Access on Lock Screen so that it does not display on the lock screen."  So another little mistake.  It's like, oh, won't these features be nice.  But they do kind of combine in a way that wasn't expected.  Okay.



TOM:  There you go.  Off.



STEVE:  And finally, finally, this is an interesting one.  For pre-iPhone 5s devices, it's assumed, being upgraded to iOS7:  "If you have an iPhone 5 or older and have updated your operating system to Apple's new iOS7, you should be aware that the password or passcode required on your phone's lock screen no longer prevents strangers from accessing your phone."  No longer prevents them from doing it.  So this occurs after the upgrade.  "They can use Siri, the voice command software, to bypass the password screen and access your phone instead.  Simply hold down the Home button, even while the phone is locked, and wait for Siri to ask you what you want.  From there, we accessed Facebook, Twitter, text messages, email, and phone calls..."



TOM:  Really?



STEVE:  "...all on our iPhone 5."



TOM:  Really, Apple?  Really?



STEVE:  "We even got access to our contacts app.  Access is limited.  You can't see anything on the phone beyond the lock screen and the Siri interface, so you can't play Candy Crush" - oh, darn - "for instance.  But you can do a lot of important basic phone stuff on someone else's phone.  Email, calls, text, and social media are probably the majority of time spent in mobile phone use.  You can stop Siri bypassing your password by reducing access to Siri in the Settings.  Go to Settings > General > Passcode Lock [enter the passcode] > Allow access when locked > Siri > switch from green On to white Off."



TOM:  So this is an example of a default being in the wrong position.



STEVE:  Exactly.  Exactly.  Now, they say:  "Here's one theory:  On iPhone 5s, the new iPhone, access to the phone is through a fingerprint security device called Touch ID," which of course is the topic of this podcast, "which utilizes the Home button as the fingerprint detector.  Only the person who owns the phone can open it.  If you're running iOS7 on an iPhone 5s, it would be impossible to unlock the phone by pressing the Home button.  The problem is that, on earlier devices, pressing the Home button brings up Siri, not the fingerprint detector.  That would explain the non-obvious workaround inside the Settings section."



TOM:  I think they should make Siri be able to recognize the owner's voice.



STEVE:  Yes.  I was thinking the same thing.  It's like, eh, you don't sound like Jack.



TOM:  Right.



STEVE:  Now, I put this note in my show notes when it first popped onto my radar, middle of last week.



TOM:  This is funny.



STEVE:  And I didn't know whether we would be talking about it, say, not yet, or yes.  But for those who don't know, there is a fun website:  IsTouchIDHackedYet.com.  And of course it now offers the news, yes.  And in fact, what was really cool was that, when it initially appeared, people began posting donations for - pledging that they would offer the person who first hacked Touch ID, and again I say "spoofed," X amount of money.  And I remember seeing the figure $16,000 at one point.  I haven't added it up.  I don't know where it is.  There were some, even after it was shown to be spoofed, some thousand dollar donation.  So it's like, okay, well, that helps pay for the materials that were required.



TOM:  Yeah, no kidding.



STEVE:  Now IsTouchIDHackedYet.com says "Yes" and provides some background information and a list of all the nice sponsors who provided lots of money.



TOM:  That's great.  That's really funny.



STEVE:  Yeah.



TOM:  So what's Apple saying about Touch ID?



STEVE:  Right.  There is, naturally, there are various types of support pages.  There's the page that shows how to do it and how to use it.  There's also a support page in their knowledge base that sort of helps to put it into context, which is useful to share and provide some additional information.  I'm sure we're going to be learning incrementally more about it as time goes on.  They said:  "To configure Touch ID, you must first set up a passcode.  Touch ID is designed" - and this is crucial wording.  And this did exist prior to the spoof.  So this is Apple's pre-hack or spoof position, which is right.



They said:  "Touch ID is designed to minimize the input of your passcode; but your passcode will be needed for additional security validation, such as after restarting your iPhone 5s; when more than two days, 48 hours, have elapsed from the time you last unlocked your iPhone 5s; or to enter the Passcode and Fingerprint settings."  So they understand that in situations where maybe asking Touch ID to provide more security than it should, the phone will fall back to prompting you for your passcode.



Then Apple continues:  "Since security is only as secure as its weakest point, you can choose to increase the security of a four-digit passcode by using a complex alphanumeric passcode."  So here they're teaching us about switching to the full keyboard and using something long.  They say, skipping over that:  "You can also use Touch ID instead of entering your Apple ID password to purchase content from iTunes Store, App Store, and Book Store.  You will be asked to scan your fingerprint with each purchase.  If Touch ID does not recognize your finger, you'll be asked to try again.  After five failed attempts," and this comes up later today, "you'll be given the option of entering your Apple ID passcode.  In addition, you will need to enter your Apple ID passcode after restarting your iPhone 5s and enrolling or deleting fingers."



So they have backed it up with essentially requiring two-factor authentication in those instances where maybe you have less - they're trying to suggest things that a bad guy might do or you do infrequently or, for some reason, you haven't apparently had access to your phone for some length of time.  They're using the metrics they can to say, in this instance, give us additional confirmation that you're still you.  So that's certainly reasonable.



TOM:  Yeah.  And this is the thing that made me positive about Touch ID when I first heard the announcement was that they weren't switching over to say, we're relying entirely now on your fingerprint for access to the phone, which would have been a horrible thing.



STEVE:  Right, right.



TOM:  Now, what about where they store my fingerprint?  That's getting a lot of attention, a lot of discussion.



STEVE:  Yeah.  And we don't know enough.  I mean, this is where Apple ID - I'm sorry.  Apple ID.  Apple is generally more secretive than I would like about security.  Apple is not open to the degree that other companies are.  So they're not telling us yet.  I expect over time - this is what I mean by we'll be learning more.  They end this page by talking about what they call the "Secure Enclave."  So they have their own term.



TOM:  Wow.



STEVE:  Touch ID, they say, "does not store any images of your fingerprint.  It stores only a mathematical representation of your fingerprint.  It is not possible for your actual fingerprint image to be reverse-engineered from this mathematical representation."  That's all good, and this is what I conjectured a couple weeks ago when I was talking about the topology of features.  "iPhone 5s also includes a new advanced security architecture called the Secure Enclave within the A7 chip, which was developed to protect passcode and fingerprint data.  Fingerprint data is encrypted and protected with a key available only to the Secure Enclave.  Fingerprint data is used only by the Secure Enclave to verify that your fingerprint matches the enrolled fingerprint data.  The Secure Enclave is walled off from the rest of A7 and as well as the rest of iOS.  Therefore, your fingerprint data is never accessed by iOS or other apps, never stored on Apple servers, and never backed up to iCloud or anywhere else.  Only Touch ID uses it, and it cannot be used to match against other fingerprint databases."



So a couple things.  Because of where we're going to go with our next story, it's interesting and key that it is not backed up to iCloud, they say.  And I will say, what they described is entirely possible from a pure architectural standpoint.  It is certainly possible to create essentially an environment where you can send in, that is, you have a write-only ability to send in fingerprint enrollment data, and no ability to read it.  So it's write-only for enrollment.  And similarly it is submission-only for a candidate to ask about matching.  And what you get out is just go, no go.  That is, it just says yes, this matches sufficiently; or, no, it doesn't.



So, I mean, this is all good news.  They're not storing prints, so they're not in there anywhere.  They're storing structural information, the so-called - again, I'm hypothesizing - some topological representation of features which have been found.  And they're storing it in a custom-designed, not just saying, I don't know, like not having a software in iOS that has set aside some chunk of EPROM somewhere.  This is hardware on the chip, designed for this data to live there, such that you can only send fingerprint image data in.  You can only say "learn this" or "compare this."  And so this is all good news.  I think they've done the right thing.  And significant that it's not backed up.  It cannot come out.  It only goes in.  So...



TOM:  Isn't there a networking security system like that where you can only send in on one channel, or one cable, or one connection, and out on a - there's an entirely separate one?



STEVE:  Yeah.  In fact, we've talked about that a couple times.  Ethernet itself, the actual physical wiring, is one twisted pair that goes in one direction, transmitting, and a different twisted pair that goes in the other direction, receiving.  And there are systems, cables you can actually make, there are even little connector boxes that deliberately drop the other direction.  So you electrically cannot send data in the other direction.  And there are even fiber optic links where you've got a photo diode and a photo receptor and a piece of plastic in between, and there just isn't any way for data to go...



TOM:  That's the one I remember you talking about.  I think that's the one I'm thinking of right there, the fiber optics system.  That's really cool.  GeekCanuck says he's going to start making rainbow tables for fingerprints.  Do you think that would get him anywhere?



STEVE:  Rainbow tables.  I don't think so.  Okay.  So we don't know exactly, we don't yet have details on what they're looking at.  There are sort of two levels of features in fingerprints.  The so-called "minutiae," and that's actually the term they use, the "minutiae," are sort of the subfeatures, like broken ridges or sort of ridges that merge, or ridges that form a little disconnected island, where...



TOM:  So kind of the imperfections, huh.



STEVE:  Yeah, they are.  Now, the larger details are what we normally see if you just, like, looked at your fingerprint on a glass.  You would see humps, and you would see what's called a "whorl," is where the ridge goes out and kind of does a loop and then goes back the same direction it came from.  So you have this ridge reversing course and going off the fingerprint, back where it came from.  You have other ones that just go up and then sort of come back down and continue going off in the same direction.  And then you have some that are just not connected to the edges of the fingerprint in any way, sort of at the top level.  And we don't really know exactly what they're doing.  But the articles we'll be covering here toward the end of the podcast give us some sense for what was necessary in order to defeat it.



TOM:  Yeah.  All right.  Our last main story here in the news, when I read the headline, it kind of threw me.  And then when you read the story you start to realize, well, maybe I should have guessed this.  "Google knows nearly every WiFi password in the world?"



STEVE:  Yup.  Now, and this is - what's interesting is this is even not news.  I mean, this is not startling except in the context now of post-Snowden era.  As far back as in June of 2011, a guy named Donovan Colbert, writing for TechRepublic, describes stumbling across this fact on a new ASUS EEE PC Transformer tablet.



So back in June of 2011 he wrote the following:  "I purchased a new ASUS EEE PC Transformer tablet last night after work.  I brought it home, set it up to charge overnight, and went to bed.  This morning when I woke I put it in my bag and brought it to the office with me.  I set up my Google account on the device and then realized I had no network connection.  So I pulled out my Virgin Mobile Mi-Fi 2200 personal hotspot and turned it on.  I searched around Honeycomb" - which of course that was the version of Android, right, back then on the tablet? - "looking for the control panel to select the hotspot and enter its encryption key.  To my surprise, I found that the EEE Pad had already found the Virgin hotspot and successfully attached to it.



"As I looked further into this puzzling situation, I noticed that not only was my Virgin hotspot discovered and attached, but a list of other hotspots were also listed in the EEE Pad's hotspot list.  The only conclusion that one can draw from this is obvious:  Google is storing, not only a list of what hotspots you have ever visited, but any private encryption keys necessary to connect to those hotspots.



TOM:  Which does all make sense.  Google keeps a profile for you to make it easy when you turn on a new Android device and load all of your settings.



STEVE:  Exactly.



TOM:  Why wouldn't your WiFi password be one of those things?



STEVE:  And that is going on to this day, two years later, more than two years later.  And thus the genesis of the headline, "Google knows nearly every WiFi password in the world."  They're saying with the massive number of Android devices which are backing themselves up to Google's Cloud, and the default setting is to back up the settings of the device, and that includes your list of known-to-that-device previous hotspots and the encryption keys for them, those are up there.  And we also know that you can, if you attach a new device, it will automatically - and synchronize to the Google Cloud, it's automatically configured with that information.  So what we now know is that Google has that stuff, and Google has the ability to decrypt it.  And the NSA has the ability to ask Google for that, if they want it.



TOM:  Well, and that's the key; right?  Because you can also phrase this story "Google knows every email in the world" because there are so many Gmail addresses that they probably know a large percentage of the email because they're either being sent to or sent from Gmail accounts.  And you can make a similar argument about documents.  It all pretty much hinges on client decryption, which is what happened when he set up his PC Transformer, he put in his password, how secure that is, and whether Google can get into your private profile and hand it over to somebody if somebody comes knocking with a subpoena.  Or not, in some cases.  They don't even need them.



STEVE:  Well, actually we do know that they can.  We know that they're now boasting good physical datacenter security and good encryption in the datacenter, but that they can remove it.  I mean, they have access to our data.  And many people have verified that through clever tests of changing their password before synchronizing, and then Google finds them and synchronizes.  So it wasn't using their password, blah blah blah.  So we understand that our link to Google is encrypted.  But once there, we're now depending upon their encryption, which they have the ability to break, being strong.  And of course the integrity of all the employees who have access to our data.



TOM:  Right, of course.  There are Snowdens on all sides of the equation.



STEVE:  Uh-huh, yeah.



TOM:  So you have your own list of iOS7 errata, things you think Apple should publish? 



STEVE:  Yeah.  Like Sarah, I ordered my phone very late in the morning, or, wait, very late in the night, early in the morning, actually, shortly after midnight.  I'm just getting a black one, but they said they'd ship it sometime next week.  So it's like, I'm not desperate for it.  But all my other iOS devices are switched over to 7.  And one of the things that I do often, have always done in the old days, pre-7, I'd lift the screen up and then slide to the left to get the control panel.  And I would adjust the brightness because - and I find I do it several times a day because the auto adjust is useless to me.  It never seems to - I thank them for trying, but they don't seem to know what I want.



So I'm manually adjusting the screen.  And sometimes it's glaringly bright, so I'll bring it down.  Sometimes I'm out in the sunlight or in a lighter setting, and so I crank it all the way up.  But it's something I'm doing all the time.  So but I immediately recognized there was a problem because of course the new way is, from any screen, you drag up from the bottom, and up comes a handy control panel.  Unfortunately, to make it more visible, Apple dims the rest of the screen, and the panel itself is not very bright.  So in raising the control panel where the brightness setting is, they're dimming the screen so I can't see how bright the setting is I'm trying to make.  And I was reminded of - you're probably old enough, Tom, I hope, to remember pre-remote controlled TVs.



TOM:  Oh, yeah.  I was the remote control.



STEVE:  You'd be sitting on the couch across the living room from the family's TV screen, and the volume would be too low.  So you'd get up and go over there to turn the volume up.  But now you're standing at the TV, and so of course it's louder.  So you adjust the volume, then you sit down, oop, now it's too loud.  So you get up again and turn it down.  So my point is, of course, where you're sitting, you can't adjust the volume, and when you get there, it's different.  Similarly, you can't change the brightness on the iPad without it changing the brightness for you so you can't tell what brightness you're going to have once you're through changing the brightness.



TOM:  And you can't use the hack that Bill Merritt used, which was to tell his son Tom to go change the volume without him getting up from the couch.  That's no way to do that with your phone.



STEVE:  Exactly.  Okay.  A little louder, Tom.  Oh, a little - okay, that's just perfect, yeah.  Okay, now, the other thing that occurred to me, actually it has been a problem for me, is - and I worried about the TWiT studio - is the local bandwidth congestion on one's network of having multiple iOS devices in the house with the auto app update turned on.  A couple days ago I was unable to watch you guys live.  It was pausing constantly.  And I was getting a little spinning disk, and then it would try again, then it would pause.  And I thought, what is going on?  Because, I mean, I'm the master of my domain.  I know what's happening all the time here.



And so I closed the stream from you guys and looked over at my router.  And I've got a big iron Cisco industrial router.  And normally the activity light flickers routinely because I have a live connection to GRC's servers, and I have a protocol that I developed for synchronizing, like when we hear "yabba dabba do" here it's because I'm sending UDP packets querying for a status update, and they come back through the multiple layers of NAT that way to get to me.  So there's a little constant activity.  I know what my network looks like.  And this thing, the light was on hard solid.  And I thought, what is going on?



So I fired up my packet sniffer.  I saw a huge amount of TCP traffic going to one IP.  It was somewhere in Englewood, Colorado, the network where it terminated.  I didn't have a clean lookup, a reverse.  And I thought, you know, I'll just bet it's my iPads because I have a couple of them and an iPhone here, all that are cruising.  And sure enough, I shut them down, network went back.  And then I was able to listen to you guys without any trouble.  And I then, because it just sort of annoyed me, turned off auto update on all of those.  You go into the iTunes Store setting over in the left-hand column, and there's an option for things that update.  You can turn off auto update.  I'm just going to switch back to, first of all, allowing them to accrue for a while, and then updating my master copy of iTunes on a Mac, and then synchronizing the pads to get the most recent app.



And so here was my concern was that it's one thing for me to have my little network disturbed by a couple iOS devices.  I can't imagine the TWiT studio with everyone there having a phone, and suddenly Elements, which is like a gig-plus, decides it needs to update on all of them.



TOM:  Oh, yeah. 



STEVE:  So I'll mention this to Leo, too, just to be aware that it could really warp the bandwidth of the TWiT studio.



TOM:  And it could do that in any kind of large situation.  I thought immediately of universities because I remember when the iPhone first came out, and it was always trolling for WiFi access points.  Some sysadmins at universities got upset about that.  This is much worse than just looking, pinging the access point.  This is, like you say, in some cases large amounts of data getting downloaded.



STEVE:  I mean, most of the time.  And we know how rapidly these apps are being updated.  They're constantly being updated.  And if you're like me and Sarah, and the app count you've lost control of, there's just a lot happening.



TOM:  What's your most hated UI change?  This is interesting.



STEVE:  Pure gripe.  It turns out that I use the app history all the time.  So I would, again, I would lift up the screen using a four-finger swipe, and there in order of reverse chronological recency are the icons of all the apps I've used, however many could fit across the bottom.  And then if I needed to go back further, I'd scroll to the right in order to get the next most old ones.  And of course I know the icons perfectly.  I know what every one of them is.  So of course what Apple has famously done is they've screwed that up completely.  Now when you do that you get big thumbnails of the last screen state of each of these, and then the icons are widely spaced out.  So that if you get, like, three, one in the middle and two on the edges, because they've been forced apart by the size of the thumbnail that is hovering over them, it's just - it's a catastrophe for me.  I mean, it's, like, just disastrous.  So...



TOM:  You know what bothered...



STEVE:  I hate it.



TOM:  You know what bothered me the most about it is a lot of times I'll just close all of those, right, as a way to track down a particular battery drainer usually.  And now you've got to swipe the screen away, that little freeze frame of the screen state that you were talking about.  That's so much slower than just having them all jiggle and then tap tap tap tap tap and get rid of them.



STEVE:  Yup.  Yup.  In fact, I'm glad that Sarah showed that on the show, where you can, while you're looking at that history view, you can drag the big thumbnail screen up and off the top, and it goes away.  So it's at least one way of closing apps, and also contracting your history again.  But I'm really, I mean, this is - I don't know how I'm going to get used to this because I feel like being able to see whatever it was, like 7 on an iPad, I mean, there's like - everything that I had been doing, I could just quickly jump back to.  And yes, you can do the four-finger swipe sideways to kind of go back in time.  But it just was so easy to quickly lift the screen and say, oh, that's the one I want; and, bang, I was there.



TOM:  Yup.



STEVE:  I've lost that now.



TOM:  It's just not as convenient.  I use that a lot, too.  I haven't noticed it being a big problem because usually the one I want is close.  It's not very far away.  So I always had to swipe maybe a couple of times anyway.  But, yeah, I know what you mean.  On to the miscellany, then?



STEVE:  Yeah.  I mentioned a few weeks ago the TV series "Orphan Black."



TOM:  Mm-hmm, big fan.



STEVE:  Yes.  And I'm through with the first - I'm halfway through.  I'm through with the first of two disks because I got it on Blu-ray.  And I just wanted to say that I'm stunned that that's one actress.



TOM:  I know.  She is incredible, isn't she.



STEVE:  That's, yes, that's what I come away feeling.  I mean, overall, it's a nice series, I mean, it's interesting.  I like it.  It's just like sort of a good procedural thriller.  But for me, what stuns me is that she isn't actually cloned.



TOM:  Right.



STEVE:  I mean, it's like the parts she plays are phenomenally different from each other.  Sometimes a little overboard, like to make them distinct.  But believable.  But as I'm looking at these people, I'm having to remind myself, this is actually the same person because she does just an amazing job.  And I don't think it's just hair and makeup.  I think it's she becomes these different people.  So that's what, for me, that's the most fascinating part of the series, which is it's just amazing.



TOM:  I remember watching that first episode and thinking, okay, they're visually different, but how long can she really keep these characters separate?  And she really - you forget.  You forget while you're watching it that it's Tatiana Maslany, or however you say her name, I apologize, Tatiana, is doing all of those parts.  I agree.  She's incredible.



STEVE:  So I also wanted - we've mentioned on the podcast several times the TV series "Homeland," of which Leo and I are both huge fans.  I'm, like, a hyper fan.  I just - it was so good the last two seasons.  I'm hoping they're able to keep it going.  But it does...



TOM:  Were you happy when Claire Danes got her Emmy?



STEVE:  Yes.  Yes.  I mean, she does a fabulous job, also.  And I just - everything about it I really enjoy.  And I wanted to make a note that it returns to the air this coming Sunday for our listeners who don't already have systems set up to capture it.



And then this is just completely random, but I just - this happened this morning when I was putting the show together, and I just thought, you have got to be kidding me.  I've always had my domains at Network Solutions.  That's, you know, back in the day they were the guys.  They were where you got domains.  I mean, we registered GRC.com at the same time that Microsoft registered Microsoft.com.  I mean, I've had the domain that long.  And so there wasn't all these alternatives.  So, and inertia has kept me there, and it's a pain to move everything, and I've got a bunch of stuff there.



Anyway, they've recently just been spamming me with marketing propaganda.  I mean, it's really getting to be annoying.  And then this morning was - I just looked at it, I thought, no, no, no, no.  A domain that I have, I got a free registration for it in .biz for one year, $0.  And I thought, first of all, I thought, what?  It's like, I was confused.  Was my account hacked somehow?  Did somebody register this for me?  Or like, what, what, what?  Then I realized what this is.  It is pure bait and switch.  It is we're going to give you an existing domain in the .biz top level at no charge for a year, hoping you will use it.  Because then you're stuck.  And I just want to flip them the bird and just say, you know, that is just slime.



TOM:  I moved all of my domains with concierge service.  And they're not a sponsor of this particular show.  They are a sponsor on the network, but Hover, you just call them up.  You tell them your domains.  They do all the hard work for you.  And then you do all the confirming and everything, so it's secure.  But that was nice.



STEVE:  Yeah.  I just looked at this, it's like, you've got to be kidding me.



TOM:  Yeah, that's annoying.  That's super annoying.  So you're working on a ton of stuff.



STEVE:  Oh, boy, I am.  So I just wanted to give our listeners a - I finished the work on this first phase of the SpinRite R&D.  We have full pre-AHCI support, which was the PCI Ultra DMA controllers, which virtually everybody has in their machines for the last couple years, although the newer machines have their motherboards set to AHCI, which is the next-generation controller.  That's the next thing I'm going to support.  What's somewhat amazing is that we achieve 100% success on all controllers that anyone in the newsgroups, and we have hundreds of people have tested this on hundreds of machines, have in their possession.  Many AHCI controllers turn out to do double duty, and so we already work with those, and many RAID controllers.  We're now able to penetrate what I call "thin RAID," where it's a RAID feature, but it's actually just a bunch of disks, and the software provides the RAID functionality.  And so it calls itself RAID in the system.  We run on all of its drives.  There was only one true, apparently true RAID by HighPoint Systems, where at this point we're unable to operate on.  And we may be, once we add AHCI support.



And we're getting stunning performance.  Because I built my own extended real-mode operating facility, essentially, that I talked about once before, and my own extended memory manager into this technology, so we're in real mode, running DOS, yet we have access to all of the machine's memory.  We only need 32MB, but that's vastly larger than the buffer we were using before.  It's the largest buffer drives can use.  But that's getting us, on a Level 2 fast recovery scan, we're seeing, like, 93 minutes per terabyte.  So now multi-terabyte drives can be scanned and data recovery performed on them in a couple hours.  So that's really going to be very cool.  And of course, as I've said, I've committed, a free upgrade to all of this for current 6.0 owners.



At this point now I've stopped work on that because I am frantically, feverishly, fervently working on documenting the identification authentication system that I've come up with.  And I'm going to try to have that as our topic for next week, Tom.



TOM:  Great.



STEVE:  I think I probably can.  Because I know that I've piqued everyone's curiosity, to say the least.



TOM:  Yes.



STEVE:  It's holding up.  I've got pages now of clear documentation and diagrams.  And I've thought things through all the way, which is what I was wanting to do, but I wasn't letting myself really spend the time until I got SpinRite, this first phase, nailed down.  And it's looking good.  So I think that'll be the big reveal a week from now.



TOM:  So no Q&A next week?  We push that off one?



STEVE:  I'm willing to for this.



TOM:  Nice.  I'm excited about this.  I can't wait to hear about it.



STEVE:  And I'd love to do it with you, and then I get to do it with Leo again the next week.  So that's...



TOM:  Oh, yeah, there you go.  Perfect.  Everybody wins.  All right, Steve.  Let's get into Touch ID.  Let's get into fingerprints.  First of all, there have been some cool hacks.  What are these hacks that people have been doing?  I love the Chaos Computer Club one, frankly.



STEVE:  Yeah.  Well, okay.  They're basically one, that is, there is one way to do this.  And so I want to share the "nanny, nanny, nanny" posting, which I've edited a little bit just so that it reads better on the podcast.  And this was the original claim that was met with some skepticism until a good video was being made.  There was some concern that the video wasn't really very good.  And I'll make a couple comments about that whole notion, too.  But this is sort of the - I want to show both sides to this coin.  These are the guys who think fingerprints are an absolutely bad idea, period, and you'll certainly get that sense from them.



So this is the official statement from the Chaos Computer Club, who were the first people to spoof Apple's Touch ID.  They said:  "The biometrics hacking team of the Chaos Computer Club (CCC) has successfully bypassed the biometric security of Apple's Touch ID using easy" - we'll see about that - "everyday means.  A fingerprint of the phone user photographed from a glass surface was enough to create a fake finger that could unlock an iPhone 5s secured with Touch ID.  This demonstrates again, they say, that fingerprint biometrics is unsuitable as an access control method and should be avoided.  Apple had released the new iPhone with a fingerprint sensor that was supposedly much more secure than previous fingerprint technology.  A lot of bogus speculation about the marvels of the new technology and how hard to defeat it supposedly is had dominated the international technology press for days."  Okay, well, I didn't see that, but I also wasn't looking for it.  But I will take their word for it.



TOM:  I don't know about dominated, but it certainly was talked about.  I'll give them that.



STEVE:  Yeah.  Starbug, who performed the defeat, said:  "In reality, Apple's sensor is just a higher resolution compared to the sensors so far.  So we only needed to ramp up the resolution of our faking technology.  As we have said now for" - actually it says "for more many years" - "for many years, fingerprints should not be used to secure anything."  These are the anti-fingerprint people.  "You leave them everywhere.  And it is far too easy to make fake fingers out of lifted prints."



Okay, unquote.  So back to the announcement.  "First, the fingerprint of the enrolled user is photographed with 2400 dpi resolution. The resulting image is then cleaned up, inverted, and laser-printed with 1200 dpi onto a transparent sheet with a thick toner setting.  Finally, pink latex milk or white wood glue is smeared into the pattern created by the toner onto the transparent sheet.  After it cures, the thin latex sheet is lifted from the sheet, breathed on to make it a tiny bit moist and then placed onto the sensor to unlock the phone.  This process has been used with minor refinements and variations against the vast majority of fingerprint sensors on the market."  We'll talk about all this in detail, what they were achieving with this, in a second.  But then they posted an update:



"The process described above proved to be somewhat unreliable as the depth of the ridges created by the toner was a little too shallow.  Therefore, an alternative process based on the same principle was utilized and has been demonstrated in an extended video available.  First, the residual fingerprint from the phone is either photographed or scanned with a flatbed scanner at 2400 dpi. Then the image is converted to black & white, inverted, and mirrored.  This image is then printed onto a transparent sheet at 1200 dpi.  To create the mold, the mask is then used to expose the fingerprint structure on photo-sensitive printed circuit board (PCB) material.  The PCB material is then developed, etched, and cleaned.  After this process, the mold is ready.  A thin coat of graphite spray is applied to ensure an improved capacitive response.  This also makes it easier to remove the fake fingerprint," so the form's mold release.  "Finally, a thin film of white wood glue is smeared into the mold.  After the glue cures, the new fake fingerprint is ready for use."



So Frank Rieger, spokesman for the CCC, who posted this, quoted himself, saying:  "We hope that this finally puts to rest the illusions people have about fingerprint biometrics.  It is plain stupid to use something that you cannot change and that you leave everywhere every day as a security token.  The public should no longer be fooled by the biometrics industry with false security claims.  Biometrics is fundamentally a technology designed for oppression and control, not for securing everyday device access."  Interesting.  Anyway, continuing...



TOM:  I suppose he has a perspective.



STEVE:  Yeah.  "Fingerprint biometrics in passports has been introduced in many countries despite the fact that by this global roll-out no security gain can be shown.  iPhone users should avoid protecting sensitive data with their precious biometric fingerprint, not only because it can be easily faked, as demonstrated by the CCC team.  Also, you can easily be forced to unlock your phone against your will when being arrested.  Forcing you to give up your hopefully long passcode is much harder under most jurisdictions," that is, the difference between something you have and something you know, and we'll be talking about that here at the end, "than just casually swiping your phone over your handcuffed hands.  Many thanks go to Heise Security team which provided the iPhone 5s for the hack quickly.  More details on the hack will be reported here."  So that's the statement from the people who say this is all dumb.



Now, Marc Rogers also defeated this, but he's a little more forthcoming about what it took.  And he posted a blog posting titled "Why I Hacked Apple's Touch ID and Still Think It Is Awesome."  So Marc wrote:  "By now, the news is out  Touch ID was hacked."  And of course, again, I say "spoofed."  This was a spoofing attack.  We have the word.  It's the right word.  "In truth, none of us really expected otherwise.  Fingerprint biometrics use a security credential that gets left behind everywhere you go, on everything you touch.  The fact that fingerprints can be lifted is not really up for debate.  CSI technicians have been doing it for decades.  The big question with Touch ID was whether or not Apple could implement a design that would resist attacks using lifted fingerprints, or whether they would join the long line of manufacturers who had tried, but failed, to implement a completely secure solution.



"Does this mean Touch ID is flawed and that it should be avoided?  The answer to that isn't as simple as you might think.  Yes, Touch ID has flaws; and, yes, it's possible to exploit those flaws and unlock an iPhone.  But the reality is these flaws are not something that the average consumer should worry about.  Why?  Because exploiting them was anything but trivial.  Hacking Touch ID relies upon a combination of skills, existing academic research, and the patience of a crime scene technician.  First, you have to obtain a suitable print.  A suitable print needs to be unsmudged and be a complete print of the correct finger that unlocks a phone.  If you use your thumb to unlock it, the way Apple designed it, then you are looking for the finger which is least likely to leave a decent print on the iPhone.



"Try it yourself," he writes.  "Hold an iPhone in your hand and try the various positions that you would use the phone in.  You will notice that the thumb doesn't often come into full contact with the phone; and, when it does, it's usually in motion.  This means they tend to be smudged.  So in order to hack your phone, a thief would have to work out which finger is correct and lift a good clean print of the correct finger.  



"Next you have to" - and he has in quotes - "'lift' the print."  Oh, and I've made a little editorial comment here.  The Chaos Computer Club article rather glibly glosses over this next part because Marc writes:  "This is the realm of CSI.  You need to develop the print using one of several techniques involving the fumes from cyanoacrylate" - superglue, commonly known - "and a suitable fingerprint powder before carefully and patiently lifting the print using fingerprint tape.  This is not easy," says Marc, who has done it.  "Even with a well-defined print, it is easy to smudge the result, and you only get one shot at this.  Lifting the print destroys the original.



"So now what?  If you got this far, the chances are you have a slightly smudged 2D print stuck on a white card.  Can you use this to unlock the phone?  This used to work on some of the older optical readers, but not for many years now" - because they've gone capacitive, and we'll talk about that in a second - "and certainly not with this device," meaning the iPhone 5s.  "To crack this control you will need to create an actual fake 3D fingerprint" from this 2D image.  Creating the fake fingerprint is arguably the hardest part and by no means easy.  It is a lengthy process that takes several hours and uses over a thousand dollars' worth of equipment, including a high-resolution camera and laser printer.  First of all, you have to photograph the print, remembering to preserve scale, maintain adequate resolution, and ensure you don't skew or distort the print."  All very good points which CCC didn't mention.



"Next, you have to manually edit the print to clean up as much of the inevitable smudging as possible.  Once complete, you have two options."  He mentions the CCC method:  "Invert the print in software, print it onto a transparency film using a laser printer set to maximum toner density, then smear glue and glycerol on the ink side of the print and leave it to cure.  Once dried you have this thin layer of rubbery dried glue that serves as your real print."  Okay.  And but then he says that apparently he was the user of the more elaborate approach.



He says:  "I used a technique demonstrated by Tsutomu Matsumoto in his 2002 paper, 'The Impact of Artificial "Gummy" Fingers on Fingerprint Systems.'  In this technique, you take the cleaned fingerprint image and, without inverting it, print it to transparency film.  Next, you take the transparency film and use it to expose some thick" - and he goes back through the whole PC board routine, exactly as the CCC guys posted in their update.  So Marc winds up saying:  "Using fake fingerprints is a little tricky.  I got the best results by sticking it to a slightly damp finger.  My supposition is that this tactic improves contact by evening-out any difference in electrical conductivity between this and the original finger.



"So what have we learned from all this?  Practically, an attack is still a little bit in the realm," he says, "of a John le Carr novel.  It is certainly not something your average street thief would be able to do; and, even then, they would have to get lucky.  Don't forget, you only get five attempts before Touch ID rejects all fingerprints from then on, requiring a PIN to unlock it.  However, let's be clear:  Touch ID is unlikely to withstand a targeted attack.  A dedicated attacker, with time and resources to observe his victim and collect the necessary data, is probably not going to see Touch ID as much of a challenge.  Luckily, this isn't a threat that many of us face.



"Touch ID," he concludes, "is not a 'strong' security control.  It is a 'convenient' security control.  Today, just over 50% of users have a PIN on their smartphones at all.  And the No. 1 reason people give for not using the PIN is that it's too inconvenient.  Touch ID is strong enough to protect users from casual or opportunistic attackers, and it is substantially better than nothing."



So I liked that because I think that really puts this into context, which is what we need.  I would argue that having something that is very good, but not perfect, then allows you to use a much stronger passcode because you need to use it much less.  You don't need to use it every time you turn your phone on, every time you unlock it to get access to it.  That's the annoying thing.  You only need to use it in those instances where the phone feels, oh, it's time for me to make sure this is the same person.  And that's infrequent enough that you can afford that one to be much more burdensome.  And that's going to be what most people who try to hack this and fail a couple times, or five times, and then it's game over, with all the other caveats.



So anyway, this is why I'm still a fan of this technology.  I think in terms of real-world use, if this moves from 50% unlocked iPhones to 100% some lock, and frankly a very good lock in most cases, then this is a huge step forward for Apple.



TOM:  I think a lot of people are getting caught up in the semantics of this; right?  I mean, I actually think Marc Rogers is making it sound more complicated than it is.  I think if someone really put their mind to it, they could probably do this.  Not that any of us have cyanoacrylate just laying around the house.  So it's a fair point that this is not easy.  And I think the Chaos Computer Club tried to make it sound a lot easier than it was, too.  But really to me that's not even the most important part, is this easy, is this hard.  The most important part is the point you get to at the end, which is how often is it really going to be taken advantage of?  How likely is it that some, like you say, like a casual thief is going to go to the trouble to do all of this?  More likely they'd just make you unlock it before you hand it over to them.  Right?



STEVE:  Well, precisely.  Yes.  And, I mean, one thing to remember, too, is that, if there's a weakness, it's that, I mean, anybody who really wants security will use a really long passcode.  Period.  I mean, that's what they will do.  Or they'll use Touch ID until they start - until they do a border crossing, because now we're seeing stories about devices being confiscated at international border crossings.  And it's like, okay, so you turn off your fingerprint, and you only use your super long passcode there.  And then, once you regain control, you switch back.  So it's worth planting in people's minds that it is subject to that because, at the border crossing, you can imagine a situation where some authority says, "Put your finger on your phone."  And if you haven't turned it off, you could arguably be compelled to do that.  Whereas something you know that's in your head is much more difficult for you to be compelled to disclose.  And recent appellate court decisions have ruled that it's against the law to force, to compel someone to incriminate themselves under the Fifth Amendment of the Constitution.



TOM:  Unless you're at the immigration checkpoint.



STEVE:  Yeah.



TOM:  Yeah.



STEVE:  Yeah.  So I guess I think this is good news.  I think the key is for people to use it with an understanding of its limitations.



TOM:  Exactly.



STEVE:  It's funny, as you were talking, I was thinking, the scenario that I could imagine, although I don't think it likely, is for some reason some whiz kid wants access to his parents' iPhone, which for some reason they don't give.  Because he's a whiz kid, his parents are leaving fingerprints all over the place...



TOM:  He's like, I know where the super glue is.  I've got some cyanoacrylate.



STEVE:  And Dad left a nice perfect thumbprint on the whiskey glass last night.  I'm going to dust that and lift it.  I mean, maybe just for kicks to see if he can do it.  But, I mean, I really do, I mean, for example, making sure that the photo is square on, that it is 1:1 scale, that's obviously critical.  That it isn't - that there's no trapezoidal distortion in either way.  I mean, I could see that it would take something to make this work.  And because this is capacitive, because it actually senses the presence or absence of substance over the sensor, that's what that means, as we were talking about it before.  It's actually, it's the 3D-ness of the ridges of your finger that this thing is sensing, in the same way that a stud finder is able to find a wood stud behind the wall.  But what's happening is it puts out a capacitive feel, an electrostatic field, and the so-called dielectric constant changes, depending upon whether there's air or a solid there.



Similarly, when you put your finger on the sensor, there is air where you've got ravines in between the ridges, and this sensor is able to sense that it is a change in capacitance from that to where the skin is in contact, just like a stud finder that people have been using for decades.



TOM:  In that Chaos Computer Club video, if I'm seeing it right, they just wrap the fake fingerprint around a real finger; right?



STEVE:  Yeah.  



TOM:  That's all they needed to do.  You don't need to make a fake finger.



STEVE:  No.



TOM:  Just wear it.



STEVE:  You just end up with like a little snakeskin sort of very thin thing.  But it's got - and the whole idea of using toner was that toner is 3D.  And you can feel, if you, like, rub your fingers on a Xerox copy that uses toner, you can feel that it is 3D.  And so that's what they  need was they needed to create, turn the image from a two-dimensional to a raised event.  And so the whole concept of going to the PC board is there you have a printed circuit board, is a much thicker layer of copper than the toner is thick on paper.  So they use the image to photo etch the copper away so you end up with raised copper, which is more raised than toner.  Then you smudge the insulating material, the glue or latex, into that.  And then when you peel that out, you've got an image of the fingerprint in relief, essentially, thanks to this little printed circuit board.



So, yeah, it can be defeated.  But, boy, I think both locking it, five times to lock - and it'd be nice, frankly, if Apple turned that number down, or if that were user controllable.



TOM:  If that were - yeah, exactly.



STEVE:  I'd set that to one.  If it proves to be reliable enough, if you don't get it the first time, sorry, enter your passcode.



TOM:  Yeah.  And that way, if somebody says we're going to force you now, you're at the border, you don't have Fifth Amendment rights right now, put your finger on that, you put the wrong finger on it.



STEVE:  Yes.



TOM:  Oh, sorry, I messed up.  I thought it was my right hand, it's my left hand.



STEVE:  And, oh, my god, and you know, I haven't had to use my passcode for so long, I've forgotten it.



TOM:  Can't remember what the passcode is, yeah.  No, exactly.  I think this is really important because people - and it's fun.  I understand people are getting caught up into, like, well, how difficult is this, and could I do it myself, and is it possible that this is easier than, like, trying to attach some kind of bot to the phone and crack into the passcode.  Those are all fair exercises.  But in the end...



STEVE:  Why do people climb mountains?



TOM:  Yeah, exactly.



STEVE:  Why do people climb mountains?  Because it's there, and they want to look around from the top.  And it's like, okay, here's a high-volume consumer fingerprint scanner.  Let's find out what it takes to crack it.



TOM:  And I'm glad they did.



STEVE:  I am, too.



TOM:  Because now I know, okay, that's how much I could rely on that sensor.  I'm not going to - and you know what, this informs my use of my phone, too.  It also informs what I'm going to allow to be stored on that particular computer, and what connections it's going to make.  Because you know it has that level of security.



STEVE:  Right.



TOM:  So it's all good stuff.  Well, Steve, thank you.



STEVE:  And if it's easy to turn it off, then you could do that intelligently.  If you understand that your phone has valuable data, while it's really in your control, you get the convenience of using your thumb or whatever finger you choose.  When it might have, for some reason, you have less control over it, then you could just turn that off and just fall back to your really long passcode.



TOM:  You mentioned it earlier in the show.  How much more secure is this than a house key?



STEVE:  Yes, exactly.  I mean, that's the other thing we forget, is that a house key is actually not very secure.  It exists in the physical world.  Some guy has to be there at your door trying keys.  But it's like a fun experiment is it's often the case that somebody else's, one of somebody else's many keys will unlock your front door because statistically there just aren't that many of them.  So again, the idea is this probably has, well, Apple is claiming a one-in-50,000 false positive rate.  So, and they actually get their statistics a little bit wrong because they believe that that means that after 50,000 tries you'll succeed once or something like that.  I can't remember exactly what they said, but it's like, okay, that's not quite the way statistics works, Apple.  But still, the idea being it's very unlikely that a stranger's fingerprint is going to also unlock your phone.  And that does the job.



Just like it's very unlikely that a specific person's key is going to unlock the front door.  But you get enough people together, and the chances are that someone's key will.  And actually, you also have the problem with the birthday attack.  If you've got a bunch of people together, the chances are very good that someone, any pair of someone's front door and someone's keys could be unlocked. Similarly, if you got a whole bunch of people together with their phones, and everybody tried everybody's phone, then the birthday attack statistics come into play, and it becomes, again, much more likely.  But those are all sort of synthesis exercises.  I just think it's - I can't wait to get mine and to play with it.  I think it's going to be a lot of fun.



TOM:  Well, thank you, Steve.  As always, fantastic show, and a good explanation.  I'm really looking forward to next week.  And I hope you're able to pull that together for next week because I'm looking forward to hearing about this new authentication scheme.  Doesn't involve fingers, does it.



STEVE:  No.  No fingers.



TOM:  Okay.  I'll keep my fingers to myself.  You can find Steve's work at GRC.com.  You have a fingerprinting service, totally different kind of fingerprinting service, that I noticed at the top of the show, allows you to detect when your secure connections are being intercepted and monitored.  But go check out...



STEVE:  I did that all pre-NSA.  But there's been a surge of interest in it because of course suddenly people actually realize, oh, maybe there is some pressure being put on connections to be intercepted.  So I've noticed a resurgence of interest in that.



TOM:  SpinRite, of course, all kinds of great things.  And you can find all of our show notes and things like that at TWiT.tv/sn.  Anything to tell folks about before we head out of here?



STEVE:  I think everybody knows that I keep the low-bandwidth versions of these, as Leo describes it, for the bandwidth-impaired.  Elaine likes to use it because she's got a satellite link to wherever she is out in the boonies somewhere, and so it preserves her bandwidth.  And of course she famously does transcripts for all the podcasts, which we have at GRC.com/securitynow.



TOM:  Check them out.  Thanks, everybody.  Oh, yeah, go ahead.



STEVE:  I was just going to say that I'm really sure we're going to do, I mean, I'm as sure as I could be that I'll be ready next week.  I'm going to show it to some close friends and to have other eyes on it and to get some scrutiny.  Maybe, I mean, there's always a possibility that someone will see something that I just could not see because I was its own parent.  So I may announce that it's busted already.  I hope not.  We could do a Q&A, in which case you submit questions to GRC.com/feedback.



TOM:  Excellent.  Thanks, everybody.  And you'll tune in next week to find out.  We'll see you then.  



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#424

DATE:		October 2, 2013

TITLE:		SQRL

SPEAKERS:	Steve Gibson & Tom Merritt

SOURCE FILE:	http://media.GRC.com/sn/SN-424.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's minimal security news, Steve and Tom take the wraps off of "SQRL" (pronounced "squirrel"), Steve's recent brainstorm to propose a truly practical replacement for always-troublesome website login usernames and passwords.



SHOW TEASE:  Coming up on Security Now!, it's my last time filling in for Leo Laporte.  We've got a new way to think about fingerprint security.  We've got some good news about IE6.  But Steve Gibson has come up with a way to virtually eliminate the need for a password to securely log into websites on the Internet.  You've got to watch this episode, next. 



TOM MERRITT:  This is Security Now! with Steve Gibson, Episode 424, recorded October 2nd, 2013:  SQRL.



Hey, everybody, it's time for Security Now!.  I'm Tom Merritt.  Sadly, for me, the last week that I'll be filling in for the vacationing Leo Laporte.  And we have got an episode for you.  Steve Gibson, the man from GRC.com, the man who may have just come up with a way to pretty much free us from passwords, joins us now.  Steve, I'm really excited about today's topic.



STEVE GIBSON:  Hey, Tom.  It's great to be with you again.  Well, this was supposed to be, in our alternating topical and question-and-answer podcasts, this was supposed to be a Q&A because we of course talked about fingerprint biometrics extensively last week.  But the way the timing all came together with my getting to a position where I had enough worked out and documented of this idea that I've been teasing our listeners with now for, I don't know, five or six weeks, when it just hit me during breakfast one morning.  I was sipping coffee, and it just was there.  And I thought, wait a minute, does that work?  Then I thought about it some more, and the coffee got cold.  So I got more coffee because, you know, you need that.



TOM:  Well, yeah, absolutely.



STEVE:  And then I was working on the tail end of weirdness of the new SpinRite code for dealing directly with hardware controllers on motherboards.  And there were a couple people in the GRC newsgroup - we have a grc.spinrite.dev, which is where the development work goes on, and that gets fired up about every decade or so, when it's time to do a new SpinRite.  And so there's been frantic participation in that newsgroup.  And a couple people had these just weird, oddball, old, but they had them, controllers that were just behaving weirdly.  Most people would run all the test code, and everything was fine.



But anyway, I wanted to really wrestle this thing to the ground because I have people who are willing to test my code, and I don't want to let them go.  So for a couple weeks my main focus was that; while pretty much like every shower, every time I was driving, I mean, every other time when I couldn't be working on SpinRite, I was thinking, okay, let me test this again.  What has this da da da da.  And it just kept looking like I actually had an idea.  As I mentioned, it happened that I had one of my infrequent marathon phone conversations with Mark Thompson of AnalogX, who's a technical wizard and good friend.  And so since he was on the phone, this was on my mind, and I completely trust him, I shared it with him.  And he got it, to his credit, instantly.  Actually, it's not that complicated.  I mean...



TOM:  No, that's the beauty of it, yeah.



STEVE:  You got it, too, because I shared this with you yesterday when I had the documentation finally ready so that I could, you know, I had something that conveyed it clearly.  And anyway, so finally about I guess maybe two weeks it's been, maybe 10 days, when all, I mean, I finally said, okay, this phase of SpinRite work is done.  Of course, this is an interruption, of course, to the work I'm doing on SpinRite.  But everybody felt that it was important enough to suspend SpinRite just to get this published.  I don't know where it's going to go.  I mean, it's not something I own, except as being the father of it.  But, I mean, it's - replacing usernames and passwords is bigger than me.  It's like, this should just be done.



TOM:  And it's saving the Internet from itself, essentially, yeah.



STEVE:  Right.  So my hope is that I can be involved enough to work out other details.  One thing we need is interoperability so that, if this thing happens - and it's just hard to see why it won't.  It's such a low-friction solution.  Anyway, I realize I'm sort of stepping on my own story here.  But my point is I just want to sort of say, here this is.  I did just this morning create a newsgroup at GRC, grc.sqrl, because that's the name of this thing, pronounced "squirrel," SQRL, where I'm sure there will be huge, interesting, fabulous discussions because we've got a whole bunch of really smart people, a lot of crypto people, and just - this thing's the kind of thing you need to have pounded on for a while.



So anyway, we didn't have much news of the week.  So I guess it all works out.  And what I think - what we may do is, because I know that questions are piling up, maybe when Leo gets back next week, maybe we'll make up for having skipped some Q&As by doing a couple in a row, based on how many questions people have, even about today's podcast.



TOM:  All right.  Let's get into the security news, starting talking a little bit about fingerprints as, well, are they usernames or passwords?  That's what this story is about.



STEVE:  Well, yeah.  Actually, a number of people brought this to my attention.  I'm not sure how it got as much coverage as it did.  But I got a bunch of tweets incoming, saying, hey, Steve, have you seen this?  Some guy named Dustin Kirkland did a blog posting, and really the title of the posting says it all.  And it's really - it's an interesting posting that's worthy of some discussion.  And the title of his blog posting was "Fingerprints Are Usernames NOT Passwords."  And I just thought that was an interesting position.  And it certainly has some merit to it. 



TOM:  Sure.



STEVE:  His argument is - we talked about Touch ID and fingerprint biometrics at length last week.  And the fact that, as we know, they are spoofable, specifically the Apple extra high-resolution reader, which required that the spoof be even higher resolution so that, if the fingerprint reader saw pixels, it would say, okay, people's fingers don't have pixels.



TOM:  Not a finger, yeah.



STEVE:  So you need to raise the resolution of the image that you're creating the finger from to a substantially higher resolution than the resolution of the image capture scanner.  So they did that, and then they were able to say, okay, look, we're still able to spoof fingers, even at this high resolution.  And then of course the other arguments are that many people have against using biometrics is that they're not changeable, whereas you can change your password if it gets out of your control.  If you're using it at a website, and the website's database gets breached, famously, how many people have received email, or has anyone not received email saying, oh, my god, you must change all your passwords immediately because we just lost control of them.



So the problem is, if you use a biometric and the website has that, well, you can't change your fingerprints.  You can't change your iris print and so forth.  So what I liked about Dustin's proposition is that a fingerprint is a name for you, like an alias, and your name doesn't change.  So your eyeballs don't.  Your fingers don't.  So I just - I thought that properly couched sort of a statement of where biometrics deserves to be.  So, yes, and actually this speaks to the notion that was raised by several people commenting on Apple's Touch ID, and that is it ought to be one factor of two, that is, yes, use your finger to unlock your phone.  That's a perfect first step.  But if you're then going to do something critical - and maybe that's enough for casual use of the phone.  But if you're going to do something critical, then still need a password.  Don't solely rely on the fingerprint as complete verification of who the user is.  So anyway - go ahead.



TOM:  Oh, yeah, yeah, it's interesting.  It's not exactly the same as a username, obviously.  Someone can more easily imitate your username than they can imitate your fingerprint, although both are possible.



STEVE:  Right.  This lies somewhere on a spectrum between...



TOM:  Yeah, right.



STEVE:  Yes.



TOM:  I just thought of this just now.  You can change your fingerprint.  And I don't mean burning off your fingers or anything crazy like that, but you've got 10 fingers.  You just can only change it 10 times, and then you're done.



STEVE:  Yes.



TOM:  It's a limited amount of iterations there.  But, yeah, I think it is much more useful to think about it like a username.  That's a smart post from Dustin.



STEVE:  Well, yeah.  And I did see people, I mean, there's been obviously a lot of discussion following the whole Touch ID, bringing this topic of biometrics and fingerprints back to the fore again.  So people said, well, don't use the obvious finger.  Don't use the thumb of your right hand or whatever you're expected to use.  Use the pinky on your left hand.  And maybe don't let everyone know that that's what you're doing so that, if you're in a situation where the authorities are saying, okay, we need you to unlock your phone for us, you say, oh, okay, and without hesitation you use the thumb of your right hand, and then it doesn't work.  You go, huh.  You clean it off, wipe it, lick it, do whatever you do, then, like, try it again.  And as we know, after what is it, five misfires, the system locks.  And so you could easily say, oh, shoot, I forgot it was supposed to be my left thumb.  Well, okay, do that a couple times, and you're pretty much down at the line.  So...



TOM:  I use the CLEAR service to get through the line at SFO when I fly from San Francisco these days because I live in L.A. now.  And they use a fingerprint to identify you, along with a card.  So it's something you have and something else you have, I guess.  Not the right way to do two-factor.  But anyway, that's how they identify you.  It didn't work for me this weekend when I was flying back from TWiT.  Thumb three times, and they're like, okay, try a different finger.  So they had backed up all my other my fingers, and I was able to get in that way.  Kind of a different biometric way of going about things.  Thought that was interesting.



STEVE:  Yeah, I've run across people whose fingers just will not scan on the laptop-style, swipe your finger on the sensor.  I don't know what it is.  I mean, there was a friend I had at Starbucks who asked me to help her set up a new laptop.  She had a Dell laptop that had the standard little strip scanner where you swipe your finger.  And since I had set it up, I had registered mine and hers.  And no matter what she did, she could not get it to recognize.  And then I would do it, and it would work the first time for me.  So it was like, okay, I don't understand what's going on here.



TOM:  All right.  We have IE6 news.  But I think in this case we could almost say it's good IE6 news, which is kind of different.



STEVE:  Oh, it definitely is.  One of the things that we've talked about on the podcast from time to time is that the orphan IE of Microsoft, Internet Explorer 6, which, while it was there, it was there for a long time for major, as a companion to major versions of Windows.  And it was, for whatever reason, a large, huge-market-share browser.  And of course it has the mixed blessing of working.  And so when Microsoft did 7, and then 8, and then 9, there were a lot of people who just stayed with 6.  And there may have been clear reasons why they couldn't upgrade.  There may have been for me because Microsoft was changing the browser each time.  So there may have been compatibility issues where the particular corporate infranet - wait, infranet?  Intranet - Intranet only ran on IE6 and so people were stuck using IE6.  And of course the problem is that it's now so old and unsupported that new problems that occur in the newer browsers, the new versions of Internet Explorer, are no longer being back-patched to IE6.



Yet the problem has been, I mean, and Microsoft has, like, launched campaigns to try to reduce the market share of Internet Explorer 6 because it was becoming a serious problem, an embarrassment for them that this old browser, they just couldn't kill it off, and that it had so many security problems, which kept getting found in the later browsers which were being fixed.  Anyway, the news is that the global market share of Internet Explorer 6 has finally fallen below 5%.



TOM:  [Whistling] Hooray.



STEVE:  Yay [laughing].  Yup.



TOM:  Standing ovation.



STEVE:  Took a long time to happen.



TOM:  How far does it have to go before we just say, okay, it's irrelevant?  Because 5% still is too many, in my opinion.



STEVE:  Yeah, 5% is one in 20 people.  So that's a lot of people still.  I would say 1%, at that point you consider it - if you're down to 1%, then you have to ask, when the total percentage is that low, then you start asking, okay, who are they, and maybe they deserve to get the trouble that they're asking for by using any browser that is that far gone that only one in 100 people have it.  And I wonder, actually, if we're not seeing this reduction in IE global market share, not because people are moving to newer versions of Internet Explorer, but because they are dropping IE altogether in favor probably of Chrome No. 1 and Firefox No. 2, since we know now that the Google Chrome browser market share is now the largest one in the world, with Firefox in second place.  So it's not that people are like, okay, I guess I'll upgrade IE6 to IE9.  They're probably on operating systems that can't run IE9, for one thing, because they're way back on Windows 2000 or maybe XP.  But probably it's just that IE6's share is dropping because they've switched away from Internet Explorer altogether to one of the newer and better alternative browsers.



TOM:  GeekCanuck is asking how many of these are behind NAT and invisible.  Well, if they access the Internet, they're still visible.  They still count as an instance of Internet Explorer.  I guess there could be people using Internet Explorer on a LAN without accessing the Internet, they're just accessing a local Intranet.  And those actually aren't problematic because they're not accessing the Internet.  But most of them are going to be accessing both.  So I think most of the usages are caught up in this number.



STEVE:  Right.  And every single time, as we've discussed through the technology of the way this works through the years, every single query that a browser makes by default contains a so-called "user-agent header."  It's the metadata, which of course has gotten a bad reputation post-NSA.  But in this case metadata is the stuff that is not seen through the browser window, but it's the background management of the query and response.  For example, cookies are metadata of queries.  And so it's easy for somebody in a central position who is monitoring queries going over the Internet, looking at, for example, server logs.  Anyone who has a very high-volume popular web server can log the user-agent headers of all the queries coming in and look at the distribution of them because the user-agent will say what the browser is.  It'll explain its make and model and, typically, like a whole bunch of other extraneous data, like what versions of plugins it has and so forth.



TOM:  All right.  And our last bit of news here is the new BitTorrent Chat client, which I have signed up, haven't got access to it yet, but I'm looking forward to trying this thing out.



STEVE:  Well, what really frustrates me is lack of documentation because we can't - we're not - I mean, from our position, the Security Now! audience, all we care about is the crypto protocol.  How does it work?  For example, that's what I'm going to completely disclose today in this notion I have for replacing usernames and passwords.  That's all that matters.  It's like, here it is.  What does everybody think?  Let's go.  But you can't do that with BitTorrent Sync, which they have not documented, or BitTorrent Chat.  And so it's like, well, okay, there it is.  I can't say anything about it because - I could say we hope it's good.  But until they release what they're doing, it's useless.  I mean, it's just - it's nothing.



So all I can say is - what I wanted to say was, to all of our listeners, in addition to BitTorrent Sync, which there it is, and we don't know what it is, but they've got, oh, it's 256 bits of this and long bits of that, but no documentation other than that.  It's like the people who say, oh, we've got military-grade encryption.  It's like, okay, but what are you doing with it?  Everybody's got that.  So there is now something in alpha.  This is alpha signup:  labs.bittorrent.com/experiments/bittorrent-chat.html.  That'll bring you to a signup page, which as you said, Tom, you have used - I'm in no hurry to, but I'm glad you're doing it - to get the alpha test.  So they're very early.  They have something.  And obviously it's supposed to be secure chat.  It's supposed to be no storage of your chats, no ability to be intercepted, I mean, we were talking about, what was it, I'm blanking now, the other chat system that was loosely based on Bitcoin's protocol, but not really.



TOM:  Oh, right.  I'm blanking on it, too, sorry.



STEVE:  But anyway, so the point is, naturally we're seeing, as we expected post-Edward Snowden and NSA revelations, and we're going to continue for some time, and at some point we'll start having good things.  I mean, this might be good.  But it's useless until we know exactly how it works, until...



TOM:  Bitmessage.  Sage got it in the chatroom, Bitmessage.  Thank you, Sage.



STEVE:  Thank you, yes.  Until they tell us, here's the protocol.  And then smart, protocol-savvy people look at it and then can say, okay.  I mean, that's what happened with LastPass.  They were completely open kimono.  I got all documentation from them, a complete explanation.  They were even able to demonstrate that's what they were doing by creating a web page of JavaScript that was not obfuscated, that exactly duplicated the functionality so that, I mean, it was, again, complete disclosure.  That's the way I was able to say I understand everything done here.  I see no errors, no problems.  I'm using it without hesitation.  And there came my endorsement.  In this case, no one can do that.  No one can responsibly say use BitTorrent Chat or BitTorrent Sync until they tell us what they're doing.  So it's good that they're doing it, but we just have to wait to get the details.



TOM:  And it'd be one thing if they're saying, we're in alpha, we're only going to give that documentation to a restricted number of people.  That would make sense.  But that's not what they've done with Sync; right?  They have Sync now available.  I can download it right now.  But you're saying they still don't have the proper documentation.



STEVE:  They've said they're open to disclosing it.  Okay.  And I have a relationship with their PR guy, and he keeps sending me marketing announcements.  It's like, oh, look, we've got a pretty website design now.  It's like, okay.



TOM:  Great.



STEVE:  That's good for you.  But I want the protocol.  Really.  Don't call me until you've got the protocol.  That's what we need.  So we just need that.  And there just can't - they can't be serious without that.



TOM:  We have one little bit of errata from last week's episode regarding a location...



STEVE:  It's funny because as I was saying it, I knew it was wrong; but I had already sort of started the sentence, and I was committed.  But a number of people noted in listening to the podcast over the course of the last week that the NSA is not in Langley, because I was referring to the NSA as being in Langley, Virginia.  That's where the CIA is.  The NSA is in Fort Meade, Maryland.  So a little errata just for keeping the record correct.



TOM:  I wish I would have caught that for you, too, but I missed it, as well.  And I should know better, too.  Favorite tweet of the week?  This is pretty funny.  I like this one, too.



STEVE:  This one came in yesterday.  In fact, I should have written down who sent it so I could give them credit.  But so I got @SGgrc, someone tweeted:  "I hope they shut down the government cleanly, or they may need a copy of SpinRite later."  And then he said, "Take a check?"



TOM:  Do you have a SpinRite that can handle that platform, though?



STEVE:  Let's restart the federal government.  You never, you know, you hope it comes back online.  Speaking of coming back online...



TOM:  Yeah, sure, go ahead.



STEVE:  The other thing that was a hoot was - and someone sent me through Twitter a snapshot of his browser.  If you can bring that link up, Tom, you'll get a kick out of it.  And that is that the BarackObama.com website SSL certificate expired on October 1st, yesterday, at 7:28 a.m.



TOM:  And guess who they can't pay to come in and fix it?  Anyone.



STEVE:  [Laughing] Exactly.  So presumably whatever it is, whatever IT system or who knows what the structure is for renewing that certificate, but that may be sitting there for a while, not something they can fix.  And it's funny because years back when I was talking about SSL certificate expiration, and actually I was more annoyed by it back then, probably because I was still using VeriSign for my certificates, so I was - really an expiration was a painful event because it was so expensive.  Now that I'm moved over to DigiCert I'm so much happier.  It's like, oh, it's going to be fun to have it expire.  I don't mind this at all.  And not that expensive, was my point.  But so I was grousing a little bit about the whole - how ridiculous it was that you were being asked to pay, like, seven or $800 for bits.



Now, first of all, that price has come way down, and I'm getting much more for my money thanks to using DigiCert.  But I also really better appreciate the value in this rolling expiration system that the public key crypto system has.  I mean, it is our way of solving a number of problems.  If someone lost control, if a website lost control of their certificate, we know that that's a problem because that would allow others to potentially spoof secure connections to their domain, essentially using their certificate illegitimately.  But we solve that problem by informing web browsers that that certificate is bad.  I mean, certificates all have essentially a hash of their contents, which they cannot change without invalidating the certificate.  So web browsers can be told, from now on, never trust a website that offers a certificate with this hash.



Well, the problem is, if certificates live forever, those lists would have to grow forever.  And so thankfully certificates expire every two or three years.  After we're sure the certificate will have expired based on its date, then the prohibition against accepting it based on its content we're able to prune from browsers so that doesn't have to grow forever.  And so there are many benefits to it.  So anyway, BarackObama.com's SSL certificate is expired as of yesterday, which I thought was sort of a bizarre event.



TOM:  Interesting.  All right.



STEVE:  And since we didn't have much news today, I was saving something for when Leo got back, but I'll just sort of share it.  It's just completely random.  But my girlfriend just got a book published, which is actually No. 6 on Amazon in science fiction and fantasy for large print books.  Jenny's book - and people have heard me talk about my girlfriend Jenny from time to time.  It's comparative religion for children.  The title is "Is God Real or Pretend?"  And first of all, I loved the title.  From the moment she told me the title a couple years ago, I thought, oh, that's just - I just love the title.  And so I'll just read briefly, for our listeners who may be interested, the description that is there up on Amazon.



It says:  "'Is God Real or Pretend?' is the story of young Franklin" - that's, by the way, Benjamin Franklin.  Jen has, like, deeply studied history and biographies, and Benjamin Franklin is one of her favorite people from U.S. history, probably just any history.  And so anyway, so she gave this child in the book Franklin's name for Ben.  It's "the story of young Franklin's engaging and enlightening journey to answer this age-old question.  Franklin's grandmother, Dr. Wendy Knowles, a professor of astronomy, first provides Franklin with the basic scientific means of determining what is real and what is not, and how science distinguishes questions it can answer and those it cannot.



"Franklin's mission of discovery continues as he meets a kindly professor of Greek mythology who offers a historical-cultural perspective on the question.  Here Franklin meets the Greek gods and their timeless myths.  Once armed with these new ideas, Franklin meets with representatives of the world's five major religions:  Hindu, Buddhist, Jewish, Christian, and Muslim.  These knowledgeable teachers from each of the great religions charm and delight as they shine positive lights on their religion.  Franklin asks probing questions, while learning to appreciate and admire the diversity and beauty of these religious beliefs and traditions.



"Ultimately, Franklin's dynamic school report on the immensity and magnificence of the universe becomes the backdrop for thinking critically about religion and questions about God.  This book is designed for anyone and everyone, young and old, religious or not, who wants to know more about these five great religions.  It's the most unforgettable and exciting journey, one every thoughtful child and curious adults in their life will enjoy."



And I have to say from what I've heard from Jen that editors and people involved in the production of this who read the book were saying, wow, you've got to write one of these for adults.  So it sounds like she did a pretty good job.



TOM:  Yeah, it does.  That's a really fascinating concept for a book, too.  That just sounds - I want to read it.



STEVE:  Well, it's not long.  It's 66 pages, large print, illustrated.  And it's the sort of thing that a parent might read with their kids, as their kids start asking questions about religion and God.  It's like, well, here's a context in which we can think about that and answer the question.



TOM:  I know you don't have it in the lineup.  Did you watch "Homeland"?



STEVE:  Oh, yes [chuckling].  I actually, I don't know if I should say this, I think I know what's going on.  But I don't think I'm going to say.



TOM:  Already, wow.  Okay.



STEVE:  Yeah.  I think, well, actually, I love "Homeland."  And it just - I care about the characters, and I really enjoyed this first episode.  And in the, I guess it was the - I don't think it was a preview of this next week, but it was - what they're doing more now is "This season on 'Homeland...'" and so you're getting snippets from various, it's like, through the future of this season of the series.  I think that gave me a sense for what's happening.  And anyway, so, yeah.  I'm really enjoying it.



And I have to say, I've mentioned this before, when I discovered this series, I was talking to Leo, and I said, "Leo, this is not a series I ever watch."  People kept recommending it to me.  I'm talking about "The Good Wife."  And it's just - it's the title.  It just doesn't sound like something I want.  I mean, I want "Firefly," and I want "Attacking Demons from the Netherworld" or something.  Not "The Good Wife."  Anyway, I love the show.  And it also began on Sunday.  And it was wonderful.  So it was.  It's just really great television entertainment.  And of course we all...



TOM:  I may have to give "The Good Wife" a chance.



STEVE:  I would.  I think it's really good television.  And there's a huge backlog of, I don't know what, maybe four, five, six - it's been on now for many seasons.  But compelling characters.  The characters are really well crafted, and you care about them, and it's just - it's just an engaging series.  And of course we also wrapped up "Breaking Bad," which - and everyone, I guess, I guess the final series conclusion, which was last Sunday, got a fabulous - was very well regarded and well reviewed.



TOM:  Yeah, record-breaking for AMC.



STEVE:  Yeah, 10-point-something million viewers.  And the creator said - he was interviewed on "Talking Bad" afterwards, and he said that the first episode, I guess there was a collision with some sports event that was also being televised, and it limped in at, like, a million or so.  And of course it grew over time.  But, yeah, it was a great wrap-up.



TOM:  All right.  Well, I can't hold back any longer.  Let's talk about SQRL.



STEVE:  Okay.  So what do we want in an ideal online authentication system?  What do we want to replace usernames and passwords?  As we've developed more maturity on the Internet, as the range of services has grown, I think that our interaction with the 'Net has expanded.  There are places where we have a fiduciary relationship, like with our bank, or to some degree with Amazon, I mean, where they really do know who we are.  They've got our name and address.  We've got accounts.  There's financial information shared, or there's products being shipped to our home or whatever.  So there we're not anonymous, but we want security in being known.



But there's another whole aspect where we really do want anonymity.  There may be places where we really need anonymity or just places where it's not important that we be known, like making a posting to some random blog.  I mean, I know that sometimes I'll see someone's blog posting, and I'll note some errors that'll stimulate me to want to reply.  And so I start to reply, and suddenly it's like, oh, you have to create an account.  And it's like, oh, my goodness.  Then they want my email address, and I have to send them - then I'm going to get a link and have to verify myself, and they're going to want this information.  And I just say forget it.  It's not worth the overhead of having to essentially decloak myself for this, just to make a posting to someone's blog.



TOM:  Yeah, it's two things going on; right?  You don't want to reveal your true identity, and it's not frictionless.  You have to go through a bunch of trouble to do something you don't want to do.



STEVE:  Or, yeah, or it's they've created a bar such that I'm just not going to bother.  It's like, if you want me to do all that - I mean, and frankly, I see that when I'm purchasing stuff, too.  I mean, it's a different case.  But I'll go to somewhere, and I'm being asked to create an account, maybe not to purchase, but to do something.  And it's like, eh, it's just not worth it.  It's like, thanks anyway.  And so the point is that, because that's the current model for identifying people, they're missing a lot of blog postings.  Other sites are missing a lot of potential long-term visitors because what they're offering just isn't compelling enough.  And we also know, oh, my god, now I need another password.  I can't use the same password I always use because we know that's not safe.  Well, in fact, I can't always use any same password.  I have to have a different password for every site.



So there's, like, there's so much burden now to do something where - and I understand they want a relationship with me.  But it's like, I don't want one with them.  As they say, I'm just not that much into them.  So, but still, they're missing something.  So first of all, there's a range of sort of depth of identity and authentication that Internet services have reasonable expectation of, and Internet users vary in their willingness to disclose.



Also in this day and age we would like to be, arguably, anonymous, that is, untrackable.  I would like an identity that I use with Amazon and my bank not to be obviously related to one that I arbitrarily use when I'm posting something somewhere entirely...



TOM:  I think the worst example of that is Facebook; right?  Like login with Facebook.  Now Facebook knows everything about you on that site, and that site knows everything about you on Facebook.



STEVE:  Right.  And remember also that Facebook knows that you logged in over there because the whole OAUTH - not OATH, OAUTH - technology has the site you're logging into going over to Facebook.  Facebook sees that transaction and knows that that's where you're logging in through them.



TOM:  They want this, yeah.



STEVE:  So all kinds of networking interaction there.  So we'd like to break that.  We'd like to have no obvious connection of our identity among different sites.  It would also be nice, in a perfect world, to avoid keyboard interaction.



TOM:  What?



STEVE:  Because how many times, I mean, it would be difficult for me - I don't think I could, most of our listeners probably couldn't, log in at a library computer, put in their username and password in a library, or in some sort of public access terminal.  We've talked about this often.  You'd be crazy.  You have no idea what malware is in there.  Many times there have been hardware keystroke loggers, little modules, little pods stuck in the cable in the keyboard connection going into the back of the machine, which just is logging into EPROM everything everyone types.  And then that thing can be polled remotely and have its contents sucked down.  So you'd be crazy to, like, do this in any sort of an insecure setting, to enter important credentials through the keyboard.



Now, the other thing we'd like to have is this notion of no shared secrets with websites.  The whole shared secret thing is a problem.  For example, a password.  Our password at every website we use is a secret that we share with them.  We know what it is.  They know what it is.  Problem is, they're proving themselves to be unable to keep our secrets.



TOM:  Right.  You hear about that all the time.



STEVE:  As I was saying before, yes, exactly, it's like, oh, my god, we just - such and such just lost a quarter million of their user accounts, including their - now, maybe they're hashed passwords.  That's good.  Except that, if they didn't do their security really correctly, as we've also seen, that, like, has my password escaped, there are sites you can go to that have already run the password hashes through high-speed cracking of password lists to see if they can crack your password.  So in general a shared secret is a problem.  Now, even more recent technology is the Google Authenticator-style approach.



TOM:  Oh, yeah.  No, I use that for the two-factor authentication; right?  I've got to go to my phone and get that little code.



STEVE:  Yeah.  Well, and I've got the original little PayPal football here that I'm holding up in front of the camera, which you press it, and it gives you a six-digit code.  That's the OATH technology, which is in this case a time-based varying six digits.  And the Google Authenticator is exactly that.  But the reason you have a whole array of accounts is we're back to the shared secret problem.



TOM:  Well, yeah.



STEVE:  It's like, yes, this is a second factor.  And so what that protects you from is your credentials being captured and somebody reusing them.  If you need to also know, not only something you know, but something you have, meaning this other factor of authentication, obviously you're more secure.  The problem is it's a secret.  That is, the way this works is your Authenticator has a secret which it shares with Google.  And that secret allows them both to calculate what six-digit code should be shown within this 30-second window, which changes thus every 30 seconds.  So the problem is you can't safely, I mean, technically you could force other sites to use the same shared secret.  Then you wouldn't need a separate Google Authenticator account for every single site that you authenticate with.



The problem is, once again, if they lose control of their database, then it's not just their secret Authenticator data that gets leaked, but any that you've shared it with.  So you're back to the same password problem of not being able to use the same password across all sites, which is very convenient, but we know is critically unsafe.  So...



TOM:  But there's also the waiter problem; right?  Even if they're hashed and salted and secured in their database, every employee that's involved in their security firm can access my password; right?



STEVE:  Yes.



TOM:  It's there on their internal server.



STEVE:  Yes.  Very good point.  And, again, in a perfect world, it might be nice if authentication was out of band, meaning that, if you've got a bad guy who has somehow hacked into your connection - now, arguably, if you're in that much trouble, then maybe authentication is the least of your worries, if you've got somebody who's, like, actively able to see your connection.  On the other hand, you'd still like them not to be able to get it.



So if you're typing your username and password in, you might have malware on your computer, or you might have something, you might have a corporate proxy which is using a certificate installed on your computer - we've talked about this often - to decrypt all of your traffic in order to run it through, they say, antispam and malware filters.  But we also know that they're actually looking at the contents and doing keyword searches on it for acceptability and content protection and so forth.  So there again, your credentials are in the clear there.  Well, it would be nice if your authentication didn't go through the same channel that your main web experience was going through.



And the other biggie, post-Snowden, and now that we know the extent of the NSA's involvement in our privacy, is third-party involvement.  That's the other big problem.  The little football that I held up before, this is authentication that goes to VeriSign.  So this is not authentication of a secret that I have with PayPal or with eBay.  This is actually - this has a serial number that I registered with PayPal, but this is a service that VeriSign provides.  So VeriSign is a third party involved in my authentication process.  Unfortunately, we now know that it's just not safe to have third-party involvement with our identity.  Many of these authentication, these, like, next-generation authentication systems, involve so-called "federation," where they want to federate authentication, where you authenticate to the third party, and the third party authenticates to the website.



Well, that might have sounded good last year, but that doesn't fly anymore because we now know that no organization can withstand a national security letter sent by the government saying we want you to turn over the information you have about this user.  So I would argue that third-party authentication is dead.  What we need is two-party, between you and the website, authentication that does not rely on the services of a third party because we just - they're not trustworthy, unfortunately.



And lastly, if we're talking about something new, it's got to be low friction.  I mean, first of all, it can't be kind of better.  It's got to be a lot better.  It's got to be free.  So there's no, I mean, one of the reasons people have moved away from this VeriSign model and eBay and PayPal football is it is really expensive.  The reason Google's not using it, for example, they did their own, is that VeriSign gets a fee for every single authentication.  So, first of all, the authentication instance has to be free.  The apps or whatever it is you use has to be free.  I mean, this is not something you could charge for.  Maybe 10 years ago, but those days are gone.



Also, it has to be not overly complex because it wants adoption.  We want people to be able to easily create whatever this is, both on the user's side and on the server side.  And we see time and time again that really complex protocols - we were talking about just the other day that, with regard to the IPSEC security in IPv6, how it's now believed that the NSA influenced the design by helping to make it so complex that cryptographers were no longer able to even understand it.  They, like, looked and said, okay, we can't say this is even secure because we don't understand it.  So also it has to be simple and easy, feasible for one person, not big teams, not organizations, just one guy who says I want to implement this, for them to implement.



And in order to be adopted, it can't be jealous of the existing system.  It has to be something which is feasible to have side by side, running next to existing authentication, as an alternative for people who would prefer to authenticate that way.  And over time, if it were to succeed, it might end up being like your first choice, where it's like, oh, well, if you can't authenticate that way, then you go back to old-school username and password.  And of course you'd always need some ultimate backup authentication for times when for whatever reason you can't authenticate this way.  So that's my laundry list of ideal online authentication.



TOM:  Now, what's crazy about this to me is, if I were to sit down today and go, okay, what should I fix about authentication, I wouldn't choose no keyboard interaction.  I would immediately say, well, that's just silly.  Of course we're going to need keyboard interaction; right?  Or sharing secrets with websites.  Like maybe we could do without shared secrets, but I'm not sure how.  You've gone through very meticulously and said, what would the perfect system involve here?  That's why - some people are getting impatient in the chatroom.  They're like, just tell us how it works.  But it's important to go through and say all of these things need to happen because what's so impressive about SQRL is it addresses every one of these points that you talked about.



STEVE:  Yes.  That's - exactly.  What I have is that.  What I have is what I just described.  It is no linkage among websites, anonymous, no keyboard interaction, no shared secrets, out-of-band authentication, no third-party involvement, low friction, easy.  I mean, and the other thing is easy for the user to user.  Maybe that's more important than anything else, is what is it that we - that annoys us so much is, I mean, I can't log on anymore without LastPass somewhere because it knows all of my different passwords, because we've all been driven all the way there, to the point where really it's just become that burdensome in order to be secure.



TOM:  And LastPass, which doesn't solve most of these problems that you've mentioned, is too complicated for a lot of people.



STEVE:  Right.



TOM:  Sadly, yeah.



STEVE:  Okay.  So what is this?



TOM:  How do we do this?



STEVE:  What is the user experience?  What does a user do to get all of this with the what I call "SQRL login," "squirrel login"?  They are anywhere - at home, at Starbucks, at a public kiosk, it really doesn't matter.  And the login page presents them with the regular, probably, username and login because, I mean, that's going to be - that's probably never going to go away completely.  But off to the side, next to it, is a QR code, one of those cute little square digital codes which we actually did a whole podcast on some time ago.  I went through the exact, everything about the structure and function and operation of so-called QR Codes [SN-382].  And underneath it, it probably says SQRL, although - I don't know what else it could be, but just to label it for people, stands for Secure QR Login.  So SQRL, Secure QR Login. 



TOM:  You don't have to be nuts to use SQRL.



STEVE:  [Laughing]



TOM:  I don't know, I'm just testing out...



STEVE:  You don't have to be - I like that.



TOM:  You'd have to be nuts NOT to use SQRL.  There you go.



STEVE:  So all you do is you scan that QR code with your smartphone, and you're logged in.



TOM:  Wait, that's it?



STEVE:  That's it.



TOM:  And I know, because I read the documentation.  But I still can't believe that that, I mean, there's a lot going on behind the scenes, but really that's all you do.



STEVE:  That's all you do.



TOM:  You don't have to press a button or take a picture of your thumb or scan your eyeball, nothing.



STEVE:  No.  Okay.  So what does it do?  What's going on?  So even the crypto system - and remember that - our listeners will remember when I was first telling Leo that I thought I had come up with something, I said, I'm tempted to call this HIPS, H-I-P-S, as an acronym which stands for Hiding In Plain Sight.  Because, I mean, I almost think that it was like, okay, why hasn't anyone done this?  And our listeners are shortly going to have the same sense.  It's like, okay, wait a minute, what's wrong with this?  Why does this work?



So here's what is going on.  Every time a site displays a login page to anyone, a QR code is generated which contains the URL of the site's SQRL authentication service.  So maybe it's like sqrl.amazon.com or Amazon.com/sqrl?, I mean, whatever.  It's the URL which your smartphone will use.  So this is the website saying we want to receive SQRL logins at this URL.  And then on the end of the URL, so it's just that, it's just the URL, the authentication service, and then a parameter in the URL tail, probably "?," and then gobbledygook, what we now know as pseudorandom junk.  In crypto terms it's a nonce, n-o-n-c-e.  It's a number used once.  And so that's the end.



So every time a page gets displayed, the server uses its random number generator, creates a new nonce, which it just offers on the page.  People who don't have SQRL ignore it.  They figure out what their username and password is for this site, and maybe they can't, so they use LastPass or 1Pass or MyPass or YourPass or whatever, somebody's pass, and log in that way.  But if you're SQRL-enabled, you just let your phone see that.  Now, it might be that the URL would actually be sqrl://.  Instead of https://, maybe sqrl, or maybe sqrls (for secure) //, although the connections to the server would be secure.  Who knows.  So maybe your phone automatically recognizes a QR code with sqrl:// and just does it.  Apparently there are, you know, smartphones have the ability to have a URL registered that way.  Or maybe you just tap your SQRL app which you've installed and let it see the code.  What happens?



So the SQRL app sees this URL.  It takes the domain in the URL and cryptographically hashes it with your master identity key.  There's something called the identity master key we'll talk about more.  But it's a 512-bit large, pseudorandom key that is, like, that's your identity.  It is universal.  You could have it your entire life.  It never needs to change.  You obviously want to protect it, and we'll talk about all of that in a second.  But so the domain name cryptographically mixes, and we actually use a an HMAC function in order to do that, a Hashed Message Authentic Code function, which is secure, to combine the domain name with this master identity key.  That produces a 512-bit private key in terms of public - an asymmetric key pair, private and public.  From that private key, the matching public key is synthesized; and the entire URL, which is the whole domain name and the nonce, this one-time pseudorandom thing, is cryptographically signed by the private key.



So, and we've talked lots about cryptographic signatures.  Basically a hash is made, and then that's encrypted under the private key.  So we basically do a cryptographic signature using the private key of the entire URL contained in the QR code on the login page.  The phone sends two pieces of information to that URL.  That is, it generates a standard web query, HTTPS web query, to the URL given; and it provides the public key, which was synthesized from the private key, and a signature.  And that's it.



TOM:  That's it.



STEVE:  Now, that's the key.  And, yes, that's it.  That's all there is to it.  The server receives this query coming in which will be for a login page that it's displayed, but hasn't heard anything back yet from the user.  So in comes a query.  The query contains a public key and a signature.  It uses the public key to verify the signature, which is how signatures work.  That tells it that whoever it was who sent this little packet has the private key that matches because only the private key can sign that URL, which is unique in every instance.  And so that proves the identity of the user.  The identity of the user is just their public key.  That's their identity.  That's the token by which the website knows who's logging in.  So the public key forms their identity token.  The fact that the public key verifies the signature authenticates that they are the person who actually has that identity.  And so this makes it proof against replay attacks and various spoofing attacks because it is a URL that was just generated that the website verifies.



And note that because the way the private key was generated was from hashing the user's master identity against the website, there's a different private key per site, and therefore a different public key matching per site.  So the whole system is site-specific.  Every time that user with that identity master key comes back to that site and scans the QR code with their phone, same hash is synthesized, same private key is made, same public key is made, new signature of the new URL presented this time on the login is signed.  And the phone makes a query back to the server to say, hi, log me in.  And that's it.



TOM:  So if somebody were to spoof that page, they wouldn't have all the information they need to create a QR code that would actually fool your phone.



STEVE:  Okay.  So there's the basis, sort of the underlying architecture, is that we have a - we synthesize a per-site private key from the domain name in the URL, which doesn't change for authentication on that web server, and the user's master identity key to create a private key.  The private key never leaves.  It's made on the fly, basically from the domain name and the user's identity, never leaves the phone.  It signs the entire URL and is also used to synthesize the public key.  And those two things, the public key and the signature, are sent back.  So that's it.



Now, there are still some things we need.  But as far as we know, that architecture is secure.  There is some fancy crypto which actually I explain on the SQRL pages at GRC, which are now up, by the way, if you go - under GRC's main menu, under Research > Recent, the top item under Research and then Recent, is the introduction page to this SQRL system.  And that is we need to prevent the phone itself from being abused.  Now what we've done is we have securely bound the user's identity and authentication to their smartphone.  Now we need to keep it from being hacked.  We need to keep it from being, I mean, their authentication from being abused.



And so for that we need good, strong, local authentication.  That is, that they need somehow to prove that they're the person holding the phone.  Mom and Dad don't want Junior to go logging into their banking site and getting up to mischief behind their backs, or doing anything else.  I mean, in general, people don't want anyone else to be able to authenticate as themselves by using their phone.



TOM:  Yeah.  When someone takes my phone, steals my phone, all that.  All those questions.



STEVE:  Yeah.  And even, like, I mean, I see people handing other people their phone.  Oh, you need to make a phone call?  Fine.  Or people are generally sort of casual with the security of their phone.  Now there's something we really need to protect.  And unfortunately, today phones don't do that.  I mean, we even saw the much-heralded Touch ID lasted less than a week.  It was a couple days before the Chaos Computer Club in Germany had come up with a bypass, arguably in all perfect conditions.  But still, the phone isn't protecting you from that kind of abuse.  And if you loaned your phone to someone, someone who needed to make a phone call, or let me check a web page or something, well, you would unlock it for them, and then they're holding your phone.  So it is...



TOM:  Right.  And the phone thinks they're you, yeah.



STEVE:  Right.  It is still the case that the best means for an individual to authenticate themselves is a password.  It is something only they know.  It is a secret.



TOM:  So we still need one password.



STEVE:  Right.



TOM:  A single one.



STEVE:  And we need it, not because the system needs it to be secure.  The crypto appears to be bulletproof.  We need it just to control access, access control to the system.  Now, I talked about no third-party involvement, which I explained as an essential necessity in this day and age.  Note that, however, what we've just described, what the SQRL system is, is a one-to-one authentication.  No third-party involvement.  You're simply saying to a website, hi, this is my token.  And notice that this solves the problem of identifying yourself anonymously to some blogging site.  You go to a blogging site, and you say, hey, I want to post a comment.  Up comes the login to the site and a SQRL code next to it.  You say, oh, snap that with your phone, and the site says, oh, okay, fine.  Welcome back.  They never know who you are, but it now has a fixed identity token to identify you.  You can then, maybe you want to assign yourself a handle by which you are known for conversations there.  That you can do. 



The point is no one can ever impersonate you, and you can come back three years later, and the site will say, oh, welcome back, just using this and nothing more.  But the fact that there's no third-party means the individual user is responsible for managing their identity.  If there were a third party involved, if there were some big brother-ish organization, and, for example, you lost your phone, and you had SQRL installed there, well, you would want it disabled.  So you could contact this third party and say, oh, my goodness, my phone's lost, deactivate my authentication that's associated with the phone, and they could do that for you.  There is no "do that for you" here in this scenario.



TOM:  Right, that's the flipside here; right?  We don't want anyone else involved.



STEVE:  Right.



TOM:  So how do we turn that off?



STEVE:  So, okay.  So a couple ways.  So the system provides very strong local password protection.  There's the obvious user interface protection, meaning you try five times, and the user interface says, you know, you're not seeming like yourself today, or at all.  So we can easily have user interface password lockout, which just after five tries it says, sorry, you're going to have to reestablish your identity some other way.  And the system provides for that.



The other type of attack is where something - malware or a hacker or the government or someone - somehow manages to get access to your phone's memory in an unencrypted state.  We know, for example, that iPhones have long encrypted their memory under their user's password.  You need to use that.  You need to unlock the phone in order to decrypt the memory on the fly and so forth.  But while apps are running, while the phone is unlocked, presumably that's available.



So we need protection underneath the user interface where, if someone got a hold of the meat of the application, the application's secrets, whatever those are, without the user interface able to block access, we still need the system to be secure against that.  So that's one aspect of password use.  And I'll come back to how we, in detail, protect that in a second because there's a second aspect that is related.  And that is the other thing we want.  Essentially, we have a smartphone with its 512-bit pseudorandom key that was made once and is potentially our online identity for the rest of our life.  If we manage it correctly, it's huge enough and unique and secure enough, it never needs to change.  Well, that means...



TOM:  Now, is that a private or a public key?



STEVE:  Well, that is the secret key which is mixed with the domain name to produce site-specific private keys.  So it is not a key that ever goes any further than that secure hash function.  But the point is we don't want to lose it.  No matter what happens.  I mean, if the phone went through a trash compactor, or just the phone died, and completely dead, we absolutely - we need our identity.  So that says we need to be able to export that key, that super-secret lifelong master key, in some safe fashion.  Well, and say you're Leo, and you've got 27 phones.  And you'd like to be able - and you're now using SQRL to authenticate yourself to all the sites you use, and you've got phone du jour that arrived during the podcast.  So you need to be able to also transport this key between devices and between it and a safety deposit box, essentially.  I mean, you want it somehow to be stored, storable, securely.



So the system provides the ability to export this super-secret master key as a QR code.  So the user can say, I want to display on the screen my identity master key.  Once it's up, then another phone can simply snap a picture of it in order to import your super-secret master identity into it.  However, in order to verify the password that goes along with that, we need to provide in the super-secret master identity QR version of your key some password authentication information.  And if we put password authentication information in there, then that exposes it itself to attack, meaning that, if some bad guy got a hold of it, then there is an encrypted, your encrypted master identity key, plus enough information to verify your password because, if you a year from now import that key into a new phone, you've got to provide the password.  And if you transport that key, clone it to another phone, you've got to provide the password.



Well, that means that that little rectangular QR code has to be able to verify your password.  And if it can verify your password, then that means it's potentially subject to a brute-force attack, meaning that there's all the information there it contains to tell an attacker all of the passwords they're guessing are wrong and to finally, ultimately, find the right one.



So how do we prevent that?  We prevent that by making it ridiculously hard to check a password.  We have technology now, we've talked about the Scrypt password-based key derivation function, PBKDF, Scrypt.  Scrypt was designed by the guy who did the Tarsnap system to be a memory-hard, password-based key derivation function.  And I think we may have done a whole podcast on this [SN-388] because I remember talking about the way this generates a huge array of pseudorandom data, and then where every item in the array is modulus the size of the array, so that it is essentially a pointer back into another item in the array.



And so the idea is that you iterate through this, jumping through this array; and, at each location, that location tells you where to go next.  So you go there in the array, and that location tells you where to go next.  The point is, by doing this, there is no way to do this in the amount of memory that a field-programmable gate array or a GPU has.  You could say we want a megabyte.  And while there may be a megabyte in the system, there isn't a megabyte in the GPU's caching size memory or in a field-programmable gate array cell region.  So this prevents acceleration by GPUs and FPGA technology.



So we use Scrypt technology to create a 60-second processing burden for the production of an exported QR code.  If you tell your phone, I want you to show me my super-secret master key for whatever reason, because you want to email it, because you want to print it to make a paper copy, which all users would be advised to do, to stick in a safety deposit or to stick in somewhere safe, it deliberately is calibrated to take 60 seconds.  It'll show you a countdown actually as a percentage from 100 because different phones will have different amounts of processing power.  So it won't always be 60 seconds, for example, when you're importing that into a different phone, or a later phone.  But it'll sit there for one minute, basically deeply - essentially doing the equivalent of deeply encrypting your super-secret, lifetime-long master key for an entire minute of your phone's maximum processing capability, and then it will show it to you.



What that means is that what it's showing you requires the same amount of processing in order to be decrypted.  For a single guess.  So once you export this, or, for example, say that you snapped it because you're Leo and you want to clone it to a second phone, you then have to put in the same password you had on the source phone.  You enter that into the destination phone and wait.  It's going to go through - it's got to perform the same operation, as burdensome, for a single attempt at the password.  So if you use a strong password, it is impossible to guess this thing, to do a brute-force attack where you're talking a processing burden of a minute per single guess.  I mean, you really don't want to even mistype your own password because you're going to have to wait another minute.



But my point is that exporting and importing these codes is done so infrequently, and we want so much security around them, that it makes sense to do a state-of-the-art, GPU-FPGA busting, memory-hard process so that it takes a minute.  And what that means is obviously you want to keep this a secret.  We're not saying you want to tattoo this on yourself.



TOM:  No, please don't.



STEVE:  You want to keep this a secret.  You want to print it out and stick it at the bottom of some drawer somewhere.  But the point is, the way the system works, any and every exportation of that information is encrypted that deeply.  It is 60 seconds of serious processing for a single attempt at seeing whether the password you used is correct.  So, like, in the worst case, if it got loose, well, you're probably okay because you just can't perform - we talked about hundreds of millions of hashes per second.  Well, now we're talking about one guess per minute.  And so, yes, you still want to use a good password.  You'd like it to be, if you'll pardon the choice of terms, squirrely.  You'd like  squirrely password.  And I'm going to propose that any keyboard that displays the password prompt for defining a password doesn't make you use shifts in order to get to funny characters, but lays them out there so that you're encouraged to use a password that's got all kinds of upper and lower and special characters and so forth so that it just won't be on anybody's password list.



TOM:  Oh, that'd be a great Android feature, when you could put in a custom keyboard like that for the app that handles this.  That's a great idea.



STEVE:  Right.  Okay.  So obviously you don't want a 60-second delay every time you use this on your phone.  And so the idea is that whole 60-second process is only for performing the super-deep encryption of your master identity key when it's going to be displayed for whatever reason - to be put up on the display, to be copied to somebody else's phone, or to be printed out for long-term archiving and safekeeping.



TOM:  How often do you think that that would need to be done?  Not very often, it doesn't seem like.



STEVE:  No, I think like five times.  Yeah, I mean, like almost never.  So, and if people wanted even more, I've just made up a minute because that seems like a ridiculously slow rate at which any password can be guessed.  And there's no way known to do this in parallel where you need a megabyte of memory statically available to this thing while it's running, so extremely acceleration-resistant.  On the UI side, when SQRL says - when, for example, you want access to the application's settings, or when you want to authenticate, you need to give it that password.  And there I propose that you're asked to wait for a second.  It's 1,001, 1,002.  That is still a substantial burden for any sort of local attack on a strong password, yet it's also short enough that it's not going to frustrate you.



And the last part of this that I haven't mentioned is that you do need to verify that the SQRL code domain that you're logging into, that is, the domain in the SQRL code, is the one you're logging into.  So the other step here is you would see a page that wants your identity.  And so you snap it with your phone.  Your phone needs to show you the domain, the domain name, www.Amazon.com or Facebook.com, whatever, that you're going to authenticate to and get your permission because the one attack which some smart guys that I shared this with over the weekend came up with, I call it the "evil domain attack."  You could be logging into an evil website, and behind your back it could go and get a login page, for example, for Facebook.  And it shows you the Facebook SQRL code that it got from Facebook.



TOM:  It's just taking Facebook and redisplaying it, so yeah, yeah.



STEVE:  Exactly.  Basically it's a type of phishing attack.  And so you don't want to blindly authenticate without verifying that you're authenticating the domain you think you are.  And so the message, it would just come up and say you are about to provide your credentials for this domain.  And then it would be, not in a little dialogue, but my intention is as large a print as will fit on the screen, it shows you.  And so you just get in the habit of making sure that basically the credentials you're about to provide are for the site you expect because, if you didn't do that, if you were at evilwebsite.com, and it popped up, and it was showing you the SQRL code for Facebook.com, you would be sending your credentials to Facebook, but basically you'd be authenticating the web session that Evil Website had started.  You'd be authenticating that login that Evil Website was doing behind your back.  And so...



TOM:  Basically riding in on your back, so to speak; right?



STEVE:  Yes.  You would give it access to your - you'd basically be giving it, be allowing it to impersonate you to Facebook.  So we can completely prevent that, just by making sure that we're providing the credentials to the site we think we are.  But notice even in that case it doesn't get anything about us.  It doesn't know who we are, doesn't get our ID, doesn't get - even the signatures, that all went to Facebook.  All that happened is that it was spontaneously logged in.  So, I mean, it's not a good thing, but it's still a limited impersonation for that session, which we can completely block just by saying these are the site's credentials you're about to share.  And if you realize, wait a minute, I'm not at Facebook, I'm at Evil Website, it's like, no.  This is a squirrely SQRL code.



TOM:  Why does evilwebsite.com want my SQRL?  Stay away from my SQRL, yeah.



STEVE:  Exactly.  And that's the whole system.  I mean, that's it.



TOM:  We've got lots of questions from people.  And I think you've touched on most of them.  One of the ones that I'm not sure we covered directly was what if I want to have two people using the same device?  I've got two people that use  my phone.  Is that possible?



STEVE:  Yes, yes.  So there are a couple variations.  First of all, I would propose that an application, an SQRL app, would have the notion of a user.  And so your phone might just have you as the user.  But there's absolutely nothing to prevent, for example, say for convenience, you and your wife, or your spouse, to be neutral, you and your spouse each have a smartphone.  You each create your own identity in your own SQRL apps on your smartphone.  And then you want to install that identity in each other's phone.  So the idea is you create an additional "user," and we'll use that term carefully, a user, so that now the SQRL app has, like, the current user.  It's either me or my spouse.  And so there's nothing to prevent you from creating - from having the app essentially have a separate key and password information for each user.  So that you could do.  And, yes, so that works nicely.  And you could freely delete them if you're no longer using them.



Your kids might want to install their identity in your phone, again for convenience sake.  You would have no access to their identity because it would have the same level of protection as your own identity has against other people. 



TOM:  Now, the other question that of people had was what if I want to surf?  What if I want to log in on the phone that I have the SQRL app?



STEVE:  Ah, yes.



TOM:  How do I do that?



STEVE:  A couple ways.  First of all, in the worst case, it's normally possible for you to copy an image on a web page.  So you hold your finger down on the SQRL code, and up comes a little dialogue saying, "Copy"?  And so you say yes, copy.  Then you just simply go to the SQRL app and paste it into the SQRL app, and you're good to go.  But the other cool possibility is, for mobile users, is that we could also do the same thing with the actual URL.  Instead of showing the graphical SQRL code, it could just, if the site knows, if it sees from your user-agent that you're using a mobile device, and it's obvious that sites are becoming aware of mobile devices because I notice sites are recognizing that I'm on an iPad when I am, then it could still provide the SQRL code, and would, but might also just have a link, that is, there would be a link, sqrl://.



And so the point is it would be a little button underneath it saying "Logon Mobile."  And so you simply click the button.  And so that executes the device that's registered for sqrl:-flavor URLs, which essentially fires up your SQRL logon, presents you with a screen saying is this the site you want to authenticate to, and you say yup, and off you go.



TOM:  And back you are.



STEVE:  And then back you are, essentially where you were, but now securely authenticated.



TOM:  In fact, QR code is really just a string of data represented as a QR code.  So there's no reason you can't represent it as a string of ASCII characters; right?



STEVE:  Exactly.  In fact, the QR code that we were talking about for your master key, that's all binary on a predefined format.  But, yes, the QR code on a web page is just text.  That's an existing standard.  If you go to a website, or if you google "QR code generator," you'll get pages of QR code generators.  There's a bunch of nice ones.  And you can put in https://www.amazon.com/sqrl?, and then, like, a bunch of nonce sort of stuff, and see what a QR code looks like.  It's just a standard URL.  But the beauty of it being a QR code is that it essentially jumps off the page into your phone, optically, just that easily.  Which was part of what hit me that morning during breakfast, was wait a minute, this seems like it could work.



And so imagine the experience.  I mean, now, I mean, this is - I want one of this, one of these things.  It's just it's my phone is able to assert my identity in a secure fashion to every site I visit.  And what I would do is, over time, as sites began to support this - and, again, it's low friction.  They leave their existing logon there.  They simply add the QR code over time.  Users add SQRL apps to their smartphone and begin using it.  And so, for example, say the first time I went to Amazon, I might snap the QR code, which I notice has finally appeared on Amazon, and Amazon would take me to a page saying, hi there.  We don't know who you are yet.  If you are an existing Amazon user, please provide your traditional logon so we can associate your SQRL identity with your Amazon account.  And so I do that one last time, and from now on, wherever I am, Amazon knows me.



TOM:  Now, one of the reasons - and we keep saying "phone," but really we're just talking about a device with a camera and an Internet connection, essentially; right?



STEVE:  Yes, correct.



TOM:  Because an iPod Touch would be able to do this if it's connected to WiFi.



STEVE:  An iPad.



TOM:  Yeah, an iPad could do this.  And I feel like one of the reasons you're saying have it on that device is that way you only have the one device that can authenticate you.  And so you don't store it on a bunch of other devices unless you really want to.  But you're sort of - you're distributing your risk; right?



STEVE:  Leo would have it on all of his phones.  And it would be safe because it's deeply encrypted and protected.  And so there really is, I mean, for convenience, I would think you'd want to have it on whatever you have with you.  So, yeah, having it on one phone is good; but having it on all of your mobile devices, that could work, too.



TOM:  Well, then a few people were saying, and curmudgeons, admittedly, probably a minority, but saying "I don't have a smartphone,"  "I don't want a phone with a camera," or even "My workplace won't allow me to have a phone with a camera," which still happens sometimes.  And they're suggesting, can I have this app on my laptop and use it the way you're saying you could use it on the device itself?  So the laptop is your device.



STEVE:  Yeah, I don't see any reason why not.  This could be done as a plugin so that the plugin sees the SQRL code and performs the handshake for you and identifies you.



TOM:  So it really has so many more uses, then, suddenly; right?



STEVE:  And actually the plugin has an advantage, too, that it could, for you, verify that the domain of the SQRL code matches the domain of the URL of the page.  So it could eliminate that extra step that we have in the phone to verify that the QR code which we're not able to read ourselves, it looks like gibberish, so the phone decrypts that so we can see the URL to where we're going to send our authentication information.  A browser plugin could do that for you.



TOM:  That's incredibly useful.  Now, your laptop doesn't even have to have a camera at that point, or at least the one that you're going to trust.  Of course, don't lose that laptop, or you're going to have to go get your code out of the safety deposit box and go through that.  I'm sure that you still want people to poke holes in this if you can.  I know you've done a lot of bullet testing on it.  What do you want people to do with this next?



STEVE:  Well, okay.  So I just had to tell the world.  We have a lot of listeners all over the place.  Everybody knows about it now.  There are pages up where I've got block diagrams and careful descriptions.  I think I've got three and, like, a quarter of maybe 10 pages finished.  So the core pages - basically, Tom, what I showed you yesterday, so that you would know what this podcast was about, that's all done.  Anyone who reads those three pages will completely get it.  I'm working on the attacks page, where I want to document all the different attacks that we know of, like brute-force password attacks and, like, DNS spoofing attacks, is there any vulnerability there and so forth.  I also want an implementation page.



I mean, as far as I'm concerned, I'd love to get back to SpinRite, frankly.  I've done my job here.  But if there's anything I can do by being some focus for this, I'm certainly willing to do it.  If people like the idea, then we'd like to have SQRL apps created.  But we'd also want to guarantee interoperability.  So that means that we need to define the protocol by which the SQRL app contacts the website.  So we need interoperability, essentially standards.  We need some standards to be created around the concept so we don't end up being fragmented because that would kill it quickly.



And I did just create a new newsgroup at GRC.  I do it very infrequently; it's been years.  But there is now grc.sqrl is the newsgroup on GRC's NNTP newsgroup server.  I haven't looked there, but I'll bet it's already active, knowing the people that are hanging out there.  So that's really going to be our central focus.  I do have a feedback page among those SQRL pages on GRC.  Essentially, if you go under Research and then Recent, and then you'll see SQRL Secure QR Login.  That'll take you to the introduction page.  At the bottom is a block of links.  And I do have a feedback page, as I always do for these things, where anybody can essentially send feedback directly to me.  I'm interested in what anyone has to say.  But for extensive dialogue and conversation it would be much better to participate in GRC's newsgroups, where we've got a bunch of really great people working on this stuff.



TOM:  And that's just grc.sqrl, right, for the newsgroup?



STEVE:  Yes, is the newsgroup, grc.sqrl.  And I actually have a link to that on the feedback page because we have a web browser interface, which is read-only, to the newsgroup so you could just see what's going on easily.  And we're old-school NNTP news server.



TOM:  Yeah.



STEVE:  We don't have a web forum.  So you need to use something like Thunderbird, or I'm still using Gravity on Windows, which is my favorite.



TOM:  Nice.



STEVE:  There's one called NewsTap for iOS that I like and I use on my iPad.  That works great.  And then, yeah, we have a really, really great group of people who are working.  And of course I'm sure that I'll talk about this next week with Leo.  We'll see what's happened in a week.  I'm going to try to get these pages finished.  And then we'll sort of see how it goes.  But that's what this is.  So far, after a bunch of crypto-savvy guys have looked at this over the weekend, we made some improvements and changes to my original concept, better understood the nature of attacks, and it's still standing.  And I wish this existed.  This is how I would log in and use my authentication across the Internet.  It's just got a huge number of benefits.



TOM:  Absolutely.  I mean, it basically makes what I do now a whole lot simpler.  So if I can have an extension on the laptop that I use and trust, right, that's better than LastPass.



STEVE:  Yes.



TOM:  It's the same as LastPass.  It's an extension.  But it has so much more to it.  And then I've got an app on my phone for when I'm on a computer that I don't trust.  And that's the same as having that Google Authenticator app that I have except, again, it does so much more and makes it so much easier.  I'm really pleased with this.  The other reason that I'm pleased with this and excited about it, Steve, is the chatroom, as they always do, is going to take potshots at this all the way through.  And between me and Sparkyman was in there answering questions as well...



STEVE:  Oh, good.



TOM:  ...I don't think there was a single objection that was brought up that we didn't have, yes, he's thought of that; yes, he's getting to that; it's at this part in the documentation.



STEVE:  Yeah.  Yeah, I know.  I think it works.  I think people are going to be going, oh, my goodness, I mean, this works.



TOM:  The only surprise I had was two people who said, "I had a very similar idea that I pitched to X company, and they said, sounds great, but it's not in our strategy right now."



STEVE:  Yeah, well, see, and that's just it.  This is not something someone can own.  One of the items I have on the first page down low, down toward the end, is did I invent something?  And I answer my own question, and I say, I don't care.  I mean, arguably, I'm sure there are people who say, oh, you know, you need to get intellectual property protection on this.  I have formally and officially said, here.  This is an idea.  It was a good cup of coffee that I had that morning.



TOM:  I want that cup of coffee.



STEVE:  You know, let's see if the world wants to run with it.



TOM:  Yeah, absolutely.  No, I think this is great.  And like you say, even if similar ideas have been floated before, they don't exist.  And what you're pushing for is let's make this happen, let's make this exist.  Here's an architecture.  And you've bullet tested it.  That doesn't mean it's done, but...



STEVE:  It's why it being so low friction matters.



TOM:  Yes.



STEVE:  When I say "low friction," I mean that it is so much better from the user's experience that there will be push for it.  It is so simple architecturally that a single guy who writes mobile web apps or mobile apps can implement it.  I didn't talk about the crypto, but all the crypto is there.  I use Dan Bernstein's, it's called Curve25519.  It's an elliptic curve crypto.  Notice that one of the requirements of this is that you be able to have a pseudorandom-generated private key.  That's different than RSA, where you use a pair of primes, and you use the product of a pair of primes.  There's no way to deterministically arrive at those from the hash function.



So one of the enabling features that I didn't talk about specifically, it's all documented already on those three pages, is that the output of that HMAC secure hash function is this 512-bit pseudorandom number.  That's your private key.  So we need cryptography which is able to accept any pseudorandom number as a private key and compute the public key and then sign something under the private key, and all of that's been worked out, too.  There's existing code, all public domain in source, for every single piece of this.  So basically all of this is already open source, public domain technology.  We've just got to glue it together.



TOM:  Well, this is fantastic.  And folks should go check this out at GRC.com/sqrl, if you're interested, as you put up all the pages.



STEVE:  Actually two SQRLs, /sqrl/sqrl.htm.  I wanted to give it its own directory to live in.



TOM:  Gotcha.  So sqrl/sqrl.htm.  You're right.  Of course you're right.  But I'm just like, I just tried it and got a "page not found" the way I did it.  So, yes, GRC.com/sqrl/sqrl.htm, no "l," and take a look at it.  Go to that feedback page if you want information on how you can further investigate this, implement this.  There's certainly lots of other stuff going on with QR code.  Somebody just put a link to an old Verge article from this summer about Google messing around with QR codes for security.  As Steve said, this is not - that's not the point.  The point of this is all of this stuff, as Steve just mentioned, is already available, free and open source.  It's just putting it together and making it work.  And hopefully some patent squatter doesn't try to come along and claim they invented it.  But that's always a risk with anything you do on the Internet.



STEVE:  I did look at what Google had done, because of course when I came up with this I thought, wait a minute, how can nobody have thought of this before?



TOM:  Right, right, uh-huh.



STEVE:  And so I spent a couple days really looking hard.  What Google did was they had an interesting idea, not this one at all.  Their idea was they would provide a QR code.  You would then snap that with your phone, and the login would jump off, essentially, off the page onto your phone.  So it was a way of, like, transporting the standard login over to your phone, and then you'd do the same thing you normally did.  It's like, okay, I'm not sure why that's better.  And of course it wasn't, and it died.



TOM:  That's just borrowing the system they use for Chromecast to send video links, which don't necessarily need to be secure, back and forth.  And just sending the login URL, that's different.  GRC.com also for SpinRite, for all the other freeware and services and research and everything that you do.  I mean, this is the thing that you've been up to.  Is there anything else to mention before we take off?



STEVE:  No, I'm sure I'll be focused on this until I get back to working on the next version of SpinRite.  And I should mention that, since SQRL is not an often-occurring string, I would bet that a week from now you just put it into Google, and you'll probably be able to find GRC's pages.



TOM:  Okay, that's a good point.



STEVE:  So I think it'll take you right there.



TOM:  Excellent.  Thank you, Steve, as always, for the show and for the great information, and for doing this.  I think this is fantastic.



STEVE:  Well, let's hope it happens.  I want it for myself.  I think it would be a great step forward.



TOM:  TWiT.tv/sn if you want to get the show notes and all of that stuff, as well; and GRC.com for all the great work Steve does.  Thanks, everybody.  And Steve, once again, thanks for allowing me to fill in for Leo.  It's been great fun these past three weeks.  Really cool.



STEVE:  Has been.  And it worked so well that I'm sure Leo will feel free to take a vacation again.



TOM:  I'm sure he will.  Thanks, everybody.  We'll see you later.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#425

DATE:		October 9, 2013

TITLE:		SQRL Q&A #176

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-425.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Following up on last week's "SQRL - Secure QR Login" podcast, this week's Q&A focuses upon the many interesting questions Steve's description of a new approach to secure website login sparked in the minds of the podcast's listeners.  And, of course, we also catch up with the week's news.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We're going to have a follow-up on his amazing SQRL technology.  We'll answer your questions, too.  I'm back.  Steve's back.  Let's talk.  Security Now! is next.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 425, recorded October 9th, 2013:  SQRL & Q&A #176.



It's time for Security Now!, the show that covers your security, your safety, your privacy online, with the - are you - did you just have a muffin?  What?  Steve Gibson's wiping his mouth off here.  Oh, okay, coffee thermos.



STEVE GIBSON:  That's my coffee thermos, and I wiped a drip off.



LEO:  Steve Gibson's here, the Explainer in Chief, the man behind SQRL.  Steve, I've been gone three weeks, and you announced a massive, major new initiative.



STEVE:  Yes.



LEO:  Last week.



STEVE:  Yes.



LEO:  By the way, was it Iyaz or Tom?  Who filled in for me?  Was it Tom?



STEVE:  Tom did all three.



LEO:  Thank you, Tom.



STEVE:  And there was just so much pressure that we were getting from our listeners that, I mean, I wanted - I thought it would be fun to do it.  But then I thought, well, I can get you both.  I can do it with Tom, and then I can do it with you.



LEO:  That's quite all right.  No, no.  I would never want you to hold back.  IBM used to do that.  They would hold back technologies because they wanted to have something for next year.  And I think that's reprehensible.  If you've invented something, if you've innovated something, then why hold it back?  And you know what I love about SQRL - and I want you to explain it a little bit to me, for those who missed last week as I did.  But what I love about SQRL is you're not encumbering it.  You said this is patentable, it's a novel idea, but I'm going to give this to the world.  And I think that's great, Steve.  Thank you.



STEVE:  Yeah, well, I mean, there may be some parts about it that are novel.  And I'm sure if it came from the typical corporate syndrome there would have been attorneys scouring it, looking for little nooks and crannies to say where it was innovative.  One of the things that's happened in this past week, it's hard for me to believe it's only been a week because it's just been an amazing reaction, just phenomenal.  I created a newsgroup at GRC on our news server one week ago, in the morning before last week's podcast.  And we're at over 1,100 postings.



LEO:  Whoa.



STEVE:  There's a page now of projects that are underway among the SQRL pages at GRC.  So a bunch of people are immediately racing to implement this on Android and iOS and web server platforms, in every language you can imagine.  I've even been contacted by the W3C, the HTML5 spec editor, who says authentication and login is like a serious problem, no one has solved it yet, this looks wonderful, let's talk.  So...



LEO:  So let me see if I understand it.  And sometimes paraphrasing is the best way.  It is a way of using either QR codes or some other secret that's shared, authenticating yourself to web pages without giving - anonymously, effectively, without giving the web page any other information about you - right? - and not using a third-party service.  This is a transaction just between you and any - let's say, let's pick a website.  Let's say Google decided to implement this, which would be wonderful.  Then I would just - this is what I - explain if I've got this right.  I would go to Google and say, okay, whip out your phone and snap this QR code, and then I would be logged in.



STEVE:  Right.



LEO:  What?  How does that work?



STEVE:  So, okay.  The shortest way to say it is that you take a combination of your own sort of like grand master secret key, which is never used online, never leaves anywhere.



LEO:  So it's the equivalent of a private key in a public key cryptography system.



STEVE:  No.



LEO:  No.



STEVE:  No, because there you have a matching public key.  This is an absolute secret that is just - it's randomly generated, just pure randomly generated.  And it's yours.  And one of the questions that we have today is, well, what if someone else got the same one?  So, because in a large population of people, as we know...



LEO:  That's going to happen; right.



STEVE:  ...there's the birthday attack problem, which is where it's surprising how few people you need to have for any two of them to share the same thing, like they have the same birthday and so forth.  So there's only 365 days in a year, so there's that many possible birthdays.  How many people do you have to have together before any two of them have the same birthday?  And the number is smaller than people suspect.  But it turns out that's not a problem here.  So you get this incredibly random large number which you never disclose.



LEO:  Okay.



STEVE:  That's - it is never disclosed.



LEO:  It's kind of like your - is it like your Bitcoin address, kind of, sort of?



STEVE:  Actually, it's very much.  Bitcoin is also 256 bits.  I changed that, by the way, since last week.  We dropped it from 512 to 256 just because...



LEO:  It's plenty, yeah.



STEVE:  ...there was no need for 512 bits.



LEO:  Now, with Bitcoin you could generate multiple addresses.  Can I do that, as well?



STEVE:  Yes, you can.  And so you can have multiple users, essentially, defined in one little app.  But let's take the case of one user.  So you've got this 256-bit, absolutely random thing that is uniquely yours.  What this does is it combines that with the website domain, like Google.com.  And then it uses that, it uses the combination of your super secret and the website domain where you're going to create an asymmetric key pair, to create the public and private key. 



LEO:  So it's like a hash of the two?



STEVE:  It does.  It uses actually an HMAC operation, a Hashed Message Authentication Code, which is just, like, it's an extra-secure kind of hash.  It just uses hashing operations a couple times to do essentially the same thing, but it's a little stronger in some ways than just a hash because there is a vulnerability potentially because the domain name is being hashed with your secret key.  It's better to use a message authentication code where it was just keyed by your secret key, and then you use that to hash the domain name.  It's just technically better.  So it creates a little more isolation for, like, things the user could control, like the domain name going into the hash.  But so the idea is, armed with this unique key, every website you use generates on the fly a unique asymmetric key pair.



And the point is that since your super-secret master key never changes, every time you come back to that website, you get the same asymmetric key pair, a private and a public key.  Now, what we do with that is simple, really.  The QR code that you mentioned, a phone can snap it, can scan it.  And we simply take that and sign it with our public key, and we send that signature and the public key to the site.  So the public key is our identifier for that site.  So, for example, every time we go to Google we generate the same key pair, and so we're going to have the same public key.  So we always look exactly the same to Google.  It doesn't - we're completely anonymous.  It knows nothing about us except this is our token.



And but then the other cool thing is, since we've signed the QR code with our private key, and we sent that along, Google is able to verify the signature with our public key, which is our identity, which proves to Google that we the person who has this public key also have the private key because we just signed the QR code that we were given.  So it's very simple.  There's, like, no extra moving parts.  Everything is tightly locked together.  Yet what this asserts is that the same person coming back to the site any time in the future is the person that was originally identified.



LEO:  As long as you keep control of your private key.



STEVE:  Yes.  Yes.  And that's one of the most important things.  There's been fabulous discussion, for example, like people said, well, what about revocation if a key gets away from me?



LEO:  Oh, good one, yeah.



STEVE:  And so it's absolutely true that there are things we're giving up when we cut out a third party.  And that's the other issue is that all of these other authentication- identification systems...



LEO:  You're talking about things like Facebook Connect or Google Connect or...



STEVE:  Well, yes.  But also there are, like, there are committees and authentication proposals in the works.  And there are so-called "federated identity systems," more like the VeriSign deal where remember that the original football that we talked about years ago, this is my little PayPal football.  Well, when I give the number to PayPal, PayPal gives it to VeriSign.  So VeriSign is a third-party authenticator.



LEO:  Ah, okay.  Is that true - that's not true of Google Authenticator.



STEVE:  No.  But, see, the problem with Google Authenticator is that it's a - there you do have a shared secret.  I've got that secret token that runs the sequence in my phone, and Google has the same secret that runs their sequence so we can make sure that we agree.  Now, while that's nice, and it is two-party, that is, there's no third party, the problem there is we have a shared secret.  There is something for Google to lose.  And the beauty of my approach is there's nothing for them to lose.  They don't have a secret of mine.  All they have is my identity, which is only valid for them.  Because it comes from their web domain, when I go to a different website, I present a completely different identity in no way connectable to the identity that I have for Google.



So this creates a unique identity for every website on the Internet.  Yet every time you go back, you're the same as you have always been for that site.  And so, for example, the reason - what's happening with Google Authenticator and the increasing number of sites that support it, is now we end up with a whole - with a growing list of six-digit numbers that are all changing.  Why can't we use the same one for multiple sites?  Well, we're back to the same password problem.  And that is, Google, I mean, people's databases are being hacked all the time.  We just had a huge Adobe breach where they lost 1.2 million of their user accounts.  So again, you have to, if you're going to share a secret like a password or like your authenticator, then there's the problem of you needing to have separate ones for each site and managing them separately.  Here there's no shared secret.



LEO:  Okay, good.  I'm sorry.  You paused.  Do you have two different coffee cups?  It looks like you're double-dipping there.



STEVE:  I have this little cup and a warmer.  And then I've got my thermos is where the coffee comes from after having been transferred from the coffee pot.



LEO:  So as I remember, you kind of had - this all came to you in a flash, like Archimedes in his bathtub.



STEVE:  I was having coffee at IHOP while I was having breakfast, of course, on a Thursday morning about six weeks ago.  And this was kind of like, oh.  I mean, it's like, wait a minute.  And I thought, well, okay.  Does this work?  And so I thought about it for a few more minutes.  And then I decided, like, it seemed to.  So I kept it to myself for about a week or two while I was continuing to work on wrapping up this phase of work on SpinRite.  And then I just - I couldn't - I said to the guys in the SpinRite development newsgroup, I said, okay, look.  I have to confess I'm being distracted by something.  We're going to get this work we're doing now finished.



LEO:  SQRL.  It's well named, I might add, yeah.



STEVE:  What?



LEO:  SQRL.



STEVE:  Yeah.  SQRL, yes.  Now, one of the things that Tom mentioned, one of the first things he mentioned was, but what if I don't want to use my camera?  What about just logging in with my laptop?



LEO:  Well, that's the question.  What does it require for me to participate?  First of all, and this might be the biggest hurdle, websites have to adopt it.



STEVE:  Yes.  Well, okay.  So that's the other thing is that there's been some confusion.  One of the things, the reason I consider this a low friction for adoption is, first of all, it's all open source.  It's all open spec.  It's all just there.  It's also very simple.  I mean, we're going to have apps, implementations of this, a few weeks from now.  So...



LEO:  There's already a Chrome extension.  So, I mean, it's moving fast.  It's moving fast.



STEVE:  And it's funny because I made a comment yesterday, or last week, I was wondering how long it would take Google to figure this out.  And it was four hours, I think, from the podcast moment where you put SQRL in, and bang, Google knows all about it.



LEO:  They scan it fast.  So, all right.  So presuming there's adoption, and there are good reasons to adopt it, what does it take for me to participate?  Do I have to have a smartphone?



STEVE:  No.  That's one of the first things we looked at was how do we eliminate the phone?  Because a lot of people like the idea of the phone as a second factor, a physical second factor.  And, for example...



LEO:  I love it.  I use it at whatever site offers it.  It's great.



STEVE:  Yes.  Now, imagine in a library or a public kiosk.  What this literally lets you do is snap a QR code that's being displayed on a computer you do not trust.  And without entering any of your credentials, you're logged in.  So, I mean, so that's really a change.  That's really cool.



LEO:  And there's no leakage of information at that point.  I mean, I could - nobody can come to that terminal and figure it out or anything like that.



STEVE:  Correct.



LEO:  I walk away with my phone and, boom, we're done.



STEVE:  Yes.  That whole computer and its connection got none of your information.  What happened was that, from its viewpoint, spontaneously, you were logged in at that site.  It just kind of happened behind its back.  So, again, it has no secrets to disclose.  There's nothing for bad guys to get, no keystrokes to be logged, no malware to catch anything.  It's just done.  But many of us sitting at our computers at home, we have laptops and so forth, yes, we have a phone by the front door charging, and we'll use it when we're out and about, but right now it'd be nice just to be able to authenticate with our computer.



The effort that's underway is for an app to be installed, like any other app, which registers the SQRL scheme, in the same way that HTTP - if you click a link on your computer which has HTTP, your computer knows to launch the web browser and give it that link to display it.  If you click a link that says "mailto," your computer knows your email client should be launched in order to start up a mail note.  So, similarly, an SQRL app on desktops, desktops and laptops and, in fact, tablets, for example, it would register the SQRL scheme, which is what those first letters are called.  So when on your desktop you go to Google.com or Amazon.com or whatever, and you see this little SQRL QR code, you click on it.  You don't use your camera.  You actually click the little SQRL QR code because it is also a link.  It's an optical link.



LEO:  Okay, yeah.



STEVE:  But it's also an HTML link.  So you click on it, and that launches the little authenticator which is on your computer in the same way that your web browser is or your email client is.  This is the little SQRL app.  So it launches it, giving it that link.  And so it is then able to handle all the authentication for you.  And again, you just leave the login form blank and click "Login," and you're logged in.  So it is, again, completely seamless authentication.



LEO:  Wow.  You know, it reminds me a little bit of - have you looked at Duo Security?  This is a multifactor system that LastPass is using.



STEVE:  I haven't.



LEO:  It's interesting.  It's a new option on LastPass.  They've added, in addition to YubiKey and Google Authenticator, something called Toopher, Duo Security, and Transalt [ph].  I think it's Transalt.  But the way Duo works is when I open LastPass on a phone, the Duo app on my other phone that's been set up with Duo gives me an alert, and it says, hey, somebody's trying to log into LastPass on this device.  Do you want to allow it?  I say "Allow," and all of a sudden I'm on.  It's very magical and mysterious, and I don't know if it's related or not.  But it feels like that.  It would be - so would LastPass be able to use something like this as a second...



STEVE:  They could, yeah.



LEO:  So it is, it could be used as second-factor authentication.



STEVE:  Absolutely.



LEO:  Yeah.  I'm not sure I completely understand it.  But well, here's the good news.  It's completely described in great detail on your website at GRC.com/sqrl.  And people can read about it.  And how has the adoption been?  I mean, it is only a week old, but people are...



STEVE:  Okay.  So it couldn't be any, I mean, it couldn't be happening any faster.  I was planning on continuing to flesh out the pages that I had been working on.  For example, there is a page about attacks where I've enumerated all the different sorts of things that I can think of and anyone has been able to think of that could go wrong.  And so that was the next thing I had planned to work on.  The problem is we've got about 20 people that, like, want to write it right now.  And I said, uh, okay, uh, okay, wait.  And so I've switched over to - in fact, if you look, there's a Projects and Implementations page where I'm following all of the projects that have been created.  There's about four or five of them on GitHub and various other places.  So I've switched over to - there's something called "Implementation Details" page, which is up now, which I spent Monday and Tuesday working on, the last two days, because I need to present a proposed protocol because people insist on writing code right now.  And so what will happen, Leo, is that short - oh, and I should tell our listeners that I am going to write one.



LEO:  Oh, good.



STEVE:  I will - I'm going to write...



LEO:  You need to at least write a reference one.



STEVE:  Well, yeah.  I'm going to write a reference Windows, because I'm not a mobile platform developer, but I am a Windows coder, as everyone knows.  I will write a Windows and Wine, so anyone with Wine, any Linux people, a reference implementation for the desktop and Windows laptop and Wine laptop application that will be, of course, it'll be in assembler, so it'll be 2K bites long.  It'll actually be a little longer than that because I'm going to have to bind in some libraries for the crypto.  But it'll be super small.  I will, of course, sign it with GRC's Authenticode certificate and make it available.  So there will be mine.  But there will be a whole bunch of them.  We're going to guarantee interoperability.  And so the clients will be there.  There's already a Drupal...



LEO:  I saw that.  That's great.



STEVE:  ...and WordPress plugins are coming.  So the clients will all be free, and they'll just be there.  And so as websites adopt this, people will begin to use it.  And an example I gave was, like, how many times have we gone to a place where someone has done an interesting blog, and you think, oh, it'd be fun to contribute to that.  Well, but the thing wants you to go through all of this...



LEO:  Rigmarole, yeah, yeah.



STEVE:  ...account creation rigmarole.  And so sites are losing all kinds of valuable input because it's just too annoying to have to, like, identify yourself.



LEO:  And so we face that.  And the way we do it, and it's not completely satisfactory, but we will use Facebook Connect, or Google+, or there are a number of these; right?  And that makes it easy because you already have a Facebook account.  And you see this on apps, too.  You just say, yup sign in with Facebook.  The problem is that Facebook's getting all that information.  So this would be a similarly simple way to log in...



STEVE:  One on one.



LEO:  ...but no one else gets it.  Just it's between you.



STEVE:  Yup.



LEO:  And there's no man-in-the-middle issues with this.  I mean, it sounds pretty good.  You're using SSL, of course, in the transaction.



STEVE:  There's also no NSA in the middle.



LEO:  Yeah, we like that, too.



STEVE:  And, see, all these other, like, all these other authentication technologies that are sort of out there churning and haven't really happened yet, they are so-called "federated identity."  There's people like VeriSign or someone, I mean, there's a so-called "authentication service" that you authenticate to, and then the site authenticates to, and so you can cryptographically assert that you are who you are.  But so can the NSA then offer them a national security letter and say we want to know all the sites that this user has been going to, has been logging into.  I think the day has passed where anyone is willing to trust a third party because we now know how vulnerable they are to, unfortunately, our own federal government.



LEO:  Yeah.  So this is very timely in that respect.



STEVE:  Yeah.  Yeah, we'll be talking, there was some news about Ladar Levison and exactly what happened with Lavabit.



LEO:  Oh, yeah, yeah.



STEVE:  Oh, our worst fears were - actually came to pass.



LEO:  Well, I didn't want for - I apologize to everybody who listened last week, I didn't want for you to completely recap the show last week.  I just wanted kind of the executive summary of what SQRL is.  And I know this is a Q&A episode.  We're going to have a lot of questions about it, as well.



STEVE:  Yeah.  There have been - lots of interesting issues have come up.  My sense is, I mean, I have no horse in this race.  I just sort of - you know as well as anyone, Leo, I have been focused on authentication as THE problem...



LEO:  It is.



STEVE:  ...that needs to be solved.



LEO:  It really is.  There's no question about it.



STEVE:  I did Perfect Passwords, Perfect Paper Passwords, Password Haystacks, the Grid, whatever that thing was, the Latin squares, Off The Grid system?  I mean, it's just - it's been on my mind.  And so here was like, wait a minute, this solves a class of problems where a site wants to collect anonymous connections.  And people have said, well, sites want to be able to leverage who you are and market to you and don't want you to remain anonymous.  Well, they're sort of confusing two things.  This provides the identifier token.  But then they could still have you fill out forms and email addresses and first and last name, I mean, whatever it is...



LEO:  Oh, yeah.  They could attach stuff to it if they wanted to.



STEVE:  Absolutely.  But it's not necessary.



LEO:  That I like.  So I have to say it's very intriguing.  And unfortunately, like a lot of good ideas, it requires a groundswell of support from everybody.  I think the need is clear, and I think the idea is good.  I just hope that everybody goes, okay, yeah, we'd like to do this.  You know, you get a few major - you know, the problem is that neither Google nor Facebook really wants anything like this because they've got their own solutions which give them information, and they want that information.  We have to demand this, frankly.



STEVE:  Yeah.  And again, it could be easily added.  Look how long it has taken sites to finally adopt two-factor authentication.  I mean, one of the stories today is that Evernote just finally added second-factor authentication, after that massive February breach that they suffered.  And they promised to do it, and they're finally rolling it out today.



LEO:  What?  No, no, they've had it for a while.



STEVE:  Evernote?



LEO:  Yeah.  I've been using it for at least a month.



STEVE:  Oh, okay.  I just saw the story that they...



LEO:  Yeah, no, no, no, it's been going on for a while.  And it's great.  And I use it.  And in fact it uses, which I love, Google Authenticator.



STEVE:  Yes.



LEO:  So it makes it very easy for me to add, yeah, sure, I'll add another layer of authentication.  It's not a...



STEVE:  Yeah, now, if they - if you were all - if the world had evolved a little differently, and you were already using SQRL for other sites, and Evernote added SQRL, then it'd be like, oh, look, I can...



LEO:  Yeah, there'd be some incentive, yeah.



STEVE:  Yeah.  So anyway, I mean, my role here is we'll get a spec out.  We'll create a bunch of apps.  I mean, I want to get back to SpinRite as soon as I can.  But this exists, and we just need to nail it down, make it real, and then see what happens.  I mean, it's a proposed alternative for  authentication.  What I can say is our listeners all got it.  I mean, it was phenomenal what the reaction was.



LEO:  Well, but they know you, and they trust you.  And we have to get the greater world to do the same.



STEVE:  Well, and it may take a while, which is fine.  My app will exist.  Other apps on other platforms will exist.  Mobile platform apps will exist.  There it will be.  And then it will be users beginning to bug websites, I want to be able to authenticate with SQRL, go support it.  And people will be creating all of the web-side...



LEO:  It should be very easy for sites to do.  That's one of the advantages Facebook Connect has.  It's just a line of code, or Google Connect.  It's a line of code.  It was very easy for me and others to, even without a big IT department or programmers, to just add that support.  And when both Google+ and Facebook added this, uptake was very quick, almost universal.  But so I would love to see that.  I mean, it would be just great to see, I think.  But Facebook is never going to do it, and Google's never going to do it, because they want to collect information.  And this is a separate, you know, this kind of deals them out of the loop, potentially.



STEVE:  Well, they did Authenticator, and there's no...



LEO:  That's true.



STEVE:  ...information being collected there.



LEO:  No, and I believe Google's - I believe at least Google, maybe not Facebook...



STEVE:  Well, and Google is actively looking at this.  I mean, they're working closely with Yubico and Stina and the YubiKey. 



LEO:  Oh, good.  Oh, good.



STEVE:  They've got pilot projects and things.  And in fact they did play with QR code login briefly.  A couple years ago, for like about a month, there was something where you could - that you could - they would present you with a QR code.  You could snap it, and the login sort of jumped over to your phone.  It took it away from the website over to your phone.  And it's funny, too, because there have been - I've been flooded with people saying, oh, Gibson, this has been done before.  And then they'll send me a link to something which has a QR code, but that's the only thing it bears in common.  So I also have...



LEO:  This is unique, as far as I can tell.  There's nothing like this, yeah.



STEVE:  I do have a page of all of that other stuff that people are finding, just so it has a place to live, so I can say, yeah, we've seen all of that, and none of it is the same.  There's even been some people saying, like showing me patents.  And if you look at the diagram on the patent, it's got 26 different things all pointing at each other.  And it's like, okay, look at my picture, and look at their picture.  There's just no comparison.



LEO:  All right.  So thank you.  And I apologize for everybody who's already heard all this.  Steve Gibson, Leo Laporte.  Before we get to questions and answers, let's get some security news.



STEVE:  Well, we are, as you mentioned, we've just passed the second Tuesday of the month.  This is one of those earliest Tuesdays it could be because the first Tuesday of the month was the first of the month, this being - wait.  Yeah, yeah.  So yesterday was the 8th, and today's the 9th.  So we have eight patches from Microsoft for their October surprise. 



LEO:  I like that, the "October surprise."  I like that.



STEVE:  Repairing 26 unique identified vulnerabilities.  Of these 26, 17 were remote code execution, six were elevation of privilege, two were denial of service, and one was information disclosure.  Microsoft is beginning now to prioritize these for administrators because they recognize there is friction on the part of IT companies or IT organizations in large companies because there have been mistakes made before.  So Microsoft says immediately patch numbers 80, 81, and 83.  Then you should also do 82, 84, 85, and 86.  And the least important is 87.



LEO:  Yeah, well, of course, as always.



STEVE:  So we had Internet Explorer that had nine privately reported execution vulnerabilities.  That's obviously...



LEO:  Nine?



STEVE:  Nine.  Ten memory corruption vulnerabilities when parsing specially crafted web pages.  And this is the update that fixes that active exploit that was being patched in the wild where there was a Fixit that I tweeted a couple weeks ago and recommended - the way I said it, for anyone who must use Internet Explorer, if you're using it, you probably ought to apply this Fixit because there's no patch yet.  So this is - this was patched in this month's Patch Tuesday, so do that.  Also there was a kernel mode driver problem in font parsing causing memory corruption, and a use-after-free vulnerability.  Seven privately reported vulnerabilities there:  two remote code execution, and five were elevation of privilege.  Problems in the .NET framework.  Problems back in the old Common Control Library, the old comctl32.dll, a problem was found.  Also in SharePoint Server, Excel, Word, and Silverlight.  So it's a grab bag, one of these big months, and definitely worth updating your Windows, especially because we've got 17 remote code execution vulnerabilities in IE.  Oh, and several of them are being exploited in the wild now.  So that puts an edge on the need to update.



LEO:  No kidding.  Wow.



STEVE:  Now, I tweeted - this hit the news days ago.  And The New Yorker did a really nice four-page piece summarizing what our friend Ladar Levison went through with the shutdown of Lavabit.  As our listeners will well remember, he was gagged and unable to say anything about what had actually happened.  And so there was that frustration, that he couldn't even tell us.  And what he posted on his site when he shut down his pseudo-secure email service was that he could not in good conscience keep it open lest he be committing a crime against the people of - all of his customers who were using his service.  So he chose to shut it down.  He was threatened by law enforcement for the act of shutting it down, which that was a little galling.



So I'm not going to read this piece.  It's long.  But I did tweet it recently, and I recommend it.  In fact, I gave it a bit.ly shortcut:  bit.ly/grc-lb, all lowercase, as in Lavabit.  So grc-lb will take you to this nice New Yorker piece.  But here's, in summary, what we learned:  They did demand that he turn over his SSL certificate.



LEO:  As you had speculated.  They wanted him to stay in business, to be basically fully compromised, and have no one know it.



STEVE:  Yes.



LEO:  So his decision was, look, either I continue to run, and every single person who has an account on my site will be open to the feds, an open book, or I just shut down.  And he had no choice.



STEVE:  Yup.



LEO:  And he couldn't talk about it.



STEVE:  Yes.  So he was gagged.  First he said, look, I can't hand over the master keys.  Basically it's the master keys to his business is the way to think about this.  I cannot.



LEO:  So he didn't do that?  He didn't give them?



STEVE:  Well, not initially.



LEO:  He kind of had to; right?



STEVE:  He said, for $3,500, paying me just for my time, I will write the code you want to give you the access to the individual whose account you want to monitor.  I will provide you with that access.  They said no.  We want everything.  And he said no, I can't give you anything.  The judge then sanctioned him $1,000 a day...



LEO:  Oh, my god.



STEVE:  ...until he complied with a court order to turn over the keys.



LEO:  And he can't say - he can't tell.  Can he get a lawyer?



STEVE:  He had a lawyer working with him.  And his lawyer, of course, was bound by attorney-client privilege not to disclose.  So, yeah, he...



LEO:  Nobody did say anything about this.



STEVE:  Nothing could be said publicly.



LEO:  This is happening completely in secret.



STEVE:  Yes.  So the only way we know all this finally is a court did release some of this information.  There was a court order to release some documentation.  Then we got some information.



LEO:  He in his farewell said, I can't tell you.  I have tried, I think he said three times, to get permission to tell you what's been going on, but I can't.  Well, apparently he did subsequently get some permission.



STEVE:  Well, so, yes, and that was just recently that he was able to get some permission.



LEO:  Oh, my god.  Well, I'm glad I paid for 10 years of Lavabit right before he closed down because that's gone towards his legal defense.  He deserves some help on this.



STEVE:  Well, so what he finally did, because he had this thousand, I mean, he's not a rich person.  He was doing all right, but - so he printed out, in text, in four-point type, and it took 11 pages, his certificate key cryptography.



LEO:  Here [laughing].  You want it?  Here.



STEVE:  He gave it to them.  He gave it to them, and they were not happy.



LEO:  No.



STEVE:  They complained that this was...



LEO:  We can't read this.



STEVE:  ...nearly illegible.  In four-point type it could not be OCR scanned.  Someone would have to manually type in 11 pages of incredibly tiny text characters.



LEO:  That's like paying your taxes in pennies, basically.



STEVE:  And one single mistake made anywhere would render it completely useless.  And his attorney said, well, there it is.



LEO:  There you go.



STEVE:  You wanted it.  And so then they upped it to $5,000 a day and held him in contempt of court, upped it to $5,000 a day, and a couple days later he shut down Lavabit because he said, sorry, I can't do this.  In fact...



LEO:  Did that get him off the hook?  I mean...



STEVE:  I think he gave them the keys and unplugged the servers and wiped them.



LEO:  You can have the keys, but I'm going to take the car.



STEVE:  Precisely.  It was, here are the keys, sorry there's nothing for you to plug them into any longer.  No more traffic will be encrypted using those keys.  So that was the story.



LEO:  I hope that he can get away with this.  I mean, I hope that this doesn't cost him - are they still prosecuting him?  Or are they just unhappy?



STEVE:  They're not happy.



LEO:  That's fine.  I don't want them to be happy.  They should be miserable.



STEVE:  Yup.



LEO:  But I want him to not have to pay $5,000 a day or go to jail.



STEVE:  So in the story it says, he says, "It was the government's insistence on collecting the SSL keys that most deeply disturbed Levison and led to the shutdown of Lavabit.  He believes that not only would the FBI have had unfettered secret access to the communications of his 400,000 customers without being required to give Levison a log of what it accessed, but putting his encryption keys in the hands of the government would have opened Lavabit to a more profound exploitation of his service's communications.



"Levison worried that, if he turned the keys over to the FBI, the NSA would have been able to obtain them without his knowledge through a Foreign Intelligence Surveillance Act court order.  We know now that the NSA has been systematically cracking encryption across the web.  And it has built a database of encryption keys that automatically decode messages.  This is dangerous, Levinson said, because it allows the NSA to read encrypted communications as they flow past the agency's taps of the broader Internet infrastructure by simply observing them, leaving no trace of the surveillance, unlike traditional man-in-the-middle attacks.



"This vulnerability, he insists, is not sufficiently understood.  And while the Times' initial reporting indicates that the NSA's method of obtaining the keys for its database is shrouded in secrecy, Levison suggests that his case also illustrates one of the ways in which it collects them, by secretly compelling companies to turn them over."



LEO:  Now, presumably they've done this to other companies, other people.



STEVE:  Exactly.



LEO:  Who haven't had the integrity to step forward as Ladar did and say I'm not doing it.



STEVE:  Well, and who also have shareholders.  As was observed when this occurred, Ladar was able to say no and give them the finger because it's just him.  I mean, he was able to make the decision unilaterally to give up 10 years of his life building this service because of his own integrity.  But no CIO or CTO or COO or CEO could do that.  They'd just be fired by the board.



LEO:  Now, companies like Facebook and Google have said, well, I don't know if they've categorically denied this particular thing.  Have they?



STEVE:  Well, remember that email companies don't have a problem because email is almost never encrypted.  And so my original hypothesis is that PRISM could simply tap upstream of Google...



LEO:  Right.  We know they're doing that, by the way.  Thank you, Dianne Feinstein.  Senator Feinstein inadvertently last week said that they were doing that, in public testimony in the Congress, in the Senate.  So thank you, Dianne, for letting us know.  She's, of course, on the Senate Intelligence Committee, confirming what you've said all along.  In fact, Steve, you have been right about this all along.  This is exactly what you presumed was happening with Ladar Levison.



STEVE:  Because ultimately it's all driven by technology.  As I said, it's about - it's the politicians are scratching their head, trying to figure out what to do.  There will be somewhere there's policy.  Ultimately, it's about bits and math.  And so we can - we understand bits and math here.  And so we can say this is what's probably ultimately happening.  Where the hardware meets the software and the data passes through it, this is what's going on.



LEO:  Yeah.  Wow.  Wowie zowie.



STEVE:  So, but the ultimate takeaway is we now know that companies have been, we know of one specifically, have been asked by the federal government to divulge their SSL keys and have had to decide what to do.  Ladar said no.  Major companies cannot say no.  So maybe, if you parse the exact terminology of the CEOs of these major firms, they don't consider giving their keys up working with the federal government.  I don't know how you parse that.  But it is certainly what the NSA wants.



LEO:  Just makes me weep.



STEVE:  Really, it almost makes - I remember when I read this the first time I was a little queasy.  It's like, oh, crap.



LEO:  Well, we should just assume this happens, and that the NSA now has all - there is no secure SSL traffic.  But this doesn't mean that PGP is not safe.  And really this is why the only really safe way to do email is using PGP or GPG or some form thereof.



STEVE:  So while we're on the topic, I will take this a little bit out of sequence.



LEO:  By the way, just to the Evernote authentication, that is now available to all Evernote users.  It was premium users only.  That's why I thought - so I'm a premium.  Of course I pay for Evernote.  And so I've had it for a while.  But everybody can get two-factor authentication.



STEVE:  What I remember reading was free users now had this, but paid users also have something else.  There was some other level of or type of authentication.



LEO:  Well, I must check.



STEVE:  Which wasn't free, I think, for Evernote to offer.  Whereas authentication, the Google authentication style, as we know, is just two-party and is free.



LEO:  Evernote's just fabulous.  They've just added the ability to edit PDFs in Evernote.  I mean, it's just a great tool.  I've put it on every single device I have.  And that's a lot of devices.



STEVE:  So I have a sci-fi alert.  I know nothing about this.  But tonight, and for those who don't listen until tomorrow or Friday, also re-airing Friday night, is the premiere of a new series called "The Tomorrow People."  It has an eight out of 10 ranking on IMDB.  The short description is "The story of several young people from around the world who represent the next stage in human evolution, possessing special powers, including the ability to teleport and communicate with each other telepathically.  Together they work to defeat the forces of evil."



LEO:  That sounds like heroes.



STEVE:  Yeah, it's heroes mixed with jumpers mixed with a couple things.  Anyway, I don't know what it is.  Greg Berlanti is one of the main guys behind it, and he brought us "Everwood" and "Brothers & Sisters" and "Dawson's Creek."  So take that for what it's worth.  I liked "Everwood" and "Brothers & Sisters" a lot, actually.  And this is on the CW, so maybe it's going to be bubblegum.  I don't know.  I'm just saying it's there.  So for anybody who's interested, maybe we'll have something.  It was based on a much older British series by the same name, "The Tomorrow People."  I think it was back in the '70s, like really old.  And so we'll see.  Maybe they've updated it and will give us something good.  My recorder will be recording it, and so we'll know.



Speaking of the NSA, I got a bunch of tweets from people because I have several times talked about how much I like the series "The Good Wife."  And remember, Leo, that many people were recommending it, and I was saying, what?  I'm not watching something called "The Good Wife."  That just doesn't seem like my kind of thing.  Well, I love it.  But even if anyone has never seen an episode, go find last Sunday night's.  It was Sunday, October 6th.  The whole thing, well, okay, three quarters was the NSA listening in on conversations.  It was really funny.  They just having - they had a huge amount of fun with this, with two geeky 20-somethings, each with these big workstations and data streaming in and eavesdropping and networking people, and, oh, now they've got permission to go from two stages removed to three and so forth.  Anyway, I got a bunch of people brought it to my attention even before I had seen it because it was sucked in by my DVR, but I hadn't watched it yet.  Anyway, it was really fun.  So if you're at all curious, you want to see a show, the first one that I've seen really having fun at the NSA's expense about all of this kind of eavesdropping, "The Good Wife" Sunday, October 6th episode was great.



Now, I was also trying to save any mention of this specifically until you got back, but we had a light news week last week, and so I thought, well, okay.  And that is that Jenny just had a book published.  I knew you'd get a kick out of it, Leo.



LEO:  Oh.  Congratulations, that's great.



STEVE:  It's a children's book titled "Is God Real or Pretend?"



LEO:  [Laughing] I love it.  And what's the answer, by the way?  I'd be curious.



STEVE:  Well, it's comparative religion for kids.  She has a character, Benjamin, and he's got a dog because Jenny's a big dog person, who has, like, his grandmother, Dr. Wendy Knowles, I think, who he talks to about this.  She's a professor of astronomy.  And he goes to somebody else.  Anyway, he ends up meeting through the - it's not long, I think it's 66 pages - meeting the major leaders of the world's five biggest top religions - Hindu, Buddhist, Jewish, Christian, and Muslim.  And they explain their religions to Benjamin.



LEO:  Oh, that's neat.



STEVE:  Oh, it's...



LEO:  So it's kind of open-minded.  It's not saying yes or not.



STEVE:  Oh, yeah, yeah.  And apparently our listeners love it.  They've been buying the book.  They've been - multiple copies.  Several...



LEO:  Is it on Amazon?  Where can I get it?



STEVE:  It's on Amazon.  And in fact I wanted to ask our listeners, if you did buy it and liked it, of course we all care about people's opinions.  And so if you could take a moment to go back and add a review to her site or for the book, that would be great.



LEO:  "Is God Real or Pretend?"



STEVE:  Or pretend.  I just love the title.  I just, you know, it just - I got a kick out of it.  And then Jenny said, "You didn't tell them that you designed the cover."  It's like, okay, well, that's really not relevant.



LEO:  You did the cover?  Wait a minute.



STEVE:  The concept.  An artist did the cover.  But I came up with the idea.



LEO:  It's a kid looking through a telescope at the world.



STEVE:  Well, and remember the picture, that painting in the Sistine Chapel where there's a human sort of with an outreached hand, and God has reached down and is sort of touching fingers.  Well, so that's what's in the - up in the moon or whatever it is he's looking at, is sort of that interaction.



LEO:  Oh, it is, it's the Sistine ceiling.  I just noticed that.



STEVE:  Yeah.



LEO:  Yeah.  Well, that's cool.



STEVE:  But anyway, that was my idea.



LEO:  It is in paperback, $13.45, available from Amazon right now by Jennifer Horsman - H-o-r-s-m-a-n - illustrated by Julie Leimann Weaver, "Is God Real or Pretend?"



STEVE:  And Jenny also said, she said, "Steve, there's also been a spike in my other books."



LEO:  I didn't know she wrote books.



STEVE:  Oh, she was a bestselling author.



LEO:  What?



STEVE:  She was doing romance novels.



LEO:  Oh, "Forever and a Lifetime."  Holy moly.  Did you do the cover on this?



STEVE:  No, no, they're five-star - they're, like, when she and I got back together, she sort of mentioned that.  And I said, what?



[Talking simultaneously]



STEVE:  No, she had Fabio on the cover of one of them.



LEO:  It looks like Fabio.  It does.



STEVE:  No, it was.



LEO:  It is Fabio.



STEVE:  She had THE Fabio was on the cover of one.  Anyway, apparently there has been a spike in the sale of those, which are, now, they're out of print, but they are available on Kindle also.



LEO:  She also wrote the "Vegetarian Weight Loss Plan."



STEVE:  She did.



LEO:  But "A Kiss in the Night," "Magic Embrace," "The Ice Queen:  A Christmas Romance," "Passion's Joy."  Wow.  And "Please Don't Eat the Animals."  "Virgin Star," "Awaken My Fire," "Passion Flower."  Holy moly.



STEVE:  But apparently they're good.  I have not, I have to confess, I have not read any of them.  But I was curious, so I went...



LEO:  You know, just a word of advice, man to man, don't read them because, if you do, then you have to give an opinion.



STEVE:  Yeah, well, other people have.  And they're, like, breathless, like this is the best, you know, when are you going to write more?  I mean, people are just going nuts over her romance novels.  So I said, well, yeah.



LEO:  And she's all yours.  Well, are you a lucky guy or what?  Does she wear bodices?



STEVE:  What?



LEO:  Nothing.  Moving on.  All right.  Let's go.  We've got questions.  You've got answers; right?



STEVE:  Yep.



LEO:  Yep [nonsense riff].  These probably have a lot to do with SQRL.



STEVE:  They all do.  In fact, we can skip the first one because he was just asking, he says he loves the SQRL idea, but he doesn't have a smartphone.  So we've covered that.  You will be able to use desktop clients.  Oh, and other advantage of the desktop client, because people have asked about browser plugins to do SQRL, well, first of all, browser plugins are kind of scary because they're in the browser, and you wonder about the browser's security.



LEO:  Anytime it's a binary ball, you've got to worry about it.



STEVE:  Well, and the beauty of this is, since we'll register the sqrl:// scheme, then you install one client, and then all of the different browsers in your machine get to share it.  So you have the advantage of it being outside the browser, separately; and, if you have Windows, written probably by me in assembler, and signed, and done.  Or in other platforms for Windows and Wine, and I'm sure people will do one for Mac, too.  But the advantage is - and it's cross-browser, and everybody gets to share that one.



LEO:  Cool.  All right.  Well, then, we'll go to, well, credit, by the way, actually that wasn't any one person.  Many users, it says.



STEVE:  It was many users, yes.



LEO:  So we'll go to Hojune Kim with a question about usability:  I heard you talk about SQRL.  While my interest is piqued, I do have a question about its usability.  If the master key is heavily encrypted on the device, wouldn't the users have to decrypt the master key every time they want to authenticate?  If this is so, SQRL would never be as usable as you describe it.  The user experience wouldn't be just scan a QR code and be done with it.  It would be scan a QR code, type an ultra-strong password on the phone.  Pain in the butt; right?  Only then would they be logged in.  So no smoother than using Keepass or LastPass on mobile.  Have you thought of this?  Thanks.  Of course you have.  Of course you have.  What's your answer?



STEVE:  Okay.  Of course.  And you and I haven't, in our start of this, discussed the question of passwords.  That's the other note.  If you think about it, nowhere in what you and I talked about for the first half hour did I mention passwords because the system doesn't need a password.  That is, the security of the SQRL system itself is perfect just using public key crypto.  No password.  But the security of your phone we know is not perfect.  And so what we need is we need a way of having the SQRL app in your phone authenticate you.  It has no problem authenticating itself to all the websites in the world.  And people are very casual with their phones.  It's like, hey, can I borrow your phone for a second?  You hand them to people.  Kids play with their parents' phones.  And so we need to lock access to the app itself in a way which is strong, however strong the user wants.  So, I mean, they could define a weak password, if they chose to, for their phone, I mean, and understand the consequences of using a weak password.



LEO:  So what you're basically saying is you secure the phone, and then the app is on the phone, and so that's your choice is how you secure the phone.  And if you've got an iPhone 5, for instance, you're in luck because you could use the fingerprint scanner, and that's pretty good.



STEVE:  Well, see, and you just - right.  And you said "pretty good."  Is it good enough?  Maybe it's good enough.  It's really up to the user how complex a password they want to use.  No matter what your password complexity, we use a password-based key derivation function, PBKDF.  We use a memory hard one, Scrypt, so that it is immune to acceleration by GPUs and FPGA arrays.  So that when you enter your password, it has to think about it for one second.  That's not long.  But the beauty of that is, it is an algorithm to decrypt your password that cannot be sped up, that takes one second per guess.  So even if a bad guy breached your phone security and got the contents of your phone, your master key would be encrypted by a technology that resists acceleration so that they would be limited to one guess per second.



Now, unfortunately, if you used "himom" or "monkey" or something as your password, well, it's going to be on a password list, and it may still not take them that many seconds, even at one guess per second.  So you'd still want to use a good password.  But so we basically, we're solving the problem as much as we can.  It's up to the user to decide, like, based on their environment.  If it's a school teacher, and she hands her phone around to the kids in her classroom every day, well, that's a very insecure use of her phone.  If you're in a bunker in some way that your phone never - you would have never to worry about your phone being compromised, then you could back off on how strong you want your particular SQRL password to be.



LEO:  So if I put it on an iPhone, like this is the iPhone 5s, I currently have it so that when I put my fingerprint on it, it unlocks it.  And but you could add a long password to that.  Can you add - could you - I guess there's no app, so we don't know yet.  But you could, in theory, as LastPass does, add an additional password to unlock the SQRL app; right?



STEVE:  Well, yes.  Oh, and that's exactly the idea is - and so we've had a couple different ideas.



LEO:  Because I choose, for instance, I keep my password in LastPass so I don't have to reenter it every time.  But I put a PIN in LastPass.  So you'd have to unlock my phone, and you'd have to know my PIN on LastPass, and then you could get my passwords.  And I consider that sufficient, but it isn't the only way to do it.  You could make it much more secure, if you wish.



STEVE:  Remember that the difference here is we're using LastPass because we have given up.  We're using LastPass as a database of all the different passwords we use.  This, if this were adopted, ends that.  You only have one password to prove who you are to the app.  And then it handles across the entire Internet worth of authentication for you with that one password.  So what's different here is one password is all you need.



Now, another thing we're considering that will probably be a feature of the app is when you first use it, for example, after unlocking it, you would have to enter your entire long secure password which protects you against hackers getting your phone.  That's its purpose is, I mean, because if someone's guessing on your keyboard, well, there'll be a five-guess lockout.  Obviously it's going to say, sorry, and wipe the key so that no one can access it.  So the idea would be the first time you use it after unlocking it, you have to say this is really me and enter a long password.  But then, if you haven't used it for some length of time, or you've switched back to the app, or who knows what rule we could have, then you only have to enter the first four characters of your super long password in order to say, yes, it's still me who wants to authenticate now to the site.



The point is you're giving it a lot of power.  It has the power to instantly log you into every site where you are using it as your authentication.  So that does need to be protected.  And it's still the case that something you know is the best protection.  Remember that the authorities can force you to put your thumb on your iPhone 5s Unlock button.  They cannot force you to give a password.  That's considered testimony.



LEO:  Isn't that funny?



STEVE:  It's self-incriminating testimony against yourself.



LEO:  Yeah.  I thought that was quite interesting, yeah.  Okay.  Moving on, Clay Cross with a tweet.  He says:  Why does SQRL use domain names to generate the private key?  Wouldn't using a SQRL ID be better, like using a hashtag versus a domain name?  Like a keyword, an AOL keyword.  Somebody in the chatroom asked the same question, or a similar question:  What happens if a website changes its domain name?  Doesn't this screw it up?



STEVE:  Right.  So, and I think we actually have that question later on...



LEO:  Oh, sorry.



STEVE:  ...because that has come up.  But that's a great question.  The reason is that that is the way the site identifies itself to the Internet.  I mean, it's relying on DNS.  We know, I mean, DNS security is something that a lot of attention has been given to.  We've talked about DNS spoofing.  I've got my whole DNS spoofability thing.  Dan Kaminsky famously found that there was like a lack of entropy in the way that ports were being used on DNS servers.  I mean, so DNS has a long huge history of, like, we understand the security of it.  It is generally extremely secure.  So that's the thing that cannot be changed.



If a website made up an ID, like for themselves, then some other evil website could use Amazon's ID, and you would be generating your authentication for Amazon and giving it to the evil website, which it could then use to log on, to impersonate you to Amazon.  So it is we bind - the way to talk about this is that the user's identity presented to a website is bound tightly to that website's name.  There's a one-to-one binding between the user's identity and the domain name so that any change to it changes their identity.  So that brings up the next problem, and we'll skip over that question when we come to it because we've already asked it in the chatroom, and that is, what if a site changes its name?  Well, that's a problem.



LEO:  Well, you just have to reauthenticate with the new site.



STEVE:  That's what you would have to do.



LEO:  Like if you changed your name.  I mean, you've got to...



STEVE:  Yeah.  So normally, if a site wanted to change its domain name, it's because it's come up with a better one.



LEO:  Right.



STEVE:  And so first of all, notice that no one ever does.  I mean, Amazon is never going to change...



LEO:  It's rare, yeah.



STEVE:  Because of the huge reputation cost of changing that name.  But typically they could hold onto the old one and start using the new one preferentially.  Now, in that case, if someone authenticated to their new domain, they would say, oh, we've never seen you before because you would be unknown under that new domain name.  And so but they would know they're in transition, and they would say, if you have an account with us, please scan this SQRL code so we can link you.  And so they would present the SQRL code for the old domain.  You would scan it, and they'd go, okay, and they'd just transfer your identity over.  So all of these problems can be solved.  I mean, there are problems created by the simplicity of this, but that's also what makes it so robust.



LEO:  Yeah.  I don't think these are - these are not intractable problems.  These are completely...



STEVE:  No, they're not showstoppers.



LEO:  Not at all.  @jmwhitty on Twitter tweeted:  For SQRL, why not just add a server-signing component to prevent evil site session - let me say that again - evil site session jacking.  And it says:  Steve, talk all about the antispoofing, antiphishing work.



STEVE:  So a lot of time has been given to the question of phishing sites because, for example, you could go to EvilSite.com, and it could say hi, and present you with a SQRL code, saying this is the code to log on.  But it could be showing you the SQRL code from Amazon.  That is, when you went to their page, it could have gone to Amazon and pretended to want to log on.  Amazon would have given it a logon page with a SQRL code, which it in turn shows to you.  So when you scan that code, you're actually authenticating yourself to Amazon, but you're authenticating the login session that the evil site started.



So we solve that problem by showing the user on the screen of their smartphone or on the user interface of their app, if they're using a desktop or laptop, we show them, you are about to authenticate to www.amazon.com, meaning you're about to provide your credentials for Amazon.com.  Well, you'd say wait a second, I'm at EvilSite.com.  I'm not giving EvilSite.com my credentials.  So we do need to show the user the domain name in the SQRL code because it's a QR code.  People can't read those.  Machines can read them.  So we show that to confirm this is the site they think they're on that they intend to authenticate to, and then they move on.



Now, the other possibility is that you're at Amazin.com, that is, it's the phishing case where you believe you're at Amazon, but you're actually not.  So there are two things that we're able to do.  One of the other possibilities is, see, what we want to do to block phishing attacks is we want not to allow a phishing site or a man-in-the-middle site to acquire our credentials.  Now, I'll note that going to Amazin.com or Amazon.cn or something, that presents you with a perfectly normal looking Amazon.com page where you type in your username and password, this is a standard phishing attack.  So it would be nice if SQRL had some way to defeat that, but it's sort of - it's, like, not our problem.  I mean, it's like, well, okay, this is a problem with logging into a site that pretends to be something that it isn't.  This is a problem we've always had.  It turns out that we actually do get some leverage, though, because what we can do is we can - what we want to prevent is this evil site session from being logged in, so that it's logging in as us.



Well, we can ask Amazon to return to the client a logon link, that is, a link to a logged on session, rather than logging on the session that's displayed the SQRL code, so essentially cutting the spoofing site out of the loop completely, cutting this phishing site out.  We then click on the link in the app, and it gives us a logged-on Amazon page.  And so it actually is complete protection against phishing for the first time.  And this is all being written up on the site.  So I know that it's - I'm running it out quickly because I'm looking at the clock, and we're not making much progress here.



LEO:  That's all right.  That's all right.  I think this is also, for some people, difficult to understand.  And so a lot of the questions that are coming up are questions that come from really mostly like, I don't get it.  As opposed to you, you know.  So we can - I don't want to give them short shrift, but read up.  Read more.  Go to GRC.com/sqrl.  All will become clear, Grasshopper.



STEVE:  Yup.



LEO:  Rich Baldry wonders about poor server implementations.  He says:  SQRL's a great idea, sounds pretty sound, and I like how you've already started to collate potential attacks or weaknesses to get everything out on the table.  And by the way, I do want to say this, and I'm sure people know this, but I'll say it again, the whole point of this, in going public with this, is to have it be vetted.



STEVE:  Yes.



LEO:  You're not saying, oh, this is the answer, it's done.  You're saying, hey, look at this, security gurus, experts.  Take a look.  Bang on this.  Let's find out what's wrong with it.  So you're certainly not, you're not saying, hey, it's perfect.  We want to find what's wrong with it.  If there is.



STEVE:  It's one week ago.  It survived the weekend, where some crypto guys looked at it before last week's podcast.  It has survived the last week of, I mean, we're getting 12,000 hits a day on the SQRL page at GRC.  So it's come to people's attention.



LEO:  So, as an example, Rich says, one weakness I don't think you've covered, risk of a poor server-side implementation of a random number generator, as you've discussed often.  You can trust the math, but the implementation may not be so good.  I can see in extreme cases that could create QR code collisions which could mess up the login process.  Would it also allow an attacker to analyze the encrypted data sent by the client and potentially discover the private key of users?  Would it even be a route for a malicious site with a specifically designed random number generator to attack the system?  Also, why does the site-specific key need to be derived from a user's master key and the domain?  Oh, this is kind of like that previous question.  Why not just use another random value for that key?  If there is no need for the site-specific identities to be related, why create this relation?  Well, it is.  That's the whole point.



STEVE:  Yes.  And so I'll just finish that last point first.  What Rich is sort of saying, and a number of people have asked this question in different ways, well, why not just make up a random key for every site you visit?  And then the problem is you have a database of random keys that you are required to never lose or forget.  The beauty of this is everything derives from one master key.  And I don't know if you picked up on this, but we have a way of exporting those from, like, out of phones into - by using a QR code.  So, Leo, if you started to use it, you could have the phones face each other...



LEO:  Oh, that's good.



STEVE:  ...and transfer the master key from phone to phone.



LEO:  Here's my master keys.  Oh, that's great, yeah.



STEVE:  Yes.  And also printed out on paper so that you're able to physically back up your identity, put it in a safety deposit box, put it somewhere safe,  so that if anything ever happened, if the phone got lost, well, you just install your master key into a replacement phone.



LEO:  You know, this reminds me of SuperGenPass, which I've used for years, which hashes the website URL with your master password and creates a unique password for every site you visit that can easily be recreated.



STEVE:  Yes.  In fact, it's funny because I remembered you talking about this after I - when I was, like, deep in the documentation.  I thought, you know, I remember Leo talking about something, I didn't remember what the name of it was, that did use...



LEO:  I've used it for years.



STEVE:  Yup.  And so basically we're talking about that tied to - where instead of a password - see, the problem with a password is a password does not have enough entropy.  And we're coming to a question about that in a second, which is really interesting.  But to answer Rick's question here, or Rich's question, random number generation on the server.  Remember that there's a so-called "nonce," an n-o-n-c-e, which is crypto speak for a number used once, nonce stands for number once, where the idea is there's a random value in this QR code which is what we're signing and sending back to the server to prove that we have the private key that matches the public key that we have given the server as our identity.  The identity is our public key.  The signature is our proof that we're the owners of the matching private key.



So it turns out that the requirement for randomness is not very extreme.  For example, say that a really, really bad server implementation never changed the nonce, it used 12345678910; okay?  So the risk is a replay attack because every time we signed that, the signature would be the same.  So even though we're using SSL to send that back to the server, an employee could capture it.  Someone maybe could hack somehow like an SSL proxy, man-in-the-middle attack of some sort.  I mean, again, my point is that the only danger is of a replay.  So it behooves the server to change that every time.



But in the spec we're working on, and it's called "Implementation Details," and there's a lot of it already there on the website that wasn't there last week, we, the client, add our own nonce, as well, specifically to protect against this case.  So if a poor server or even a completely broken server were giving us the same SQRL code every time, we're appending our own nonce, which will not repeat, in order to guarantee that the signature we're sending is different every time.  So we've solved that.



LEO:  In other words, it doesn't have to be that robust.  The requirements [indiscernible] that necessary.



STEVE:  Correct.  It actually isn't - there's not a huge problem, if it just used an incrementing counter.  It just has to be different.  



LEO:  Right, yeah.



STEVE:  Its predictability is not a problem.  It just has to not be the same thing we signed before, or an older signature could be used as a current signature.  By using a counter, that's prevented.



LEO:  Prevents replay attacks.  All right, Steve.  Our next question comes from Mr. Tickle [laughing].  I hope he's somebody's boss, and that that person says, "Yes, I have to ask Mr. Tickle if I can do this."  Steve, I wonder - he's got to be British; right?  I wonder if you considered implications of this SQRL with rapidly advancing augmented reality technology.  Maybe Daniel Tickle is his Second Life handle.  Mine is - you know what mine is?  Pruneface Spatula.  I'm not kidding.  I wish I were.  While phones and tablets and such will be very handy, with upcoming devices like Google Glass and Meta (Spaceglasses.com), this would be a perfect method of authentication when dealing with such a hands-off technology.  Oh, I like this.  You look at a web page, you look at a QR code, and now you're logged in.  You don't even have to pull out the phone.  You just look.  I'm here.  It's a wonderful idea.  I hope SQRL gets the attention it needs and deserves.  Had you thought about that?  That's great.



STEVE:  I just thought that was a cool idea.  You're right, it's a - yeah, yeah.



LEO:  I can see people doing that.  Kehnin Dyer wonders about master password one minute unnecessary.  I don't know what that means.  Let's read.  Why, he says, is it necessary to have offline verification of proper decryption of the master QR code to get your master secret?  In my mind, silently failing, that is, generating a real, but not YOUR, master code is a much better option.  The only way to verify the key was properly imported in this case is to try to log into a website that has your credentials.  If it fails, well, that's not it.  This makes it an online attack.  It also makes having your QR master code no better than random guessing master codes to someone without your password.  You're going to have to figure out what that means.  I have no idea what he's talking about.



STEVE:  Oh, fortunately I do.



LEO:  Good [laughing].



STEVE:  So what we decided was that, if you export this super-secret master key in any fashion out of the app, it needs to be deeply encrypted because bad guys could get it.



LEO:  Right.  That's a weakness.



STEVE:  Yes.  And so the idea is that we use this PBKDF function with Scrypt where we require a second of authentication that is processing, essentially, decrypting a second of decryption when you type it into your phone.  To encrypt and then decrypt an exported version is 60 seconds.



LEO:  Oh, that slowdown.  I get it.



STEVE:  Yes, yes.



LEO:  I get it.



STEVE:  So that any time that code is outside of your phone, if you've printed it out, it will require 60 seconds of constant crunching per guess for a single password entry to be decrypted and then turned into your code.



LEO:  That really effectively prevents brute-forcing.



STEVE:  It completely does.  It makes it absolutely impractical.  And there's no way around it.  But part of what is exported is a check to see if you've entered the right password.  So what this questioner is asking is, well, the check is what allows it to be brute-forced, even though it takes a minute, he says.  And he's saying why even bother with that?  Why take a minute?  Why not just use whatever password the user puts in?  Technically you could.  That is, the password is mixed with a secret key, and that generates the proper identity.  But from a usability standpoint, in terms of like regular moms and dads using this thing, they would enter a password.  And if they made a mistake in entering it, if there wasn't the ability to check the password, then it would say, okay, fine, but then the site wouldn't know who they were.



LEO:  It just wouldn't work.  Or it would think you're somebody else.



STEVE:  It would be, yeah, you would be someone else.  And so we decided we have to verify the password for usability.  But an option, when you export the password, is not to include the verifier.  Then it's on you.  If you're someone who you don't want the verifier in there, it's like, okay, that's fine.  But you'd better enter it right, or it's not going to work.  Now, there's one problem, is there's another way to verify.  Kehnin was saying that it had to be an online attack.  It turns out that's not the case.  If you've got any authentication for a user, their use of SQRL on any website, then you've got that site's domain name, and you've got their identifier, their public key for that site.  That's all you'd need to run an attack, trying every possible password to see if, for that domain, you get the proper public key.  So there is an offline brute-forcing attack that does not require you to actually use the Internet except just once to capture one authentication for one website.



So we've come to the conclusion that the right thing to do is just deeply encrypt this so that it takes 60 seconds to decrypt it, and let the user know, whoops, sorry, that was the wrong password, we'll tell you a minute from now, and then try again.  I think we found the right set of interactive, like, tradeoffs.



LEO:  Sounds good.  You've obviously thought about this a lot.



STEVE:  It's all I've been doing, Leo.



LEO:  Murray McEwan wonders about online forum user culpability and the anonymous poster, to wit:  If this SQRL makes personal identification unnecessary, would this have the effect of increasing slanderous and hostile postings by anonymous users who feel they are safely hidden?  I don't even want to go on.  I would think that a scrupulous forum manager would still want traceability of users who post on his forum, and this means some sort of account set-up of the forum posters would be required.  Yes, that's right.  Also, hey, can SQRL help defeat spambots and spammers who want to sign up on forums?



STEVE:  So this has actually come up a lot.



LEO:  No, it's good to answer the question.  I agree.



STEVE:  Yeah.  It has come up a lot.



LEO:  It's kind of obvious, but okay.



STEVE:  Yes, well, but the idea is that I'd promoted it last week, and even in the teasing weeks before, as anonymous.  I mean, it is.



LEO:  Well, it allows anonymity.  But it's not a requisite.  I mean...



STEVE:  Correct, correct.  So, for example, it's a token that never changes that represents a user.  A forum could require nothing but it, or they could still require an email address loop confirmation, or, more probable, a CAPTCHA.  I mean, you might still require a CAPTCHA.  Or you might use a CAPTCHA just once per ID, per SQRL ID.  And as long as it's not abused, as long as there are not too many incoming posts, then you would, like, not require a CAPTCHA every time.  What this does is it provides a secure assertion of who you are to a website.  What they choose to do with it is up to them.



LEO:  It doesn't change any of the stuff that a website would normally do.  It could, or it doesn't have to.  Just as Facebook Connect, same thing.  I mean, this is all - yeah.  This is not new stuff.  Now, I do find the spam question interesting.  Is it possible, it would be, wouldn't it, to robotically generate these logins?



STEVE:  Yes.  So it does, yes, it does nothing to defeat spam or spammers.  You could just invent keys and just come in as a billion different individual people.



LEO:  In fact, that might be a little bit of an argument against it because it would in fact make it easier to automate mass logins.  You could log into a site thousands and thousands of times.  A site would still have to implement some sort of antispam technology.



STEVE:  Well, yeah.  And remember that the first thing that's going to happen is it's going to say, I don't know you.  And so you then say, oh, crap, so you need to know me before I can post something.



LEO:  Right.  But that's up to the site to do.



STEVE:  Correct.



LEO:  Obviously, yeah.



STEVE:  So right now, if a site had no login requirement, spambots could go crazy.



LEO:  Anyway, right.  It just means they can go crazy faster.



STEVE:  Actually, it doesn't change the speed of crazy.



LEO:  No.  They're still pretty fast, yeah.



STEVE:  They can go just as fast crazy.



LEO:  The speed of crazy.  What is the speed of crazy, after all?



STEVE:  We answered No. 9 already.



LEO:  Changing domains, okay.  So let's go to No. 10, John in Illinois.  He wonders about not saving the key:  What if the SQRL password on the phone was used to generate the key each time so that there would be no key for an attacker to get?  Multiple people could use the same SQRL app under the same device but have different SQRL passwords every time.  Also, every password entered would generate a QR code.  The attacker would not get a failure message and would have to try each QR code on the website.  Is this a good addition to your excellent idea?  What say you?



STEVE:  So, okay.  So to paraphrase that, John is suggesting that the password that the user chooses is their identity for a given site.  So I choose a password.  That is hashed with the domain name to create the key.  Sort of interesting, if it was impossible for two people ever to use the same password.



LEO:  Which of course is ridiculous because...



STEVE:  And that's the problem.  We already know most people use "monkey," having followed your excellent example.  And so...



LEO:  Hey, I use "monkey123," get it straight.



STEVE:  So we obviously need more entropy because what we don't want is a collision.  And as I mentioned at the top of this, the "birthday attack" is what this has been famously named because there's only 365 birthdays possible.  And I think it's, what is it, is it 23 is the number?



LEO:  It's a very low number.



STEVE:  Surprisingly low number where...



LEO:  But that's not - so it's not like, if you say, hey, whose birthday is November 29, that's not what we're talking about.  Two people in the room having the same birthday, it needs only be around 23 people before it's almost certain that two of them will have the same birthday.  But you don't get to say which birthday it is.



STEVE:  Yes, exactly.  Nor...



LEO:  That's kind of a critical thing to understand.



STEVE:  Yes.  But that is this problem because, for example, how many people would it take before two of them might have the same password?



LEO:  Right.  And it's a surprisingly low number.



STEVE:  Probably five.



LEO:  It's not 365, yeah, right.



STEVE:  Yeah.  Okay.  So our question that we're posing is  we're using a pseudorandomly generated master key.  And in my proposal, in the case of a smartphone, we use entropy from the platform, from iOS or from Android.  But I also have the person wave the phone around, and we stream data in from the camera.



LEO:  Brilliant.  Love this.



STEVE:  Yes.



LEO:  And this is just a reference implementation.  Others could do something different; right?



STEVE:  Yeah.



LEO:  But this is a nice idea.  I like it.



STEVE:  Yeah, because it absolutely frees you from the possible lack of entropy or NSA involvement in the pseudorandom number generator in the phone and generates the key.  So yesterday, preparing for the podcast, I posed a question to my gang, fabulous group, over in the newsgroup.  And I said, "Gang, would someone like to do some birthday collision math?  What we really want to know is, for a given number of people, what is the statistical chance that any two of them have the same public key identity for any single website, which would be an identity collision at Amazon or Facebook or whatever, which is the same as any two having the same identity master key, since both are 256 bits."  I said, "As we know, assuming 2^256 randomly distributed master key identities," okay, so 2^256, that's how many bits - there's 256 bits in the user's super-secret, like, grand master key.  Okay, well, that ends up being 116 times 10^75.



LEO:  And that's because the key is so long.



STEVE:  Well, because it's 256 bits.  How many...



LEO:  Yeah.  The birthday thing, there's only 365 chances, possibilities, 366 with leap year.



STEVE:  Right, right, right.  So 2^256 is equal to 116 times 10^75.



LEO:  It's good.



STEVE:  So that's, okay...



LEO:  That's a big number.



STEVE:  ...116 and 75 zeroes.  It's huge.



LEO:  It's more people than have been alive in the lifetime of the world and then some.



STEVE:  Well, okay.  So I said, "That many total possible public key identities," I said, "as I understand it, a rough estimate of the number of people required for there to be a 50% chance of collision is the square root of the size of the total key space."



LEO:  That's right, yeah.



STEVE:  In our case, that's simple, since the square root of 2^256 is 2^128.



LEO:  Yeah.



STEVE:  I said, "So in order for there to be a 50% chance of two people having the same identity master key, we would need to have 2^128 users on a single website.  So that's 340 times 10^36 people, all using this system on a single website.  And then there's be a 50% chance of a collision."



LEO:  That's only a 50% chance.



STEVE:  I know.  Exactly.  I said, "What I think would be very useful would be to see the collision probability calculation for the Earth's current population."



LEO:  Yeah.  If all seven billion people logged into the same website, what's the chance of a collision?



STEVE:  Yes.



LEO:  Pretty low, I guess.



STEVE:  If everyone on Earth were using SQRL, what would be the chance that any two would have the same identity master key?  So one of our great contributors, Sam, posted.  With a 2^256 key size and seven billion keys, he used the same population figure you just cited, the odds of a collision are one in 4.73 times 10^57.



LEO:  I don't even know.



STEVE:  The entire population of the earth, one in 4.73 times 10^57.  I'm sure there's the same...



LEO:  That's sufficiently unlikely.



STEVE:  ...chance of a huge asteroid...



LEO:  Oh, much bigger.



STEVE:  ...hitting within the next five seconds.



LEO:  Oh, much bigger, yeah.



STEVE:  Than that.



LEO:  I think we're safe.



STEVE:  So then...



LEO:  I love that.



STEVE:  ...Taylor jumped in, and he said - oh, somebody responded, how many people will have to sign up for there to be one collision?  Just wondering from the perspective of a non-math genius.  And Taylor, who's a very crypto-savvy person, said for there to definitely be a collision, definitely, 2^256 plus 1; right?



LEO:  Yeah.  Right.



STEVE:  Because every - you could have 2^256...



LEO:  They'd all have to sign up, yeah.



STEVE:  ...all with a separate key, and they - one more...



LEO:  That one extra guy puts you right over the top.



STEVE:  Got to be, yep.  Now that's the guarantee.  And he cited a Wikipedia article called "The Pigeonhole Principle."



LEO:  Well, it just makes sense that's how many possible choices there are.  For 100% certainty you'd have to have one more than the total number of possible.



STEVE:  Now, not being satisfied...



LEO:  In other words, you'd have to have 366 people in the room to guarantee a birthday collision.



STEVE:  Precisely.  Exactly.  But not being satisfied with that, he said we will never - because Taylor is nothing if not thorough - we will never have to worry about that, though.



LEO:  Why not?



STEVE:  Since you can't fit 2^256 people within a light lifetime of each other.



LEO:  What's a light lifetime?



STEVE:  Well, remember this information cannot travel faster than the speed of light.



LEO:  Right.



STEVE:  So information is the limiting factor when you have a huge ball of people.



LEO:  There's just not enough bandwidth to do this.



STEVE:  Well, light can't get from one part of the diameter of the people ball to the other.  So Assumption No. 1:  A person occupies one meter cubed, one cubic meter of space.  Assumption No. 2:  The speed of light is 299,792,458 meters per second.



LEO:  Yes, we know this, yes.



STEVE:  Okay.



LEO:  Thanks to Michelson and Morley.  Okay, go ahead.



STEVE:  So, yeah, just short of three whatever it is.



LEO:  Three thousand kilometers per second, okay.



STEVE:  Yes.  So 2^256 people would then occupy 2^256 cubic meters of space.



LEO:  Yes.  That's the people ball.



STEVE:  And if you arranged them in a sphere, its diameter would be...



LEO:  Which, by the way, is the most compact way to arrange them.



STEVE:  All this ball of people.



LEO:  It's not random.  That's...



STEVE:  Big.



LEO:  Yeah, sphere.



STEVE:  Big mother ball of people.



LEO:  Yeah.



STEVE:  So that would be three times 10^25 meters diameter.



LEO:  Okay.  Got you so far [laughing].



STEVE:  It would take light, let's see, I didn't even put commas in here, so looks like 3 million, 198 thousand, 109 - wait, no, 3 billion.



LEO:  Three billion.



STEVE:  Three billion, 198 million, 179 thousand, 120 years...



LEO:  To cross the people ball.



STEVE:  ...to traverse from one side to the other.



LEO:  Okay.



STEVE:  Even then, it wouldn't matter.  He's really going to take this all the way.  Since the people in the center of the sphere would be undergoing a nuclear fusion reaction...



LEO:  There's enough mass now to actually create a sun.



STEVE:  [Indiscernible] components turned into heavier elements.  This is why it's fun to be in the GRC newsgroups.



LEO:  Taylor, by the way, you got the job at Google.  They're going to be on the phone to you right now.  That's a good one.  That's...



STEVE:  He says, I don't think they will care about their SQRL ID.



LEO:  Because they're now thorium.



STEVE:  Taylor is at Defuse.ca, if anyone is interested, D-e-f-u-s-e dot c-a.



LEO:  Oh, that's the Defuse guy.  Oh, he's great.



STEVE:  Yeah.



LEO:  Oh, that's...



STEVE:  That's Taylor.



LEO:  Yeah.



STEVE:  He's wonderful.



LEO:  Defuse.ca.  Yeah, we've talked about him before.  Oh, Steve.  What?



STEVE:  He's firexware, is his handle, but he unmasked himself a while ago as Taylor.



LEO:  That is - Taylor, well done.



STEVE:  And so are we, my friend.



LEO:  We are well done.  Well and thoroughly done.  What a fun show.  What an interesting idea.  Again, the whole purpose of this, of making it public, I know Steve would say this, is to get these arrows shooting at him, shooting at not him, but the idea, so that we can validate it.  And some arrows have more wood than others.  But pretty cool.  I'm very encouraged.



STEVE:  People have worried about what if I lost it, what if it got loose.  It's like, yes, that's a problem.



LEO:  But that's a problem with everything.



STEVE:  Well, it is.  And, see, if there was an intermediary, if there was a third-party, you could call them and say oh, I lost my SQRL ID.  Please cancel it.  Well, that would be convenient.  But it would also represent a huge liability for the NSA, who says - or I mean an opportunity for the NSA, a liability for the user, saying we want to know every time this person logs in somewhere.  So part of the fantastic benefit of this is it is one to one, and it is cryptographically secure.  There is some responsibility.  What I said in that original page was who do you want to have be responsible?  You could farm that out.  You could outsource the responsibility.



LEO:  No.



STEVE:  But post-Snowden, I don't think anybody wants to do that.



LEO:  That's the reason we need this.  We've got - that's been solved, if that's what you care about.  But this is something that doesn't have that as an issue.



STEVE:  And with that comes some responsibility.  My solution is to empower the user with all the tools they need to protect themselves, to back themselves up securely, to clone between devices, to keep people from abusing their phone.  We'll give them those tools.  With that comes some responsibility.



[Talking simultaneously]



STEVE:  ...comes really good security.



LEO:  We're assuming you're grownups.  This is a solution for grownups.  If you want to be a kid, use Facebook Connect.  It's fine.  That's still...



STEVE:  And you don't have to use this everywhere.  You could just use it on which sites supply it where you feel comfortable using it.



LEO:  Well, and it's my great hope that sites will supply it.  I mean, that's, I'm telling you, it all comes down to that.  You've got, now, I think you're going to vet - I think we're vetting it.  I think it's going to, knowing you and knowing your great group there...



STEVE:  The HTML5 editor of the W3C already has a dialogue open with me to talk about making it a standard.



LEO:  So I think the key really is to get that implemented so that sites have that.  And then they'll probably still give you Google+ and Facebook Connect and all the other ways of authenticating.  But it'd be really nice if they'd add a little QR code, a little SQRL QR code, and make that be one of the options.  I love it.



STEVE:  And my guess is people will start asking for it.  They'll say, hey, add this.



LEO:  I would.  I would.  I'll ask for it.



STEVE:  Yeah.  We'll make it easy.



LEO:  Steve Gibson is at GRC.com.  If you want to participate in this conversation, GRC.com/sqrl.  You can also ask questions at GRC.com/feedback.  You could follow Steve on Twitter:  @SGgrc.  Don't email him because he doesn't want to know.  Go to the website.  There's forums.  There's plenty of ways you can have this conversation.  He wants to have this in public, as it should be.  It should be...



[Talking simultaneously]



LEO:  ...channel, it's got to be in public.



STEVE:  We do maintain old-style, because they're great, Internet network news, you know, NNTP-style forums.



LEO:  Right on, yeah.



STEVE:  Thunderbird is a good newsreader.  I use Gravity on Windows.  And there's something called NewsTap for iOS devices which is very nice.  If you go to GRC.com/discussions, or you can just find it under Services on the main menu, that'll show you everything you need to know about how to set up and join.  We've had a whole bunch, an influx of new people, all coming onboard in the grc.sqrl newsgroup, just in the last week, who are saying, hey, I want to write some code, or I want to talk about this.  So everybody's welcome.



LEO:  You can get copies of this show there, as well.  He's got 16Kb audio for the bandwidth-impaired.  He's got transcriptions written by an actual human being, Elaine Farris, so that's really the most compact.  And a lot of people like to read along while they listen.  We have higher quality audio and even video available at our website, TWiT.tv/sn.  And of course you always can subscribe wherever you get your podcasts, from iTunes or Zune or whatever.  And in fact, do subscribe.  That way you get every episode.  You have a collection.  This is, of all the shows we do, the one that you want to have the full, the complete set.  You want all, what is it, 300 and, what is it, 400...



STEVE:  Four hundred twenty-five.



LEO:  Hmm, 420, you want all of them because it's like having the Encyclopedia Britannica.  It's just you want to have that on your shelf.  And you can always go back and say, hey, what was that Honeypot Monkey thing that we - what was it?  What was that?



STEVE:  HoneyMonkeys.



LEO:  HoneyMonkeys, Episode 1, about 80 years ago.



STEVE:  [Sighing]



LEO:  [Sighing] We do this show 11:00 a.m. Pacific, that's 18:00 UTC, on TWiT.tv every Wednesday.  Please stop by, say hi.  Thanks once again to Tom Merritt for filling in during my vacation.  It won't happen again for another year.  Or thereabouts.  I'll be watching TV tomorrow night with you, Steve.  Anything else we need to say?  I think that's it.  Thanks for joining us.



STEVE:  Yeah.  I'll be seeing "Gravity" tonight, Sandra Bullock and George...



LEO:  I hear good things.  I'm dying to see this.



STEVE:  I'm so surprised.  It looks so dumb from the previews.  It's like, oh, you know...



LEO:  I thought, how are they going to get two hours out of Sandra Bullock twirling in space?  But apparently they did.



STEVE:  Exactly.  It's, well, actually it's only an hour and a half, so the burden was a little bit lower.  But, I mean, everybody is raving about it.  So...



LEO:  All the geeks love this.  It's apparently great.



STEVE:  Jenny loves 3D, so we're going to see it in 3D, apparently.  And she was on Jon Stewart a couple nights ago.  And if we're to believe Jon, he really, really liked it, too.



LEO:  And all the geeks are loving this.  It's - I was surprised.  I agree.  But it's a great director, and who doesn't love Sandra Bullock and George Clooney and space?



STEVE:  Yes.  Yeah, exactly.



LEO:  All right, Steven.  We'll get your review next week.  We will talk then.  Thanks for joining us.



STEVE:  Thanks, my friend.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#426

DATE:		October 16, 2013

TITLE:		SQRL: Anti-Phishing & Revocation  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-426.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After following-up on a week chockful of interesting security news, Steve and Leo continue with their discussion of SQRL, the Secure QR code Login system, to discuss two recent innovations in the system that bring additional valuable features.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson has the latest - yes, another Java patch - and more information about Lavabit.  More information about the NSA, too.  What is a Ferret's Cannon?  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 426, recorded October 16th, 2013:  SQRL, Anti-Phishing, and Revocation.



It's time for Security Now!, the show that covers your privacy and security online.  Somebody in the chatroom before we began the show today, Steve Gibson, Explainer in Chief, said we should call it "Insecurity Now!" since it really talks mostly about insecure.  But not today.  Today we're going to talk about better security.



STEVE GIBSON:  Well, yeah.  Actually, this is one of those episodes where so much happened in the last week in security news that, I mean, we just - there's a whole bunch of really interesting stuff to talk about.  And in the past when we've done that we've just said, okay, we're not going to have any major topic because too much happened.  Yet there was also some news over in SQRL land, SQRL, the Secure QR code Login system, where we made some advances in antiphishing protection, which is something that people have been concerned about.  And also the issue of revocation, that is, revoking your credentials on a site, because those are both things that are - for example, because of the simplicity of the system, these things are more difficult.



For example, when you have a public key infrastructure, you can revoke a certificate.  In fact, one of our stories today is how GoDaddy revoked Lavabit's certificate once the FBI had it.  So thanks to the involvement of a third party, you can certainly achieve revocation.  But how do you do that in a two-party system?  And of course one of the big huge benefits of SQRL is it is deliberately two-party.  It is Trust No One else.  Would that be TNOE?  Anyway, we don't want to add an "E."



LEO:  2NO.



STEVE:  Just TNO.  But anyway, huge, a ton of really interesting news for the week.  And then I want to talk about some, basically some advances in the way SQRL operates, which - and my god, Leo, we're just seeing an explosion of interest, huge number of projects started.  There's even a presentation at next week's HTML5 Developers Conference at Moscone Center in San Francisco on SQRL.



LEO:  Oh, that's neat.



STEVE:  Yeah.



LEO:  Who's doing that?  Not you.



STEVE:  It's, no, I'm not doing it.  No, somebody - and then there's another, there's an annual identity conference, and it's going to be presented there, also.



LEO:  Wow.



STEVE:  So, I mean, it's, yeah, it's taking off.



LEO:  Very exciting.  Well, good.  All right.  Well, so I guess we'll start with security news.  And it wouldn't be security news if there weren't a Java update.



STEVE:  Oh, and baby, do we have one today.  This is - you want to be at Java 7, Update 45.  That's the newest one.  Fifty-one security vulnerabilities, all but one of which are remotely exploitable without any authentication.



LEO:  Oh, that's not good.



STEVE:  So 50 out of 51 are, if the bad guys know this, you're hosed, basically.



LEO:  Wow.



STEVE:  So it's just phenomenal.  And but the problem is, it is a full-feature big language that should have never been put online.  It's not a problem, as we've said often, if you have it on your desktop.  It's when Sun, and then of course Oracle continuing this, when they decided that it would be a good idea to make this a browser plugin - oh, look, just think what we can do if you can download Java applets.  You could have full Java features on your browser.



Well, listeners to this podcast know that's just not going to turn out well.  I mean, Flash is sort of a - is a subset of that.  JavaScript is a subset of even Flash.  And all of them have problems.  It's just - it is a bad idea to allow a website to run code on your computer.  That's never going to turn out well.  So, I mean, because it's so valuable, I mean, no one's going to argue that it really makes the web come alive.  I mean, it's Google's entire world is based on now running apps from them on our computer.  That's how Google Docs works, and all of - many of these cloud-based systems are working that way.  So we're not going to succeed in absolutely saying no.



But it's the reason, for example, that I wouldn't consider operating without NoScript in Firefox, is that my default is no, just as it is for every firewall now in existence.  Firewalls used to be, allow it in unless we know we want to block something.  Now all firewalls are block it unless we know we want to permit something.  And that's what NoScript does.  And when you configure it properly, it's not a problem.  Some sites don't work until you say, okay, yeah, I'll allow you to work this time, and then they come alive.  Of course, HealthCare.gov never works, whether you enable it or not.



LEO:  And it's in WordPress.



STEVE:  It's 60-some JavaScript files.  Talk about a JavaScript nightmare.  I don't even think you could permit it to work in NoScript.  NoScript would probably crash if you tried to go in and individually enable all the JavaScript that the HealthCare.gov website needed in order to function.



LEO:  No, I really want to emphasize, and I know our audience knows this, Java is not JavaScript.  They're two different things which are inappropriately similarly named.  You know, I was really peeved, just before I left, actually I guess it was last week when I got back, I needed to contact Comcast.  We're moving, and so I wanted to move.  And the only way you can move with Comcast is using their Java-based chat client.  So I had to - normally I don't have Java installed on my machines.



STEVE:  No kidding.



LEO:  So I had to install Java.



STEVE:  So it's like, all other methods of contact are now, sorry, this is...



LEO:  Well, they don't, you know, I guess you could call them.  But they really don't want you to.  And you can't do it just on the web.  You have to go through this person.  So I was just looking, and you reminded me, oh, god, I've got to turn off - because I had to allow it, and now I have to un-allow it again so that I'm not - it's just terrible.  Terrible.



STEVE:  Yeah.  So I will reiterate that, first of all, you will, by this point, you will know if you are a person who needs Java.  Whenever we talk about it, I get tweets from the Scandinavian countries that say, well, all the banks over here require us to have Java.  The good news is I've had some updated tweets that say they're moving away from that.  It's like, okay, good.  So this is something we just need to kill because here we are at Java 7 Update 45.  We've talked about how Java 6 no longer has updates, yet, okay, here's 51 security vulnerabilities that also exist in Java 6, that will never be patched.



LEO:  Wow.



STEVE:  So this is what's happening is the bad guys are seeing the mistakes which are bubbling up and being fixed in the current version.  When they look at the patch, they figure out what got changed.  That tells them what was fixed.  Then they go looking, deliberately looking, it gives them a pointer to the problem in prior versions which are not being fixed.  And of course this is the same problem we expect to be seeing when XP goes out of service in 173 days.  I have my XP counter on my Windows 7 machine.



So the only strategy, first of all, you probably by now know you need it, if you do, just as you had the experience, Leo, of needing to use it in order for a specific purpose, for a window of time, and then saying no.  The best solution, because we've all got browser choices now, is to remove it from your go-to browser of choice, that is, remove the Java plugin so that Java won't run on that browser.  And you could verify doing that.  I have, actually have a Java applet on GRC, that big number calculator which you can access at GRC.com.  It's completely benign, but it's a nice way of verifying, oh, good, it doesn't work, because you don't want it to work unless you absolutely know you do.



And then only allow Java to run in, like, your third-choice browser, your browser of last resort.  If you've got no other choice, that's the browser where you want Java to be.  That way you're not using it by mistake, and it doesn't have an opportunity because the point is normally the browser will request a Java applet by default.  So all you have to do is touch a website which is either malicious or has been hacked to install, like, a malicious ad or a malicious little tag.  The browser sees it, goes and grabs that Java code and runs it.  That's the default behavior of browsers with Java.  So it's - you just can't allow that to be.



LEO:  We must not allow it.



STEVE:  We must not.  So put it on a browser you never use, and only if you need to talk to Comcast in order to re- after you move a home.



LEO:  So frustrating.  So frustrating.



STEVE:  Yeah.  Now, speaking of frustrating, there was a really sad piece of news that is an upshot of the NSA revelations, more blowback from what Edward Snowden showed us.  And this is a news alert posted on the InternetGovernance.org site on the 11th of this month.  The headline was "The core Internet institutions abandon the U.S. Government."  This is not as significant, for example, as if the dollar stopped being the world reserve currency, but it has that feeling.  We've sort of - we've had ICANN and IANA, I mean, because the U.S. invented the Internet, we developed the technology, we basically - taxpayer money funded the Advanced Research Projects Agency, ARPA, back in the day, to experiment with the concept of packet switching.



And back in the packet-switching podcasts that we did we talked about how - what an amazing insight it was that you could achieve the same thing as dialing up your modem, as we used to in the old days to connect to a service, you could achieve the same thing with sending little packets of data that just somehow found their way to their destination, completely a different concept, which people said, "Wait, wait, wait a minute, how do I know it's going to get there?"  Well, you don't.  "But how do I know when it's going to get there?"  Well, you don't.  But it's good enough.



And it turns out if you layer, on top of that uncertainty, you layer protocols that provide for order of arrival and guaranteed arrival and sort of make up for the fact that the underlying architecture is weird, sort of nondeterministic, the whole - it actually works, and we're all using it.  So what's happened, unfortunately, is that the world has said, uh, we don't think we should leave these organizations with the U.S. anymore.  So just the first two paragraphs of this sad announcement said:  "In Montevideo, Uruguay this week..."



LEO:  Montevideo.



STEVE:  Montevideo, thank you.  Montevideo.



LEO:  Montevideo.



STEVE:  Monty's Video.  Montevideo, thank you, Leo, Uruguay, "the Directors of all the major Internet organizations - ICANN," the IETF, another one that we often talk about...



LEO:  The Internet Engineering Task Force.



STEVE:  Yup, "the Internet Architecture Board (IAB), the World Wide Web Consortium," that's the W3C that we often speak of also, "the Internet Society, all five of the regional Internet address registries - turned their back on the U.S." - I know, thank you for the heavy sigh - "turned their back on the U.S. government.  With striking unanimity, the organizations that actually develop and administer Internet standards and resources initiated a break with three decades of U.S. dominance of Internet governance."



LEO:  I'm not sure that's so bad, really.  I mean, in general, for the world, I think it's probably good.  Why should we dominate?



STEVE:  Well, no.  But that's just it.  There's - I agree with you.  This is the right outcome in the same sense that I believe...



LEO:  For the wrong reason.



STEVE:  ...having it known, yes, in the same sense that for the reason I believe having it known what the NSA has been doing is the right outcome.  But it's a black eye.  Or maybe it's a bruise.  I may be - we won't go so far as a black eye.  Maybe it's a pimple.  So, "A statement released by this group called for 'accelerating the globalization of ICANN and IANA functions toward an environment in which all stakeholders, including all governments, participate on an equal footing.'  That part of the statement constituted an explicit rejection of the U.S. Commerce Department's unilateral oversight of ICANN through the IANA contract.  It also indirectly attacks the U.S. unilateral approach to the Affirmation of Commitments" - that's capital "A" and capital "C," that's a formal "pact between the U.S. and ICANN which provides for periodic reviews of its activities by the GAC and other members of the ICANN community."  And it says in parens, "(The Affirmation was conceived as an agreement between ICANN and the U.S. exclusively.  It would not have been difficult to allow other states to sign on as well.)"  But that's not the way it was done.  So it's like, okay, well, yeah.



LEO:  Yeah, I think this is not inappropriate, though.  It's time, it was - it seemed odd that we controlled it as much as we did.  I don't blame other nations for not being thrilled about that.  So, but what happens?  Is it the U.N. now?  I mean, what is the - is there a body at all?  Or is it just these are all just multigovernmental?  Or NGO, nongovernmental?



STEVE:  Right.  They're NGOs.  They will, I mean, and they've all got committees and teams.  And so they'll just basically cut themselves loose and float off and no longer recognize even a modicum of preferential rights by the U.S., which...



LEO:  Yeah, I think that was...



STEVE:  ...arguably they used to have.



LEO:  That's a good idea.



STEVE:  And I agree with you.  I agree with you.  But we know why it happened.



LEO:  Yeah, yeah, yeah.  But, you know, there you go.  This precipitated a lot of good.  It revealed a lot; you know?



STEVE:  Yes.



LEO:  And this stuff has been floating - it's not like - the stuff Snowden revealed has been floating around for a decade.  And this just forced everybody to pay attention to it, I think.



STEVE:  I wouldn't say that, actually.



LEO:  No?



STEVE:  We got a ton of facts.  We learned a lot, Leo.



LEO:  We suspected a lot.



STEVE:  Yes.  It was in the air.  But it's very different to have slide presentations with them boasting and chuckling about what they're doing.  That's more than what we thought.  And on that note, Yahoo! on the one-year anniversary, upcoming, not yet, we still have a few months away, it will be on January 8th, Yahoo! has announced that on the one-year anniversary of allowing, that is, supporting HTTPS connections, only four years after Google did, this coming January 8th they will be on by default.



LEO:  Yay.



STEVE:  So the checkbox which is normally off will be on.



LEO:  Good.



STEVE:  Starting January 8th of 2014.



LEO:  That's fabulous news.



STEVE:  So that is, that is just, you know, better late than never, I say.  I don't know, I haven't looked at their servers to see whether they're - whether they've implemented perfect forward secrecy.  We certainly hope they have because it's now time for everyone to step up and do that.  We've got some interesting news about that, too.  Oh, and in fact we're stepping into it because, as I mentioned earlier, GoDaddy revoked Lavabit's certificate.  Now, this news was initially, like, yay, you know.  And, like, I tweeted this news.  And a lot of people came back and said, really?  They care?  Or I'm surprised.  Or I give them more credit than I - and I would be surprised if it was their idea.  I think it was probably Ladar who said...



LEO:  He says please revoke my certificate, yeah.



STEVE:  Yes.  And who knows what the timing was?  The news came out.  But Leo, you ought to just go, if you want to show this on - just go to https://Lavabit.com.  And when I checked this morning, before reminding myself that I was going to mention it, you can see right there, Firefox, my browser du jour, or of choice actually, says, whoops, this certificate has been revoked.



LEO:  It says you might - Safari says, "You might be connecting to a website that's pretending to be Lavabit, which could put your confidential information at risk."  That's exactly the behavior you want.  That's good because in fact it might be an NSA front.



STEVE:  Right.  So anyway...



LEO:  What happens if you continue, just out of curiosity?  Do you get - oh, you still get there.  But you get his note, Ladar's note saying I'm out of business, yeah.



STEVE:  Correct.  Now, what we don't know is when he implemented perfect forward secrecy.  But the good news is he has it now.  So, and again, we may well have always had it.  I was impressed, though.  SSLLabs.com has added the ability to check a website's support for perfect forward secrecy.  And Ladar Levison's Lavabit.com servers, which as you just saw are still online, even though - and in fact, SSL Labs notes that the certificate has been revoked, so it sees that and flags that.  But he did float the Ephemeral Diffie Hellman Key Agreement Ciphers up at the top of his server's recommended and supported ciphers list.  So, and those are the ones that - we did a whole podcast not long ago [SN-412] on this whole - on perfect forward secrecy and how it's because traditional ciphers use the certificate, essentially do not have separate keys for authentication and signing, but rather they use the same key, that is, the server's secret key, for both authenticating their certificate and for signing the session.  That means that, if somebody in the future were to get the key, they could decrypt past conversation.



Well, using perfect forward secrecy ciphers prevents that from happening because then you are negotiating a so-called ephemeral key on the fly that only exists between those endpoints until it expires.  But it means that capturing the server certificate doesn't give you an advantage in being able to decrypt old traffic.  So the good news is Lavabit's servers are configured that way.  Again, we don't know - it matters when they were configured that way because traffic that may have been captured prior to then, and we now know that the FBI does have the old certificate, so old traffic could be decrypted if perfect forward secrecy had not been in place all along.



And, remember, I was never really impressed with all of this because it's email.  And you can't really encrypt email.  Paying customers got their data at rest encrypted.  That is, it would have come in probably unencrypted.  Even if Lavabit supported connection encryption, both ends have to in order for that to be successful.  And many web servers still today don't.  So it would have been unencrypted on the wire.  Then he was encrypting it while it was stored.  And then of course when it was going back out it would be unencrypted unless you were connecting to his server securely.



So again, it takes a lot for email to really be encrypted point to point.  In fact, it takes PGP, GPG, GNU Privacy Guard and all that extra layer stuff.  You really want to encrypt it in your browser or in your email client all the way to the destination email client.  That's the way to be sure.  So he was offering a service better than not, but we don't really know what it was the FBI got and whether there is an archive of previously encrypted traffic that the old certificate still allows them to decrypt.



But the other news from Ladar is that he has briefly brought Lavabit back up.  Leo, if you go to liberty.lavabit.com, that takes you to a new page.  And he says, "Due to concerns about the continued integrity of customers' passwords, we are offering a..."



LEO:  Hmm.  I'm not getting anything.  Liberty, oh, did I spell it right?  Liberty...



STEVE:  Liberty.lavabit.com.  He says, "Due to concerns about the continued integrity of customers' passwords, we are offering a short window of five days in which users can change their password before we allow anyone to download an archive of their stored emails.  The download functionality will be available starting this coming Friday, October 18th...



LEO:  Oh, that's why.  It's not up yet.



STEVE:  I brought it up.  Came right up for me, https:// - oh, did you do a secure link, https?



LEO:  No, I didn't.  I just typed "liberty."  So let me try again.



STEVE:  Ah, liberty.lavabit.com.  So starting this coming Friday, October 18th...



LEO:  Yeah, now I've got it, okay.



STEVE:  Okay.  At 7:00 p.m. Central time.  He says, "Since the SSL certificates formerly used to protect access to Lavabit have been compromised" - notice you're using a new GoDaddy certificate, https://liberty.lavabit.com.  "Since the SSL certificates formerly used to protect access to Lavabit have been compromised, we recommend manually validating" - and this is unfortunate; but, okay, I'll explain why in a second, "the serial number and fingerprint your computer received before using this website."  So then he shows them.



LEO:  Yeah.  So that would be pretty easy to spoof that, then, is what you're saying.



STEVE:  Yeah, that's the problem, is if it's compromised, they're just going to put this - they're going to change the page to show the serial number and fingerprint of their spoofed certificate.  So what you need to do is, first of all, the best thing to do is to ask for details, certificate details, and look at the certificate chain.  You will see liberty.lavabit.com at the end of the chain.  Then you will see, one step up, GoDaddy secure certification authority.  And then the root should be, and this is in Firefox.  The different browsers may have different roots, but in Firefox it says "Builtin Object Token: Go Daddy Class 2 CA."  So that's the chain.  If there's anything different than that, then something is intercepting your SSL connection.  Unfortunately, it doesn't work to show the serial number and fingerprint in the page you're trying to verify because, as I said, if it's been compromised, that'll be changed to the compromised certificate.  But, again, his heart is in a good place.



Speaking of which, he wants - he's got a money-raising operation.  If you go to, again, https://rally.org, r-a-l-l-y dot org, that takes you to the home page of a money-raising site.  And his page is rally.org/lavabit.  His goal was $96,000, and he's just about there.  He's at $93,876 when I looked this morning.  So that is Ladar hoping to raise money for his legal defense fund in order to deal with the fact that he's basically fighting the government over what they're doing.  And he has said that he hopes, maybe, if things work out, he could bring Lavabit back in a way that he's comfortable with in the United States.  He's not willing to move it offshore.  That's - he lives in Texas, and he wants to stay in Texas.  So there is that site, rally.org/lavabit, if you want to learn more about it.  He's got a neat little video where he spends most of his time scratching his dog.



LEO:  I see the dog.  He's a nice man.  He has a dog.  He's a dog lover.



STEVE:  He is.  He scratches - his dog jumps up on his lap in the middle of the video.



LEO:  Well, how could he be a bad man if he has a dog who loves him?



STEVE:  I think it's very clear his heart is in the right place.



LEO:  Yes, yes.



STEVE:  No doubt about it.  So, and of course in the news another day, another data collection program revealed of the NSA.  This was in the news this week.  BoingBoing covered a report that the Washington Post had.  You may want to bring the Washington Post slides up, Leo, that's that second link in my show notes, where it is revealed in some additional documents that the NSA has been collecting half a million, okay, 500,000 buddy lists and inboxes per day.



LEO:  You can have my buddy list.  Really?  Buddy lists?



STEVE:  Buddy lists, yes.



LEO:  Terrorists have other terrorists on their buddy lists?



STEVE:  From instant messaging clients.  Well, they want to build - the whole deal is networking.  That's what this metadata, email metadata gave them is that, even if they didn't have the content, they had - they were able to build networks of inner connectivity.  And it's clear that that has a tremendous value to intelligence gathering.  So the Washington Post said:  "Rather than targeting individual users, the NSA is gathering contact lists in large numbers that amount to a sizable fraction of the world's email and instant messaging accounts.  Analysis of that data enables the agency to search for hidden connections and map relationships within a much smaller universe of foreign intelligence targets.  During a single day last year" - this is from the documents and the slides that the Washington Post showed - "the NSA's Special Source Operations branch" - okay, one day - "collected 444,743 email address books from Yahoo, 105,068 from Hotmail, 82,857 from Facebook, 33,697 from Gmail, and 22,881 from other unspecified providers."



LEO:  Now, I'm looking at this.  Is this done by malware or with cooperation of these providers?



STEVE:  This is the tap that I talked about in my first surmise of...



LEO:  Upstream.



STEVE:  Yes.  They are passive taps provided by Internet service providers that allow the NSA to monitor all this traffic.



LEO:  Not Yahoo!, not Google, but in fact their Internet service providers, their upstream providers.



STEVE:  Like AT&T that's a major, yeah, Tier 1 provider.  So this says:  "...according to an internal NSA PowerPoint presentation.  Those figures, described as a 'typical daily intake' in the document, correspond to a rate of more than 250 million per year."  Okay, so they can multiply, half a million a day.  "Each day, the presentation said, the NSA collects contacts from an estimated 500,000 buddy lists on live chat services, as well as from the 'inbox' displays of web-based email accounts."  So that's interesting.  The web-based email account, when the web page shows you your inbox, they're getting all of that, basically all of your inbox contacts.



LEO:  Hmm.  Hmm.



STEVE:  Yeah.  So...



LEO:  That's interesting.  So I think that this points to the fact that the metadata is really, in many cases, more valuable than the content, is who you talk to, who they're talking to, building a web of communications.



STEVE:  Right.



LEO:  And then you have a person of interest, you can see who they talk to and who their friends talk to. 



STEVE:  Right.  The way to think about this is where, if you consider our podcast, a group of smart people, we're a bunch of techies that understand this stuff.  We know how the Internet works, how this technology works.  We know what can be done.  So consider then the NSA is a well-funded, financed, organization of people every bit as smart as the people who invented and designed the Internet, and they're doing everything they can.  That is, what are they doing?  Everything possible.



LEO:  Everything they can.



STEVE:  Everything they can.  If any of us smart people could think of something that could be done, the NSA has some wacky names for it, and it's on some slides, which we either have seen or will be seeing.  And in fact we have an interesting article from Bruce Schneier, who's got some eye-opening names of NSA programs.



First I wanted to mention that there was a somewhat sad commentary about whether the Do Not Track initiative might be dying.  This was also in the Washington Post.  The headline was ""The Internet's best hope for a Do Not Track standard is falling apart.  Here's why."  It goes on to explain.  And basically it's what we would expect.  I'm not hugely disheartened because all I wanted was the technology to be there.  Just get the header into our browsers.  And everyone thought, well, okay, but, Gibson, that doesn't mean anything if people don't support it.  And it's like, I know.  I understand that.  But the wheels of justice turn slowly.  Legislative things happen slowly.  Once we have that in our browsers, then there's a chance for laws.  Until we have that in our browsers, there's no chance.



So my feeling is this has all been worthwhile.  It certainly didn't cost us anything.  There wasn't any effort on our part.  There was a lot of effort that went into people really trying to make this happen.  In the subhead on the Washington Post, they say, "Should businesses be forced to stop tracking your movements on the Internet?"  And I'll share just a few paragraphs of this because it wound up with the EFF making their position known.



The Washington Post writes:  "It sounds like a simple question.  But judging by the growing despair among members of a diverse group assigned by a standards body to resolve just this issue, the answer is hardly clear.  The task force itself is deeply divided.  In a member survey completed Wednesday" - that's last Wednesday - "half of respondents, albeit a minority of the entire working group, said the negotiations weren't working and should be abandoned.  'This proceeding is so flawed, it's a farce,' wrote Jeffrey Chester, executive director of a privacy group involved in the talks, in a comment. 'Global online users deserve better.'"  So he's just disgusted.



"The working group is affiliated with the World Wide Web Consortium (W3C), the official custodian of web standards. It was initially brought together to develop a negotiated approach to online behavioral tracking.  The collection of ad companies, privacy advocates, and outside experts" - I mean, you couldn't ask for oil and water to be mixed together - "were supposed to settle a longstanding debate about consumer privacy and help determine the future of advertising technology.  But what began as cautious engagement among these [admittedly diverse] groups has devolved into open revolt against the process."



And so here's the EFF saying, quote, "'We appreciate the efforts of the W3C and all the chairs to date,' wrote Lee Tien, a top lawyer with the Electronic Frontier Foundation.  'But EFF has lost confidence,'" he writes, "'that the process will produce a standard that we would support.  We therefore prefer that the group simply end.  If the group continues, we [the EFF] would seriously consider dropping out.'"



LEO:  Wow.



STEVE:  Yes.  "The impending collapse of the Do Not Track conversation is part of a broader failure to agree on what obligations advertising companies have with regard to online tracking, and what the word 'tracking' even means."  So anyway, I mean, no one expected this to be easy.  I mean, and in fact no one expected it probably to even be possible.  But this was the sort of thing, well, you want to try it and hope that maybe something could be resolved, and it doesn't look like that's the case.



LEO:  No, no.



STEVE:  Meanwhile...



LEO:  Meanwhile, back at the ranch...



STEVE:  Yes.  Well, there's some interesting stuff here.  Bruce Schneier, our famous cryptographer who's become very involved in this and almost, I wouldn't quite say an activist, but certainly a spokesperson for the Internet freedom and privacy side, who understands the technology, wrote an interesting piece in the Atlantic which I want to share because it's some additional news with lots of specifics about - which I would reduce to saying that what the NSA is doing it turns out is not even passive, or is not only passive.  Everything we've been talking about so far has been passive eavesdropping on the part of the NSA.  There's a program called FOXACID which is, again, their name, which is anything but.  And so this is Bruce, remember, not some random alarmist.  And he couched this description in wanting to help us understand how the NSA thinks about security and risk.  And he said:  "At this point, the [agency] has to assume that all of its operations will become public, probably sooner than it would like."  And he said - and so this was, this what I'm going to share was written in the Atlantic, but it was also posted in the Guardian.



He says:  "As I report in the Guardian today, the NSA has secret servers on the Internet that hack into other computers, codenamed FOXACID.  These servers provide..."



LEO:  I love, by the way, all of these names like Ferret Cannon and FOXACID.  Somebody's got some sense of humor, anyway.



STEVE:  I know.  Oh, goodness.  FOXACID.  "These servers provide an excellent demonstration of how the NSA approaches risk management and exposes flaws in how the agency thinks about the security of its own programs.  Here are the FOXACID basics:  By the time the NSA tricks a target into visiting one of those servers, it already knows exactly who the target is, who wants him eavesdropped on, and the expected value of the data it hopes to receive.  Based on that information, the server can automatically decide what exploit to serve the target, taking into account the risks associated with attacking the target, as well as the benefits of a successful attack."  So it's a complete cost benefit analysis of actively exploiting a target.



"According to a top-secret operational procedures manual provided by Edward Snowden, an exploit named Validator might be the default, but the NSA has a variety of options.  The documentation mentions United Rake, Peddle Cheap, Packet Wrench, and Beach Head, all delivered from a FOXACID subsystem called Ferret Cannon."  Oh, lord.  "Oh, how I love some of these code names," writes Bruce.  "On the other hand, EGOTISTICALGIRAFFE has to be the dumbest code name ever.



"Snowden explained this to Guardian reporter Glenn Greenwald in Hong Kong.  If the target is a high-value one, FOXACID might run a rare zero-day exploit that it developed or purchased.  If the target is technically sophisticated, FOXACID might decide that there's too much chance for discovery, and keeping the zero-day exploit a secret is more important.  If the target is a low-value one, FOXACID might run an exploit that's less valuable.  If the target is a low-value and technically sophisticated target, FOXACID might even run an already-known vulnerability.  We know that the NSA receives advance warning from Microsoft of vulnerabilities that will soon be patched.  There's not much of a loss if an exploit based on that vulnerability is discovered."  Meaning that the window of opportunity will be pretty short.  "FOXACID has tiers of exploits it can run" - tiers - "and uses a complicated trade-off system to determine which one to run against a particular target.



"This cost-benefit analysis doesn't end at successful exploitation.  According to Snowden, the TAO - that's Tailored Access Operations - operators running the FOXACID system have a detailed flowchart with tons of rules about when to stop.  If something doesn't work, stop.  If they detect a PSP, a personal security product, stop.  If anything goes weird, stop.  This is how the NSA avoids detection, and also how it takes mid-level computer operators and turn them into what they call 'cyberwarriors.'"



LEO:  It's interesting because that same exact behavior sounds very familiar.  Remember, was it Flame?  What was the name of the virus nobody ever claimed but we always suspected was written by a governmental agency?  Did exactly the same thing.



STEVE:  It was very cautious, yes.



LEO:  If it detected this, stop.  If it detected that - so, boy, that's interesting.  You have to wonder - well, anyway.



STEVE:  And he says:  "It's not that they're skilled hackers, it's that the procedures..."



LEO:  Stuxnet?  Was it Stuxnet?  All right.



STEVE:  "It's that the procedures do the work for them."  So they literally follow a flowchart and just step by step doing what they need to.



LEO:  Just script kiddies.



STEVE:  "And they're super cautious about what they do.  While the NSA excels at performing this cost-benefit analysis at the tactical level, it's far less competent at doing the same thing at the policy level.  The organization seems to be good enough at assessing the risk of discovery - for example, if the target of an intelligence-gathering effort discovers that effort - but to have completely ignored" - and this is Bruce's whole point of this article - "have completely ignored the risks of those efforts becoming front page news.  It's not just in the U.S., where newspapers are heavy with reports of the NSA spying on every Verizon customer, spying on domestic email users, and secretly working to cripple commercial cryptography systems, but also around the world, most notably in Brazil, Belgium, and the EU, the European Union.  All of these operations have caused significant blowback for the NSA, for the U.S., and for the Internet as a whole.



"The NSA spent decades operating in almost complete secrecy, but those days are over.  As the corporate world learned years ago, secrets are hard to keep in the Information Age, and openness is a safer strategy.  The tendency to classify everything means that the NSA won't be able to sort out what really needs to remain secret from everything else.  The younger generation is more used to radical transparency than secrecy and is less invested in the national security state.  And whistleblowing is the civil disobedience of our time."  Finally, he says:  "At this point, the NSA has to assume that all of its operations will become public, probably sooner than it would like.  It has to start taking that into account when weighing the costs and benefits of those operations.  And it now has to be just as cautious about new eavesdropping operations as it is about FOXACID exploits attacks against users."



LEO:  Wow.



STEVE:  Yeah, yeah.  So nice, nice summary.



LEO:  You know, mentioning the Guardian and Glenn Greenwald, you saw that he's leaving the Guardian.



STEVE:  Yes.



LEO:  But I thought very interesting where he's going.  I don't know if you've seen that detail.



STEVE:  I didn't see where.  But he did say, because I think I saw the news before he announced it, and I haven't followed up, he did say any other journalist given this opportunity would take it.  So...



LEO:  So it turns out it's Pierre Omidyar, the guy who founded eBay and is pretty much one of the wealthiest men in the world.  He, according to Jay Rosen, journalist professor, writes about this in his blog, he tried to buy the Washington Post, was outbid by Jeff Bezos, and then started thinking, well, what if I took that same amount of money or more, a quarter of a billion dollars, and put it towards building a new investigative journalistic enterprise?



STEVE:  Wow.



LEO:  And so apparently that's who Glenn Greenwald is going to be teaming up with.  He's looking for other well-known  names.  It's going to be an interesting thing.



STEVE:  Interesting.  We'll be talking here, we have a piece about a recently gone open source system called SecureDrop we've talked about before.  But first I want to mention something that I think is really just good news.  We've talked about Matthew Green, who's the cryptographer at Johns Hopkins.  We've been talking about him a lot because he's been involved in blogging recently.  He's one of the people behind the TrueCrypt audit, which is a tremendous effort.  He's created IsTrueCryptAuditedYet.com.



And the top of the IsTrueCryptAuditedYet.com page says:  "TrueCrypt is an open source file and disk encryption software package used by people all over the world.  But a complete cryptanalysis has not" - never - "been performed on the software, and questions remain about differences between Windows, Linux and Mac OS X versions.  In addition, there has been no legal review of the current TrueCrypt v3.0 open source license, preventing inclusion in most of the free operating systems including Ubuntu, Debian, Red Hat, CentOS and Fedora.  We want to be able to trust it, but a fully audited, independently verified repository and software distribution would make us feel better about trusting our security to this software.  We're pledging this money to sponsor a comprehensive public audit of TrueCrypt."  So right now they have - their goal is to raise $25,000.  They have 16 of that 25, although a $10,000 lump came from an Atlanta-based security firm.



Matthew Green wrote in his own blog:  "We're now in a place where we have nearly, but not quite enough to get a serious audit done.  That depends on how many favors we can get from the security evaluation companies.  I'm trying to answer that this week."  And then in his blog he also wrote:  "In case you haven't noticed, there's a shortage of high-quality and usable encryption software out there.  TrueCrypt is an enormous deviation from this trend.  It's nice; it's pretty; it's remarkably usable.  My non-technical lawyer friends have been known to use it from time to time, and that's the best 'usable security' compliment you can give a piece of software."



He said:  "But the better answer is because TrueCrypt is important.  Lots of people use it to store very sensitive information.  That includes corporate secrets and private personal information.  Bruce Schneier is even using it to store information on his personal air-gapped super-laptop, after he reviews leaked NSA documents.  We should be sweating bullets about the security of a piece of software like this."



So, I mean, and this has come up often.  There's, like, there's weird conspiracy theories about, like, the past domain registrations of the TrueCrypt domain.  And I see stuff like this from time to time, and it's like, well, okay.  But this is just good news.  Everyone on the podcast knows that I'm a huge fan of TrueCrypt.  I really think that Matt is right, that this - it beautifully combines ease of use and really good security.  But it needs an audit.  And I mean, and this is always what you and I talk about, Leo.  It's one thing for it to be open source.  But if no one independent goes through and reads the source, I mean, who really understands cryptography, then it is possible that it could have some little widgets snuck in.



In fact, we've got a story about that coming up about a D-Link router hack.  But so TrueCrypt needs this.  It needs an audit, and then that audited code needs to be locked down, and any change made to it similarly looked at very carefully so that we can then say, okay, we have absolute, I mean, we trust it because we believe in the intentions of everyone who is involved.  But we don't - we can't really assert to absolute certainty the intentions of everyone involved.  We just assume good, well-meaning people built this for us.  So...



LEO:  Yeah, I mean, I've always kind of presumed, because something is open source, that somebody, at least informally, is looking at it.  But I guess it's the case that there's a lot of code there and it's possible there's something snuck in.  It'd be hard to do.  Pretty hard to do.



STEVE:  Yeah, I don't think anyone has probably looked at it, Leo.



LEO:  Well, people look at it all the time.  No, no.



STEVE:  Well, but, yeah, but, I mean - okay.  Who?



LEO:  Interested parties.



STEVE:  The good news is we're going to absolutely have a certificate.



LEO:  I mean, you can download all the code yourself and put it on your computer and comb through it.  I would be - I would be surprised if many people have not done so.  Maybe we're all assuming the other guy's doing it.  I don't know.



STEVE:  I think that's what happens. Yeah.



LEO:  Yeah.  It certainly wouldn't hurt to have an official audit, that's for sure.



STEVE:  I think it's great.  I absolutely think it's, I mean, the problem is we want to relieve people of their concern.  We want to be able to say it has been audited by security-aware people, end of story.



LEO:  Right.



STEVE:  And, I mean, it makes sense to do that for a super-popular, heavily used piece of software.  I mean, TrueCrypt's what I use.  No computer of mine has ever been hacked or attacked, but it just makes sense to have that.  I wouldn't operate a laptop without it because laptops are mobile by nature, and stuff happens.



There is a really interesting project, SecureDrop, which has just been moved over to GitHub.  If you go to GitHub, you can - it's a - Freedom of Press is the account, and SecureDrop is the subdirectory under that.  It is an open source whistleblower submission system which has been managed by Freedom of the Press Foundation.  And the idea is that media organizations can use it to securely accept documents from anonymous sources.  The code was originally written by Aaron Schwartz.  We've talked about this a couple times.  It is a complex system; but in order to do this, unfortunately, it's going to have to be complex.  So there are five machines, sort of five machine roles in the system.  And all of them - well, okay, four dedicated machines, all of which would be located in the offices of an organization that wanted to securely accept documents.



So, for example, in this new organization where Glenn Greenwald is going to be, this is what they would use.  They would set up these - and it's all open source, using versions of Linux.  They've got a USB-bootable system called Tails OS.  And so there is a - one of these computers is a so-called "viewing station" machine, which should be an air-gapped laptop, meaning no wire networking connected to it, an air-gapped laptop running the Tails OS from a USB stick.  And in the description it says "that journalists use to decrypt and view submitted documents."  And it says, "If this laptop does not have a DVD drive, buy an external DVD drive you can use with it."  So that's one machine is an air-gapped laptop.



Then there will be what they call the "source server," is an Ubuntu server running a Tor hidden service that sources use to send messages and documents to journalists.  Then there's a "document server" machine, another Ubuntu server running a Tor hidden service that journalists use to download encrypted documents and respond to sources.  And then there's a third Ubuntu server which is a so-called "monitor," which monitors the source and document servers and sends email alerts.  So it heavily uses Tor hidden services, and the idea being that independent sources can access these machines through Tor, which gives them anonymity, and there's a broadcasting mechanism where credentials are made available and usernames are kept anonymous that allows anonymous people to securely encrypt and upload through Tor that end up arriving at these systems, where then the encrypted document is lifted from the document server and hand-carried over to, probably burned to DVD.



I haven't gone into the protocol, but that's probably why this viewing station, it boots from USB, but you probably burn the document to DVD, take it over to the air-gapped laptop, which is able then to decrypt with the recipient's credentials in order to make the documents available.  So, yes, it's a lot of moving parts.  But it's been very carefully designed in order to achieve the goal that everybody's identity is protected, the information is completely safe, yet you are able to have a conversation, ultimately, between a source and a set of journalists.



LEO:  Interesting, yeah.



STEVE:  So a very cool technology, yeah.  And last bit of news for the week.  Like I said, we had a lot.  I tweeted this so people could get it from the tweet.  I also created an all-lowercase bit.ly link.  So it's bit.ly/ and then just this episode.  We're Episode 246, so it's sn-246.  So it's a bit.ly link, bit.ly/sn-246.  It is a wonderful walkthrough of a guy who hacked the firmware belonging to a family of D-Link, standard D-Link consumer routers and found a backdoor.  He wasn't looking for it.  He just fired up some music that he describes at the top of his posting, Rush I think it is, I've never heard of them, but that's, you know, Sarah probably has.



LEO:  You're never heard of Rush?  Come on.  Okay.



STEVE:  No.



LEO:  A fine Canadian rock band headed by Geddy Lee.



STEVE:  Good.  So he had good music to help him with his hacking.  And what he goes through, he just - he, like, looks through a list of all the subroutines, and he sees the authenticate subroutine.  And so he says, oh, that's interesting.  Let's go see what the, well, I'm just curious, what does the authenticate algorithm look like?  And he's looking at ARM assembly language using a disassembly and reverse-engineering tool to see what the branch conditions are and string comparisons.  And he sees an interesting string comparison that for some reason in the authenticate routine he follows some pointers, and it seems to be comparing the contents of the user agent.  And he thinks that's odd.  You'd want to be checking the password and the username.  Why would you care about the user agent, which of course is, like, the user agent is Firefox or Internet Explorer or Safari or whatever.



So he follows it along some more, and he finds this weird string which the user agent, the contents of the user agent header in a query is being compared with.  And it's compared with a string which has a weird-looking text - it's roodkcableoj28840ybtide - until you reverse that string.  And that string in reverse reads editby04882joelbackdoor.



LEO:  Wow.  Is that a date, you think?



STEVE:  I don't know what the 04882 is.  Maybe it's something in leetspeak if you turn it upside down or backwards or who knows.  But it turns out this is a backdoor for logging into a family, a broad family that all use this firmware, of D-Link routers.  And all you need to do is change your user agent to that string, and you do not need a username and password.  It bypasses authentication on these D-Link routers.



LEO:  Wow.



STEVE:  And it's like, whoopsie.  Now, hopefully this is not exposed to the WAN.  Everybody should have certainly turned off WAN-side login on any router.  I mean, that's Security 101.  Unfortunately, apparently there's that search engine, I can't remember the name of it now, which does aggregate - it's an Internet search engine for publicly available servers.  And apparently there's all - I saw that there was an NMAP script had been written for finding these hackable routers.  So it may very well be that we have, I don't know, I haven't looked to see whether there is WAN-side administration available.  I just - I hope not because, if there is, and if it's on by default, then this is a massive breach of security for this family of D-Link routers, all using this.  But mostly I just, for people who are curious, it's very well written.  He shows screenshots of each phase of his discovery, little subroutines linked together courtesy of this great reverse-engineering software.  He comments what he finds.  Anyway, so it's bit.ly, bit.ly/sn-264.



LEO:  246.



STEVE:  I'm sorry.  Sorry, yes, 246.



LEO:  And it's confused people because the episode number of 426.  But it is 246.



STEVE:  Oh, my...



LEO:  It's okay.  Somebody in the chatroom also added 426, so both work.



STEVE:  Oh.  Sorry about that, folks, yes.



LEO:  Doesn't matter.  You said that right.  It's driving people in the chatroom crazy.  They're apparently fairly anal.  No, no, Steve, the episode number is 426.



STEVE:  Okay, yes.  So...



LEO:  Except it doesn't work.  Moving along.  Both work now.



STEVE:  So total - we're out of news.  A little bit of miscellaneousness.  I saw a tweet from someone who's, well, his name is Pudding, and his Twitter handle is @tonofpudding.  So I don't know what that means.



LEO:  Well, it's more pudding than just one pudding.  It's a lot of pudding.



STEVE:  It's a lot of pudding, yeah.  So he said, @SGgrc, he said, "I bet Elaine is now a total security expert, having to listen closely to every episode to transcribe them."  And what's funny, the thing that caught my eye is that Elaine just said last week - see, she does amazing due diligence for the transcripts.  So when we were talking about Taylor at Defuse.ca last week, and you knew of Defuse.ca and remembered who Taylor was, well, Elaine googles, goes to his site and looks around.



LEO:  Wow.  She verifies.  Wow.



STEVE:  Because she wants to spell his name and make sure she gets the URL right, I mean, she really does it.



LEO:  You go, Elaine, wow.



STEVE:  So apparently in Taylor's rsum he says, one of the items, I guess it's somewhere on his site because Elaine found it, he says "Listened to every SN podcast twice."  And Elaine read that and said - so wrote all this to me and said, you know, so have I.



LEO:  Come to think of it.



STEVE:  Because she listens to it once to transcribe, and then she proofs it.  She listens to the entire thing a second time, proofreading her first pass transcription.  So she said, yes, Taylor and I have listened to every Security Now! podcast twice.



LEO:  And she is now officially a security expert.



STEVE:  So, okay, Leo.  I had not seen "Gravity" last week.



LEO:  Oh, you didn't go - oh, you know what, I didn't get to see it.  We said I would, but I haven't yet.



STEVE:  Well, I have.



LEO:  Okay.  No spoilers.



STEVE:  No, no spoilers, of course.  I would just say...



LEO:  It has something to do with space and falling, I think.



STEVE:  Okay.  Well, then, we'll leave it at that.  I liked it.  I wouldn't really call it science fiction.  I would call it science drama.



LEO:  Yes.



STEVE:  And it was fun.  It was fun science drama.  I mean, it was - but if you're going, if you want sci-fi, "Ender's Game."  That's what we're waiting for.



LEO:  Yes.  Exciting, yeah.  But read the book first.



STEVE:  Yeah.  You know that I did reread the book, just because I knew that now the movie was coming, and I wanted to - that's Orson Scott Card, for those who don't know.



LEO:  Read the book first.



STEVE:  And we do have "The Tomorrow People."  I watched it.  I watched the first episode last Wednesday.



LEO:  What did you think?



STEVE:  Eh, I mean, it's a little bubblegum.  But beggars can't be choosers, and I'm definitely begging for sci-fi.  So I'll give it a while and hope.  It looks like it could be fun.  We'll see how it evolves.



LEO:  Nobody has yet disproved my theorem that science fiction on TV is pretty much not so great.



STEVE:  Well, "Firefly" was great.



LEO:  "Firefly" was, no, you're right.  Okay, I'll give you that.



STEVE:  And "Star Trek."  "Star Trek" all began on television.  I would say there is no good contemporary - there's nothing now at the moment that is...



LEO:  "Firefly" was the last.  And it was mangled on TV.  So it doesn't complete disprove my theorem.



STEVE:  Good point.  They did it out of order, and they canceled it without even airing all the episodes they had made.  Like, what is wrong with you people?



LEO:  It was made properly, just never displayed on TV properly.  Just briefly, a couple of weeks ago while I was on vacation, Steve introduced something called SQRL, Secure QR code Login.  And the world is beating a path to your door, it sounds like.



STEVE:  Well, I've been watching a lot of the dialogue going on.  And the short version is, yes, this concept has captivated a lot of people.  What I like about it is that it is simple.  And so the GRC newsgroup has gone crazy.  I'm something like 800 posts behind, and I was current for a while.  But I think we're about 2,200 postings that have been made, just because so many people want to be involved and to communicate.  As I mentioned last week, I've been contacted by the W3C, the World Wide Web Consortium, about considering adding this to the HTML5 spec, opening a dialogue.  Next week is the HTML5 Developers Conference, the web developers conference at Moscone Center.  And a Dan Holmlund is going to be giving a presentation on SQRL, basically doing a presentation to explain...



LEO:  Oh, awesome.



STEVE:  ...what it is and how it works.



LEO:  Wow.



STEVE:  In his little snippet, in his synopsis of his presentation, he said:  "Recently, the computer security community has been set on fire by a proposal for a new authentication scheme named SQRL from Steve Gibson of GRC.  SQRL is an easy-to-use, high-security replacement for usernames, passwords, reminders, one-time-code authenticators.  It provides authentication that can be anonymous, and it requires no trusted third party that can be compromised by hackers or three-letter government organizations.  We will walk through how SQRL works and how it can be implemented on your web or mobile application."



So, I mean, and if you look, there's an Implementations page in the SQRL pages at GRC, as you mentioned last week, GRC.com/sqrl.  Actually, when you mentioned it, that link wasn't working because it's actually sqrl/sqrl.  But I thought, ooh, I'd better fix that, so I did.



LEO:  Oh, good.



STEVE:  So that works now.



LEO:  Too many SQRLs.  That can always screw things up.



STEVE:  But, I mean, people are, like, writing code like crazy.  So I've sort of been trying to ride herd of this, like, too much interest, almost.  And the thing I've run across is - and this is not a complaint, I consider this good, it's just a lot - is everyone wants it to do everything.  And it does not do everything.  And what I believe we have with it is there are many benefits.  One of them is its simplicity, the fact that it isn't a kitchen sink, that it doesn't involve a third party.  There's plenty of identification schemes trying to even exist that are third-party schemes.  But I think third-party schemes, all of them, are dead now in this post-NSA, post-Snowden era.



So my best example of a system that works, but it's not perfect, and I've used this, and it's one of my favorite analogies, is cars, driving cars.  Imagine that cars didn't exist, that there hadn't been an evolution, but that they just, like, people were saying, okay, we need to stop walking everywhere.  What are we going to do?  And someone says, I know.  Let's create a 2,000-pound, gas-powered, high-speed missile with a steering wheel, and we're going to just let people go wherever they want to.  Well, I mean, people would have said, you're crazy.  That's insane.  People are going to crash into each other.  Oh.



LEO:  Oh, the horror.



STEVE:  Well, I guess that could happen, but most people are not suicidal.  And we'll help them.  We'll give them traffic lights.  And everyone will agree, if the light is red, it would be good to stop your missile before crossing oncoming traffic.  Everybody will be happier if we agree to some rules.



LEO:  Yes.



STEVE:  And so my point is I don't think it could have ever happened.



LEO:  No.



STEVE:  If, I mean, it just would have never happened if you didn't already have it.  It's because we slowly evolved from horses - in fact, one of my very favorite Henry Ford lines is - it echoes a Steve Jobs line.  Steve Jobs said, I love this, "It's not the customer's job to know what they want."  That's just brilliant.  I love that.  He didn't do focus groups.  He just said, "Here it is.  Suck it up."  And of course we all sucked up all of Apple's goodies.



LEO:  Right.



STEVE:  Henry Ford said, "I asked people what they wanted, and they said they wanted a faster horse."  So...



LEO:  I hate to say it because I love that quote, and I've quoted it.  And I have been told that that's - that he never really said it.  But it's...



STEVE:  Henry Ford?



LEO:  Yeah, and it's a great line.  I love the line, yeah.



STEVE:  Great quote.  Anyway, so my point is that what I've been trying to do is keep the system simple.  For example, revocation.  The idea is people - I say, okay, you just have one master key, and we're going to help you protect it.  I mean, we're really going to go out of our way to help you, to support the idea of one master key.  The beauty is that the key is never used.  Nothing, there's no vulnerability to using it.  Websites don't get it.  They get a derivative of it based on their domain name, which allows you to identify yourself to them.  And even if they leaked that derivative, your identity for them, it's different on every other site.  So people just - they love all of that.  They say, oh, okay, great.  But then they say, but what if I lose it?  Okay, well, right.  What if you run through the red light?



So my point is that we will do everything we can to protect you from yourself, to help this simple system actually work.  So there's two aspects to it.  To keep bad guys from getting it, we use extremely strong encryption.  And there's not really even a term.  I say "deeply encrypted" when I talk about, well, it takes a minute to do the encryption, which allows you to then export your key in a QR code, like to print it out, to stick it in a drawer so that you're prevented from losing it.  And it also takes a second or two when you enter your password to remind the phone or to prove that you're the one using it.



So we really create barriers to you losing it, that is, getting out of your control, or bad guys getting it, because we want to make it as practical as possible just to have one key.  If we can, then the benefits are huge because you can literally use this to identify yourself uniquely across the entire Internet in a way where you don't have to have any per-website stuff.  It's just this one thing.



But people said, okay.  What if I have a bad breakup with my - with a partner.  And he or she has my key in their phone.  And you can have your key in someone else's phone, protected by your password, and it's safe because we've made it so difficult to do password guessing.  Or what if your phone is confiscated at the border and they keep it for a week before giving it back to you?  So the point is there are arguably some scenarios where you could forever after something happens feel uncomfortable that your key may have gotten out of your control.  Somebody has it on their phone; or they decrypted your phone, the government decrypted your phone and then sucked its data out and gave it back to you, and now they can be working on it in the background, where again, all the protections we have prevent it from immediate - prevent your key from having any rapid reverse-engineering, no way for anyone to get it without, I mean, it's completely infeasible to do brute-force attacks.  But still, what if?



And so we've come up with a small improvement, the simple improvement to the protocol which solves this problem.  And that is that the inevitable problem, or the possibility - we don't want it to be like something everyone does.  But it's like, okay, what if you wanted to retire a key for any reason?  All we've changed is you can take whatever your current key is and assign it as your previous key, sort of just change it to your previous key, and invent a new one.  So now your SQRL client has the notion of a previous key.  Just one.  Again, you don't need 10 because this is the kind of thing that shouldn't ever happen.  But if it does, then we want to provide a means for replacing a key that you regret may have gotten out of your control somehow.  And even though it doesn't mean you're hackable, it's just we ought to have a way to do that.



Now, I've always felt that websites, a website that you're using, would give you means to manage your account.  They probably still have an email address for you.  I mean, that's still something you uniquely control.  And so you probably could go to a SQRL-supporting site and say, "Hi there, it's me, I want to change my email address," the way we do now.  And they might say, okay, well, we don't have a password on file for you because you're using SQRL.  But we did ask you for some security questions so you can prove who you are through another means.  I mean, these sorts of things still function.



Well, certainly there ought to be a means there to say "I would like to replace my key."  I mean, I have always imagined you'd be able to do that.  The problem is it's still kind of awkward.  It's like, well, you've got to log in with your old key.  And then what, do you have, like, how do you - you have to switch users, your user account in SQRL in order to say, okay, here's - now I'm going to scan my new key, so you get that.  Anyway, that's just sort of awkward.



So we've made it simple to do this.  Anytime your SQRL authenticating device, your smartphone or a SQRL app on a laptop or a computer, however you're doing it, anytime you have defined a previous key, your old key, then the authentication query, which is what identifies you, simply provides both.  It provides your new key and your old key and two signatures of that.  So the two signatures is the old sig and the current sig, essentially.



So what that does is, anytime you log into a website, it will - and the website sees you have an old key defined, you're giving it an old key, it will first check to see whether it has a record of you under the old key.  If so, it replaces that immediately with the new key and forgets the old key.  And it knows that you were the owner once of the old key because you have correctly signed the old key.  Actually, the old key's private key was used to sign this whole query, as was the new key's private key.  So basically you've double-signed this to say I know both of the private keys that are associated with this old identity and the new identity.  And the site simply replaces the old one with the new one.



So logistically that makes this arguably important sometimes or possibly need to relatively easily replace your keys manageable.  You simply retire the key you were using, come up with a new one, and then you just go, you just visit the various important sites that you use most, your bank and Amazon and Google and those major ones.  And your prior identity is flushed from them.  There will certainly be some, like random blogs and things, that you don't get to immediately.  They'll still have your old identity until you next go there, and then your identity will automatically be replaced on the fly for you.



So that's a simple change, an enhancement we made to the protocol that solves the problem of, if I lose control of my galactic master identity key, and I really, really, really have to change it, how do I do that?  And it's not like we changed every key in the world.  There have been proposals in GRC's newsgroup, like keeping a record of every site you log into.  Well, okay.  Then we have a very stateful client.  Then how do you move that between devices?  What if you log in somewhere else on a device that isn't synced to the cloud?  I mean, suddenly the whole system becomes a huge problem, if you try to perfectly solve the revocation problem.  I argue, just as with driving cars, if we provide people with the tools that they need so that they will not hurt themselves, then this operates in a sweet spot where it is very simple, easy to implement, and provides tremendous value.  And we help people to be responsible.



And then the second thing which has happened in the last week which is very cool is we actually have come up with extremely good anti-phishing protection.  Phishing is a topic we've discussed on the podcast through the years.  It's an ongoing problem for the Internet.  Typically you get a link in email, and it's because of this problem that the wisdom is never click a link in email.  It's because you can't see where the link is taking you.



And it may look, it looks like a PayPal invoice.  I've seen some spam like that.  It's like, hey, we just wanted to let you know we just cleared the $374 purchase you made, yay, in PayPal.  Click here if you want to check your account.  And so that's of course a scare tactic.  Someone says, wait a minute, I didn't authorize a 300 and whatever it was dollar purchase.  So they click the link, and it takes them to a page that, sure enough, looks just like PayPal, but it's not.  It's a variation on PayPal's name, something where they're just not going to notice that it's .cn instead of .com, for example.



So people have said, hey, Steve, is there anything that SQRL can do to solve this phishing problem?  It turns out there is because, first of all, a site that wants to spoof SQRL login has to go to a much greater effort to do so.  In the PayPal example, it's a passive spoof.  They show you a PayPal page that looks just like PayPal and says give us your username and password.  And you type that into this fake PayPal page and hit Submit.  Instantly they have your credentials.  They've got your username and password for PayPal.  And now you're in trouble.  In order to successfully spoof login with SQRL, the spoofed site would have to get a valid SQRL code from PayPal.



Now, that can be done.  Basically it becomes a man-in-the-middle attack where - so that ups the ante, just using SQRL ups the ante of phishing, but still makes it possible.  So that site, when you display the page, behind the scenes the evil site goes and gets a - essentially it starts a logon on PayPal, gets the SQRL code that PayPal thinks it's showing you, and then the bad site displays it on its page.  Now, you scan that.  And what you're doing is, because it's a true PayPal link that just came from the PayPal logon page, you are truly, you are authenticating yourself to PayPal, but you're authenticating the session which the evil site started.  That is, it opened the login page and then showed you the SQRL code, which you would be authenticating.



The problem is the IP addresses don't match.  Think about it.  The web server, .cn or .ru or wherever it is, the web server asked PayPal, the PayPal server, from its IP for the SQRL code.  When you authenticate, you're coming from either your web browser's IP or from your phone.  They will be different.  And so there is a large class of phishing which we're able to block.  Remember that we talked last week about being able to either optically scan the QR code to use the whole multifactor "I'm using my phone as my identity" approach.  But many people, even Tom, when I first mentioned this two weeks ago with Tom, he said, well, what about if I just - if I've got my laptop with me, and I want to log on with my laptop?  And of course since then we have fully fleshed out that.



You can have an SQRL client installed on your computer, whether a laptop, a desktop, a tablet, or your phone.  And if you're logging in on that device, then you just tap or click on the SQRL code.  And because it has an sqrl://, it understands that that's the so-called scheme of the URL and does the authentication for you.  In that case, in any instance where you're logging in on the same device that you're browsing, the IP address will be the same.  Your browser will have asked for the login page, and that will be the same IP as the SQRL client asks for, performs its authentication query.



So what we've added to the spec is something very simple.  The client knows if the IP address is expected to be the same.  It's probably not the same if you're using an optical scan and a cellular carrier for bandwidth because then the IP is going to be different than the machine you're scanning.  But if you were at home, and your cell phone was on your home WiFi network, then your public IP of your browser and your phone are still going to be the same.  So even there, even using your phone with the same WiFi on the same network as your computer, the IP that the public sees is the same.



What's cool is if the client knows if the IP is expected to be the same.  If it's a client on a laptop or desktop or tablet or phone, not being optically scanned, and not cellular carrier, it adds an option to the query.  The option is "Enforce."  And what this does is it tells the web server where you're authenticating to enforce a same-IP policy.  And the option cannot be removed by any man in the middle because the signature which we use to sign the URL encompasses all of the options and other features.  So we're signing the whole package.  So the signature, after the signature gets verified, the web server sees that we've asked for enforcement; we, the client who's doing the authentication, is asking for enforcement of the same-IP policy.  And if the IP that it gave the SQRL code to is different from the IP that is asking to authenticate that SQRL code, it fails.  It sends an error message back saying "IP mismatch, authentication failure."



And so what that does is it essentially imbues this system, not in every possible case, not in the optical scan cellular carrier because there you'd expect your IP of your computer and your phone to be different.  But in the huge instance of anyone working at home, at office, where they're using their same SQRL identity to log into websites during the day, or if you're on a tablet, or if you're logging in on your phone, in all of those instances the IP should be the same.  This completely detects and blocks phishing, which nothing else has ever been able to do before.



LEO:  Seems that, though, in a lot of cases, that this is an option that's going to be left off.  Is it going to be off by default?  Probably; right?



STEVE:  On by default.



LEO:  On by default.



STEVE:  Yeah, it'll be off for the optical scan mode, but it'll be on for the authenticating non-scanning when you're clicking or tapping because the IP ought to always be the same.  You'll be able to override it.  So essentially it'll come, your authenticating device, whether your phone or the SQRL client, will come back and say, explain in understandable English for our moms that, well, I don't know how we're going to explain it to our moms.  But you'll be able to push past that if you want to.  It'll explain that there may be a problem with the website, that there is an authentication problem, refresh the page, make sure the URL is spelled correctly, whatever we end up, how we choose to end up wording this.  But it is always the case that the IP should be the same.  And only in the event of a third-party obtaining the SQRL code on your behalf and trying to trick you would the IP mismatch.  So, and again, we'll put this out; we'll experiment with how it works and see how it goes.



LEO:  Yeah.  I mean, if it becomes an issue, you can obviously - nothing's written in stone.



STEVE:  Yeah, you'll be able to turn off the checkbox.



LEO:  Right, right.  Very interesting.  Once again, more strides going forward.  So tomorrow is the HTML5 presentation?  Is that tomorrow?



STEVE:  No, it's next week.



LEO:  Next week.



STEVE:  It's next week.



LEO:  Very interesting.



STEVE:  Yeah.  At HTML5devconf.com.



LEO:  That's awesome.



STEVE:  Is the location.



LEO:  Yeah.



STEVE:  So, yeah.  I'm not going to turn this obviously into the SQRL podcast.  I hope this - I'm going to try to - we'll do a Q&A next week and take a lot of questions, and I will certainly not have SQRL dominate the podcast.  But that's what I'm working on until we get it done.



LEO:  Cool.  If you want to participate, of course, there's a group, working group going on right now at Steve's site, GRC.com, in the forum there.  You can also submit questions for next week on any topic, SQRL or otherwise, at GRC.com/feedback.  GRC is where SpinRite lives.  You didn't mention SpinRite this week, I don't know why, Steve, but I'm going to mention it...



STEVE:  Thank you.



LEO:  ...the world's best hard drive recovery and maintenance utility.  If you have hard drives, you must have SpinRite.  You can get it right now at GRC.com, along with a bunch of other...



STEVE:  It does pay all the bills.



LEO:  ...freebies.  Yeah, that pays the bills.



STEVE:  And a free upgrade to the next version is guaranteed.



LEO:  Yeah, yeah.  That's awesome, too.  He's working on that, too.  GRC.com is where you'll find 16Kb audio of this show for the bandwidth-impaired.  Those full transcriptions we mentioned by Elaine Farris, very nicely done.  We have full bandwidth audio and video of the show at our site, TWiT.tv/sn, for Security Now!.  Collect all 462 or whatever, 26.  I mean, you might as well get them all.  Must have them all.  They're all there.  And have a complete set, just like I see you have the Oxford English Dictionary.  You know, I never noticed that over your right shoulder, yeah, your right shoulder.



STEVE:  Oh, yeah.  Love it, wow.



LEO:  And somebody's mentioned that your blinking lights are not moving as fast.  Did you slow down the refresh rate on your PDP-8?



STEVE:  Ah, we've got smart, we've got...



LEO:  They pay attention.



STEVE:  We've got sharp-eyed people watching.



LEO:  They pay attention.



STEVE:  I changed - the switches allow me to change the characterization.  I thought, oh, let's change the way it feels.



LEO:  Little less frenetic.



STEVE:  Yeah.



LEO:  If you want to watch the show live, we do it Wednesdays, 11:00 a.m. Pacific, that's 18:00 UTC on TWiT.tv.  Please tune in live and watch.  The chatroom, of course, is always a big part of all of our shows, and that's the only way you can be a part of the chatroom is to watch.  But you can also visit us in-studio.  We have some nice people visiting this week.  All you have to do is email tickets@twit.tv.  There are really limited spaces, only about five seats here in the little studio.  Big studio has kind of unlimited room.  So do email us and let us know ahead of time so we can make sure we can get you in:  tickets@twit.tv.  Steve will be here next week to talk more about security and answer some questions, I think.



STEVE:  Yup, GRC.com/feedback will get you to the Security Now! feedback page, GRC.com/feedback.



LEO:  Thanks, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#427

DATE:		October 23, 2013

TITLE:		A Newsy Week!  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-427.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  So much happened during the past week that today's podcast will consist of a series of rather deep dives into the many interesting things we have to discuss.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and it's just a potpourri of security news.  There's so much to talk about, including a new, amazingly well-coded malware that's bad news.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 427, recorded October 23rd, 2013:  A Newsy Week.



It's time for Security Now!, the show that protects you and your loved ones, your privacy, your security online.  I mean, this is the show that continues to grow because there's never been more interest in all of this.  Steve Gibson is our Explainer in Chief, the king of Security Now! for the last 427 episodes. 



STEVE GIBSON:  Wow.



LEO:  And he's back again.  Yeah, wow.  And we thought when we started there wouldn't be enough to talk about.



STEVE:  Oh, yes.  And that was my concern when you proposed a weekly - it was going to be a weekly half-hour rather than what it's become, is often 100+ minutes per week.



LEO:  Yeah.  Well, you're in a - you have the luck of being in a booming business.



STEVE:  Well, and as we have seen, I mean, looking back over the history of the podcast, since I love technology, security is sort of the hub.  But then we've gone off and, like, covered exactly how the Internet works, what is packets and routing and all of that.



LEO:  But all stuff you need to know, really, I think, to understand these topics.



STEVE:  Exactly.  So it's all of that rich background that creates a good knowledge base.  Today there's just been - there was so much that happened this past week.  And so we're technically a Q&A, but I decided not to do the Q&A format because instead the content is by popular request of our listeners.  I want to chat with you a little bit about yesterday's Apple announcements.  John McAfee is back in the news, believe it or not.  Google has something called...



LEO:  His 15 minutes aren't up?  God.



STEVE:  He almost got a lot more, but then the government shutdown preempted him.  Google has something called Project Shield, offering DDoS protection.  Another casualty of the NSA.  Everyone's been asking for me to look into CryptoLocker malware.  I've already warned Jenny about it because this would be really bad.  Although she's using Carbonite, and I did check recently that it was, like, all lit up and working for her.  So that would be good.  There's a Flash virtual machine in JavaScript.  Some news, a lot of news, actually, in the instant messenger category:  Hemlis, BlackBerry, and Threema.  Some U.S. Patent Office news about the so-called "Steve Jobs Patent."  And, believe it or not, even a bunch of miscellaneous stuff.  So tons of stuff to talk about this week.  And so we've just got - that's what we're going to do for the next however long.



LEO:  All right.  Do you want to talk about Apple's thing?



STEVE:  Well, just briefly.



LEO:  I'm curious what your take is.  You're an iPad owner and user.



STEVE:  Oh, Leo, I use my Pad more than any other electronic device I own.  I mean, it's...



LEO:  Yeah.  You're not alone.  I think that's very common.



STEVE:  It is my device.  It is - I just - I take it with me every morning.  I do reading and research.  And I'm, I mean, I love it.  And so for me the question is, I mean, yes, I will get the new device.  The question is which is it?  I was interested yesterday to hear you talking about that you really like your mini.



LEO:  Yes.



STEVE:  And I think I do, too, because maybe then it's a little more easy to always have it with you.  On the other hand, the phone - remember that I've traditionally been a BlackBerry user.  And I am, I do, I got my 5s last week.  And I'm in the process of migrating myself.  I need to convert all of my custom sounds over to M4R ringtones so that I can get them into the phone and associate them because I really love having per-contact sounds for instant messaging and email.  And then I'm going to just swap the numbers.  I will exchange the phone numbers between the iPhone and the BlackBerry, which is me being committed, and then see how it goes.



LEO:  I think you might - it might be painful initially because of the keyboard.  But I think you might find you like it, especially since you like the iPad so much.



STEVE:  What I'm finding is that I can't hold it and do the double-thumb typing, which I do on the BlackBerry.  It doesn't set itself up for that kind of double-thumb typing.  But I hold it in one hand and then type with the other, with my first finger of my left hand, and that seems to work.



LEO:  Unfortunately, I've never been able to type effectively on an iPhone.  It's just too small.  And once I got to the bigger Android devices, I found much more comfort there.  Plus you can change, they have a variety of different keyboard styles which I find more comfortable.  But you may never really love the keyboard on the iPhone, I guess is my point.



STEVE:  Yeah.  And I, yeah, I may just not type as much.



LEO:  Just don't type as much, yeah.



STEVE:  But to have, like, a...



LEO:  Dictation is quite good on it, you know.  And that's kind of a nice feature.  I don't know if you use the dictation Siri on the iPad.



STEVE:  No.



LEO:  I dictate a lot of stuff now.



STEVE:  Hmm.



LEO:  That saves me that typing.



STEVE:  Hmm.  Interesting.  So...



LEO:  So the new iPad - Apple has a problem, in my opinion, which is that the iPad, going back probably almost to the iPad 2, is pretty much perfect.



STEVE:  Yes.



LEO:  It doesn't - it's hard to do much to improve it.



STEVE:  Yes.



LEO:  So they've done what they can:  thinner, lighter, smaller bezel, faster processor.



STEVE:  Well, and are they obsoleting them?  I mean, like I'm going to replace my existing one and find somebody who needs it.  But are they broadening the market?  I mean, like what's their...



LEO:  Well, the only way...



STEVE:  It's not like Microsoft, that's always trying to sell us a new OS in order to kill off the old one and generate revenue from upgrades.



LEO:  They've updated the OS for all but the oldest iPads to iOS 7.



STEVE:  Oh, and by the way, Leo, going to 7.03 and turning off all that ridiculous animation is so much nicer.  You just get...



LEO:  People thought I was nuts when I said all this swoopy-doopy's making me sick.



STEVE:  You just get cross-fade between...



LEO:  Too much.



STEVE:  Yeah, it's much nicer.  Faster and nicer.



LEO:  They had this accessibility switch before to turn off motion, but it only turned it off a little bit.  Now, with iOS 7.0.3, it turns it off entirely and replaces it with a dissolve.



STEVE:  Yup.



LEO:  I find that much more appealing.  It wasn't a deal breaker, but it's - thank you, Apple.  Obviously we're not alone.



STEVE:  Yeah, it was just nonsense.  It was eyewash.  It was unnecessary.



LEO:  Waste of cycles, yeah.



STEVE:  Yup, exactly.



LEO:  I turn that off on Android, too.  I turn all those visual effects like that off.  So I would say that you should try a mini.  Now that it has the retina, it's the same resolution as its big brother.



STEVE:  Yes, and that's what I've been waiting for.  That's more, well, same pixel resolution, but higher pixel density.



LEO:  Higher PPI, yeah.



STEVE:  Even than the latest iPad.  So...



LEO:  Buy a couple, yeah.



STEVE:  I'll get one of each, and then I'll see which one...



LEO:  That's one way to do it.



STEVE:  I'm still grandfathered into my original AT&T unlimited bandwidth account.



LEO:  Oh, that's nice.  Be careful with that.  You know they're going to try to take that away from you.



STEVE:  Yes.  So far they haven't.  And it's moved between Pads very nicely.  So...



LEO:  There's an interesting argument.  A lot of people say, well, look at the Nexus 7, $229, really nice device.  And I agree, I have one, love it.  But there's an interesting and kind of unexpected dichotomy between the aspect ratios.  16:9 is a little strange compared to 4:3.



STEVE:  Yeah.



LEO:  And it seems like a small thing.  But I actually think I prefer 4:3. 



STEVE:  I know what you mean.



LEO:  The widescreen's just a little too wide.



STEVE:  Yup.  And in fact, that's what I felt when I got one was, for example, when you're reading a page, it was too tall.



LEO:  Yeah.  It's weird, it's a little weird.



STEVE:  Yeah.



LEO:  But for reading and for a lot of the things, music scores, things like that, 4:3 is actually a more optimal aspect ratio, unexpectedly.  It's not more optimal for watching movies and TV.



STEVE:  Right.



LEO:  So, yeah, you should have all of them [laughing].  Oh, my goodness.  That's why I'm in this business, so I can have everything.



STEVE:  Well, and I do love the idea that they may have fixed, like tweaked the full-size Pad, which we're not going to call the Maxi Pad.



LEO:  No, the Air.



STEVE:  By pulling down the borders, making it lighter and a little thinner.  And it's like, wow, that might be just the ticket for, like, so you still get the larger screen, but it does feel physically smaller, and it is definitely lighter.



LEO:  I think I said that yesterday, which is, while I am a fan of the mini, they may have made the Air small enough that it accomplishes the same thing.  So I'm not going to buy both, but Sarah's going to get the new Air for iPad Today.  And I'll get the mini because I like that.  And then I can decide which I want to use all the time.  But this is iPad 3, third generation, not even the fourth generation, not even the current one.  It's fine.  I don't feel - and this is where Apple has a problem.  I don't feel any urgency to upgrade.



STEVE:  Yes. If it wasn't the device I use all the time - for example, I have three others.  And I'm not going to bother upgrading them because they're just fine.  They're retinas, and they're all I need.



LEO:  That's kind of a problem for Apple.



STEVE:  And I do really like the ecosystem, the iCloud Sync now and cross-syncing the devices.  I'm beginning to play with that.  And it's nice that you buy an app once, and you've got it on all of your various form factors.



LEO:  I agree.  I agree, yeah.



STEVE:  Okay.  So get a load of this.  CNBC was the first person or the first outlet that I saw pick up on this.  Actually, Rachel Maddow did a hilarious segment on this.  Her opening segment last night was 15 minutes of this, where she did, as Rachel does when she does a deep dive, really went into John McAfee's background and said, "You're not going to believe how this ties into Washington."  And she kind of held that to the end because prior to the October 1st shutdown and debt ceiling mess, John McAfee had been selected and chosen by the Affordable Care Act Oversight Committee to provide them with advice on the HealthCare.gov website.



LEO:  Some moron senator said, you know, I have that McAfee antivirus.  Let's get him.  And what's Peter Norton doing today?  I think we should ask him, too.  Holy cow.



STEVE:  Oh.  And, I mean, Rachel even reminded us, she went as far as to remind people how, when they buy a new computer, it's got this really annoying McAfee antivirus stuff, like preinstalled, and it's difficult to get rid of, and it wants you to upgrade it after it expires, blah blah blah.  I mean, and she talked about, as we have, we've covered it, how he was in Belize, and he had 11 dogs, Rottweilers or something, I think, and they were barking, and his neighbor was complaining, and his neighbor ended up being shot in the head, and then the escape to wherever it was he went to.  I mean, it's just...



LEO:  All they have to do is show that crazy video.  Well, is he still on the panel?



STEVE:  No.  Apparently it got dropped, somehow it got dropped during the shutdown.  And maybe people who were a little more clued in said, You might want to watch this video and decide..."



LEO:  A staffer wandered over and said, "Congressman, take a look."



STEVE:  Right.



LEO:  Is this what you want?  That, by the way, I don't know if - we haven't really talked about the health exchange snafus.



STEVE:  Oh, Leo.



LEO:  I have to say that I think what happens is people go, well, look, Facebook handles this fine.  Google handles this fine.  How come the government can't make a website?  But what they're trying to do, and once I dug deep into it, and actually...



STEVE:  Yes.  The integration...



LEO:  Harper Reed, who worked on the Obama campaign and is a superb computer scientist, said this is nontrivial.  They're integrating 50 different databases, or more than that.  I mean, it is not a simple thing to do.  I don't know many hundreds of millions of lines of code it is.  It could - it's not surprising it doesn't work, frankly.



STEVE:  Yeah.  I'm unsurprised.  It does sound like it was a catastrophe of design.  The subcontractor that did it is a wholly owned subsidiary of a Canadian firm.  Among other things, it loads 65 different JavaScript files in order to operate.  So there's a concern.



LEO:  That's a problem.



STEVE:  Yeah.



LEO:  They say, well, we didn't - we wrote the front end.   But the back end, the connections to all the databases, that's not our thing.  And that's really where all the problems are occurring is the connectivity that's required for this thing.



STEVE:  Yeah.  And of course the problem is that all anybody wants is for it to work.  And so everyone is, you could argue rightfully, blaming what they see, is HealthCare.gov doesn't work.  And no one is going to be able, I mean, can you imagine this going to some congressional committee?



LEO:  They don't understand it.



STEVE:  Again, they chose John McAfee.  They chose John McAfee to, like, oh, you must know what's going on.  So...



LEO:  Well, and the other issue is that it's government.  And I think it's an impedance mismatch between technology and government.  Government's designed to move slowly, to move by consensus, by committee.  Everybody gets their two cents in.  This is the worst way...



STEVE:  And to fight.  I mean, that's...



LEO:  Right.  And they were making changes till one week before the launch.  I mean, of course it didn't work because - and I think that this is a structural - I remember talking to Harper, we interviewed him on Triangulation, about how was it the Obama campaign was so technically literate, but then once you got to the White House, this transparent White House just never materialized.



STEVE:  Apples and oranges.



LEO:  He says, well, the technology in government is ancient.  I mean, they're using Windows XP and stuff.  And we were stymied by security regulations, politics.  You can't do it.  And I think it's a fundamental mismatch between the way this government was designed by our founding fathers intentionally to be inefficient.  They don't want an efficient government.



STEVE:  Jon Stewart had a hysterical piece also, Monday's Comedy Central "Daily Show," where one of his guys, after he got through really lambasting the administration, one of his roving reporters had been trying to get in and was somehow transported into the server, where Pacman was chasing him around going [making sounds].  And Jon said, "How old is this software?"  So it also had sort of a look like "The Matrix" with numbers changing, and Jon said, "What are those fours and fives?"  And the other guy said, "I know, they're supposed to be ones and zeroes, but this one has fours and fives."  So anyway, it was pretty good.  If you can see Monday's "Daily Show"...



LEO:  John Oliver, he is so funny.  I love him.



STEVE:  Yeah, exactly, John Oliver.



LEO:  Yeah, so, I mean, there's not much for us to say about HealthCare.gov except that...



STEVE:  I'll just end by saying that what I believe is that, whatever happens during the 2014 midterm elections, that it will be decided based on the Affordable Care Act.  I mean, if they get this fixed, and it comes up and runs and is doing a good thing, then that'll be one outcome.  I mean,  it's very possible that this really just could collapse, that, I mean, that it's going to take months.  And what I'm worried about is I'm hearing the pundits say, "We have three weeks."  They're saying, like, this has to be working in three weeks, and otherwise it's just too long.  And it's like, well, maybe three months.  As you said, it is big and complex.



LEO:  I don't know if three months is enough.  I mean, I don't know.



STEVE:  I know.  It could be easily - it could take a year for it to all get running correctly.  It's big.  It's bad. 



LEO:  Yeah.



STEVE:  So Google has something interesting, and I wanted to fix some of the misconceptions about this because the news, the little snippets that I saw were saying, oh, Google is going to be offering DDoS protection.  Well, kinda.  Forbes carried the story and carefully explained what Project Shield was and was not.  And so they said:  "Over its years as an Internet behemoth, Google has learned a lot about fighting hackers who would knock its services off the web.  Now it's offering its muscle to a far more vulnerable set of targets."  And that's the point.  Well, I'll go on.



"On Monday of this week, the company announced that it will offer free - free - protection for websites against so-called 'distributed denial of service' cyberattacks that flood them with junk traffic from hundreds or thousands of computers, taking them offline.  The project, which is part of the company's Google Ideas initiative to take on global problems, has already been working for months with at-risk sites around the world in countries like Iran, Syria, Burma, and other places where sites with political content are often subject to attack, and will expand in its initial phase to hundreds of sites.



"CJ Adams, an associate with Google who announced the Shield project at a company summit in New York, said, 'We're able to take the people who face the greatest threats to distributed denial of service attacks and get them behind our protection.  If they face an attack, it has to get through us first, and after years of working on this we're pretty good at stopping these attacks.'  Among the beta users of Project Shield are the Persian-language political blog Balatarin, a Syrian website called Aymta that provides early warnings of SCUD missile launches, and an election monitoring website in Kenya called the Independent Electoral and Boundary Commission.  Adams said in his talk at the summit that Project Shield had enabled the Kenyan site to stay online through a Kenyan election for the first time in its attack-ridden history.  Adams said, 'Things that can take many of these sites offline are so small to us, we can easily absorb them.  That's made this something we can provide fairly easily.  It has a huge impact for them, and we can take the hit.'"



So I just think that's neat.  It's pro bono.  It's sort of selectively helping organizations that Google deems worthy of having sort of the right to be on the Internet.  And not available commercially.  You can't buy this from Google.  And it's those sorts of politically and socially sensitive sites and Google sort of promoting free peace or free speech, rather, is just saying, yeah, we're just going to do this for you.



LEO:  Good.



STEVE:  So that's neat.



LEO:  Yeah.  It's not a full - there are companies that provide this kind of DDoS protection.



STEVE:  Yes.  Oh, that you buy for extreme...



LEO:  And this wouldn't replace that.



STEVE:  Correct.  So, for example, gambling sites that absolutely have to be on during the big fight, where they have been subject to extortion, saying either you pay us this much money or you're going to be down during this period of time that you absolutely have to be online.  And it is often the case that those sites will go down.  Then they'll learn their lesson, and then they'll start paying for very expensive bandwidth that is, you know, you have to essentially share a really big pipe with a lot of people like this in order to manage the costs because really big pipes are really expensive.



LEO:  Right.



STEVE:  We have another victim of the NSA's, essentially the NSA's and actually our government's approach to dealing with the Patriot Act consequences.  A VPN, a commercial VPN service known as CryptoSeal said, they posted a couple days ago:  "With immediate effect as of this notice, CryptoSeal Privacy, our consumer VPN service, is terminated.  All cryptographic keys used in the operation of the service have been zero-filled (purged).  And while no logs were produced (by design) during operation of the service, all records created incidental to the operation of the service have been deleted to the best of our ability.  Essentially, the service was created and operated under a certain understanding of current U.S. law, and that understanding may not currently be valid.  As we are a U.S. company and comply fully with U.S. law, but wish to protect the privacy of our users, it is impossible for us to continue offering the CryptoSeal Privacy consumer VPN product."



The statement continued, saying:  "The government takes the position that, if a pen register order is made on a provider, and the provider's systems do not readily facilitate full monitoring of pen register information and delivery to the government in real-time, the Government can compel production of cryptographic keys via a warrant to support a government-provided pen trap device."



So this is a sort of somewhat more formal statement of what we saw play out with Lavabit.  We saw the drama of Lavabit.  And so here is their understanding of why, as a U.S. company, they can no longer honor their obligation to provide the security that they believed they could.  And so they're just saying, okay, we're wiping our keys and shutting down.



LEO:  Wow.



STEVE:  Yeah.



LEO:  If you were using this service, what's the impact to you?



STEVE:  I don't know in detail what technology they had.  That is, whether, for example, the connections had perfect forward secrecy as an option, that is, were they negotiating keys for the connections that were not dependent upon the master keys.  But what this does say is they've wiped the keys and deleted them so even if traffic had been captured, by preemptively wiping the keys, they can no longer be compelled to turn them over.  So they're gone.  So in this case, even if the connections were not using perfect forward secrecy, they have kept those keys out of the hands of the U.S. government.  And so the prior possibly recorded encrypted traffic of their customers is safe.



LEO:  Good.



STEVE:  And so that was their goal.  And that's what you have to do if you really want to - if you're serious about this.



LEO:  People probably are wondering about our sponsor, proXPN.  And they are based out of Holland and Singapore.  I don't know - they're multi-homed, and I think one of the reasons is they don't want to - they're worried about U.S. requirements.  But I don't know what they require.  I don't know what the status is.  Are all VPN services now that operate in the United States subject to this problem?



STEVE:  I don't know.  I mean, they have stated, proXPN has stated that they do comply with the laws of the countries in which they operate.  So...



LEO:  Well, as everybody does.  You have to, or you don't operate in the country anymore.



STEVE:  So maybe that means you connect to non-U.S. endpoints which proXPN offers, and then that way you're out of U.S. clutches.



LEO:  I think you have to.



STEVE:  That's what I would do, yes.  That's what I would do.



LEO:  Geez, Louise.  I mean, now, and we talked, and I think I sent you a link to this very interesting article by a long-time security guy, security researcher Dan Greer.  Or Geer, I should say.  And I think maybe in a future episode we should talk about it.  But I want to - I put it in the chatroom, and I'm hoping people will take a look at it because he makes an interesting point, which is you don't have much choice.  As soon as the political will of the people and of the governing bodies, the government, is we want total security, never again will we have an attack on our shores, as soon as that mandate is issued, the only way to ensure it is for total information awareness.  You need to, you cannot with a hundred percent certainty protect the country unless you know everything that's happening.  Otherwise you can't say with certainty that something hasn't happened.  And so he says we've made a deal with the devil, in effect.



STEVE:  People have probably seen the news about IBM's Watson computer, which won the, what was the game show that Watson...



LEO:  "Jeopardy."  "Jeopardy," yeah.



STEVE:  "Jeopardy."  And now it's apparently, I just saw a blurb that it's better at diagnosing cancer than cancer specialists, than oncologists are, given the same data.  And you can well imagine the NSA ordering up some Watson machines.



LEO:  Well, they did.  We already know they did.  We know Watson is now helping - oh, no, we - they - IBM has said it, that Watson's new task is no longer playing television game shows or curing cancer, but analyzing security threats.  Oh, no, they've already said that.



STEVE:  Oh, boy.



LEO:  But, and so he raises the really, I mean, important point, I think, that the NSA is really - you can't really blame these security agencies.  They have been tasked with doing something that is virtually impossible and which requires gathering of all information.  And so they're just doing their job.



STEVE:  So we're going to talk about instant message clients here in a minute.  But we know that the good news is TNO technology, Trust No One technology, is readily available.  So we have cloud backup that cannot be compromised.  We have instant messaging that cannot be compromised.  Not everyone uses it.  And you have to be careful how you operate.  But the problem is, if you want to connect to a remote server over the public Internet, there you don't have the same one-to-one encryption guarantee that you can create when you're backing up your own data.  And so only you need to be able to get it.  Or you have a - you've established cryptographic keys a la PGP with somebody else.  Then it's absolutely the case that the fact of your communication cannot be hidden, but the content of your communication can.  So...



LEO:  Right.  Although ironically, and Dan Geer talks about this, as well, the metadata is often more valuable than the content.  So the fact that they can in fact see all the transactions is probably all they really need.



STEVE:  As you and I talked about when the whole PRISM thing first broke, and people were saying, oh, but it's only the metadata, it's like, oh, my god, that's the social network that is of vital importance.  And that's why, as we talked about last week, they're sucking in everybody's buddy lists in order to, again, to build networks.



LEO:  Right.  Incredible.



STEVE:  Okay.  So we have - okay.  So the headline here is I don't know why this didn't happen sooner.  And we've been on borrowed time, really, with malware that hasn't been really evil.  Years ago there was a piece of really evil malware called the Chernobyl virus.  CIH was the acronym for it.  And it wiped out the first megabyte of your hard drive.  That's what it did.  If you got infected with this thing, it zeroed, wrote zeroes over the first megabyte of your drive.  And because of my position in the industry with SpinRite, I got all this influx of, like, oh, my god, will SpinRite help me?  And of course no.  I mean, the first megabyte of your drive is gone.  But then I thought about it, and I ended up writing FIX-CIH and gave it away for free.  In the same way, remember Trouble in Paradise, TIP, which was a thing that fixed...



LEO:  That's how we met.



STEVE:  ...the Iomega Zip drives.  Yes, it was.  So this thing, what I realized was, even though it wiped out your partition table, it wiped out the root directory and, like, most of the FAT - with drives at that time, the second copy of the FAT had not been touched.  That is, the first copy of the file allocation table was it pushed things far enough away that I was able basically to perform a full drive reconstruction.  And to a huge number of people's relief, because this thing spread like wildfire, they were able to run FIX-CIH, and then everything was back.  They were, like, a little surprised.  But so what we have today - I mean, so there was just pure malice.  And it didn't make anybody any money, which is why probably it died off quickly.  Also it tended to kill its victims.  And when something kills its own, like, kills its host, then it's unable to propagate from there.



So now what we have is something that surfaced about three weeks ago called CryptoLocker.  And the most recent incarnation of it accepts anonymous payments through Bitcoin.  Okay.  So let's back up a bit because our listeners have been asking me to tell them about CryptoLocker for a while.  The headline that Dan Goodin at Ars Technica wrote said:  "You're infected.  If you want to see your data again, pay us $300 in Bitcoins."  And the subhead was:  "Ransomware comes of age with unbreakable crypto and anonymous payments."  So, and if you want to, Leo, just put "CryptoLocker" into Google, and you will see, I mean, it is bad.



Okay.  So what does it do?  It is typically installed through phishing attacks in email.  So people will get an email that looks reasonable to them, and they will click on a link, and it'll be an executable, and they will now be infected.  It installs itself into the Documents & Settings folder under a randomly generated name and adds itself to - and this is Windows only - to the Windows autorun list so that it executes every time you run Windows or start up Windows.  It produces a lengthy list of random-looking server names in the domains of .biz, .co.uk, .com, .info, .net, .org, and .ru.



And we know from talking about this before that these are cryptographically generated domain names where the code knows, based on date, what set of domains out of a huge array may be online at that time.  So this is the way they avoid anyone getting involved in shutting them down is this - it's like it's a spray of long, random-looking domain names, one or two of which will be valid among a huge population.  And it's continually changing.  So the bad guys know what the domain name-generating algorithm is, and they selectively register valid random-looking domain names out into the future.  And so it's really difficult for authorities to get in there and stop this.



So after generating this large collection of random-looking server names, it then tries to make web connections to each of these servers in turn, trying one every second until it finds the valid one hidden among this debris which responds.  When it does, it uploads a file which essentially we can think of as the CryptoLocker ID for the user.  Then that remote server generates an asymmetric key pair, 2048-bit RSA asymmetric encryption, public key encryption, based on the user's unique ID, and sends only the public key back to the user's computer.



I mean, so what I'm going to describe here is perfect cryptography.  Evil, but perfectly executed.  I mean, these guys made no mistake.  So then the malware uses the public key.  It generates a random 256-bit AES key.  So it uses AES 256-bit encryption, generates a random symmetric key which it encrypts with the user's public key and sends that back to the server.  So now you have an encrypted with the public key symmetric key for performing bulk encryption that can only be decrypted with the never sent to the computer, never present on the victim computer, private key.



The program then goes through and enumerates and encrypts under the Rijndael AES cipher every single document that it can find on your machine - images, videos, spreadsheets, there's a large list of filename extensions that it - wildcard, *.doc, *.txt, *. spreadsheet, everything.  Everything, all the kinds of files that are typically user-created content, it runs through.  It also searches for files on all drives and in all folders it can access from your computer, including workgroup files shared by colleagues, resources on company servers, and more.  Anything within its reach.



LEO:  Backups, by the way, including backups.



STEVE:  Yes, exactly.  Including - so if you have hot online backups, they're victims of this.  So essentially, the more privileged your account is, the worse the overall damage will be.  So it does that to you, and then it pops up the pay page, giving the victim a limited time, typically 72 hours, to buy back - oh, and so once done with all this encryption, it overwrites and erases, zeroes the symmetric key.  So it is gone now from your computer.  That no longer exists.  Nothing on your computer has the information to decrypt what was just encrypted.  And in this little message, well, in fact, I'll read what it says.  This pops up on your screen and says, not in good English, says "Your important files encryption produced on this computer:  photos, videos documents, etc.  Here" - with a link - "is a complete list of encrypted files, and you can personally verify this."  So it shows you the list of everything that it just ruined for you.



Then it goes on, saying, "Encryption was produced using a unique public key RSA-2048 generated for this computer.  To decrypt file you need to obtain the private key.  The single copy of the private key, which would allow you to decrypt the files, located on a secret server on the Internet; the server will destroy the key after a time specified in this window.  After that, nobody and never will be able to restore files.  To obtain the private key for the computer, which will automatically decrypt files, you need to pay 300 USD / 300 EUR, similar amount in another currency.  Any attempt to remove or damage this software will lead to the immediate destruction of the private key by server."  And then it shows you a countdown timer of hours, minutes, and seconds remaining until you no longer will ever have access to your data.  And I've heard from several people who were stricken by this who tried to get a MoneyPak, and wherever they went the person said, well, it's weird, there's been a run on those recently.



LEO:  Oh, yeah.



STEVE:  We're out of MoneyPaks.  And it's because of this thing, and people are - and what's sad is that, when law enforcement has found and taken down the servers...



LEO:  Doesn't matter.  All they do is hurt people.



STEVE:  Well, precisely.



LEO:  They're killing the keys.



STEVE:  Precisely.  They are killing the keys, and then it's impossible for you to get your files back.  Not good.



LEO:  Wow.  Now, in this, Dan Goodin, who's so good, writes that you should have a cold online backup.  What is the difference between a hot and a cold online backup?



STEVE:  Well, that's...



LEO:  I guess Dropbox would be hot, right, because it's active.



STEVE:  Yes.  Anything that your computer can see through Windows Explorer, where you're able to browse through the normal file system, would be considered a hot backup.



LEO:  So Dropbox, any kind of built-in sharing kind of, yeah.



STEVE:  Yeah, anything that creates, yeah, essentially, if it has a drive letter, and you can see it in Windows Explorer, then this thing is able to find the drive letter, go out and look for files and encrypt them.



LEO:  Presumably then Carbonite would be immune.



STEVE:  Yeah.  Yes.



LEO:  Because it's just running - it's running as a program.  It's not - you don't have - you can't see the...



STEVE:  You don't have a file mapping to Carbonite.



LEO:  Right, right.



STEVE:  Exactly, yes.



LEO:  Well, then, let me do a Carbonite ad.



STEVE:  Now would be a good time, Leo.



LEO:  Yeah, and I would bet, knowing Carbonite, because they're very sharp about this kind of stuff, that they also provide further protections against this program accessing your data in any way.



STEVE:  I mean, it's horrifying.



LEO:  It is.



STEVE:  As I said at the beginning, I mean, there is no mistake they made.  This is cryptography being perfectly deployed for malicious end.  And the hook is it's not like it wiped out your files, ha ha ha.  It has taken them from you, and you actually can get them back if you pay $300.  And apparently they're making a ton of money.



LEO:  Oh, yeah.  The FBI said, with other ransomware things, as much as $5 million a year.



STEVE:  Yes.



LEO:  Presumably this is even more.  You could see the incentive to do this.  Almost impossible to catch you.



STEVE:  Yeah, and I would just say to our listeners, warn your friends.  I know people who listen to this...



LEO:  Well, I'll talk about it on the radio show, for sure.



STEVE:  Yes.  People who listen to the podcast are among the savviest users.  We do not click on links in email.  But our friends and family aren't so careful.  And that's who's getting bit by this, and it's a bad bite.  So, yeah.



LEO:  Wow.  It's just amazing.  We've seen this before, but this is really a particularly nasty variant.



STEVE:  Well, and the problem is all of the technology is in place now.  As I said when I started this, I don't know why it didn't happen sooner.  The technology has been available.  We've really been on borrowed time that malware has just sort of oddly existed for the sake of existing.  I mean, yeah, I guess there's some weird, like installing search bars and cruft in browsers, where there's some way to monetize that so that you - it changes your search to something where there's - some sort of, like, social networking search stuff where people install this junk and make money.  But this is a problem.  This is generating, I mean, the problem is this is going to succeed, and we're going to see more of this.  My sense is this is going to change the landscape a little bit.  I'm not sure how.



But, I mean, this is really bad.  And so this is not a nuisance.  Jenny got her laptop infected with one of these search bar things.  It was popping up a whole bunch of tabs a couple weeks ago.  And so I fixed it for her.  And it was like, okay, it's fixed now.  But this is a different category.  This is not "Remove it and then you're okay."  This is "Your data is gone."  So, yeah, I'm glad she's using Carbonite, as she is.



LEO:  Tell your friends.



STEVE:  So I got a neat tweet a couple days ago from a friend of ours who we've heard from before, Christian Alexandrov, tweeting from @Diabolikkant.  I'm not sure what that is, but that's his Twitter handle.  And first he sent me a tweet, he said "SpinRite saved me twice today.  I wanted to share with Security Now! listeners."  And so I just - I glanced up and saw that in my TweetDeck.  And so I wrote back, I said, well, okay, you could do a video, or you could write it up and post it to GRC.com/feedback.  I said, if you do, tweet me, and I'll go get it, so that I see it.



And so not long after that I got another tweet, he said, "I sent the story to you in text on GRC.com/feedback, titled "Twice the time, twice the good."  So, and it was kind of fun, so I wanted to share it.  So this is - he's in Sofia City, Bulgaria.  And he said, "Hello, Steve and Leo.  I want to share a SpinRite story with all Security Now! friends.  I called my dentist to schedule a session for a tooth that hurts me.  My dentist tells me his computer went down again."  And we may remember this is where we heard from Christian before was that he had dental problems and got some free work done.



He says, "So he told me I have few hours before he can do anything," meaning that I guess the office was closed because he has no computer.  So Christian says, "I decided to go to the nearest restaurant to have a breakfast.  Guess what?  Restaurant was out of business for the day.  Guess why?  Computer failure.  You see where this is going; right, Steve and Leo?" he writes.  So I offered my help to both restaurant and dentist.  Then it just struck the dentist like bolt of lightning, we had an arrangement.  I fix his computer, he heals my teeth in return."



Then Christian writes, "Dentist is done."  Whatever that means.  "So dentist told me to come to my clinic at 1600 hours to take care of the PC, and I will take care for you.  Good.  I had six hours free," writes Christian.  "The restaurant owner was desperate and accepted my offer.  I let SpinRite loose on restaurant's computer on Level 2.  It took SpinRite four hours to process the drive.  After that, some Windows and Office updates, disk cleaning, registry cleanup, defragment the drive, and the computer was every bit as good as new.  The restaurant owner was happy and promised me a dinner for me and my beloved.  Later, I went to my dentist with my tools."  And teeth, apparently.  "Same operations like the restaurant were in order for the PC.  But SpinRite..."



LEO:  So funny.  So funny.



STEVE:  Things must be rough in Bulgaria.  "But SpinRite brought me a headache," he wrote.  And I thought, what?  Anyway, he says, "While SpinRite was loose on Level 2, the dentist healed me.  When we finished, I interrupted SpinRite and rebooted the PC.  Turns SpinRite fixed the problem while the dentist was healing me.  Well, SpinRite brought the disk back from the realm of the dead to realm of the living to find that the computer was infected.  I used Sysinternals tools to remove the malware.  Thanks, Mark Russinovich, for such great tools.



"Well, the PC was up and running.  Then the dentist's phone rang.  It was IT support, telling the dentist they can take his case in 48 hours from now, apologizing for inconvenience.  The dentist told them not to bother, he hired someone else to fix the problem, and the PC is up and running.  After I removed the malware, I updated Windows, Office, and ran disk cleanup, registry cleanup, disk defragment, and after all finished I asked my dentist to check my work.  The dentist loved it.  Then out of nowhere his IT support came to ask what is going on.  The dentist just fired him without much explanations.  Now I'm his IT support.  So he was so happy that he asked, what else can I do for you?  I asked him to check my girlfriend's teeth."  [Laughter]  "He not only checked her, but started full and complete healing sessions for her FOR FREE" - in all caps.



LEO:  Wow, he's a happy dentist.



STEVE:  "Later this evening we got back to the restaurant, where we had our romantic dinner with nice music, fine meals, and fine wine, as promised by the restaurant owner, for free.  Thank you, Steve, for this great software.  Thank you, Leo, for your great Security Now! podcast.  And last but not least, thank you, Mark Russinovich, for your great Sysinternals tool and your great books, 'Zero Day' and 'Trojan Horse.'  I look forward for the third one, 'Raw Code.'  Christian Alexandrov."



LEO:  Awesome.  Awesome.  Next time I want you to read that in a Bulgarian accent.



STEVE:  Oh, I can't, no.  We would never get through it.



LEO:  [With accent] SpinRite fixes teeth and makes dinner.  Makes happy girlfriend.



STEVE:  Oh, that's wonderful, yes.  Makes girlfriend happy.  And happy teeth.  So...



LEO:  Continue on.  I have one more ad to do, so you tell me when it's an appropriate time to break.



STEVE:  Okay.



LEO:  All right.



STEVE:  We have a - this is really interesting to me.  Written entirely in JavaScript by the Mozilla Project, a Flash Virtual Machine.



LEO:  Oh, wow.



STEVE:  Yeah.  It's called Shumway.  And I ran out of time.  I meant to look up, what does Shumway mean?



LEO:  That's a very familiar name; isn't it.



STEVE:  Isn't it?  It's like somebody in some movie or series or something.  It just seems familiar to me.  Shumway must have been someway.  I'm sure the chatroom will probably instantly identify it.



LEO:  Norman Shumway pioneered heart surgery at Stanford.  I don't think it's him.  Sounds like something from, like, "I Dream of Jeannie" or something; doesn't it?



STEVE:  Or something maybe more pop and recent, I don't know.



LEO:  Oh, Gordon Shumway is Alf.  Or Norman Shumway.  Alf.



STEVE:  Was the actor who played Alf?



LEO:  I don't know.



STEVE:  No, Alf was a puppet.



LEO:  Alf had a real name.  Gordon Shumway.



STEVE:  Oh, really?  Okay.  So the website...



LEO:  I don't know what that has to do with Flash.



STEVE:  The website is AreWeFlashYet.com.  So you can just go to AreWeFlashYet.com, and that will - you'll be in the Shumway project.  And this is a group.  Their official statement - it is over on GitHub.  Their official statement is "Shumway is an HTML5 technology experiment that explores building a faithful and efficient renderer for the SWF file format without native code assistance."



LEO:  That's amazing.



STEVE:  I know.  I just can't, it's like, thank god that's not my project.



LEO:  Do you need to have Flash?  Or you don't need Flash at all.



STEVE:  No.  No, this will run...



LEO:  It replaces it.



STEVE:  Yes, it replaces it with native - in the same way that Firefox is now natively rendering PDFs, they are working towards native rendering Flash.



LEO:  Wow.



STEVE:  So they say, "Our goal is to create a general purpose, web standards-based platform for parsing and rendering SWFs.  Integration with Firefox is a possibility if the experiment proves successful."



LEO:  You know, the name may come from the old joke.  Ask me what's a Shumway.  Ask me what's a Shumway.



STEVE:  Okay.  Leo?



LEO:  Yeah?



STEVE:  What's a Shumway?



LEO:  About five pounds.  No?



STEVE:  Oh, my god.



LEO:  No, that's pretty bad.



STEVE:  Unfortunately, that's the humor I grew up with.



LEO:  And it may be the humor the Mozilla folks grew up with, too.



STEVE:  My grandfather would say, "I opened the window, and influenza."



LEO:  Yes, exactly.  All right.  The chatroom may have it.  So what is Alf backwards?  FLA.  The filename extension for a Flash file, one of them, is Alf backwards.  And Alf's real name was Gordon Shumway.



STEVE:  Got it.



LEO:  That's a long way to go.



STEVE:  Wow.  That's a really...



LEO:  But you know geeks.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Okay.  So the first of three instant messaging topics:  BlackBerry Messenger now available for iOS and Android.



LEO:  Now, you're one of those people still using a BlackBerry.  So I'm curious what you think of this.  By the way, it's so popular, when you download it and install it, it says "Wait in line."



STEVE:  Yes.  So 10 million downloads in the first 24 hours, says BlackBerry.  It became the No. 1 download on both iOS and Android platforms after announcement.  And they were overwhelmed with response.  And so as you said, Leo, I think it was maybe Monday, maybe Monday evening, I got it, and then it said, sorry, you're going to have to wait in line.  And then this was on my new iPhone 5s that I wanted to install it because, you're right, I'm still - haven't yet made the conversion over.  I'm still using a BlackBerry.  So I thought, oh, cool.  And I gave them an email address for me, and they said, "We'll email you when you are first in line."  And then I saw a link to a way to get around needing to wait.  CNET has a story, "How to Avoid Waiting for BBM on Android and iOS."  It turns out their blockage isn't very high tech, and so it's easy to get yourself first in line.



And what PC Mag said was:  "BBM was the originator of the modern read receipt, and while that's been replicated in both iMessage and Hangouts, BBM still does it pretty well.  You can also do group chats, share pictures, and send files.  It basically does all the stuff the first-party messaging clients do, but it's running through BlackBerry's servers.  If you're worried about security, this should be on your radar."  Now the problem is, I take issue with that.  I mean, we know that BlackBerry was big on security.  The problem is, even BlackBerry themselves say that you should consider your messages scrambled and not encrypted.  And my message to our listeners is BlackBerry Messenger is not TNO.  BlackBerry uses a PIN technology, and you're assigned a PIN when you register your BBM on - you get one on a BlackBerry, and it assigns you one when you register it on an iOS or Android device.  And unfortunately the encryption uses a global key that everybody has.



LEO:  Everybody has, great.



STEVE:  I know.  So thank you very much.



LEO:  It stops nothing, no one.



STEVE:  Yes, exactly.  In BlackBerry's own documents they said PIN-to-PIN messages are encrypted under a common global key, and they pass through BlackBerry's infrastructure.  They are definitely subject to selective decryption.  PIN-to-PIN is not suitable" - that's okay, Leo, keep sighing, because we're going to talk about one that is here in a minute.  But "not suitable for exchanging sensitive messages, although..."



LEO:  It's also lame because you have to find out somebody's PIN.



STEVE:  Yes.  Although PIN-to-PIN messages are encrypted using Triple-DES, which...



LEO:  Oh.  That's strong.  Of course, everybody knows the key.



STEVE:  Yes.  That's the problem.  "The key used is a global cryptographic key that is common to every BlackBerry device in the world.  This means any BlackBerry device can potentially decrypt all PIN-to-PIN messages sent by any other BlackBerry device, if the messages can be intercepted and the destination PIN spoofed.  Further, unfriendly third parties who know the key could potentially use it to decrypt messages captured over the air.  Note that the 'BlackBerry Solution Security Technical Overview' document published by RIM specifically advises users to 'consider PIN messages as scrambled, not encrypted.'"



So they're obfuscated.  Now, so where would this be useful?  I don't know why 10 million people downloaded it.  And I'm not sure now why I'm one of those.  But I did.  However, after doing additional research, that is, this research, it's like, that's not what I wanted.  What I was looking for was something to lift a dialogue with my best friend out of texting because, first of all, it's annoying that you have 140-character limit in texts, or I guess is it - I guess it's 160?



LEO:  It's 160, technically, yeah.



STEVE:  Yeah, exactly, because Twitter is 140.



LEO:  Yeah.  And that's because of UNICODE or something, I can't remember.  There's a reason.



STEVE:  So that's annoying.  Well, it's because you want to encrypt your handle back and forth in order for that, for public stuff.  But so that's annoying.  But mostly he's using a corporate iPhone, and he's a little anxious, like when we're talking about playing hooky and rendezvousing to go see some wonderful sci-fi on a Friday afternoon, that, well, I wouldn't like my boss to know that that's what I'm doing.  So it's nothing mission critical.  We don't care if the NSA knows.  But we would just like to not have it, because it's a company phone, for his employer to have access to it.  So it's like, okay, this looks like it would be nice.  I mean, it's very nicely executed.  I did play with it for a while.  BBM is a nice piece of work.  Not TNO.



So, next up, I just got email from Hemlis.  Remember that Hemlis means "secret" in Swedish.  And we have so far been unimpressed.  Their site is Heml.is, so they found their name by finding a top-level domain that's .is and then doing an H-e-m-l in front of it in order to get their name as their domain.  And what they sent me was news of a new video showing it in operation, where they have three phones, and they're, like, sending text messages between these three phones.  And it's like, okay.  So now it works.



The problem is, in their Q&A, their own question is:  What technology will Hemlis use?  And then the answer is:  We are building Hemlis on top of proven technologies such as XMPP with PGP."  Then the next question is:  Why not use OTR?  That's of course Off The Record, which we did a podcast on, which is what Cryptocat uses for its secure messaging, and it's really good.  But they respond to that question:  Even though we love OTR, it's not really feasible to use in a mobile environment.  The problem is that OTR needs both parties to be online for a session to start, which is true.  But a normal phone would not always be online.  It would not work at all for offline messages, neither, they say.



And then the kicker is the last question that I highlighted:  Will you provide an API and/or allow third-party clients?  Their response is:  At this point we don't see how that would be possible without compromising the security.  So for now the answer is no.  And that ends it.  Because what we know, I mean, there's no lesson our listeners should know better than a system that relies on the secrecy of its architecture is not secure.  Just look, for example, at SQRL, SQRL that I've talked about.  Completely open.  Here's how it works.  This is what it does.  No secrets.  Because the architecture is secure, and anyone who wants to make a client is able to do so.  So, I mean, that's the way you do security now.  It's like GNU Privacy Guard, where it's completely open.  It's like TrueCrypt.



LEO:  You have to, yeah, yeah.



STEVE:  Open source.  Here's TrueCrypt, open source, and the point is that you can - anyone could do, could write a TrueCrypt-compatible interpreter to interpret a TrueCrypt volume with the documentation that's there.  That's the way you do it.  So the idea that they're saying, no, we won't let you look inside, it's like, that's wrong.  And it's the other reason that I felt so good about LastPass was that, when they - when Joe showed me how it worked, explained every detail of it, he even had sample code JavaScript right there, demonstrating it functioning.  So it's like, yeah, prove it to yourself.  Encrypt something, and go to the web page here, and we'll decrypt it for you, and you can look at the code.  It's like, yep, that's the way you want to do it.



So I tweeted about BlackBerry Messenger this morning, and I got a bunch of people who responded, saying, well, then, what is TNO?  What should we use?  And so I wanted to remind everyone about Threema, which I really like and which really looks good.  And when I remind you, Leo, that it's the one with the three dots, then you go, oh, yeah, I like that one.  It's not free.  It's $1.99 U.S.  So, and the good news is, you pay two bucks, and you're supporting them.  You're not wondering what their economic model is for existence.  They say:  "Threema is a mobile messaging app that puts security first.  With true end-to-end encryption, you can rest assured that only you and the intended recipient can read your messages.  Unlike other popular messaging apps (including those claiming to use encryption), even we as the server operator have absolutely no way to read your messages."



And so these three levels, Level 1, one dot which is red, is the ID and public key have been obtained from the server because you received a message from this contact for the first time.  No matching contact was found in your address book, by phone number or email, and therefore you cannot be sure that the person who they claim to be is - I'm sorry.  That the person is who they claim to be in their messages.  So they're saying, okay.  That's the red level of trust.  Then Level 2, the orange level, which is two dots, the ID has been matched with a contact in your address book by phone number or email.  Since the server verifies phone numbers and email addresses, you can be reasonably sure that the person is who they claim to be.  And then, third, the full-strength, three-dot green level, is you have personally verified the ID and public key of the person by scanning their QR code.  Assuming their device has not been hijacked, you can be very sure that messages from this contact were really written by the person they indicate.



And so what I'm doing is I'm going to have my buddy Mark buy Threema, and we will meet and swap QR codes, swap public keys face to face, and that way...



LEO:  That's a great idea.



STEVE:  Isn't that neat?  And then...



LEO:  I'm going to do that, too.  I'm buying it, downloading it right now.



STEVE:  Yup.  I really - this is my choice.  These guys make...



LEO:  iOS and Android, which is great.



STEVE:  Correct.  And they said the verification levels don't change anything in the encryption strength.  It is always the same high-grade elliptic curve cryptography-based encryption.  But they are a measure of the trust that the public keys saved for your contacts really belong to them.  Having the wrong public keys leaves you open to man-in-the-middle attacks.  Therefore it is important to verify the keys.  And then they also said:  Why the name Threema?  And I was curious, so I looked.  It says it started life as an abbreviation, EEEMA, for End-to-End Encrypted Messaging Application.  The three E's were a bit unwieldy, so it became Threema.



Anyway, the other thing I love about this, Leo, you can, on that FAQ page, they're saying:  I don't know anybody yet who has Threema.  How do I make sure it's working?  And they give you a QR code right there for their ECHOECHO person.  And so I scanned it.  It created a contact in my contact list, and I sent it a message which instantaneously was returned.  And that's the other thing that is so cool, is why I like being in an Internet-based service rather than texting, is that sometimes Mark and I, he'll be swinging by to pick me up, and I'll say, "Send me a text, and I'll run out."  And the other day he said, hey, you know, he finally called me.  He said, well, hey, I texted you, and you didn't come out.  It's like, well, okay.  And it wasn't until we were at dinner that I finally got his text message.  So just not having any texting delay is really nice.  This thing, you could easily have instantaneous real-time conversations using Threema with absolute standard, public key-swapping, end-to-end encryption.



LEO:  So I got it on - I set up a key.  Now it gave me a string, an easy-to-remember-and-say string of, I don't know, seven or eight letters.  So I could give you that.



STEVE:  Yes.  What I'll do is...



LEO:  But the QR code would be more secure.



STEVE:  Yeah.  I will put you in my address book, and I will send you something so that you can get it, so you and I can exchange and achieve orange level.  And then when I see you over New Year's, we'll aim our phones at each other and go to green level.



LEO:  [Chuckling] I love this.



STEVE:  It's very cool.



LEO:  I have no idea if it's good or not.  But I trust you, so.



STEVE:  Okay, so...



LEO:  It's not open source so there could be a backdoor in it; right?



STEVE:  I just don't see any, I mean, it's like, okay, yeah, but I'm trusting these guys.  They seem 100% to have done it right and to be doing the right thing.  And wherever they are, they're not in the U.S., either.



LEO:  Switzerland.  They're Swiss.



STEVE:  Yes.  Yes.



LEO:  Cool.  All right.  Now, Steve Gibson, and something weird in the Patent & Trademark Office.  Doesn't seem unlikely, frankly.



STEVE:  Well, okay.  After last week's podcast, on Thursday, October 17th, came the news that the U.S. Patent & Trademark Office had reversed a prior decision...



LEO:  By the way, I said proXPN, not OpenVPN.com.  ProXPN, proXPN.com.  Let's get that right.  Go ahead.  They've reversed their decision.



STEVE:  They have reversed their decision on what is being called the "Steve Jobs Patent."  This is a patent that Apple has which is amazingly broad and essentially forecloses any other use of touch for managing a device.  There are 20 claims in this patent.  And there was a - it was secretly contested, meaning that someone, and it is speculated Samsung or Google, said to the U.S. Patent & Trademark Office, we need - we're challenging this patent secretly, so we think it needs to be overturned.  Initially, that was granted.  Last Thursday, on further analysis, all 20 claims were upheld.



And, for example, among them is you put your finger on a touch-sensitive surface, and moving it vertically scrolls the page.  That's Claim No. 1.  You put your finger on the touch-sensitive surface and moving it side to side changes items.  That's Claim No. 2.  And it goes on like that.  I mean, I don't know what this means, but it seems like it's really bad news for anybody else who wants to do a touch-enabled device, like Samsung and Microsoft and Google, because this has been really looked at, and the claims are being upheld.  Maybe what now has to happen is that this goes to court, and those with interests other than Apple, maybe they'd get together or individually they find a prior art, or they demonstrate that this fails the obviousness test because that's of course one of the tests that a patent has to pass is that it would not be obvious to someone trained in the art.



I remember I had a crazy program, it's the Windows program that I wrote to teach myself Windows programming called ChromaZone.  It was a commercial product that GRC did that used palette animation.  And one of the things that ChromaZone did was you could scroll the help by putting the mouse on the surface and dragging the surface, which is exactly what you do with your finger dragging the surface.  So it's like, well, okay, is that not the same?  I don't know.  But it stuns me, first of all, that this patent, it seemed reasonable that it would be overturned.  Now it's been - all 20 claims have been upheld.



LEO:  Wow.



STEVE:  So, wow.  



LEO:  Yeah.  Patent Office loves that Steve Jobs.



STEVE:  Well, and Steve's name is No. 1 in the list of inventors.  There's about 50 in the list.  It's like everybody at Apple.



LEO:  I doubt Steve actually invented it.



STEVE:  One wonders what his role was, yeah.



LEO:  Wow, that's kind of surprising.



STEVE:  But really, Leo, how would you scroll something on a touch surface without doing that?  It's like, uh, duh.  So, yow.



LEO:  Well, and this is the risk of inter partes appeal of patents.  You can get a reexamination, but it doesn't guarantee they're going to do the right thing.



STEVE:  Yeah, and I think it's going to have to get litigated, and it's going to have to be - it's difficult to understand that Apple would be getting...



LEO:  [Indiscernible] is doing the same thing with the podcast patent.  And it's a debatable strategy because, if you win, it ends all litigation.  If you lose, it makes it that much harder to...



STEVE:  I think I just saw really good news, Leo, about that.  I was thinking of you.  Didn't I send...



LEO:  No, no.  They began the inter partes.



STEVE:  Oh, okay.



LEO:  That's - it's 18 months before we'll have a result.



STEVE:  Wow.



LEO:  Takes a long time.



STEVE:  Yeah.



LEO:  So beginning it is not concluding it.  And there's - you don't - I presume the lawyers at EFF looked at it and said, hmm, this prior art is strong, and we think we have a case.  But it's a very risky thing to do.  And we don't know if it was Samsung that pursued this.  It's an anonymous request.  And the problem is that now makes it very difficult for Samsung.  And I'm not saying this is a bad thing because I'm a Samsung fan or anti-Apple.  It's a bad thing because it means innovation now has a tax in touch.  You have to pay Apple if you want to use their patent.



STEVE:  Yes.  Yes.  Yes.



LEO:  And it does seem like a pretty trivial and obvious solution.



STEVE:  So our comment last week about there not having been any great sci-fi on TV...



LEO:  I was so wrong.  I take it back.



STEVE:  It drew a lot of ire from our listeners, who said, what?  Did you not see "Fringe," you moron?  It's like, oh, yeah, of course.  I loved "Fringe."  And, I mean, everyone did.



LEO:  I didn't like "Fringe" all that much, but...



STEVE:  Okay, I did.



LEO:  "Battlestar Galactica."  You had mentioned "Firefly," which is true.



STEVE:  Right.  And I've talked about "Stargate SG-1."  Anybody who wants to just fall into a beautifully produced sci-fi series, "Stargate SG-1" was really good.  What I loved about it was the premise that these - an ancient civilization completely covered the universe with stargates that allowed you to hop from place to place.  And so "Star Trek" solved the problem by getting in a bus and going somewhere.  And we need warp drive so we can get there in a lifetime.  "Stargate" solved the problem by creating wormhole between portals.  And it just - it's a perfect substrate for building a science fiction series.  And I loved it.  It had Richard Dean Anderson, who from "MacGyver" on I thought he was whimsical and fun.  So I loved it.



And I will confess that I'm enjoying "Agents of S.H.I.E.L.D."  Which is about - I think we're about four episodes in.  And, I mean, it is a little bubblegum.  But it's fun.  I'm liking it.  So, yeah, there is some sci-fi.  And, yeah, "Galactica" was also great for the first couple of seasons.



LEO:  It was I who said that.  Not Steve.  I said that.  Steve defended television sci-fi.



STEVE:  Steve may be on jury duty.



LEO:  Good luck.  It's actually fun.  I enjoyed it.



STEVE:  Well, I've never been impaneled, and I got the notice, like, six weeks ago.  I start phoning in Friday.  So there's a chance it could impact next week's recording, which is why I'm mentioning it now.  I've never been impaneled.  A litigator who's a friend of mine from Starbucks said the end of the month tends to be, like, no one's starting a new case then.  So they're not needing lots of new jurors because they're winding things down.  For some reason, she said, there's no real reason that anything would be month aligned.  But people don't like to start them at the end of the month, for some reason.  So anyway, we'll see.  Maybe you and I can find a time to do it when I'm, like...



LEO:  Oh, yes, we'll work it out.



STEVE:  That works for both of us if I'm unable to do it on Wednesday.



LEO:  We'll do it at night.



STEVE:  Because we know there would be an uprising if we...



LEO:  No, we have to do it.  And we will do it.



STEVE:  If we didn't have it.



LEO:  And don't try to get off the - you wouldn't do this, I know.  But sometimes people say, oh, there's good strategies for getting off the jury.  No, because that means all the smart people get off the jury, and the only people left are people who are too stupid to be able to get off juries.



STEVE:  Actually, the same person - I tried to last time.  I would love to.  I've never done it.



LEO:  Yeah, serve.  It's part of your civic duty.



STEVE:  This litigator said, "Steve, you are the last person they want on a jury because..."



LEO:  You're analytic.



STEVE:  ..."it's clear, well, and you cannot be controlled.  They want people that they can control."  And she said, "And frankly, knowing you, you would probably end up being the foreman, and so you'd run the show, and so, well..."



LEO:  They don't want you.  I thought the same, and I was impaneled, and I was very surprised because I said, you know, the judge, or maybe it was one of the attorneys, I think it was the judge said, "Would you talk about this on the air?"  And I said, yeah, after the trial's over.  They said, you know, it was very obvious that I - I thought, oh, there's no way you're going to put a journalist who will then write about the story after the fact on the panel.  No, they did impanel me.  So it's unpredictable.  But you know what, you want to get on there.  That's your job.  We will support you.  I will give you the required $20 a day.



STEVE:  It's only - I think I get 15.



LEO:  Fifteen.



STEVE:  It's only the collision with the podcast which would give me pause.  And so if we can work around that, that would be great.  There is an amazing illustrated guide to SQRL.  Go to SQRL.pl.



LEO:  You didn't do this.



STEVE:  No, not by me.



LEO:  Somebody in Poland.  Somebody in Poland did it.



STEVE:  Well, .pl, wherever that is. 



LEO:  That's Poland, yeah.



STEVE:  They may have just gotten it.  SQRL.pl is beautiful.  It was, yeah, they really did a neat job of visually explaining it.



LEO:  Wow.  Holy cow.  Holy cow.  Very nice.  This is great.



STEVE:  Yeah, it's just beautiful.  My mention last week of an addition, an expansion of the protocol to allow people to change their identities, like remember I said, like, okay, you broke up with a spouse who had your phone, or maybe not a spouse, just a boyfriend or girlfriend who had your phone, and they took their phone with them, but your identity was in their phone.  Or you were crossing a border, and bad guys confiscated your phone for weeks or days, or for whatever reason you felt uncomfortable about your SQRL identity maybe being compromised.  And we know it's deeply encrypted, so it would take anyone forever to, I mean, like impractically to brute-force it.  But for whatever reason you just want a change.



And so what I talked about last week was that a simple extension to the existing protocol, where you'd offer the old key and a new key, and that was signed by both, allowed the server to very smoothly change identities.  Well, that created a firestorm of concern in the GRC newsgroup.  We're approaching 3,000 postings, unfortunately.  I'm again 1,100 behind.  I briefly got caught up.  And so it's been tough to stay current because there's just so much interest and dialogue going on about this.  But the feeling was that allowing what I'll call "in-band identity changing" as opposed to out-of-band changing, where you would go to a website, and you would prove your identity with email or by using old-school username and password, and then it would say, okay, you've authenticated by some other means than SQRL.



The argument that the really security-concerned people had was that you're using a credential that you fear may be compromised in order to authorize the change to the new one.  They said, okay, that's just brain dead.  It's like, well, okay.  I mean, I could see their point.  And so the argument was that, if a bad guy got your credentials, that is, somehow you used a really bad password, really, like, "abc" or something, or like "monkey" or "password," something like the first thing a bad guy would guess, or it was somebody who might know your password.  For whatever reason, if they were able to acquire your identity before you, then allowing in-band identity changing would let them change your identity and lock you out of your use of SQRL.  And I thought, okay, I, yeah, I can, I mean, if we allow all those things lined up in a row to be true, then, yeah, I could see that in-band identity changing should have a higher bar.



So yesterday morning I spent a couple hours at Starbucks.  And I designed the protocol - I designed a protocol that does that.  It is again perfect.  It's a technology where your identities will be locked after you assert them and associate your SQRL identity with a website.  Nothing can change it.  That is, even you can't change it because, again, a bad guy could be you.  A bad guy could be impersonating you.  And the way this works is there's a separate key which is not your normal master key, which you can freely move around among devices.  But this is your identity unlock key, which you would only use in the event of wanting to change your identity associations, change your master identity key.



And so the point is it does not live in your device.  It is never written to nonvolatile memory.  It will not be stored.  It is just for this purpose.  And it turns out it's a pretty simple protocol.  It uses all the existing primitives we already have, very low requirement over on the web server side.  It just has to make available a little more storage.  But the client does the work.  I haven't published it yet.  I've got diagrams and text written, but I just need a little more time with it.  But so that's where we are with the project.  We're moving forward.  More people are supporting it.  And we're ticking off issues and solving problems as we get this thing nailed down.



LEO:  Any sentence that begins "I spent a couple of hours in Starbucks and created a protocol" is my kind of sentence.  You're my kind of guy.  Steve Gibson.  You'll find more about SQRL, not only at SQRL.pl, but also at GRC.com.  That's Steve's site, and it's a great place to go, I mean, there's all sorts of stuff there.  Of course SpinRite, the world's best hard drive maintenance utility.  You've got to get that.  But everything else there is free, including his security forums.  The discussion of SQRL lives there.  If you want a question answered by Steve, the best way to do it, he doesn't do email, is to go to the website, GRC.com/feedback, pose the question there.  I guess we'll do questions next week.



STEVE:  Yeah.



LEO:  So this would be a good time to leave those questions there, barring some emergency security topic, and get all the free stuff, read about passwords, it's becoming more and more just a great place to go for everything that you're interested in.  Because you're listening to the show, I figure that's a safe bet.  Steve, let me know about the jury duty.  We'll let people know, we'll put it on our calendar at TWiT.tv.  There's a calendar there of our broadcast and production schedule, and we'll update that as soon as - if there is a change, thanks to jury duty.  What else?  You could find 16Kb versions of this show, the audio for bandwidth-impaired, or transcripts, too, that Steve pays to have done by the great Elaine Farris on his site, GRC.com.



On our site, full-bandwidth audio and video, each and every week on demand, TWiT.tv/sn for Security Now!.  But you can also get it anywhere you get podcasts.  If you subscribe, you'll get it every week automatically.  And that's a nice thing to do.  Everybody should have the complete set, in my opinion.  Looks nice on the wall.  Somebody maybe we'll do DVDs, the Steve Gibson Collection.  No.  I don't think that's going to happen.  I don't think that's going to happen.  Who's on Triangulation tonight?  Is it Ladar Levison?  It is.



STEVE:  No kidding.



LEO:  So you might be interested in tuning in...



STEVE:  Cool.



LEO:  Yeah.  You might be interested in tuning in for Triangulation, about 4:00 p.m. Pacific, 7:00 p.m. Eastern tonight.



STEVE:  Yay.  Just to remind our listeners, he is the founder of Lavabit who deliberately decided he had to pull his service down.



LEO:  You know, I would love it, Steve, if you wanted to join us for that.  You would be more than welcome.



STEVE:  I would, if I didn't have plans this evening, but I do.



LEO:  [Singing] Jenny.



STEVE:  Yup, it is Jenny.



LEO:  I would never want to get between you and your loved ones.  Well, anyway, if you can't watch the show live, you can always get a copy of Triangulation, as well, at TWiT.tv.  All of our shows are available that way.



STEVE:  You're going to do a great job.



LEO:  Well, thanks to you I'm kind of up on this subject a little bit.



STEVE:  Yes, cool.



LEO:  I can't wait.  I think it's a great score to get him on.



STEVE:  Yay.



LEO:  And I'm sure there's a lot he can't say, so it's going to be a little bit of a dodging and ducking and weaving kind of a...



STEVE:  Yeah.  He may have his attorney sitting next to him.



LEO:  I hope he does, for his own sake.  I don't want to entrap him by any means.  And I certainly don't want the government to use what we talk about on their behalf.  So thank you, thank you, thank you, Steve Gibson.  And thank you all for being here.  We'll see you next week sometime.  Maybe our regularly scheduled time, which is 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 18:00 UTC on Wednesdays.



STEVE:  Almost certainly.



LEO:  Almost, yeah, you're not going to be [inaudible].



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#428

DATE:		October 30, 2013

TITLE:		Listener Feedback #177  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-428.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Yes, we have security news.  Steve Gibson has the latest.  And then we'll answer questions, a lot of questions about this new CryptoLocker virus, coming up next on Security Now!.  Steve's got the answers.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 428, recorded October 30th, 2013:  Your questions, Steve's answers, #177.



It's time for Security Now!, the show that protects you and your loved ones online - your privacy, too - with this guy right here, the Explainer in Chief, Steven Tiberius Gibson.  Hello, Mr. G.



STEVE GIBSON:  Yo, Leo.



LEO:  Yo, yo, yo.



STEVE:  We have a Q&A finally.  Finally the universe has allowed us to actually respond to listener questions, although we've actually been doing that all along because our listeners sort of guide what we talk about based on what they're interested in.  But we're incrementing the Q&A counter officially to 177.



LEO:  So we're back on mod 1.



STEVE:  I don't know what mod we're on.  But we're - even episodes are now Q&As, until...



LEO:  Oh, this is an even episode.  So we're mod 0.



STEVE:  I think we are.  I don't know.



LEO:  I don't know.



STEVE:  Yeah, we're even parity.



LEO:  Hey, a programming note before we get to - we've got security news.  We have questions and answers.  But we are...



STEVE:  Don't panic, anyone, though, because it's for 2013.



LEO:  This is not till next...



STEVE:  Oh, wait.  No, 2014.



LEO:  Yeah, you and I both are finally figuring out that the year is now 2013.



STEVE:  Can you believe tomorrow's Halloween?  It doesn't even feel like tomorrow's Halloween to me.



LEO:  Happy New Year.  I don't - it's still, you know, New Year's Day.



STEVE:  Completely out of touch.



LEO:  So can you believe, first of all, that we're going into 2014.  Now, here's a little tip for you youngsters.  When you get old, and you remember years like 1982 vividly...



STEVE:  Fondly.



LEO:  ...as an adult...



STEVE:  Or '73 when you graduated from high school.



LEO:  A good year, '73.  Those were the days, my friend.  When you say "2014," it sounds like you're living in the future.  Right, John?  John says so, too.  So we're going to 2014.  As of, now...



STEVE:  The 6th.



LEO:  The 6th because, yeah, January 6, 2014, this show is moving.  Don't panic.  I know that you may have conflicts.  That's why we're telling you now so you can rearrange your life to fit our new time.  We are moving the show.  A number of shows are moving because - and I'll explain why.  It's not Steve, it's me.  It's not you, it's me.



STEVE:  Yeah.



LEO:  I wanted to get two days off in a row.  I haven't had that in, like, a long time.  I wanted, in effect, a weekend.  I can't, I always work weekends, but at least I can get a Thursday and a Friday off.  So we're moving shows around so that I will be working now Saturday through Wednesday will be my five-day week.  And so in order to do that, Steve has very kindly agreed to juggle his schedule a little bit.  The full schedule's on our blog, inside.twit.tv.  Security Now! will now be Tuesdays at 1:00 p.m. Pacific, that's 4:00 p.m. Eastern time, that's 21:00 UTC, starting January 6th.



STEVE:  And it's good for me.  One of the - when I was talking to Lisa about this, she was initially proposing Monday.  And for me that was a problem because I often do so much prep for the podcast that that would have sort of messed up my Sunday because I would be worrying about the Monday podcast on a Sunday.



LEO:  Yeah, I didn't want to do that, yeah.



STEVE:  And so, anyway, by putting me to Tuesday at 1:00, it gives me, essentially, all of Tuesday up until the podcast.  So I get two more hours on the day of the podcast.



LEO:  Oh, good.  Oh, good.



STEVE:  And so I think what I'll end up doing is just, I mean, I worked on the podcast all this morning, and because it was a Q&A, I figured, okay, I can get it all done in just one day.  But sometimes I start the day before.  Certainly when I'm doing new heavy content stuff I'm researching it often for days leading up to the podcast.  So this is good for me.  So 1:00 p.m. Pacific time on Tuesday.  So a day earlier and two hours later.



LEO:  And there are a few other shows moving.  You can see the entire schedule, as I said, at inside.twit.tv.  None of this happens till next year, till 2014.  And the other advantage, if you don't watch live, you'll get the show a day earlier for download.  You'll get it now on Tuesday afternoon or Tuesday evening instead of Wednesday afternoon or evening.  Yes, the Google calendar will adjust, of course.  If you download or subscribe to our calendar at TWiT.tv, it will automatically adjust for you.  Most of the shows are not changing.  Tech News Today is not moving.  TWiT's not moving.  The Tech Guy is not moving.  But a few of the weekday shows are moving around a little bit.  And almost all just my shows.  But thank you for being - accommodating that.  And I apologize to anybody that that's messing with your schedule.  We don't like to do this, and we won't do it again, but having Thursday and Friday off will be a boon for me.



STEVE:  And really you don't do it often.  I think we've made one change to me in eight or nine years, so...



LEO:  Well, I know people want consistency.  And there's no reason to change it willy-nilly.  But we want to have it.  If you go to January 6th on the Google calendar, it actually apparently is already changed.  Thank you, Replicant.  So, that out of the...



STEVE:  With that bit of programming note...



LEO:  Yes.  What are we doing today?



STEVE:  We have a Q&A.  We've got eight questions because I try to balance the length with the question count, and a lot of this is retrospective to last week, following up on various topics from last week.  Lots of interest in CryptoLocker, of course, which we talked about also last week.  I've got feedback from people who have been infected and recovered, recovery stories.  There are remediation tools.  There's a great page with great information.  I was tweeting a lot as I was putting things together so that I would get this out into my Twitter feed.  So just lots of great stuff to talk about.



LEO:  That is very timely.  And I'm glad to hear there is remediation.



STEVE:  Yeah.



LEO:  Steve talked about this, of course, last week.  We had him on the radio show because we wanted to unwashed masses to hear this.  I'm sorry, I shouldn't say that while you're having a cup of coffee.  Almost got you...



STEVE:  I didn't spit it out.  I know you well enough to know...



LEO:  You knew it was coming.  And then we also put it on TWiT.  So I think we did our best to get the word out.  And I hope we've succeeded on that.  Anyway, let us, you know, I just - it makes me - I swell with pride to see people who have - and you have this experience, I'm sure, people come up to you all the time and say, "I watched you, and I got inspired, and I got into the business."  We have classrooms that use Security Now! for curricula.



STEVE:  Yeah.



LEO:  We have people come up all - and I still - people come up and say, "Look at me."  I say, "Yeah?  Okay."  "I've lost 50 pounds thanks to Steve."  So it's weight loss and security.



STEVE:  We got you covered.



LEO:  We got you covered.  So what's new in security news?



STEVE:  We're going to keep you alive longer, and we're going to make sure you're safe while you're...



LEO:  Yeah, we can't afford to lose any fans.  We want you all to live a long, long time.



STEVE:  So I picked up on a little tidbit that somehow escaped me until I was doing some background research on yesterday's release of v25 of Firefox.  Somehow I had missed the fact that they update Firefox every 42 days.



LEO:  That's funny.



STEVE:  Isn't that hysterical?  I love that.



LEO:  Geeks, you gotta love 'em.



STEVE:  Uh-huh.  And of course everybody knows what 42 is.  That's just not a random number.  That's an important number within our culture.



LEO:  Absolutely.



STEVE:  And so what this means is that they're constantly moving the code forward.  And essentially they do a stable drop of where they are every 42 days, increment the major version number, in this case from 24 to 25, and say here's what's new in 25.  Now, in this case there's one interesting set of improvements that our listeners will really care about a lot.  They fleshed out the Web Audio API.  Basically they're sort of continuing to move Firefox forward in standards, just like the big web standards.  So the Web Audio API is now complete.  And apparently that is of most significant importance to gamers.  This allows a fully web browser-based, real-time audio gaming level experience, just using the native browser, with no third-party plugins or extra, outside-the-browser paraphernalia required.  So that's one thing.



Also, I had noticed that the Find window, when you want to find text on a page, that when you change tabs, the Find window stays, which I guess is useful to some people who want to find the same thing across pages.  But the Mozilla folks felt that that wasn't the typical case, so now Find is no longer shared among pages.  Oh, and then also, if you've been gone for, like, if you've stopped using Firefox for months, and then you come back to it, it now knows that.  And it says, oh, welcome back.  And it assumes either you've been on a long vacation or you went off, I hope not to Internet Explorer, maybe to Google or Chrome or Opera, who knows where.  But anyway, for whatever reason, you've fired Firefox up again after some length of time away.  And so it greets you, says welcome back, and offers to re-import another browser's history and settings into itself in case maybe you've made changes wherever you were, you've made changes and you want to update Firefox to make it the latest and greatest.



The feature that I think is most interesting is that v25 - which anyone can get just by opening up Firefox and going Help > About.  And when you open up the About box, that seems to trigger its self-check.  And it says, oh, and then immediately starts downloading 25 if you were on 24 or earlier.  They have made more of the critical security information available to plugins.  And, for example, there's a plugin called Calomel, C-a-l-o-m-e-l.  It's called Calomel SSL Validation.  And they posted on their blog relative to, or in the updates for their add-on, relative to their Calomel SSL Validation add-on for Firefox, under Update No. 2 they said:  "Firefox 25 now allows the add-on to query the full cipher suite.  We have added the ability to grade the connection on each part of the cipher including key exchange, signature, bulk cipher, and message authentication code."  So Firefox 25 gives them visibility into the fully granular handshake and crypto status of your connection to the server.  And so they said:  "We also check and grade the cipher if it supports Perfect  Forward Secrecy (PFS)."



LEO:  You know what Calomel is; right?



STEVE:  No.



LEO:  It's a fungicide and insecticide.  Mercury chloride is called "calomel."  Whoa.



STEVE:  Okay.



LEO:  It's good, it's actually a great name.



STEVE:  So, yeah.  So if you get 0.64, their version 0.64 for Firefox 25, you get this extra stuff that Firefox 25 now offers.  And I think that's cool.  That'd certainly be of interest to our users.  One thing they did that I'm a little curious about is they said in their notes that resetting Firefox, which I assume means restarting, no longer clears browsing session.  And they said that - so I'm assuming that that means that session cookies span resets.  Which is - I guess that means that closing the tab is now what causes session cookies to be removed.  But closing the browser and restarting it, which reloads tabs, apparently now in v25 deliberately retains session cookies.



So I guess that's okay as long as people understand that.  That does represent sort of a stretch, but I can see where, from a usability standpoint, they wouldn't - so the idea would be that, like, it wouldn't log you out of all of your ongoing sessions if you closed Firefox and restarted it immediately, or reset Firefox, whatever that means, as opposed to manually closing a tab, closing a window, which then would clear the session cookies for that session.  So it's like, okay, that's an interesting change.



Also, what we've had on the desktop since v23 of Firefox, Android now gets, and that is guest browsing support in Android.  So people who are for whatever reason not using Chrome, which would seem to be the default browser in Android, if you are using Firefox, then now there's guest browsing where you can prevent anyone who's borrowing your tablet from seeing anything about your browser history.  It locks that and creates a brand new personal state for the browser which the guest then uses.  And when that's closed, everything, all of that is flushed, and your default browser state is restored.  So that's there.  Oh, and also mixed content blocking.  We've had that for quite a while on Firefox, and now Android also has that, where you'll be alerted if there's any sort of mixed content games being played.



LEO:  You mean reset or restart?



STEVE:  Okay, what is reset?  Is there a reset Firefox?



LEO:  I don't know.  The chatroom is asking that.  I think most browsers have a kind of reset, clear everything.  I don't know what Firefox might call it.



STEVE:  Yeah, I don't...



LEO:  But you're saying "restart," is what you're saying.



STEVE:  Yeah, I'm assuming that if you just close it and then restart it, it does come back with all the tabs.  And apparently now session cookies, which are typically how sessions live, you won't be logged out of all of the sessions that you were logged into across a restart of Firefox, whereas before you were.



LEO:  The chatroom tells me that there is a - the way to reset in Firefox, and this is actually a very handy thing to know, is if you go to about:support, there's a big button that basically says go back to your initial installed state.



STEVE:  What?



LEO:  Yeah.



STEVE:  No, that can't be what they mean.



LEO:  Reset Firefox to its default state.  If you're having major problems which you can't resolve, start fresh with only your essential information.  Oh, I guess it does preserve some information.  That's in about:support.  That's a handy thing to have.  But that's not germane to the...



STEVE:  Yeah, that seems, like, aggressive, yeah.



LEO:  That's if you've got a real - there's a plugin...



STEVE:  Somebody's really gone wonk...



LEO:  ...crashing you or whatever, yeah.



STEVE:  Yeah.  So Bad Idea of the Week, Leo.  Now, maybe of the year.



LEO:  Ooh, this must be really bad.



STEVE:  This generated so much upheaval among our listeners.  And you probably could guess what this is, or you'll maybe agree, or it must have crossed your radar.  LinkedIn has decided that they want something called - they want to offer a new service called Intro.  With LinkedIn Intro, you deliberately let them proxy all of your email.  It's just unbelievable.



LEO:  So you send your email to LinkedIn?



STEVE:  No.  You give them all of your login information so they pull all of your email for you.



LEO:  I know it's a bad idea, but I do that myself with TripIt, for instance, and a number of places.  I allow them access to Gmail so that they can look for reservation information and stuff.



STEVE:  Okay.  Well, in this case...



LEO:  It's a terrible idea if you don't want them to get your email.



STEVE:  Oh, well, I mean, it's - actually, it turns out it can officially break attorney-client privilege.



LEO:  Oh, yeah, sure.



STEVE:  I mean, it, like, does all kinds of bad things.



LEO:  Yeah, don't do it if you're an attorney.



STEVE:  So then you get - you then pull your email from them.



LEO:  Oh, no, I don't do that.



STEVE:  Okay.  But that's what this does.  They modify your email.  When they recognize people within LinkedIn that are sending you email, they add their content to your email, saying, oh, this is this person.



LEO:  Here's what we know about them, yeah.



STEVE:  So they introduce you to people who are sending you email that you might not already know.  It's like, oh, wow.



LEO:  There are ways to do that without doing it in such a draconian solution.  There's plugins for Chrome, for instance, Gmail plugins that will add contact information as you're looking at an email, things like that that don't require you to send your emails to another...



STEVE:  Yup, and this routes your email through them.



LEO:  That's a terrible way to do that.



STEVE:  Well, and consider also that they lost 6.5 million LinkedIn accounts not long ago.  I mean, their security has already shown some problems.  And so, oh, yeah, I'm going to route my mail through them.  They're storing it because it's a store-and-forward.  So they're going to store your email on their servers, and then modify it to add their content so that - and build this as a service to you.  It's like, yeah.  This really sounds like a good idea.



LEO:  A lot of people will do it.  A lot of people will do that.



STEVE:  Not our listeners.



LEO:  No.



STEVE:  No.  So anyway, wow.  And everyone saw this and started tweeting me, like, Steve, have you seen this?  It's like, okay.



So CryptoLocker follow-up.  We talked about it at length finally last week.  I got a tweet from a Rob Pickering Monday, who came into work and was greeted with the news that one of the execs in his apparently rather major corporation got CryptoLockered over the weekend.



LEO:  Oh, dear.  Oh, dear.



STEVE:  And so Monday morning it was, um, I have something on the screen.  And Rob had already heard last week's podcast.  So he said...



LEO:  Oh, even worse.  He knew what he was looking at.



STEVE:  Yeah.



LEO:  Oh, the feeling in the pit of your stomach when you see that.



STEVE:  And he said, "Read me exactly what it's saying."  And so it was verbatim the beginning of that sort of broken English that I shared with our listeners last week.  And he did have that sinking feeling.  And he said, "Okay, don't touch anything.  We'll see what we can do."  So he started tweeting to me.  And he ended up putting up a really interesting first-person narrative experience blog posting.  Unfortunately, when I tweeted that, of course, it crashed his server because so many people were interested in tracking it down.  I had him produce a PDF of the page which I then hosted so that everyone could get the PDF from me.



So for anyone who's interested, this is in my Twitter stream.  And remember, you can always find my Twitter stream, you can obviously go to Twitter.com/SGgrc.  But   then there's that neat guy that's aggregating my stream for me, and he's at bit.ly/SGgrc.  And that'll bounce you over to his page, where you can easily find those tweets, where I have links to both Rob's original blog post, which he has updated since, and the PDF that I had him make for me so I could host it with my bandwidth, which is hard to crash.  So the good news is 100% recovery.  They paid the ransom.  They got the key.  It began doing the work.  And all the files came back.



LEO:  Well, that's sort of good news.  I mean, they're out 300 bucks.



STEVE:  Yeah, but they had files that they needed that weren't backed up anywhere.



LEO:  I don't know if that's the good news.  They gave 300 bucks to a bad guy.  It's like, "Good news:  I got mugged, but I'm not dead."



STEVE:  Well, and so we hadn't seen - from everything I'd seen online, there were mixed results, but no affirmative full recovery report.  And we were sort of chuckling, you and I, that it didn't look like the bad guys had spent as much time perfecting the recovery, the decryption, that they had the encryption, which of course was understandable, I guess.  But at the same time, if this thing developed the reputation of not giving your files back after you paid your $300, then people would stop paying the $300.  So anyway, it does successfully decrypt.



LEO:  As long as law enforcement hasn't shut down the server with the keys.



STEVE:  True.  True.  And that has been happening also.  Another listener, Tony Casazza, I guess, C-a-s-a-z-z-a, he tweeted earlier this morning, "My client just called up with CryptoLocker virus.  They are paying the ransom.  Cross my fingers it works."  And then a bit later he wrote - I'd sent back to him, I said, "Good luck, as far as we know it does."  And he says, "Thanks for the reply.  Wait.  Just got message payment activated.  Decrypting files.  Holding my breath."  So the bad news is these guys are making a ton of money.  As you said, Leo, I mean, it's a mixed blessing.  They are making a ton of money.  And this is why it was immediately clear to me last week that this was the new normal.  I mean, this was what we're going to see.



LEO:  Well, I just hope awareness of this spreads as fast as possible.  That's why I put you on every venue I had, because if people back up, then they don't have to give 300 bucks to these guys.  And I really think that giving them 300 bucks is not the ideal outcome because it just, as you point out, encourages it.



STEVE:  It's going to encourage it, yeah.  But on an individual level, what choice do they have?



LEO:  No, I understand.  That's why be proactive.



STEVE:  Yup.



LEO:  Back it up.



STEVE:  Yup.



LEO:  And how come he didn't have a backup?



STEVE:  Well, you'd have to ask him.



LEO:  This is a business, and you don't have backups?



STEVE:  Well, this was the executive's personal machine at  home on the weekend.



LEO:  Oh, it's the nitwit executive.  Oh, yeah.  That's the problem with, you know, executives.  Yeah.



STEVE:  Yeah, those darn...



LEO:  I'm sure the business was well backed up and wouldn't have a problem here.



STEVE:  No doubt, no doubt.



LEO:  In fact, in a way that's Darwinian.  Executives should have to pay $300 just for being executives.



STEVE:  Darwinian.  I did, I have also heard of instances where someone in a corporation had the shared drive mapped to a drive letter, and it encrypted the corporate drive.



LEO:  Oh.  That's what we were worried about.



STEVE:  Yes.  We've had confirmation that it is going after drive letters.  And so it will enumerate the drives and go look for anything out, any enumerated drives on the system.  So it did reach into a shared server and encrypted those documents.



LEO:  So be careful.  Back up.  Please.  I beg of you.



STEVE:  Well, and the issue of hot and cold backup, then, of course becomes very germane because - so you need versioning backup, where the versions are deep enough that you will recognize the problem and still have backups that predate the moment of encryption and when your backup snapshot occurred.



LEO:  I mean, this isn't a hard thing to do.  Both Macintosh and Windows have versioning backups available, Time Machine and I forget what Microsoft calls it, folder thingamabob.



STEVE:  They're snapshots.



LEO:  Yeah.  So you absolutely can do this without any expense or really even much trouble.  But do it.



STEVE:  Yeah.  So two Snowden updates.  One is a few days old, well, okay, Monday.  And this just sort of crossed my view, and I thought, well, this is sort of sad, and that was - this is via Reuters that reported that British Prime Minister David Cameron said on Monday his government was likely to act to stop newspapers from publishing what he called "damaging leaks" from former U.S. intelligence operative Edward Snowden unless they began to behave more responsibly.



LEO:  This is why we need WikiLeaks.



STEVE:  I know.  Quoting him, he said:  "'If they don't demonstrate some social responsibility, it will be very difficult for government to stand back and not to act,' Cameron told Parliament, saying Britain's Guardian newspaper had 'gone on' to print damaging material after initially agreeing to destroy other sensitive data."  So, wow.



LEO:  [Sighing]



STEVE:  And then this morning's news.  There's a link that I have in the show notes, Leo, if you want to click it and bring up a picture because this Washington Post article, which copies something that the Guardian had posted - I assume it was in the Guardian.  Maybe I'm not so sure now.   But the Washington Post did a picture of today's most recent slide, courtesy of Edward Snowden [wapo.st/HuOzL9].



LEO:  Now, I have to warn you, if you are a government worker...



STEVE:  Oh, right.



LEO:  That what I am about to do will force you to burn your computer and hand in your badge or whatever it is that you have to do.  Because if I show this classified slide...



STEVE:  On a non-classified computer...



LEO:  ...on a non-classified computer, you've got to tell your boss.  So turn off the podcast now.  Or get a better job.  Think about the private sector.



STEVE:  So what this slide shows...



LEO:  This doesn't look like a slide.  This looks like a Post-it note.



STEVE:  [Laughing] Well, it is yellow.



LEO:  It's a Post-it note.  It's yellow and handwritten.



STEVE:  So this shows, on the left is the public Internet cloud with all of the regular things out there, showing SSL encrypted links going to something called a...



LEO:  This is the worst - if this is a PowerPoint slide, we are in more trouble than I thought.



STEVE:  It's also got a smiley face on it.  So it is very...



LEO:  This is so depressing.  There's a smiley face.



STEVE:  So this shows all of that and something called a "GFE Box," which stands for the Google Front End.  And then behind the GFE, the Google Front End, is another cloud showing Google datacenters exchanging data not encrypted.  And what we now know is that the NSA - and there's a name for this program that the story discusses.  There is another part of the program is the NSA deliberately tapping Google's cloud communications, which have been decrypted by the Google Front End and are in the clear.



LEO:  This is where the smiley face appears.  It's right under the GFE:  "SSL added and removed here," smiley face.  This, I don't - I'm sorry.  This doesn't - it feels not credible to me, like this is - the NSA would do this?  Like this Post-it note with a smiley face?



STEVE:  Well, they're not known for their graphics.  Their prior slides were not award-winning in terms of their design.  So...



LEO:  This is the most ghetto slide I've ever seen.



STEVE:  Well, the bad news is, I mean, it makes sense.  The way SSL operates, one of the things you often do is you run - a major SSL provider will have accelerators on their border, so-called "SSL accelerators."  They're hardware assisted, performing all of the crypto work.  And so the SSL communication is point to point between the SSL accelerator and the user.  And then inside that you have a non-SSL encrypted connection.  It is decrypted by the accelerator because the accelerator is tuned specifically, often with strong hardware crypto technology, to deal with the bandwidth and the extra SSL handshaking.  And then inside you don't have that.  So it entirely makes sense that at some point this is what was going on.  And the slide tells us that the NSA was deliberately tapping, essentially in the cloud.  That is, as this data, which is private Google IPs and point-to-point, but it does, in order to go from one datacenter to the next, it's traversing the public Internet, even though it's private IP to private IP.  The NSA knew that.  They knew it was decrypted, and they arranged to tap it.



LEO:  The tool is called "Muscular."



STEVE:  Uh-huh.



LEO:  And the reason the British don't like these revelations is because it's operated jointly with GCHQ, the British spy agency.  So...



STEVE:  Yeah, the British equivalent of our...



LEO:  Yeah, NSA, yeah.  So that's why David Cameron's so peeved.



STEVE:  Yeah.  So more from - more details.



LEO:  And judging - this feels credible.  I mean, I've got to say the Post-it...



STEVE:  It does.



LEO:  ...doesn't feel credible.  But the information therein is perfectly reasonable.



STEVE:  Yeah, yeah.



LEO:  Yeah.  And if they weren't doing it, they're probably thinking about doing it now.



STEVE:  So a little quick instant messaging follow-up.  I talked about the BlackBerry Messenger and its phenomenal number of downloads since it was released.  It was, what was it, 10 million in the first day?



LEO:  Yeah.  Downloaded.  I wonder if used.  But anyway, that's - I downloaded it, and as soon as I looked at it I went, this is horrible.



STEVE:  Well, and now we're at 20 million in one week.  And Boy Genius Reports did a follow-up where they showed that, not only was it 20 million in the first week, but they had surprisingly held their position among the very top iOS and Android downloads throughout that entire week.  Boy Genius said that many times something will spike, and you'll see it in the top ten for a day, then it immediately drops back down.  BBM, the BlackBerry Messenger, has held its position for seven days, which they said was really unprecedented, I mean, that it had that kind of staying power.



So and I did install it, like you.  It happened that our podcast friend, Simon Zerafa, who often tweets, I happened to see him.  He tweeted something, and I sent him a message with my BBM ID.  And so we sort of - we played with BlackBerry Messenger a little bit for 10 minutes.  And it was like, eh, okay, well, you know.  Other people explained that the reason it was so powerful was it had good group messaging features.  Apparently that's one of the strengths...



LEO:  So does every other - so does WhatsApp and everything else.  This is the '90s are calling and they want your messenger back.  I don't think this is state of the art by any means.  The real reason people are downloading it is because they still know people, that's how they communicate with them on BBM because you need their BBM number.  I mean, it doesn't even go by name, it goes by PIN, which is...



STEVE:  Right.  You need their PIN.  And the thing that I wanted to do, which is why I brought it up initially last week, was to disabuse people of the belief that it was somehow really strong security.  It's not.  So I wanted to let people know, yes, from everything I've seen, Threema, T-h-r-e-e-m-a, that we also discussed last week, is really strong.  And I have also played with it.  And I don't have a pressing need for point-to-point encryption.  I'm happy with iMessage on my new iPhone.  But if I do need really strong, point-to-point encryption, Threema would be, I think, my app of choice.  There are alternatives, but Threema really looks like they did it right.



LEO:  So many people have Threema'd me now because of this, and I have responded.  I've kind of done the same thing I did with PGP, which is, yup, your Threema's working.  We are connected.  You and I are connected via Threema, but we haven't yet exchanged QR codes.  We have to do that in person over a glass of fine Cabernet.



STEVE:  Right.  I think I associate it with my email address.



LEO:  That's right.



STEVE:  And since you have my email address in your account, it said, oh, somebody you know is using Threema, and then it was able to connect you.



LEO:  You know what's nice, though, Threema, like BBM, but for privacy reasons, doesn't associate it with a name in many cases.  So when I get a Threema from somebody...



STEVE:  Correct.



LEO:  ...it's just a number.  It's an ID number.



STEVE:  And you're able to give them a - you're able to assign that account your own nickname.  And it suggests that you not use your real name, but rather that you use a handle that you're comfortable with somebody else seeing.



LEO:  Is this a TNO solution, though, really?  It's not.



STEVE:  It absolutely is.



LEO:  It is.



STEVE:  Yes, yes, yes.  Absolutely.  I meant to do - since I talked about it last week, I ran across much more detailed information about their cryptography.  I mean, for example, they're using the same elliptic curve stuff, they chose exactly the same stuff I chose for SQRL.  These guys said this is the right one.  And so it's like, whoa.



LEO:  And it's done on your device.  It's not done on their server.  Nothing is stored on their server unencrypted.  Nothing goes to their server unencrypted.  It's like PGP.  You encrypt it on your end, send it.  They do hold it so that they can have a store-and-forward briefly.



STEVE:  For 14 days.  But it's, yeah, so it uses Dan Bernstein's ECC, the same 25519 elliptic curve technology that I chose to use for SQRL, which has been looked at a lot.  And as far as we know, I mean, it's completely NSA-proof.  So your Threema client generates a public key pair.  The private key never leaves you.  The public key then is what you want to - the reason that they have these three dots is that you want to obtain a level of confidence that the public key belongs to who you really believe it does because authentication then is the challenge.  After you've achieved privacy, you want to make sure you're not subjecting yourself to a man-in-the-middle attack by having someone - someone gives you their public key.  You give them yours, thinking that they are somebody else.  And then they turn around and give theirs to the other person and establish a man-in-the-middle position.



So that's why there's this red, orange, and green three dots is the level of certainty.  And so, for example, you and I would have orange level, two dots, because we used our email address books to identify each other more than just exchanging the public key itself.  And when we meet we can aim our phones at each other.  They will then do a first-person, phone-to-phone public key exchange, and that will bring us up to green level, which is we're absolutely sure that we have each other's public keys.  And so, yeah, I'm very, very pleased with Threema.  I think...



LEO:  It's a neat idea.  And it does - I don't - it doesn't do - maybe it does group.  I haven't - but it does do multimedia, so you can send images and all that.



STEVE:  Yup.  It's not group, it's just point to point.



LEO:  Just point to point.  That makes sense.  You couldn't do group, probably.



STEVE:  Be more tricky to do that.



LEO:  More tricky, yeah.  Very nice.  Good.  I've been using it.  Put it on my front page.



STEVE:  Yeah.  So it's there for...



LEO:  Now, should I hold up my QR code and put it on camera and let everybody take it?



STEVE:  You know, I was tempted to post mine on, like, on my own website just because it's like, hey, here's my QR code.



LEO:  Why not, yeah.



STEVE:  And that would allow everyone to get green dots, which is sort of nice.  And so...



LEO:  Is there any reason not to do that?



STEVE:  For me, you would want to be on SSL, and of course GRC is a hundred percent SSL, because then the real, the security kneejerk people would say, wait a minute, a man-in-the-middle attack could have changed that image, and you wouldn't know that it was real.  But, yes, you could hold it up, like on the podcast right now, on the video, and there it would be.  So anyone whose phone was able to scan that...



LEO:  It's my public key.



STEVE:  It's your public key.  That's all it is.



LEO:  So the only negative to this would be that then everybody would know my Threema code, not just my friends.



STEVE:  Correct.  And so you could get spammed.  Anyone could send you stuff on Threema.



LEO:  Well, anybody who watches Security Now! is my friend.



STEVE:  That's right.



LEO:  Right?  So there is my Threema QR code, right there.  I'll just hold that there for a second.  You don't need it for very long, you just do a screen grab.  I think that's good enough resolution.  I'm really amazed by the - we've talked about this before, how much redundancy and how effective QR codes actually are.



STEVE:  Yup.  They're very reliable, varying levels of error correction.  It uses strong error correction because in many situations, like where there might be a poster, the poster could be physically damaged.  Sometimes people will even put logos in the middle of the QR code, which completely violates the encoding.



LEO:  But there's so much redundancy, it...



STEVE:  There's so much error correction that it'll just error correct right around the weird little logo in the middle.  So I think that's cool.



LEO:  I do, too.



STEVE:  Well, and speaking of QR codes, we have officially renamed SQRL.  It's still...



LEO:  What?



STEVE:  No, no, it's still SQRL.  But it stands for Secure Quick Reliable Login.



LEO:  You've retronymed it.



STEVE:  We've retronymed it, yes.  The problem was too many people were thinking all it was, was QR codes.  And it's evolved way past that so that you don't need a smartphone, you don't need - it's like, well, how do I log in on my phone?  Well, you just tap the QR code.  How do I log in on my computer?  You just click on the QR code.  You don't have to scan it with your phone.  And so we decided we would, I mean, nothing else has changed.



LEO:  I like that, Secure Quick Reliable Logins.  I like it.



STEVE:  Login, yeah.  It's funny because I just changed the title on the web pages yesterday, and when I looked at it for the first time, I thought, that really works, I like that.  So we have a person in our newsgroup, Monty, who said, you know - and he's been out browsing around the 'Net, seeing what other people are saying.  And he says everyone's getting tangled up in the QR code part.  They're saying I don't have a phone, or I don't like QR codes and blah blah blah.



LEO:  Right, right.  I think that's appropriate.



STEVE:  Okay.  Let's back away from QR codes and just say Secure - because it is secure, quick, and reliable.  Login.



LEO:  Good.  I like it.  Hey, before we get to your miscellany...



STEVE:  Okay.



LEO:  Before we get to the Gordon Shumway project.  Because I learned something from this.  This is good.  I like it.  I was kind of - I misunderstood really what Gordon Shumway stood for.



STEVE:  So I did want to follow up a little bit on my discussion last week just briefly of SQRL's new, what we call ID Lock.



LEO:  Oh, okay, good, yeah.



STEVE:  Identification Lock.  I had just released it - remember I'd spent a couple hours at Starbucks and figured out a protocol.  And I just put the page up.  And I'm not going to try to describe it on the podcast because it's tricky.  What I wrote was, I said - and this was on the ID Lock page, so it's completely documented in the SQRL pages at GRC.  And I started by saying, "The Identity Lock protocol is admittedly a bit tricky.  It needs to be more complex than SQRL's comparatively straightforward identification protocol because its requirements are more complex.  While operating, it must be able to generate and provide something to every web server so that its identity can later be proven.  But what it generates and provides to each web server cannot in any way identify it to the server since the SQRL system provides strong anonymity guarantees to prevent web servers from having anything they might compare to identify and track users.



And on top of that, since it must be truly hacker-proof, the system that generates this identity-proving information must not itself be able to prove its own identity.  Otherwise, a compromised or hacked SQRL client could be used to maliciously prove its identity in order to unlock and alter a user's website identification.  So we need to be able to provide anonymous identity proof without being able to prove our identity."



LEO:  [Laughing]



STEVE:  And that's what I did.



LEO:  Okay.  That's confusing.



STEVE:  And so, well, no, I mean, it is.  And people in the newsgroup have, like, have studied the protocol and understood it because it's not like it's super voodoo.  It's not that complicated.  But it's just a little too cumbersome for me to describe verbally.  But I wanted to invite our listeners who are curious to go check out the Identity Lock page [grc.com/sqrl/idlock.htm].  I just finished a rewrite late last night because the way it sort of evolved, it ended up being clunky.  So I went through, and I cleaned it up and unified the naming that I'd used, and it's clearer now than it was.



But it's pretty nifty because the cool thing is, as you're using SQRL just during the day, and you're associating your SQRL ID to new websites, the SQRL client is at the same time providing information which locks your identity so that, if the worst happened, and someone were ever to hack your SQRL client, they could not change your identity.  They couldn't lock you out of your accounts.



And what that also means is, if you discovered that someone had apparently been logging in as you, which is what could happen if they somehow hacked your SQRL password and master key, if they got a hold of that, then you can, by then loading this Identity Unlock key, which is always offline, no part of it lives in your SQRL client, but you get this out of your drawer where you've been saving it.  Then you're able to preemptively change your identity and essentially take it back from bad guys that may have gotten it.  So you are able to take back your identity if it were ever to escape.  And because that ability does not live in the client, bad guys can't do that.  So we really made some great progress with this.



LEO:  Yeah, that's good, yeah.



STEVE:  I think it's going to happen.  So, Shumway.



LEO:  So thrilled.



STEVE:  Remember last week I was just, like, Leo, why does this sound so familiar?  Why?  I couldn't figure out what it, I mean, like, Shumway, why is that - I felt like it was current.



LEO:  Right.



STEVE:  Well, the mystery was solved, thanks to people who listen to the show and listen to me and know the things I'm doing and watching.  But it turns out, first of all, where Mozilla came up with Shumway, remember that this Mozilla Shumway Project was their codename for their project to build a native JavaScript-based Flash VM.  They were going to basically host a Flash Virtual Machine, run Flash files without needing to load Flash, the Flash plugin, in the same way that they now, for example, are able to give us PDFs reading natively in the browser without needing to load an external PDF plugin.  So that was Shumway.  So it turns out, thanks to a bunch of people who tweeted, that Gordon Shumway is the - I guess was Alf?



LEO:  Right.  And we said that [SN-427].  Maybe you didn't hear me.



STEVE:  I didn't know that.



LEO:  We said that in the - because the chat room came up with that one.



STEVE:  Oh.  And then I guess Flash Gordon inspired the naming of Gordon.



LEO:  Shumway.  Of Alf.  Because Alf...



STEVE:  So you have Flash Gordon, and that's where the Flash comes from, and then Gordon Shumway.  So they're, like, two of these weird references linked together to get to it.  But the reason it was so familiar to me was Julia Shumway is one of the characters in "Under the Dome," which I read the book, and then I...



LEO:  That's where you'd heard it, yeah, yeah.



STEVE:  Yes.  That's why it was so familiar to me was just, like, Shumway.  What have we been talking about recently that is Shumway?  And it was Julia Shumway, who's one of the characters in "Under the Dome."  So that's what that mystery was.  And now, Leo...



LEO:  I just got a Threema from somebody who says, "Thank you.  I work for a group of doctors, and now they can text each other."



STEVE:  Ah, they really can.



LEO:  "It's HIPAA compliant..."



STEVE:  Yes.



LEO:  "...since all messages are encrypted.  This is going to make us more secure for the new 2014 regulations."



STEVE:  Yes.



LEO:  That's great.



STEVE:  I mean, it is absolutely secure.  Those guys did it right.  And they've freely talked about how they're doing it, which you have to these days.  Leo, there's - I had a big change in my life.



LEO:  Steve, Steve, Steve, you cannot get married again.  It's just - go ahead.



STEVE:  Fortunately, there's no sign of that happening.  Jenny is as uninterested as I am.



LEO:  I love Jenny.  She's great.



STEVE:  She is.



LEO:  You two are a very good couple.  You kind of remind me of Lisa and me.  There's just - it's just a great relationship.



STEVE:  She had never seen "Gremlins," so we watched "Gremlins."  And, first of all, when she saw that it was Steven Spielberg, she says, oh.  That helped her a lot because she was a little skeptical.  And but then she knew there would be a story, and she really enjoyed it.  She's anxious to see, and we will be seeing, "Ender's Game" on Friday.  I mean, so, yeah, there's a lot of great overlap between us.  And also the fact that we're happy as we are.  No.  The big change for me...



LEO:  Okay, wait a minute, let me guess.  You're not switching to tea.  You got an iPhone?  Or is that an Android?



STEVE:  No I switched.



LEO:  What is that?



STEVE:  It's an iPhone, and I've switched.



LEO:  Well, for you, I think that - you got the 5s with the fingerprint; right?  I think that's a good...



STEVE:  I did.  The problem was I could never make the change because I liked BlackBerry's keyboard and messaging.  But I have to say that the keyboard-aware correction on the iPhone...



LEO:  It's pretty good, yeah.



STEVE:  ...is excellent.



LEO:  You have to - it takes a little while because you have to learn to trust it.  So if you just type, even though you know you're typing inaccurately, and it somehow knows.



STEVE:  Well, and it should, because it should be able to see the letter proximity and use adjacent keys as hints for the spell corrector.  And I believe they really did it right.  But I contacted Verizon a couple days ago, and I said, okay, I want to exchange these phone numbers.



LEO:  Oh.  That's a big switch.  That's a...



STEVE:  Oh, Leo, I did not do it cavalierly.



LEO:  You should have at least gotten a Google voice number and...



STEVE:  For a while I was carrying both of them.  I thought I needed a crossover period.  So my right front pocket was a little heavy for a while.  But now - and I actually weighed them both, and the iPhone weighs less than the BlackBerry.  So I'm a little bit lighter, and I'm very happy so far.  I've just - yeah.  Oh, and I did go into Verizon and looked at the iPad Mini.  Even though it's the old one, it's still going to be the size.  I think that may be the one, Leo.



LEO:  Yeah.  I can't decide.  The reviews for the Air are now coming out because they seeded the big names.  And very positive.  It's 80% faster than the previous version, which was very fast, this new A7.  And it's smaller.  So I think, well, the problem is you don't - you could go in and play with an Air starting Friday.  So maybe that's what you should do.



STEVE:  Yeah.  Yeah.  I don't know.



LEO:  And then, if you say, no, that's still a little big, then hold off.  We still don't have a ship date for the Mini with retina.



STEVE:  I know.  But the Mini, it's like enough bigger than the iPhone that you can actually do real work on it, I think.  I mean, you can really easily...



LEO:  Oh, totally.  Oh, totally.



STEVE:  ...really read web, well, I mean, it's the same resolution as the larger pad.



LEO:  Right.  Just shrunk down a little, yeah.



STEVE:  Just smaller, yeah.  That may be the one.  So, okay.  Now this is...



LEO:  You're going all-Apple, dude.



STEVE:  I am.  And things are, like, syncing.  It's amazing.  Like it knows what my tabs are on different - it's like, I'm getting all this cloud benefit.  So, yeah.



LEO:  See, it really is 2013 now.



STEVE:  Beginning to happen.  So this is an odd - I ran across this from Justin in Lacey, Washington, and the subject line caught my eye when I was going through the mailbag this morning.  It said:  "SpinRite helps to uncover lazy employees."  And I thought, what?



LEO:  [Laughing] Never thought of using it for that.



STEVE:  Well, he wrote:  "Several employees were given a stack of hard drives to wipe with a company-approved wiping software for disposal.  I decided to run SpinRite on some of them.  I am not sure exactly what the wiping process entails, but the end result I know is that the same ASCII character is repeated across the entire hard drive.  While running SpinRite and peering into the drive through SpinRite's real-time analysis window, several drives came up showing me data other than what I knew I should see on a wiped drive:  recognizable file information, filenames, corporate data, et cetera.  And since each drive was assigned to employees by hard drive serial number, it was easy to track down the person who was simply deleting the partition table and calling the drive 'wiped'."



LEO:  No, no, no.



STEVE:  We've never talked about this.  But in SpinRite 5 there used to be a large area of the real-time analysis window or screen that had a bunch of data that became obsolete in SpinRite 5.  So I thought, hmm.  What am I going to put in there?  And I thought, well, I'll just show the drive data.  And so it's really - it's actually kind of fascinating because you can watch this screen while SpinRite's running, and things you recognize go flashing by.  I mean, it's showing you...



LEO:  Ooh, that's not good, yeah.  That's a little scary.



STEVE:  It's showing you what's in the drive.  And, I mean, it's not decrypting or anything.  It's just showing you what it's reading.  And so I thought this was really an interesting hack for SpinRite that had never occurred to me before, is if you want to verify that drive-wiping worked, you can run SpinRite on it and just stare at that little - stare into the drive through the window and see if you see filenames and data and stuff that's not wiped or encrypted. And so that was a kind of a cool use for SpinRite that had never occurred to me.



LEO:  Well, there you go.  Isn't that good news.  A great way to see what's on that drive.  All right.  Are you ready?  Got questions.  You got answers; right?



STEVE:  Yes, you betcha.



LEO:  Launch right into it here with Question #1 in our listener-driven potpourri.  From - you got me excited a little bit for a moment.  John Sellitti in Venice, Florida wants positive VPN proof.  Okay, he says, I'm convinced I need a VPN.  But how do I know if it's working?  Steve and Leo, you sold me on proXPN.  Good.  I travel a great deal, and I use the scary unsecured hotel wireless.



STEVE:  Ooh.



LEO:  You know what's fun, a little fun trick, if you're...



STEVE:  That's got to be the worst, Leo.



LEO:  If you're on a Macintosh, and you do that, you'll see all the other people on Macintoshes.  You'll see their iTunes shares.  It's really fun.  All their iTunes libraries just pop right up.



STEVE:  Oh.  Oh [laughing].



LEO:  You can't, I mean, you can't steal their music - usually.  Depends how they've set it up, of course.  I signed up for proXPN, used the offer code SN20.  I use it with my laptop and my Nexus 7 tablet.  I can confirm that my IP changes after connecting to proXPN.  But here's my question:  How do I know the VPN is doing its job?  How do I know my traffic is encrypted?  Surely there's a cool test on GRC.com.



STEVE:  Okay.  So that's a great question.  For a belt-and-suspenders person who, I mean, first of all, if you recognize how scary that environment is, exactly the scenario you talked about, Leo - and remember in the old days, before personal firewalls and before anyone understood about Windows filesharing, people's C: drives were out on the Internet.  I mean, that what - that prompted me to do ShieldsUP! was to show people, uh, I can see your C: drive, guy.  So you should take some precautions.  So his question is, how does he know it's truly encrypted?  And unfortunately, there is not a cool test at GRC because GRC will see the outside-the-tunnel traffic after the tunnel has been decrypted, just prior to emerging on the Internet.  So what you need is you need some kind of what's called "packet capture" software.



Now, on a desktop machine, like on Windows or a Mac, Wireshark is, like, the standard in packet capture, relatively easy to use.  And what you would do is you would run Wireshark, tell it to monitor the traffic on your NIC, on the Network Interface Card or controller on your actual Internet interface.  And just you can - you start it doing that, and then doing unencrypted things like go check your mail.  You'll probably see your mail go by right there in the clear.  And then, if you bring up the VPN tunnel and are monitoring your network interface, and do the same thing, you should see it just looking like gibberish.  It will just be, I mean, looking like cartoon-character cussing, just absolute nonsense, nothing at all intelligible.  It'll completely disappear in the encrypted tunnel.  And there's something called Android PCAP and also tPacketCapture are two Android tools, if you want to do the same sort of thing on your Nexus 7.



So you definitely can, if you're curious, do a before and after, with and without the encryption tunnel running.  And then you could also do other things, like you could, if your network was set up on a hub, you could run this on a hub where you could see the other computers' traffic and capture it in a third-party situation.



So you can use packet capture in a number of ways.  But probably the easiest is to run it on the same machine where you've got the VPN running, and then look at the interface, not the VPN's interface, because it'll create a virtual network interface card which you connect to.  But you want to look at the physical NIC on the network, and you'll see the before and after change.  It's dramatic when the tunnel is up and running.  And it's really a cool experiment to run, by the way.  I've done it a bunch.



LEO:  Everybody needs a packet sniffer in their...



STEVE:  Yeah, in their bag of tricks.



LEO:  Always a good thing to have.



STEVE:  Yeah.  Oh, and, boy, go to Starbucks, and it's frightening.  Oh, boy.



LEO:  So did they - it was Wireshark, and now it's...



STEVE:  It used to be, oh...



LEO:  Or is the new name Wireshark?  Because...



STEVE:  The new name is Wireshark.



LEO:  Oh, okay, good.



STEVE:  And I can't remember what it used to be.



LEO:  But it's free.  It's open source.  It's really handy.



STEVE:  Yeah.  And it is THE tool.  In fact, it's based on the original, I think it's called - was it NPcap?  I think it was called NPcap, which was a beautiful open source...



LEO:  Oh, used to be Ethereal.



STEVE:  Ethereal, exactly right. 



LEO:  Yeah, yeah.



STEVE:  Yup.  So, and that was based on the NPcap library, which is what I originally used to build ShieldsUP! in order to add low-level packet capture...



LEO:  Oh, neat.



STEVE:  ...to Windows.  I later wrote my own network interface capture at the low level because there was more stuff I wanted to do.  But it's a great packet capture library and has been ported to all platforms.



LEO:  Do you ever use NMAP?



STEVE:  I'm aware of it.



LEO:  That's kind of more of a pen testing or...



STEVE:  I just never really had a need for it, yeah.



LEO:  Yeah, or a protocol.  It's another - it's essentially a security scanner that's also free and open source.



STEVE:  And also has a strong scripting background.  So you can do, like for example, someone did mention the other day that there was an NMAP scanner script for, like, open webcams or something that we'd just talked about.  Oh, no, it was a vulnerability in the D-Link router that we discussed where, if you set the user agent to a certain string backwards, then it was able to do unauthenticated access to the user.  And so someone quickly whipped up an NMAP script that would just find them for you on the Internet.



LEO:  That's great.



STEVE:  It's like, oh, thank you very much.



LEO:  And, by the way, the good news is we now know that NMAP will still be in use in 2154 because, when they hack Matt Damon's brain in "Elysium," if you look up close at the screen shot, it says "Starting NMAP 13."  [Laughing] That's - somebody, whoever did their screens for "Elysium," knew what he was doing.





STEVE:  Yeah, they had some good techies, yeah.



LEO:  I love that.  Question 2, shall I move on?



STEVE:  Yes.



LEO:  This comes from John Vandiver in Smithfield, Virginia, home of the fine Smithfield ham.  Steve and Leo, I thought you might be interested in this site, Livingto100.com.  You fill out a questionnaire, it gives you life expectancy.  Thought you might want to try it out now that you're so healthy.  I'm going to live to 97.  I thought I could retire at 72, but I may have to launch a new career.  Jim from Smithfield, Virginia.  I guarantee you he doesn't eat a lot of Smithfield hams if he's going to live to 97.



STEVE:  Yeah.  So, okay.  First, so, well, it would be.  Well, it can be.  First of all, I tweeted it, and immediately found out from a good friend of mine that they want your email address.  Then other people said that there's no verification at all, and so you can just type random gibberish for your email address.



LEO:  Oh, good, right.  So that's a good start.



STEVE:  And I have not tried it.  I can't vouch for its accuracy.  But I thought that our listeners might find it interesting:  Livingto100.com.  And I don't know what they're trying to sell you, or what the deal is, but - and it does seem to be giving people a lot of encouragement because I had, in the feedback that I've seen, everyone seems to be in their 90s.  So either we've got an unusually healthy...



LEO:  Oh, wait'll I fill it out, dude.  What did you get?



STEVE:  Tell the truth.



LEO:  What did you get?



STEVE:  Oh, I haven't - I just found out about it this morning, and I've been working on the podcast all morning, so I've had no time to do it.  I didn't want to get myself involved where I thought, well, I might be late for getting all my notes together.



LEO:  Check all that you feel currently stressful.  This is good, yeah.  This is good.



STEVE:  So don't worry about having to give it a real email address.  You can just make anything up that you want to.



LEO:  They didn't ask me for email.  Maybe they ask at the end.



STEVE:  They do at the end, apparently.



LEO:  So they can mail you with your results.



STEVE:  They bait you, yeah.



LEO:  Jamie Brand in Burnaby, British Columbia, Canada wonders about a possible way around CryptoLocker.  I'm curious, says Jamie, if you happened to have whole drive encryption turned on with TrueCrypt, would CryptoLocker be able to hijack your data?  Would it prevent them from encrypting it as it would already be locked, per se?  Or would it just be an onion router situation where it would encrypt the encrypted information and you'd still be screwed?  Love to know your thoughts.  Also, why isn't Security Now! called This Week in Security Tech, TWiST? It has a nice ring to it.  Love your show, hopefully I can get your feedback.  Jamie.



STEVE:  So the bad news is, if a system gets infected that is whole drive encrypted, then CryptoLocker is running on and in the drive and can see all of your files and encrypt them.  So unfortunately it is like the onion router.  It is double-encrypted, which is definitely not what you want.  You only want it encrypted by TrueCrypt and not anything else.  If this was a drive offline, then it could not encrypt it.  I'm assuming that the file extension that TrueCrypt uses is not among those which CryptoLocker encrypts.  Normally it just goes for things that are videos and documents of various sorts that it finds in your documents file.  So I don't remember what the file extension is for a  TrueCrypt container, probably not on CryptoLocker's list because it would feel it was a waste of time, although it could certainly damage you if it did that.  But, so, yes, unfortunately, and a number of people asked this, so I wanted to answer the question, whole drive encryption of a mounted drive won't protect you.



One thing that will, toward the end, the last question in our list, is some interesting prevention suggestions.  But someone asked about a virtual machine.  And that would protect you as long as the virtual machine couldn't see out into any of your other important files.  So if you ran email in a VM-style virtual machine, it would be blinded to what else was there.  And if that got infected from clicking a link in email, then you'd be okay.  Just FYI.  That's probably the strongest prevention I can think of.  We'll have some that we'll, as I said, we'll talk about here in a second, which is good.  But as you and I talked about on the weekend, Leo, the problem is it's a little bit in the cat-and-mouse category.  Once this becomes popular, the authors could work their way around it.  So it's not as strong as putting your email in a virtual machine, which is really robust protection.



LEO:  Steve Gibson, Leo Laporte.  We're answering questions from our vast and brilliant, if you don't mind me sucking up a bit, listening audience.  Chris McCormack...



STEVE:  We have great listeners.



LEO:  Yeah, I do, I really like them because they just - they ask great questions.  I'm sure you enjoy this.  Chris had a thought about malicious encryption:  While you were discussing the recent trend of malicious encryption - in other words, CryptoLocker, the first of many I'm sure - an idea formed in my head.  If you were to back up a static, never-changing file from your computer to a secure backup, could you use this file to determine the key used to encrypt the recently encrypted version of the file on your hard drive after the attack?  In other words, kind of figure out what the encryption was to reverse it?  Seems it would be trivial once the algorithms used by the attack are determined.  Love the show.



STEVE:  Well, so that's interesting.  We've never talked much about cryptanalysis.  We've touched on it here and there.  But essentially what Chris is talking about is a huge area of cryptanalysis, and it's got some well-understood terms, a known plaintext attack, and in some cases a chosen plaintext attack.  The idea is that the question is, if you knew what the unencrypted data was, that is, the plaintext, so known plaintext, can you learn anything useful in, like, what the key is that was used to encrypt that known plaintext, because presumably you already have the encrypted text.  And then a slight variation on that is the so-called "chosen plaintext attack."  And that's a situation where the person trying to crack the encryption is somehow able to put their own tests in and see what the plaintext they choose is turned into, and that gives them in some cases more control.



Well, the good news is, well, the good news for most of us who want strong encryption is that AES, and any modern cipher, I mean, the so-called "known plaintext" and "chosen plaintext" attacks are, like, the basis of cryptography.  So any recent cipher will absolutely not leak information about, like, the encryption key used, even if someone trying to learn what that was had both the plaintext and the encrypted ciphertext at their disposal, which is what Chris is suggesting.  So modern ciphers are completely immune to that.



A perfect example of this being done is a, for example, we've talked about this often also, a simple stream cipher using XOR to merge the plaintext with the pseudorandom stream.  Remember, if we have a pseudorandom stream of bits, and we take plaintext, and we XOR those two, even though it's a little counterintuitive, what you get is really good crypto, except it is absolutely vulnerable to, for example, a known plaintext attack.  Because if you took that ciphertext, and you XORed it with the plaintext, you get back the pseudorandom stream, that is, you get back the key stream that was used for doing the XOR.



So XOR is an example of it's a little fragile.  If you use it very carefully, just right, it's secure.  But you can't ever use the same stream twice, or that opens you to an attack because it is so easily reversible.  Whereas something like a modern cipher, like Rijndael used, which was chosen for AES, the Advanced Encryption Standard, is not subject to this kind of known plaintext or chosen plaintext attack.  But great question.  Several people asked it, too.



LEO:  Phil in Leicester, U.K. wanted to check-in for your recommendations:  First, big fan of the show.  I've learned about security over the years through the podcast and your superb free tools, Steve.  Thank you for doing this for the community.  Given the ever-increasing need to protect our computers, I was just wondering if you could recommend any good free firewall and virus/antimalware protection software.  My apologies if you've already covered this and I've missed it.  I'm currently using Microsoft's Security Essentials with the built-in Windows 7 Firewall and Malwarebytes, but I'd like to know if there are any free alternatives.  Once again, many thanks.



STEVE:  And I'm using the same thing.  I have never been a big user of third-party AV stuff.  And Windows Firewall provides good, unsolicited, incoming protection.  So, and of course I'm also behind all kinds of layers of NATs and routers and things.  So I've got good security.  But I just thought it was an interesting question.  I know that our listeners would be interested, Leo, if you've got any favorites.



LEO:  Well, we've had for many years a sponsor, ESET, which I think is excellent.  Kaspersky, a lot of people say very good things about that.  My kind of - most of the security people I know don't really take any extra steps, A, because they believe, and I think they're absolutely right, that really behavior is the biggest issue.  And so even - in fact, as we know with CryptoLocker, even if you've got the best antivirus, if you don't behave well on the 'Net, even inadvertently, it doesn't matter; right?  So I think a false reliance on antivirus is risky because it's not going to protect you if you're clicking links and opening attachments and, hey, let's see what this is.  You're going to get bit.



STEVE:  Yup.



LEO:  I think that, absolutely, Security Essentials, while not even close to the best antivirus out there, is probably adequate.  In fact, Microsoft's own monthly check with its malware removal tool is a good start.  In fact, you already have it if you have Windows.  We've talked about this, I'm sure.  You click Start > Run > mrt, you could do - it doesn't normally do a thorough scan, but you can coerce it to do a thorough scan.  That's not a bad idea.  It's not an antivirus.  It's not proactive.  But it will - it's a great way to see if there's something on your system.  And Microsoft does, I think, proactively remove some of the better-known malware issues.  I think Windows Firewall is fine.  The issue, as we've said before, is it's a one-way firewall, does not protect you against outbound attack.  But it's great against protecting your systems against other systems that are on your network, if somebody comes in and plugs in an infected - yeah.



STEVE:  The thing that annoys me a little bit about it is that it is prone to software in your machine bringing down ports, or opening things into them.



LEO:  It allows it.



STEVE:  And so, yeah.  And so that was the tradeoff Microsoft had to make for ease of use, which is why you really want to be behind a NAT router.  And of course I think everybody is.



LEO:  Everybody is.  And, yeah, and that is, of course, a must have.  And that's a - but if you've got that, I think you really have got a very effective firewall because it's just dumb.  I can't imagine anybody who listens to this show sits a computer out on the public Internet without a router because that would be not advisable.



STEVE:  I almost fell victim to a phishing email the other day and had to scold myself.  It came in, looked like it was from PayPal.  I use PayPal a lot.  And it said, "Just confirming we're adding another email address to your account."  And it's like, oh, what?  And I take every precaution all of our users know we should take.  But there's always that how did maybe something happen?  Maybe somebody got in; maybe this is legitimate.  And, I mean, I was, like, reaching for the mouse.  And I said, oh, oh, oh, oh.  And sure enough, I went over into my inbox and pulled the raw ASCII, and the whole thing was malicious.  It was just - and the links were masked.  It really is a problem that email - I'm still using an old Eudora client.  I don't know if other email clients are better.  But I cannot see what is behind an email link.  It will not show me the domain it refers to.  And so it's really annoying.  I mean, it's just - it's really trouble-prone.



LEO:  Well, I don't use HTML email.  I turn it off.  And I really wish people wouldn't use it.  I think it's terrible.  Didn't you block HTML email for a long time?



STEVE:  For a long time.  I said, eh, that's not real email.



LEO:  But the problem is everybody uses it.



STEVE:  It's now, yeah, exactly.



LEO:  It's by far the majority of emails.  Malwarebytes, a lot of people love Malwarebytes.  I have very mixed feelings about that.  I think it's also another case of a false sense of security.  So if you - Microsoft Security Essentials, while not a great antivirus, nobody thinks it's a great antivirus, is okay.  If you want to buy an antivirus as a form of protection, I do like ESET a lot.  I think it's a really good antivirus.  My best advice:  Use a Mac.  Because almost all of these attacks, including CryptoLocker, are aimed at Windows.  It's not that the Mac is inherently more secure, although they've done some very good things to protect you.  But it's just not a target.  If you're using...



STEVE:  I love what Apple is doing, Leo.



LEO:  If you're - yeah, yeah.



STEVE:  I'm really drifting in this direction.



LEO:  If you're compelled to use Windows, then all of this is germane.  Or Linux.  Linux would be appropriate, too.  Although you have to be more of an expert to secure Linux than you do on Windows or Mac.  You really have to kind of know what you're doing.



Question 6, David Troxel in Maryland offers a heads-up about Match.com, a site neither of us uses or needs to, and its insecurity:  Dear Steve, blah blah blah.  I recently had an interesting occurrence that you should probably mention.  I got a few emails from Match.com, with my wife standing next to me at the time.  That's embarrassing.  After looking and wondering for a few minutes, I concluded that someone, a female in her 40s, from the Midwest apparently, gave the wrong email address when updating her profile.  Match does not send out the email with the link to make sure you did it right.  Oh, I know this.  And I'll tell you how I know.



STEVE:  [Groaning]



LEO:  Match then emails me just about all her information - her screen name, her password - oh, you idiots.



STEVE:  I know.



LEO:  And from listening to this podcast I know that means the passwords aren't encrypted on Match.com, so not even LastPass can save you.  I also got her gender, zip code, and birth date.  Oh, for crying out loud.  I don't think anyone hijacked my email because I have text message two-factor ID, and I didn't get a text message.  This looks like just some really poor security.  With such a tech-centric following, I'm pretty sure someone listening to this show uses the Internet for dating purposes.  They should know about this.  Well, I do know that Match.com makes no attempt to validate email addresses because I get subscribed to Match.com regularly by pranksters [mirthless laughter].  But that's worse.  That's a leak of information that is horrific.



STEVE:  Yes.  This is a horrifying privacy leak.  And so I wanted, I mean, I actually - Mark Thompson has used Match.com.  Several decades ago I did, and met someone fun, and we dated for a while.  So I was there once upon a time.



LEO:  Yeah, it's a good service.



STEVE:  Boy, it's the No. 1, the No. 1 Internet dating service online.  But with security this bad, I just wanted to make sure our listeners knew because I think David is right.  There's no doubt that people who are hearing this are probably active users, and they need to be very careful with their email address and password going forth.  Wow.



LEO:  Yeah.



STEVE:  Really crazy that a site like that would be so lax with security.  Because, I mean, it's the definition of personal information.



LEO:  [Sighing] I mean, that's really enough to perpetrate identity theft, I think.



STEVE:  Oh, my goodness, yeah.  And he could have clearly logged in as her and had complete access to everything she's able to do from her account.



LEO:  Right.  Mike Graham in Hopatcong, New Jersey - I don't know how you say that - wonders whether TrueCrypt is dead?  It better not be.  Hi, Steve.  Based on your mention in a recent Security Now! episode, I checked out TrueCrypt.  I take back what I said about our smart listeners.



STEVE:  Leo.



LEO:  No.  No, it's a simple and an easy mistake.  To me, this site has all the earmarks of being dead.  There's not been a release for over a year.  The news page is similarly stale.  I checked because I have a new laptop with Windows 8 and a UEFI BIOS, and TrueCrypt does not yet support this for full disk encryption.  I was hoping you may have an in with the TrueCrypt developers.  Mike.  Love the show.  Keep up the good work.  TrueCrypt, is it dead?



STEVE:  No.  But this raised an interesting point, and this is why I thought this was a worthwhile question, is that TrueCrypt is done.  And that's why they haven't touched the page for so long.  I mean, okay, now, yes, it apparently needs to be updated to support UEFI BIOS and so forth.  But with a project like this - and of course I face this with SpinRite because SpinRite has sat, doing what it does, for 10 years because it did what it did perfectly.  And I wasn't needing to update it continually because it was done.  Yes, I will be working on it soon as I get SQRL put back to bed.  I will be back to SpinRite 6.1, and I'm going to give everybody a free update, and support in the UEFI BIOS is one of the things on my list because the old-style partition table only has 32 bits, so it can't handle ridiculously large partitions, which are becoming increasingly prevalent.



But I guess I felt for the TrueCrypt developers, like this is all voluntary.  It's all free.  It's open source, fabulous software.  We know that it's not dead because as we've been discussing, we're in the process of raising, well, we the community are in the process of raising money to do the first official audit of TrueCrypt so that everyone can know what it is.  So, and this is a problem that you sometimes get into with free, open source software, is that it gets done, and then the world changes out from under it, and at some point people are going to have to come back and put in a substantial amount of effort in order to update it to new standards.



LEO:  It's really because it's open source, and people do this in their spare time.  It's for fun.  It's not a paid project.



STEVE:  Yeah.  And they did a fabulous job with TrueCrypt.



LEO:  Yeah, yeah.  And it does say, if you go to the site, updated October 11, 2013.  I mean, it's not like nothing's happening there.  So if the main point is why hasn't the software been updated in six months, well, that's why.  It doesn't really need to be.  And I'm sure they're working on UEFI.  Although, as you know, that's nontrivial.



STEVE:  It is nontrivial.



LEO:  If you've relied on BIOS, you have to rewrite a lot of low-level stuff.



STEVE:  Yep.



LEO:  Is it well documented?  UEFI?



STEVE:  Oh, yeah.  We have absolute all the information we need.  It's a public open standard and becoming increasingly - one of the reasons I was able to put off, you know, I've been busy doing other things, and I was able to put that off is that we just weren't having many problems with people using UEFI because, for example, the Mac had moved there, but SpinRite was for the PC, and PCs were still staying BIOS-based.  And so it wasn't becoming a problem.  Now it's beginning to be a problem.  So of course that has my, as we know, has my attention again.



LEO:  Our last question coming up, I just want - a little programming note.  If you didn't hear our interview with Ladar Levison last Wednesday, that is up now on Triangulation, TWiT.tv/tri.  He's of course the creator of Lavabit.  And he talks very candidly about what happened, why he decided he had to bring it down, what legal fight he's going on right now.  And he mentioned something that we talked about before the show began, the new Dark Mail that he's doing in conjunction with Silent Circle.  And that's exciting.



I asked Ladar, I said, come on, really, no email service can be secure because the nature of SMTP is that most of the time you're sending mail unencrypted.  So few servers use encryption, it doesn't make any sense.  And he agreed readily.  He said, yeah, PGP or the like is the way, if you want secure email, you have to secure it on your side and give the guy on the other side the key.  He said, but as Edward Snowden learned when he tried to get Glenn Greenwald to use it, and Ladar said, and even my lawyer, I said we've got to use PGP, and my lawyer couldn't figure it out.  It's nontrivial, not easy to figure out.  Our audience can figure it out, but normal people probably not.  So I think that my sense is that his goal is to make that kind of encryption, just as Threema does, easy to implement in an email client.  So we'll see.  And of course Silent Circle is Phil Zimmermann, the guy who created PGP.  So that's a good pairing.



Also, Triangulation today, I love this, we're going to interview Tom Standage.  He wrote "The Victorian Internet," which was a great book.  His newest is about social networks.  It's called "Writing in the Wall:  Social Media - The First 2,000 Years."  And I think it's a great premise.  It's the history of social networks from the agora in Greek times to coffeehouses in London in the 17th Century.  Really a great - and then the rise in mass media, really a great subject.  So that's coming up this afternoon.



STEVE:  And I have to say, Leo, that I received a number of tweets from people saying, Steve, you've got to go watch what Leo did with Ladar.  So I had other people saying it was really a great Triangulation.  And you were really up to speed, apparently.  So I thought that was great.



LEO:  Well, thanks to you, I mean, I knew what was going on because we'd talked about it.  And I don't take any credit.  I think the reason it was interesting was because Ladar was surprisingly upfront and frank, given his potential legal problems.



STEVE:  Given his limitations, yes.



LEO:  Yeah.  He didn't have a lawyer sitting next to him, just his dog.  And he was great.  I really enjoyed talking to him.



STEVE:  Neat.



LEO:  Final question from Mr. Liquid Bread, Chris Phillips, who appropriately enough lives in Battle Creek, Michigan, home of Kellogg.  He brings news of a CryptoLocker Prevention Kit":  I ran across this packet of group policy changes, to prevent CryptoLocker from saving itself to your PC, on a Spiceworks forum.  I've downloaded it, and me and my colleagues are still discussing whether to deploy this in our enterprise environment.  Check it out and see if it's worth mentioning on your next Security Now! episode.  He gives three links, four links if you include Steve's.



STEVE:  Actually, those are all mine.  Yeah.  So, first of all, this is what you and I talked about.  There is something called CryptoPrevent.  And that's - it's sort of a turnkey tool which will use Windows group policies to block CryptoLocker from doing what it wants to do.  So this is a useful thing.  I'm a little uncomfortable because it has a chance of triggering false positives, that is, your - the good news is CryptoLocker's behavior is a little odd in how it wants to install itself and run itself.  And that can be used in order to block that behavior.  The good news is that group policies are an absolutely well-documented, well-understood solution for, especially in a corporate environment, for managing PC behavior.  But it's sort of a soft fix because CryptoLocker's future behavior could change so that in order - deliberately to work around the CryptoPrevent group policy fixes.  However, for today, for now, it's a very clean and nice solution.



And so what I did was I tweeted a bunch of stuff, just before the podcast, so anybody who wanted to get the links could again go to bit.ly/SGgrc, or just check the SGgrc Twitter feed.  And I created some bit.ly shortcuts:  blockcl, prvntcl, and bleeping.  The bleeping link, it's bit.ly/bleeping, is to absolutely the hands-down best page discussing CryptoLocker, talks about what it is...



LEO:  That's a good site in general.  BleepingComputer is really a good site, yeah.



STEVE:  Yes, BleepingComputer.com is great.  And they've got a fabulous CryptoLocker page for anyone who wants to come up to speed.  Oh, and that Spiceworks link that Chris put me onto, which is bit.ly/blockcl, I'm hosting their ZIP file on GRC, first, because I didn't want to crash their server by tweeting it as I did crash Rob's the other day.  And also because I verified the file is a legitimate ZIP before I opened it.  I looked at it through a binary viewer to verify that it was a ZIP format and not executable myself.  And then I opened it and looked at the files.  It's beautiful because it's just a toolkit.  And in fact I received some tweets back from corporate people who said, oh, thank you, thank you, this is just what we need for corporate deployment.  So it doesn't do anything itself.  It's very good documentation in PDFs, and the files that anyone who understood Windows group policy could use for establishing group policy settings that would absolutely lock CryptoLocker out of people's systems.



LEO:  It is ironic that they send it out with a ZIP file containing what looks to be PDFs, which is exactly how...



STEVE:  I know.



LEO:  ...CryptoLocker works.  But okay.



STEVE:  So it's frightening.  It's why I decided - I looked at it carefully myself and then hosted it on GRC.



LEO:  Crazy.  Crazy.



STEVE:  Yeah.



LEO:  All right.  Good.



STEVE:  So anyway, worrying, and this is the current big problem is CryptoLocker.  As far as I've seen, the AV tools are still behind on this, and people are still getting themselves infected.  So we really need to be careful with clicking on links.



LEO:  We do, indeed.  And the best way to be cautious is to stay up on what's going on.  And if you listen to this show, you're miles ahead of everybody else.  Steve Gibson keeps it all on the lowdown at GRC.com.  That's his website, where you'll find SpinRite, the world's best hard drive maintenance utility.  You gotta have it.



STEVE:  And allows you - you could peer into your hard drive with it.



LEO:  Know if your employees are up to snuff.



STEVE:  Yup.



LEO:  You can also get a lot of free stuff there, including 16Kb versions of this show for the bandwidth impaired, and full text transcriptions written by an actual human, the wonderful Elaine Farris.  So you can read along as you listen to the show.  We host full-quality audio and video of the show on our site, TWiT.tv/sn.  And of course you can always subscribe.  The podcast version's available almost everywhere you can get podcasts, including Stitcher and the like.  We do this show currently, at least through the end of the year, on Wednesdays, 11:00 a.m. Pacific, 2:00 p.m. Eastern time.  Next week, because of our change off summertime to standard time, we will be at - we move to GMT+8.  So we'll be at 19:00 UTC, if you want to watch live.  But if you don't, don't worry.  Like I said, on-demand versions always available.  Thank you, Steve.



STEVE:  Leo.



LEO:  You're coming up for New Year's Eve, our special event.



STEVE:  Yup.  I'm going to be with you at least for a while, while you're following users around the globe.



LEO:  I'm going to spend the whole 24 hours.  We start 4:00 a.m. New Year's Eve, end 4:00 a.m. New Year's Day.  We are going to celebrate New Year's at least every hour, in a couple of cases every half hour, in every time zone, a countdown.  And I hope, and in fact, if you're listening, I hope you'll participate, a viewer or a listener, in that time zone.  You can sign up, there are many time zones unfilled, at TWiT.tv/nye.  If you're in Papua, New Guinea, we need you.



STEVE:  I did ask to get late checkout the next day.



LEO:  You're going to want it.



STEVE:  So that I can stay up with you for a while, Leo.



LEO:  [Laughing] It's going to be a lot of fun.  I've wanted to do this for years.  Nobody would let me.  24 hours of New Year's from the TWiT Studios.  All the shows will be on.  All our people.  We'll have bands.  We'll have jammies.



STEVE:  Wow.  You're going to be in your jammies?



LEO:  No, I have been informed that I must wear a tuxedo the entire time.



STEVE:  Ah, there we go.



LEO:  It's going to be fun.  Thank you, Steve Gibson.



STEVE:  Thank you, Leo.



LEO:  We'll see you next time.  How do I say - how do you say "Papua"?



STEVE:  Oh, and by the way, no jury duty for me so far.



LEO:  Oh, yeah.  I forgot about that.



STEVE:  Not sure about tomorrow.  But I've been watching it day by day.  But nobody in the reserve group has been called.  Apparently there are people who are not call-in.  There are people who "you must show up" people.  And so no one has been taken out of the call-in groups that I've been able to detect from looking at the website status.  So I think I'm in the clear for this round.



LEO:  Yeah.  You did your duty.  This Week in Google next.  Thank you, Steve.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#429

DATE:		November 6, 2013

TITLE:		"Monkey" Was 26th!  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-429.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  The past week was so jam-packed with so much fun and interesting security news that we had a hard time just fitting it all in.  So this week's podcast is news, news, news!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Such a big security week, he's just going to talk about security news, everything from the big Adobe breach to the idea that viruses could leap through the air.  And a couple of engineers at Google respond to NSA spying allegations with a profanity-laced post.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now!, with Steve Gibson, Episode 429, recorded November 6th, 2013:  "Monkey" was 26th.



It's time for Security Now!, the show that protects you, your privacy, and your loved ones online.  And it does all that thanks to this man right here, the Explainer in Chief, Mr. Steven "Tiberius" Gibson.  He is the guy...



STEVE GIBSON:  If you keep saying that, it's going to work its way into the Wikipedia page.  That's what's going to...



LEO:  It's my goal.  Hey, if Moxie Marlinspike can be named Moxie Marlinspike, you can be Steve "Tiberius" Gibson.



STEVE:  Yup, and we take him very seriously...



LEO:  Heck, yes.



STEVE:  ...because he knows what he's talking about.



LEO:  He is in fact going to be the subject of one of your screeds today.  We have a lot of tech news, so much so that we maybe won't get to questions.  Is that right?



STEVE:  Yeah.  So much happened this week.  And really fun, interesting stuff.  Lots, I mean, I was busy tweeting things.  So my Twitter feed is full of links that people may want to check.  And I was actually tweeting a bunch this morning as I was finding things that I wanted to talk about.  And just I was sort of - my plan was originally that this would be another Q&A because we'd been skipping so many Q&As, just because there was too much happening.  We weren't able to get to them.  So I thought, let's do a little makeup Q&A.  But too much happened again.  So it got pushed off. 



LEO:  That's all right.  We'll get to questions, you know, someday.



STEVE:  I couldn't decide whether to call this "Monkey Was 26th" or "256 Bits Is the New Black."  So we've got...



LEO:  Boy, those are both intriguing.



STEVE:  Yeah.  We've got a new zero-day Windows Office vulnerability.  We've got an update on the TrueCrypt auditing project.  Ladar Levison wants to raise money.  Viruses are leaving the network and leaping across the room.



LEO:  [Laughing] I really want to know your take on that one, by the way.



STEVE:  An escalation of the CryptoLocker battle.  A major new update to LastPass.  Sync news from BitTorrent.  Google versus the NSA.  My reactions to the iPad Air, "Ender's Game," and my discovery of the best iPhone case after trying 50 of them.



LEO:  Wow.  Wow.



STEVE:  Yeah.  And maybe we'll have time for a sponsorship or two.  I'm not really sure, though.  You'd better get one in right now, Leo, otherwise it's just - there's not going to be any hope.



LEO:  By the way, it has made it to your Wikipedia page.  You are now Steve Tiberius Maury Gibson.  That's not how you spell "Tiberius," kids.  But other than that...



STEVE:  Boy, those editors are fast.



LEO:  [Laughing] It's i-u-s.



STEVE:  SQRL has a Wikipedia page, by the way.



LEO:  SQRL?  Well, of course it does.  I would expect that, yeah.  I absolutely expect it.  Our show today, we'll get to all of that and more in just a bit, but our show today brought to you by our friends...



STEVE:  That was a summary, by the way.



LEO:  I know.  You did a nice job.  I thought that was - this is a new feature of the show.  There's so much in it, it's like a Victorian novel.  In the old days of Victorian novels they loved lists.  Remember?  You would have, at the beginning of a Victorian novel, a chapter.  It would say - a chapter heading would say something like "In which our hero discusses...," you know, or "takes on the champion boxer of...," and it goes on and on and on.  The Victorians loved that stuff.



STEVE:  I worry about sometimes science fiction books where you open up the book, back when you could open up a book - actually, eBooks do it, too - and they show you a fabulously detailed map of the universe with all kinds of little points noted.  And you're thinking, okay, wait.  Will there be a test on this?  Do I have to memorize this?  What am I supposed to do with this map?



LEO:  Memorize the universe.



STEVE:  Shows random places that the author made up.



LEO:  Steven Tiberius - I didn't know your middle name was Maury.



STEVE:  Yeah.  My dad was Maurice, and he never liked that.  He just - and in fact I remember him telling me once that he, when he was choosing this name for me when I was in the process of being born, he wanted to deliberately choose a name that I would be proud of, that I would like.  And I like Steve.  I think it's, you know, it's like Mark or Paul or...



LEO:  Steve's a great - is it Steven?



STEVE:  S-t-e-v-e-n, yes.



LEO:  Not p-h.



STEVE:  Not p-h.



LEO:  Yeah.  So I could call you Steven Maury Gibson, and you'd feel like you were in deep trouble.



STEVE:  At the AI Lab at Stanford, where I spent a couple years, we used our initials as our logins.  And so they were calling me "Smog."



LEO:  Oh, I love it.



STEVE:  I don't really want to be Smog.



LEO:  I hope they spelled it, not S-m-o-g, but in the true geek fashion, S-m-a-u-g.



STEVE:  No, no, this, well, no.



LEO:  You know why.  Smaug is the dragon that hoards all that gold in "The Hobbit" that they go out and steal from.



STEVE:  Yeah, that's a real pissed-off dragon at the moment.



LEO:  Yes.



STEVE:  Where we left him, he was not happy.



LEO:  Not happy.  And I've seen the trailers for this Christmas.  I'm very excited.



STEVE:  I have, too, and he looks like he's getting more annoyed.



LEO:  So I'm going to call you S-m-a-u-g, Smaug.  I love it.



STEVE:  Okay.  I'm getting myself in more trouble here.







LEO:  All right.  Let's get to the matter at hand.  There's lots to talk about.



STEVE:  Tons.  So first off, standard business.  Microsoft issued a report a couple days ago that they had this sort of an emergency out-of-band report.  They don't have a patch for this yet.  But they were alerting people who subscribe to their various security lists that they have found targeted attacks using a deliberately malformed TIFF image file.  You remember TIFF, Tagged Image File Format.



LEO:  Still quite widely used by Photoshop users and others.



STEVE:  Yup.  It was an early format and...



LEO:  It has the value of being lossless, if it's got compression at all, lossless compression.



STEVE:  Yup.  So, okay.  The good news is the latest version of Office - this affects Windows Office users.  The latest version of Office, Office 2013, is not affected anywhere.  But Office 2003 and 2007, which is not the next most recent because that would be Office 2010, but '03 and '07 are affected across all platforms.  All versions of Windows have this TIFF image file format problem.  Office 2010 only has the problem on XP and Server 2003.  So specifically not Windows 7 or 8 or Server 2008.  I don't know who would be using Office on a server platform, but you never know.



So the exploit bypasses Microsoft's exploitation mitigations, specifically DEP that we've talked about, Data Execution Prevention, which is where you mark regions of memory as being executable or not.  So, for example, the stack would typically not have execution prevention.  Well, this avoids that problem.  And also Address Space Layout Randomization, ASLR, where code jumps to known locations to pick up little bits of existing code and is able to knit together its devious needs that way.  And this bypasses those protections, too.  So it's a problem.



Microsoft has a quick fix.  I created one of my little bit.ly shortcuts called "notiff."  So bit.ly/notiff, all lowercase.  That'll quickly take you to Microsoft's page, where all they've done essentially is they've - turns out they've added a line in the registry to disable the TIFF codec, so it kills rendering of TIFF files.



LEO:  It also kills your ability to look at TIFFs.



STEVE:  Well, but I don't know that that's going to really annoy anybody because, as you said, it's been around for a long time.



LEO:  No, it's still widely used, absolutely.



STEVE:  Oh.  Okay.



LEO:  Oh, no, no, no.  That's not insignificant.



STEVE:  Yes.  So it will kill your ability to see TIFF files.  So right now these are targeted attacks, mostly in Europe and Asia, not even in the U.S.  But Microsoft knows how these things go, and now the word is out.  So if you don't have Office, you have nothing to worry about.  If you've got Office 2013 you have nothing to worry about.  If you've got Office 2010, but not XP or 2003, again, nothing to worry about.  But you may, if you fall within that class where you - and people are receiving email or browsing to websites that display a TIFF file.  Just receiving the email with a TIFF embedded in it will display it and take over your computer.  Don't even have to click on it or anything.  So if you fit that profile, it may be worth disabling TIFF format file images, unless you know you need them.  And this little bit.ly shortcut will do that for you.  All it does is add a line to the registry saying turn off that codec, please.



LEO:  Hmm.  That's a pretty weak fix.  I'm sure they'll have a patch next Tuesday.



STEVE:  Oh, yeah, yeah.  Absolutely.  Okay.  I labeled this "Adobe Face Plant" because, boy, did they...



LEO:  They scared the hell out of me.  I got the email, like last week maybe.  And they offer you a year's free security check.  I have a credit card on file with them.  And they forced me to reset.



STEVE:  Well, in fact your email is in the list.



LEO:  Oh, it is?  You checked?



STEVE:  Actually, people tweeted the fact to me because I sent them news, because I got a note from Joe Siegrist at LastPass that he had just added a new LastPass service.  So anyone who wants to check and go to LastPass.com/adobe, which - and they've done this before.  We've covered it before.  He's taken the entire database and made it instantly email address searchable because one of the things that was leaked was the password database, which contains everybody's email address in the clear.



Now, what's really bad about this is, I mean, this is every best practice ignored.  So when Adobe first announced the problem, they said, well, don't worry because the passwords were "encrypted."  And people who knew, like, best practices, thought, well, that's just probably some PR flack who didn't understand that what they really meant was "hashed."  No, what they really meant was encrypted.  We're guessing based on the evidence because the block length of the encryption is 64 bits.  And so we're thinking, okay, well, maybe that's a DES, that is the encryption that DES uses with a key length of 56 bits.  But it's probably 3DES because that's readily available.  And so they're...



LEO:  Secure, and the other is not.



STEVE:  Yeah.  And you use DES three times, so you process - to take 64 bits in and process it, get 64 bits out.  Then you send it in again to another round of DES, but with the next 56 bits' worth of the key.  And then you do it a third time with the final 56 bits' worth of key.  So you end up with a long enough key length and pretty good encryption.  And so the problem is that this is not the way you store passwords because what an analysis of the database also showed, and this was posted on the Internet, the initial release was we believed it was about 3 million customer records.  Then, as additional information came out, it looked like, well, maybe it was more like 38 million.  Well, now we know that it's 130,324,429.



LEO:  Somebody said in the Guinness Book of World Records for the largest compromise in history.  Likely, anyway.  



STEVE:  Yes.  It's also been...



LEO:  The year's not over yet.



STEVE:  ...the dumbest one because the database that's out has all these records, everybody's email address, their account ID, but apparently very few people had one in the database.  But also the password hint, which was in plaintext.



LEO:  And very revealing.  I've read some of these password hints.



STEVE:  Yes.  For example, "rhymes with assword."



LEO:  That was my favorite.



STEVE:  What could that be?  Yes.  The title of this podcast is "Monkey Is 26th," because of course we've often talked about "monkey" and what a sort of a random-seeming word that is, which is always near the top.



LEO:  Isn't that funny.  I used to use it, too.  I don't understand what part of our brain...



STEVE:  Yes.  Yeah.  I like "letmein."  That was No. 25.  That's just one above.  We have "sunshine," which is a positive.



LEO:  Sophos has a really great, on their Naked Security page, analysis.



STEVE:  Yes.  And I have - I tweeted a link to the Sophos page saying it was absolutely the best write-up that I have seen [bit.ly/nodobe].  Now, No. 1 on the Adobe hit parade, used by 1,911,938 individual people creating a password for themselves on Adobe's website, and the password is, "123456."



LEO:  People clearly didn't take it seriously.  But they, in many cases, I mean, I had credit card information in there.



STEVE:  Well, no, that's the other problem, is their credit card information was also encrypted, and the worry is it was encrypted the same way.



LEO:  Right.



STEVE:  Now, see, here's the problem, is if they had used a salted hash, where the salt is a so-called "initialization vector," you can show the salt.  You just want to, in fact you need to, you need to have the salt available because you add that to the user's password, then you hash it.  Then you get out something that's a fixed length, that is, the length of the hash.  And if the salt - the salt doesn't have to be secret.  It just has to be a nonce, a so-called, you know, a number used once.  It just has to be a pseudorandom value that you mix in because what that does is it makes everybody's hash different.  Which is what you want because, if that's not done, then everybody who has the same password gets the same hash.  And as we know, there are rainbow tables that are basically big lookup tables where they've put in all these passwords once, done the hash, found the output, which makes it very easy to essentially reverse the hash.



Well, Adobe didn't do that.  Adobe used a block encryption in the worst possible way.  They used what's called - it's ECB mode.  We've talked about encryption modes where, if you have a really good cipher, like Rijndael, which was chosen as the AES, the encryption standard which everyone is encouraged to unify around because we know it's really good.  The idea is that every time you put the same thing in, under the same key, you get the same thing out.  So that's good, except that's like the simplest, dumbest way to do encryption because, if different people's passwords, for example, just began with the same stuff, then you're going to get the same thing out.  So - and that's called Electronic Code Book, ECB, because it's like a codebook.  Same pattern in, same data out.  Same pattern in, same data out.  That's why we know exactly how many people used "123456," because there are 1.9 million instances of EQ7FIPT7I/Q.  That's what happens when you put "123456" through this symmetric cipher.  You get that out.



Now, we don't know what the key is yet which does that.  And that's what probably people are working on right now because that will then reveal everyone's credit card number.  And they would probably like to have that.



So the problem is there is a key which you put this in, and you get the same thing out.  All Adobe had to do was once again use an initialization vector so that they would mix that in and then every single instance would be different.  But they didn't.  They simply, from what we've seen, they simply put the first eight bytes of the password into DES and encrypted it, and out came a different eight bytes.  Then, without any dependence, that's the other thing you want to do with a symmetric cipher is you chain.  That's why CBC, Cipher Block Chaining, is what you want to do.  You want to take the output and then XOR it with the next one's input.  That way you end up with a reversible sequence, that is, it's possible to decrypt that.



But that means that every successive block is dependent upon the one that came before.  And the first block is dependent upon the initialization vector.  So that's the proper way of doing encryption with a symmetric cipher.  And Adobe didn't.  They just used probably 3DES and said, oh, this is good enough.  I mean, and of course our listeners are always freaked out when they say, "I forgot my password," and Adobe says, "Oh, here it is."  The fact that they can give it back to you, and they ought to be really embarrassed if they say, oh, here, it's 123456.



LEO:  Yeah, no kidding.



[Talking simultaneously]



STEVE:  ...very good that it is.  So anyway, this was just - now is anyone worried or, like, confused about the problems we've had with Flash and PDF documents over the years?  I mean, this is the security that the company that produced Acrobat Reader and Flash, which has caused so much grief for us all, this is their security practices.



LEO:  It would be prudent for everybody to change their Adobe password.  But if you had a long, strong password, is there cause for concern?



STEVE:  If it were something that came out of LastPass, for example, or picked up...



LEO:  Yes, that's what mine is, yeah.



STEVE:  Yes, or something like, you know, I have a password generator at GRC.com that lots of people use which is just absolutely high-quality pseudorandom noise.  Then no one else will have used it, and you're okay.  See, here's the problem.  If you use a password that any of the other 130 million people might have used, and their plaintext hint says "Password is..." blank, and many of them do that, by the way, many of the password hints on the list...



LEO:  Don't, don't do that.



STEVE:  Password is...



LEO:  Of course they shouldn't - unencrypted.  But still...



STEVE:  That's quite a hint.  Anyway, so the point is, if you used a password that anyone else used, and your hint was very good, but their hint was very bad, then because of the way Adobe did this, your encryption matches their encryption, and so the bad guy knows your password because the bad guy knows their password.  I mean, this is so wrong in every way you can imagine.



LEO:  Wow.



STEVE:  Yeah.  So Adobe face plant.



LEO:  Yeah.



STEVE:  And some.  Oh, and Sophos finishes up, saying:  "After all this, there's more to concern yourself with.  Adobe also described the customer credit card data and other personally identifiable information that was stolen in the same attack as 'encrypted.'  And, as fellow" - this is the Naked Security blog on Sophos - "as fellow Naked Security writer Mark Stockley asked, 'Was that data encrypted with similar care and expertise, do you think?'  If you were on Adobe's breach list - and the silver lining is that all passwords have now been reset, forcing you to pick a new one - why not get in touch and ask for clarification?"



So, and I did mention that LastPass.com has now a /adobe page where you can check to see if your password was among those.  And the wonderful, the ever-wonderful xkcd.com...



LEO:  Oh, I love their cartoon on this.  Yes, yeah, really good.



STEVE:  Oh, not to be outdone.  It's No. 1286, so xkcd.com/1286 describes this as the best crossword puzzle ever.



LEO:  It is.  It's kind of - that's kind of a good - because if you have the - so the idea is you have the hint, and you have the, I guess, do you have the length of the password?  Can you deduce that from the - no.



STEVE:  What happens is, apparently there's a null termination character as C store strings as seven characters plus a zero.  So if the password is seven or fewer, it fits within one block of encryption.  And so it's the first length.  If it's eight characters of actual password, the null zero on the end forces it out of the first block, so it requires two blocks in order to encrypt it.  So that's where you see the two things, the first one and the second one.  And if you thought you were doing a good job by using a really long password, Leo, I'm tempted to wonder, I mean, there's a password here, No. 14.  61,453 chose "1234."  So there was no minimum length, apparently.  Or, if there was, it was four.  I'm wondering if a password of one would have been accepted.  Nobody chose one that I could see, or at least not many, because I'm only looking at the list of the top 100.  I wouldn't be surprised if it's there somewhere because Adobe certainly wasn't enforcing any minimum because "1234" was completely acceptable.  Unbelievable.



LEO:  Unbelievable.



STEVE:  Unbelievable.  "Fdsa," where is that, fd - oh, that's the first - that's asdf backwards.



LEO:  Oh, clever.  Oh.



STEVE:  We have, of course, "fy," the expansion of that, ever present.  You wouldn't want to miss the opportunity...



LEO:  "Fu," yeah, yeah.  I wonder if they take two letters.  I can just do "fu."  That'd save me some typing.



STEVE:  27,415 people chose "Michael" as their password, which is not up there with "monkey," but it's close.  Oh, we have "princess."



LEO:  You know why it's a good password?  Because it's not my name, it's my kid's name.  No one would guess that.



STEVE:  Oh, good, yeah.  "Soccer," yeah.



LEO:  My sport.  No one would guess that.



STEVE:  There's "Jennifer" and "Jordan" right next to each other.  Oh, and a number of our listeners did point out that No. 70 on the list - want to get there first, Leo?



LEO:  Monkey123?



STEVE:  No, No. 70.



LEO:  Okay.



STEVE:  "Trustnoone" [laughter].  Certainly not Adobe.



LEO:  They listen to the show, but they don't quite understand it.  Oh.  "Peacock," I love it.



STEVE:  Speaking of not understanding something, there is some reason to wonder whether a security researcher by the name of Dragos - boy, I was pronouncing his...



LEO:  Oh, I love his last name, yeah.



STEVE:  Ruiu?



LEO:  Yeah, I don't know.



STEVE:  R-u-i-u, Ruiu.  Dragos Ruiu has made some claims.  Now, he's apparently a researcher of some repute.  So what he wrote was not just ignored.



LEO:  No.



STEVE:  But because of the outrageousness, it was the single most tweeted thing that I received all week.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  Because what he was claiming was that for three years he's been battling some insidious BIOS-based malware virus thing which has been jumping from one system to the other.  And he even - it was even jumping onto laptops with no network connection, no wire, no WiFi, yet it was leaping across the room.  And so it wasn't until he disconnected the microphone and speaker on his laptop that he believed that finally the computer was cut off, which led him to the conclusion, which is what upset everyone this last week, that this was an airborne audible networking virus using ultrasound.  So our friend Dan Goodin at Ars Technica did a nice job.  He said:  "As Ars reported last week, Dragos Ruiu said the malware first took hold of a MacBook Air of his three years ago..." - boy, I have one.  I'm glad I don't live near him.



LEO:  Or within earshot, anyway.



STEVE:  Within earshot, yes, "...and has since infected his laboratory computers running Windows, Linux, and BSD."  So it's a multipurpose piece of malware.



LEO:  We should mention that Dragos is the creator of CanSecWest.  He does the Pwn2Own hacking competition.  This guy's well known in the community.



STEVE:  Yeah.



LEO:  He's not just some guy.



STEVE:  He's not a crank.  Which is why people took him seriously.  And then Dan says:  "Even more intriguing are his claims the malware targets his computers' low-level BIOS, Unified Extensible Firmware Interface," that's the UEFI, "or Extensible Firmware Interface," which apparently was before it got unified, "and allows infected machines to communicate even when they're not connected over a network."



Now, finally, after a week of turmoil that this caused, our other good friend, Tavis Ormandy - we've spoken of Tavis often, a Google security researcher - posted a note to Dragos.  He said, "Dragos..."



LEO:  What you smokin'?



STEVE:  "I've looked at your" - yeah, that's the short version.  Tavis is very polite.  "I've looked at your BIOS dump, your procmon" - procedure monitor - "your procmon logs, font files" - because there was also a claim that the fonts were infected - "and your disk images.  I see nothing" - just like, it wasn't Colonel Klink, it was...



LEO:  "I know nothing" was...



STEVE:  I know nothing.



LEO:  I know nothing.



STEVE:  I know nothing.  Sergeant somebody.



LEO:  Sergeant Schultz.



STEVE:  Sergeant Schultz, yes.  "I see nothing," says Tavis, "to suggest there is anything suspicious here.  These are either all entirely consistent" - and, by the way, this was the evidence that Dragos made available to other security researchers to prove his claim.  "These are either all entirely consistent with what I would expect to see, or have very simple explanations that do not require a sophisticated attacker.  My guess is it's just a combination of stress and healthy paranoia" - this is the ever-polite Tavis - "causing you to connect unrelated events."



Then a little bit later in his note he said:  "Regarding the procmon logs" - this is still Tavis.  "Regarding the procmon logs, one is noisy, and the other is much quieter; but the noise is mostly consistent with just general usage.  I can see you were working on some documents, browsing Facebook, installing some Sysinternals tools and so on.  Nothing suspicious there.  Hopefully you trust my opinion on font exploitation.  I've published on the topic multiple times, was nominated for a Pwnie award for some of my research, and have been credited in lots of Microsoft advisories on the topic.  The behavior you described is not consistent with font exploitation, and the font files you published all look well formed to me.  If they're connected to any malware, it's just the regular kind, and not an exploitation attempt.  I get the impression you're not going to believe me, but please at least think about taking a break from this."



LEO:  Wow.



STEVE:  And then he did a little smiley face.



LEO:  Smiley face, wow.



STEVE:  And then Dan Goodin finishes, saying:  "As every student in an Intro to Logic course learns, the absence of proof is not proof of absence.  I continue to agree with other security researchers when they say it's perfectly feasible for a determined attacker to develop malware as advanced as 'badBIOS'" - which is what this thing became known as - "and unleash it wittingly or otherwise on Ruiu's machines.  At the same time, extraordinary claims require extraordinary proof."



And then in the midst of all this, because, I mean, I just, I let this sort of wash over me, and I'm thinking, okay.  I mean, and Leo, I know you and I have both received really over-the-top email over the years, where well-meaning end-users are convinced that for five years they have had a specific attacker who's been after them.  I get email like that.  And so it's like, okay, I've seen this kind of concern.  But I posted on Saturday a tweet that said - or I tweeted:  "badBIOS reality check."  And I said:  "This somewhat cranky analysis makes a LOT of sense."



And this is a guy with a lot of experience with BIOSes.  And so, just quoting a small piece of this, he said:  "Look, I'm not known for pulling punches, and I'm not about to start now.  The fact is that everything I have read about badBIOS is completely and utterly wrong, from the supposed 'escaping air gap' to, well, everything.  And I should know.  I've dealt with malicious BIOS and firmware loads in the past.  I've also dealt with BIOS development and modification for two decades.  It's a very important skill to have when you regularly build systems that are well outside manufacturer-recommended areas.  The whole of the analysis would be laughable if people weren't actually taking it seriously and believing it because they've seen edge cases or very specific examples.  And the result is that they're looking in the wrong place.



"First and foremost, the very idea that there is some malicious BIOS load that can escape air-gapping and is portable is beyond laughable.  I don't care what you think you know, BIOS code is not portable, period.  Oh, sure, you can have a common source for multiple motherboards.  But every single model, revision, and minor revision requires you to recompile UEFI elements in the best case.  That's before you get into changes to UEFI libraries and shells.



"Secondly, the concept that BIOS malware could somehow escape detection is, again, beyond laughable.  Look, I've been doing BIOS work for ages and then some.  I can and would spot any malicious load pretty much instantly even before flashing a board.  Certainly I would have no trouble finding it from a ROM dump.  Period."  So...



LEO:  There's not a lot of code in BIOS.  And of course it's always written specifically to the machine.  The point of BIOS is its low-level - it's assembly language, I presume, right, code?



STEVE:  Yeah.  Well, some of it's actually been written in...



LEO:  I guess it could be C.



STEVE:  It's been in Forth.  Forth is often used for BIOS because it's so compact, and it allows them to quickly port it.  It gives them some processor independence because they can write a little Forth interpreter, if it doesn't already exist.  It probably exists for every chip made.  And then you have all this.  But it is not - inherently, it never needs to move.  So it's not position-independent code.  It is position-locked.  And that more than anything else means it just can't jump into a different motherboard.  I mean, it can't.



LEO:  Right, because of where it loads.



STEVE:  So maybe Dragos is misinterpreting what he's seeing.  Again, as you say, he's not a loon.  So how, you know - and this thing's been bothering him for three years.  So...



LEO:  That's the thing that bothers me.  It took three years, yeah.



STEVE:  Yeah.



LEO:  Okay.



STEVE:  Okay.  And our hit parade continues.  We have new customer service options offered by CryptoLocker.



LEO:  [Laughing] This is the malware we spent a lot of time last couple of weeks mentioning and talking about.



STEVE:  We covered it extensively last week.  I saw a lot of people appreciating the fact that we explained how it works; why they did crypto right, unfortunately; and why somebody who has been gotten by this is in trouble.  Well, now the AV companies are catching up, and that's sort of the bad news because, for example, Microsoft will happily remove it from your machine.  Unfortunately, that may not be what you want, if you're willing to pay $300.  Now, I am seeing everyone's advice out there saying, oh, no, no, don't pay the ransom because that encourages them.  Well, okay.  But if you don't have a backup, I mean, it's very easy for those advice-givers to give that advice.  But in the real world, if you don't have a backup, and you desperately need all the things that it just encrypted, $300 doesn't sound like such a problem.



LEO:  Yeah.



STEVE:  So now we've got some evidence that it may be, in later incantations, or incarnations, deleting volume shadow copies, because it wasn't initially.  And so if you had so-called - a volume shadow copy is the technical term for Microsoft's rollback technology in Windows.  It allows you to go back to a previous version if something you've done has hurt your machine.  So that was the advice.  Of course, any advice that appears on the Internet, these guys are also seeing.  And so that's why long-term I'm very concerned that this is going to be difficult for us to deal with.



However, if the worst happens, and you eradicate the registry key, which apparently is the key for your being able to decrypt your stuff and/or remove - if you remove the whole virus, you have been able to download it again.  It's something called, it's ridiculous, it's 0883.exe or something, that has been available.  So you could reinfect your machine in order to then go through the decryption process to get your files back.  So the problem is three days might pass; and then, as we know, you have a 72-hour window, in which case, after that, you're hosed.



Ah, but we now have the new high-priced service being offered through the Tor hidden services system.  So this is a service hidden by the Tor network, and we've talked about how Tor hidden services work, where for 10 bitcoins at the current going price, whatever that happens to be - currently a bitcoin is about $210.  So 10 of these...



LEO:  260.  Just went up.



STEVE:  Ooh, boy.



LEO:  It's at a record high.  Or not record, but it's very high.



STEVE:  I'm liking it.  I'm liking my 50 bitcoin...



LEO:  Yeah, baby.



STEVE:  So, yes, now we're at $2,600 you would have to pay them to get your files back.  The good news is there's no time limit on this.  So if you are in a position where this is your only recourse, you have no backup, the stuff you need is worth whatever the current price is for 10 bitcoins, and as Leo said, currently $2,600, you can go to this Tor hidden service, and you give it one of your encrypted files.  Apparently the encrypter puts a header on the encrypted file that allows it to perform a search for your public key.  So it puts like a - it's a 1024-bit header is what I saw.  So that would allow it to find your public key.  Then it says, ah, found it.  So we can decrypt your files.  Download the handy-dandy decrypter from this link and pay us 10 bitcoins.  They then wait for the bitcoin network to verify the transaction.  They wait, they stated, from 10 to 15 confirmations out on the network.  And then they will provide you with the matching private key in order to perform your decryption.



Oh, and if the three days have not expired, that is, if you want to use the service within the 72 hours because you did - something came along and removed this before you were able to pay them, then in an update on Monday they made a change such that, within the first 72 hours you only have to pay the two bitcoin price.  Which now would be, what, 512 or, no...



LEO:  Yeah, 520.



STEVE:  There was 260, yeah, 520.



LEO:  Kind of amazing, yeah.



STEVE:  So that's certainly better.  So you can use the service within three days and pay the reduced price.  Or, if you wait past 72 hours, then you're going to have to pay $2,600 at the current going price.



LEO:  At least they save it.  Because sometimes you're out of town, and you don't get to see it, and I think that's just fabulous, yeah.



STEVE:  Yeah.  Yeah.  So for frequent travelers we have a service.



LEO:  Geez, Louise.



STEVE:  Now, in an interesting sort of related post, it turns out that users of the OpenDNS Umbrella service are safe from this.  Because, when you think about it, this is all based on DNS.  It turns out - and I'll just quote from their blog.  They said, the Umbrella service said:  "First, a quick recap of how OpenDNS provides protection against CryptoLocker.  In a previous post, we introduced a predictive algorithmic method called 'The Ripple Effect' for detecting CryptoLocker command-and-control domains."



And remember we've talked about how they're just a bunch of gibberish.  It's a long crypto-looking thing dot something - .ru, .nz, dot whatever.  It's in a bunch of top-level domains, but then it's just gibberish-looking.  And the bad guys only need to register one of the many that are generated.  And the CryptoLocker infection on the user's machine uses the current date in order to generate a large list of candidate domains.  And it doesn't know which one is valid, but the bad guys know.  But what we do know is that one among them will be valid.  So the virus starts doing DNS lookups in very short order of this random gibberish.  Oh, and these are 1215 characters long.  So when you think about it, a smart DNS server could see your computer beginning to do this and say, whoa, hold on.



LEO:  Awesome.



STEVE:  And it does.



LEO:  Now, that's their Umbrella service.  What is their - it's business security.  So you have to...



STEVE:  Yes.  It's only corporate.



LEO:  That's a paid service.  It's not for...



STEVE:  Yes.



LEO:  Because I use OpenDNS, of course, but...



STEVE:  Yeah, and unfortunately it's not available to OpenDNS users, and it's not cheap.



LEO:  But Umbrella is designed to protect you against malware and botnets, so this is good.



STEVE:  Yeah.  So, "The method uses the fact that the malware contacts a set of randomly generated domains to fetch an asymmetric crypto key before it starts encrypting the data files on the victim's system."  So this blocks it after infection, but prior to encryption, which is perfect.  And it says:  "The Ripple Effect method relies on the co-occurring pattern of the domain requests made consecutively by the malware within a short time window."



And then they said:  "A number of users of our free DNS service were infected with the malware."  Meaning that OpenDNS itself doesn't provide this protection.  "But OpenDNS customers using Umbrella are protected against losing their valuable data to CryptoLocker because we successfully cut off the outbound communication initiated by the malware for retrieving the encryption key."  That is, if the client can't reach the command-and-control server, it can't get the key.



"OpenDNS customers are spared the data loss and gain time to remove the malware before it can cause damage.  If you're an Umbrella user, you can check for evidence of CryptoLocker in the Dashboard," which is their UI to the client, the user side of this.  "On the Security Activity Report, filter by security category 'botnet.'  There is a very good chance, if you were infected by CryptoLocker, you will see a long list of botnet domains displaying the following patterns:  12, 13, 14, or 15 random characters, top-level domains rotating among .info, .com, .ru, .biz, and .co.uk."  And then:  "Frequent requests made in very short intervals to about 1,000 unique domains following the above string patterns."  So a thousand.



LEO:  Now, I wouldn't, if I were them, crow too much because it would be easy to modify CryptoLocker slightly to bypass this.  Right?  Somebody in the chatroom said, yeah, just encrypt with a weak encryption and then send the key out, or, I mean...



STEVE:  Ah, good point.  You could do a - good point.  You could easily generate locally your own symmetric key, so use local entropy on the machine to generate a very strong symmetric key, hold that while you're waiting to share it with command central, and encrypt all the files using that.  So, yes, you could absolutely do that.



LEO:  So don't get - don't make too big a deal, OpenDNS, about this.  You're just attracting attention.  You started saying it was expensive.  How much is the service?



STEVE:  It's like 29 per something per user.  So I don't know...



LEO:  $30 a user per month, probably.  That makes sense.



STEVE:  Wow, that's pricey.  I mean, ouch.



LEO:  Maybe it's per year.



STEVE:  Oh, it's per year or per month?



LEO:  Maybe, I don't know.



STEVE:  Anyway, if you put "Umbrella" into Google, or "OpenDNS Umbrella," it'll take you there, and you can see that they have a big button you click to get pricing.  And it shows you, like, four different types of plans they have.  But, boy, they're not cheap.



LEO:  Seems like it's something we probably should do here.



STEVE:  Oh, yes.



LEO:  $33 per user per year.  That's...



STEVE:  Okay, that's not that bad.



LEO:  No, it's nothing, in fact.  And then, yeah, $39 for the top-of-the-line protection.  Okay.



I was going to say real quickly, one thing that, if LastPass is listening, you might want to change in that nice, that kind of nice idea that you go into LastPass.com/adobe to see if you've been hacked, and you enter your email, unfortunately LastPass then sends out an email to that address.  And I've received many, many emails from LastPass as people test my address in the Adobe cracked database.  So LastPass probably might want to change that.



STEVE:  I wonder why they're doing that.



LEO:  That's really annoying.  Well, because they want to - you are receiving this email because you have - because hi.  You're receiving this email because you used LastPass - not me, but somebody used LastPass - to confirm your Adobe account credentials were leaked and requested that your Adobe password hint be mailed to you.  Actually, maybe that's a checkmark in that page?  Let's just go quickly and see.



STEVE:  Oh, but, yeah, they can't...



LEO:  It's really annoying.



STEVE:  Oh, email the hint.  Yeah, that's a good point.  The hint is there with every email address.



LEO:  But it doesn't say, it just says put your email in and test my email.  It doesn't say - I didn't - nobody [growling].  Stop it, LastPass.  I liked you up to now.  I've gotten a lot of these.  I don't need more spam.



STEVE:  You probably do have - Leo, with your email address being leo@leoville.com?



LEO:  Oh, thanks for telling everybody that [laughing].



STEVE:  Yeah, I know, that's a secret.  I guess the problem is you're receiving it from LastPass, and they're whitelisted on your spam...



LEO:  Well, not anymore.  I've just told Google this is spam, LastPass.  Little hint.  Might not want to do that anymore.



STEVE:  So to wrap up our CryptoLocker update, CryptoPrevent, which is a very nice free or paid - you can pay for the auto-updating version if you would like auto updates.  And that would have paid off, by the way, because they've updated it now to - we were at 3.0, I think, last week.  Now we're at 4.0.  So additional features.  The guy is continuing to hone it.  My concern is that this is - it's not strong protection.  It's certainly better than nothing.  So it uses Windows' group policy system in order to block some of the behavior which CryptoLocker exhibits in terms of where it puts things to execute.  But all it has to do is put them somewhere else.  And that's why it's like, eh, okay, it's better than nothing.  But it also kind of messes things up in your system.  And there has been a problem with it blocking, doing a false-positive block because other things are able to behave in the same way that CryptoLocker does.  So it's like, eh.  Okay.



However, Sandboxie, our old friend Sandboxie, is effective in containing CryptoLocker.  It's been verified that, if you were to put your email client and your web browser in Sandboxie, if you were to Sandboxie those two things, and we've talked about - we did a podcast on Sandboxie [SN-172].  Anybody could, like, google "Sandboxie Security Now!," I'm sure you'll find it, or go to GRC.com/sn, and I've got a search field that I pay Google handsomely for, and put Sandboxie in, and you'll find the podcast where we explain it.  What happens is, if you get a CryptoLocker infection through email or web browsing, and you have employed Sandboxie, then an encrypted copy of your files are created in the sandbox, but nothing gets out of the sandbox.  So your original files are all fine.  And all you do is empty the sandbox, and CryptoLocker and all of its damage it tried to do is gone.  So...



LEO:  Nice.  Nice, nice, nice.



STEVE:  Yes.  So that's a solution that makes sense.  I like Sandboxie because it is lightweight.  The heavyweight, the industrial-strength solution is a virtual machine.  I've always owned VMware, so I still have that.  But the free VM, the one that Oracle offers, I can't think of what it's called.  It's the one everybody uses because it's good, and it's free.



LEO:  Oracle?



STEVE:  Isn't it Oracle?  Sun?



LEO:  Oh, yeah, yeah, Onebox.  Or VirtualBox.  VirtualBox.



STEVE:  VirtualBox.  VirtualBox, yes.  VirtualBox is industrial strength.  Many people have asked, well, would that work?  Absolutely.  So you set up VirtualBox and do email and surfing there.  And there you have total control over what drives are visible.  And drive letters is what CryptoLocker ties to.  Thus network shares that are mapped to drive letters are what CryptoLocker is able to follow in order to, like, encrypt people's shared network storage, which will ruin your day.  So the problem is that using a full VM takes up a chunk of memory out of your system.  I mean, it's stronger protection, but just using Sandboxie is a very nice lightweight solution, and we know now that it is effective in blocking CryptoLocker.  So yay to that.



Now, I'm sorry you're not happy with LastPass, Leo, because...



LEO:  I'm mad at you, LastPass.



STEVE:  ...the world is happy with LastPass.  They came out with a big v3.0 upgrade.



LEO:  Yeah, I like v3, yeah.



STEVE:  Yes.  And many people do.  In fact, I just googled, I wanted to kind of get a sense for it.  So I just googled LastPass v3.0.  The first link that came up said - it was a forum posting, and it read:  "Hi.  I'm a recent LastPass user.  After trying several alternatives (1Password, Locko, Dashlane, and KeepassX), I chose LastPass mostly because it offers the best feature set for a competitive price, a good tradeoff of security versus flexibility, and Steve Gibson can be mighty persuasive."



LEO:  That must make you happy.  That's great.



STEVE:  Then he said:  "But the one thing that really put me off was the poor user interface."  And we're talking about the old version.  "LastPass hasn't been designed, it has been programmed."  Now, frankly...



LEO:  Never bothered me.



STEVE:  ...that's what turned me on to it.



LEO:  Yeah, yeah.  Never bothered me at all.



STEVE:  Serious, serious technology.  Joe has been completely open about how it works.  That's why I've been able to talk about it.  I still can't talk about BitTorrent Sync because they won't tell me how it works.  So it's like, well, okay.  They're bragging about having a million users.  It's like, okay.  I mean, it's probably safe.  But we can't know.



LEO:  We don't know.



STEVE:  Until they'll share it with us.  So anyway, this guy just goes on to say, basically, he loves the change that's been made to the aesthetics, all kinds of things.  The flow is better; the design is better.  So this is a very nice, substantial usability and UI upgrade to LastPass, taking it to 3.0.  And also there's a thing called Family Folders, which is a new feature that allows members of a close-knit family group to share in some fashion.  I haven't looked at it closely because it's just me using LastPass.  But bravo.



LEO:  Yeah, no, I just think they've done a really nice job.  It's cleaned up; it's beautiful.  They probably hired a designer.



STEVE:  Yeah, which is good.  But I'm glad they did that first.  The problem, for example, with - there was that messaging client.  It wasn't Threema, although Threema just apparently added group messaging, which I haven't had a chance to look at it yet.  I just saw that this morning.



LEO:  You know, I had to delete Threema from my - so if people sent - first of all, I made a mistake giving out my QR code because I was getting, like, 30 or 40 messages an hour.  But then, and maybe it's because I was getting so many messages, Threema just crashed my Moto, that's my Android phone, badly, forcing a reboot.  And so I've removed it because I can't...



STEVE:  There was one, it wasn't Threema, but apparently they were, like, UI designers.  And I've talked about them several times.  The name will come to me.



LEO:  Not Hemlis.  Not the Hemlis guys.



STEVE:  Hemlis, yes, Heml.is, Hemlis.  Gorgeous-looking.  Very pretty.  Rainbow colors.  Oh, and it's got just such a nice balanced-looking UI.  However, their crypto, they're saying, well, we can't tell you how it works because them maybe it could be hacked.  It's like, what?



LEO:  That's a bad sign.



STEVE:  What?



LEO:  Always a bad sign.



STEVE:  Yeah.  So LastPass just came out of the gate saying, look, this is what we do.  And that's the reason I fell in love with it is that it's like, okay, that's correct.



LEO:  And that's the right way to do it.



STEVE:  You did everything right.



LEO:  Yeah, that's correct, yeah.



STEVE:  Yes.  It's the only way to - and it's like the way the SQRL project is going.  I have an update on that, by the way, because I scrapped the Identity Unlock that I had last week with one that I came up with Monday that made it much better.  But we'll get to that in a second.  So bravo, LastPass.



BitTorrent Sync, as I mentioned, just had a big ballyhoo news that they have a million users.  They have also opened the developer API.  But apparently you still use a closed, nondocumented engine.  So the developer API lets third parties now create apps on top of the BitTorrent Sync protocol, which is closed, and which we know nothing about.  And I'm sure lots of people will.  And I don't understand why they're not telling us how the protocol works because that's reason for concern.  But they're not.  So it's still closed protocol.  No security analysis is possible of it.  We just assume that it's a good thing.  So, and a million people are apparently doing that now.  It's free, and it's out of alpha, and download it and go.



LEO:  Leo Laporte with Steve Gibson.  Yes?



STEVE:  I was going to say password lists are just fascinating.



LEO:  Oh, you're reading that Sophos list?  Yeah.



STEVE:  It's just wonderful.  I did tweet, for anyone who's interested, a link to the nice list of passwords [bit.ly/1bYTopN].  It's just wonderful.  I don't know what it is about it.  It's sort of like you get to sort of reverse-engineer what people are thinking.  Like there's "1q2w3e4r," which of course comes right off the keyboard.  And you had to think, whoa, nobody is going to come up with that one.  And 22,000 people did the same thing.



LEO:  "1q2w3e4r."  That's a good one.



STEVE:  Yeah.  It's just sort of - we've got "Hannah" and "Ginger" and...



LEO:  Yeah.  Again, I'm sure that's not their name because that would be too easy.  It's their kids' names or their dogs' names.  In fact, some of the clues are "My dog's name."  I love the hints.  The hints are as much fun, frankly, as the passwords.



STEVE:  Oh, god, yeah.  Oh, it's wonderful.  Okay.  So the good news is, a piece of software that we here on the podcast love...



LEO:  Yes?



STEVE:  TrueCrypt.



LEO:  Uh-huh.



STEVE:  ...has easily made its audit money goal.



LEO:  Oh, that's such good news.



STEVE:  And I'm annoyed that they're over on Indiegogo because I don't have an account there.  But I'm going to have to set one up just so I can pay them the money and get the T-shirt because I need the TrueCrypt T-shirt.  And you get stickers and all kinds of other stuff.  They wanted to raise $25,000, which I think is a very reasonable number - unlike what Ladar wants, but we'll get to that in a minute - $25,000 to do the audit.  And they're at $35,264 last I looked, a few hours ago.



LEO:  Yay, yay, yay.



STEVE:  So an additional $10,000 over their goal.  And of course this is Matthew Green, a world-renowned cryptographer, who said, you know...



LEO:  He doesn't work for TrueCrypt, we should mention.  Right?



STEVE:  Say what?  What?



LEO:  He does not work for TrueCrypt.  This is an independent audit.  Or does Matthew...



STEVE:  Oh, absolutely.  No, no, completely, no.  He's with university of something, living in Chicago maybe [Johns Hopkins, Baltimore].  I don't remember exactly where.  But, yeah, this is absolutely independent.  The goal is that they're going to take the source, and they're going to verify that they get binary identical builds by having lots of separate people create it.  So the idea will be we can get a reproducible binary image from the source, and then they're going to do a complete careful read, really crypto-smart people reading this line by line, was everything done right.  Is there anything wrong in here, anything hinky, anything that doesn't look like we understand why it's there?  And, I mean, it'll just give us all a neat warm fuzzy.  And then we'll lock that down, and that will be the source for TrueCrypt.



And, I mean, I think it'll tremendously increase its value.  I mean, I use it now because it's, like, sure better than NoCrypt.  But it'll be nice to know that there is nothing that crept in.  I mean, one of the things we've learned, unfortunately, from Snowden is there has been an infinite budget and infinite will to get everywhere possible in security.  It certainly is not beyond the pale to imagine that the NSA may have had some influence.  So we just need to know that that isn't there.



Speaking of the NSA, yesterday Google engineer Mike Hearn weighed in on Google and the NSA.  He in his Google+ posting quoted another colleague in the security team, Brandon Downey.  And he said, "Recently Brandon Downey, a colleague of mine on the Google security team, said, after the usual disclaimers about being personal opinions and not speaking for the firm," he said, "which I repeat here," and I can't say what Brandon said, but eff these guys, meaning the NSA.  I mean, this gives us...



LEO:  They were pissed.



STEVE:  Yes.  The reason this is interesting to me is this really gives us a window into Google's feelings about this.  And so then Mike says, this is yesterday:  "Now I join him in issuing a giant FY to the people who made these slides," referring to the NSA slides.  "I am not American, I am a Brit, but it's no different - GCHQ turns out to be even worse than the NSA.



"We designed this system to keep criminals out.  There's no ambiguity here.  The warrant system, with skeptical judges, paths for appeal, and rules of evidence, was built from centuries of hard-won experience.  When it works, it represents as good a balance as we've got between the need to restrain the state and the need to keep crime in check.  Bypassing that system is illegal for a good reason.  Unfortunately, we live in a world where, all too often, laws are for the little people.  Nobody at GCHQ or the NSA will ever stand before a judge and answer for this industrial-scale subversion of the judicial process.



"In the absence of working law enforcement, we therefore do what Internet engineers have always done - build more secure software.  The traffic shown in the slides below is now all encrypted, and the work the NSA/GCHQ staff did on understanding it ruined.  Thank you, Edward Snowden.  For me personally, this is the most interesting revelation all summer."



LEO:  We said that, when we talked about that slide with the smiley face on the Post-it note, here's where we get all this stuff, we said - they had shown it to somebody at Google who, like, was - that's outrageous.  Was it Eric Schmidt?  I think it might have been Eric Schmidt.  So I'm really starting, between these two posts and Eric Schmidt, I'm starting to think Google really doesn't know anything about this, and they're miffed.



STEVE:  Well, and then in response to Mike's posting, we learned something else, I did, which I thought was very interesting.  Jeff Weiss was the first person to respond, saying:  "Until this article, no one had mentioned that the intercepted traffic was on leased fiber, not on the public Internet.  That makes the cleartext transmission seem like a less glaring error.  I suppose I can see how it wouldn't seem necessary.  In fact, anyone claiming it was necessary probably would have been seen as paranoid until now.  Still," Jeff writes, "encrypting data sent over the wire is not difficult.  Considering the value of the data in question, and the number of parties who could access it - at least two, the fiber owners and the government - it seems like a worthwhile investment.  Lesson learned, I suppose."



And then Mike replied, the original poster who I first quoted, Mike replied:  "I think the fact that Google uses private fiber has been well known for quite a while, actually.  Just search for," and he says, "'google dark fiber,' and you'll find many news stories discussing that, and it was mentioned offhand in previous stories as well, I think.  Yes, that's pretty much it.  Encryption was being worked on prior to Snowden, but it didn't seem like a high priority because there was no evidence it would achieve anything useful, and it cost a lot of resources.  Once it became clear how badly compromised the fiber paths were, there was a crash effort to encrypt everything."



And then he finally says:  "Re: 'not difficult,' I disagree.  Doing end-to-end," meaning encryption, end-to-end encryption, which is, as we know, the gold standard, that's all that matters, doing end-to-end, which is why, for example, PGP works for email, but nothing else does, "doing end-to-end on the scale of Google is a lot harder than it looks.  Ignoring CPU capacity constraints, the entire thing requires a large and complex key distribution and management infrastructure," he says, "(fortunately already present).  Also, lots of different protocols flow over our wires, each one of which has to be handled."



So there was a lot here that I thought was interesting.  As you said, Leo, we get a look, finally, into Google's authentic feelings about this.  And the fact that this - they were buying, essentially, leasing their own fiber.  So this was not going out on routers across the Internet.  This was, you know, we've talked about how the Internet is packet-switched.  And the brilliance of it was that you could just send little packets off into sort of nowhere, and they would, with an address, just carrying a destination address, and they would get there, sort of like writing an address on an envelope and dropping it into any mailbox, and it finds its way to its destination.  That's how the Internet works.  Whereas before that, we used to have dialup lines where you and your modem called CompuServe and their modem, and your phone was tied up, and no one could call you.  You got a busy signal if you tried while you were using CompuServe or the Source or AOL in the old days.



So these are like that.  This is Google purchasing dedicated, their own, they have all of the bandwidth of this optical connection where they blink lights in one end, and it blinks out the other, essentially, between their data centers.  So they had every reason to believe this was absolutely private.  The government tapped that.



LEO:  And that's why they tapped it, of course, because it was likely unencrypted.  It isn't now, by the way.



STEVE:  Well, Leo, because it was there.  They tapped it because it was there.  And I wanted to wrap this segment up by just saying, in the NSA's defense, we got what we asked for.  That is, it really was the case that, in the U.S., at least, Congress said, "Protect us from anything like 9/11 again at any cost.  Get full information.  Do whatever you need to do."  So now the good news is, as a consequence of Snowden's revelation and all of the backlash, we understand what we unleashed.  And so now it looks like there will be some dialing back of that.  It's like, oh, now we know what happens if we say "Do anything you want," and you have as much money as you need.  Well, I mean, that's what the people in the crypto palace want is carte blanche.  And we gave it to them, and they tapped everything.  So now it's like, whoa.  Okay.  Except maybe not Angela's phone anymore because that really annoyed her.



LEO:  Angela Merkel, Chancellor of Germany?



STEVE:  Yes [laughing].



LEO:  Yeah, I don't know, maybe they stopped, or maybe they just made it a little bit more secretive.  I don't know.



STEVE:  I know.  So anyway, this has been good.  Again...



LEO:  Oh, yes.  This is - anybody who thinks that what Edward Snowden did is somehow unpatriotic doesn't - I think is missing the point.



STEVE:  And that was our first reaction upon hearing it.  The first moment this came out, I watched that video that was made of him in the hotel room, and I thought, okay, this guy knows what he's talking about.



LEO:  Yeah.  Boy, the more we see, the more - my only complaint is that it seems that they're dribbling it out with an aim to maximizing profit as opposed to...



STEVE:  I think it maximizes that because...



LEO:  But also attention.  It maximizes attention.



STEVE:  Yes, yes.  I think this is brilliant because, if it was just a big blob...



LEO:  Be too much.



STEVE:  ...if they dropped - it would be overwhelming.  Yes.  This is like, it's like, oh, god, you wake up on a Monday morning, and the NSA has to be thinking, what now?  What?  What?  Because they know what hasn't been revealed yet.  And they have to be thinking now, he got it all.  So it's just a matter of time.



LEO:  Hey, speaking of spam, can I apologize?  And did you get an email from me asking you to join Twitter?  I apologize.



STEVE:  Oh, I did, actually.  I got two.  And I...



LEO:  Okay, yeah.  If I have - just ignore it.  If I have several addresses on file in my contact list for anybody, you got one for each address.  Dr. Mom got six invitations from me.  And let me just show you.  I think it's Twitter's fault.  Well, it's my fault.  But let me just show you because I was signing up for - I was signing up with my Twitter on my new Nexus 5.  And this is how it happened.  You're now on Twitter.  Follow your friends.  Now, I should have just said skip it.  I said, oh, no, no, that's good, I'd like to follow.  Yeah, you can have access to my contact list.  And this is where my troubles began.  Follow your friends.  I'll follow them all.  Yeah, actually I think I did follow them all.  Okay.  Now, invite friends.



The default on the phone is a little different.  This is on iPhone.  On Android it's defaulted to "select all."  If I press this right arrow - this is the default.  Tell me how you get out of this.  Because, if I press this right arrow, all of the contacts in my address book, each address in my address book will get an invitation from Twitter.  Every one of them.  And it was just, I mean, admittedly I should have paid more attention when I was signing up.  But there was no are you sure you want to email everybody in your address book or anything like that.  It just did it.  And so I apologize.  My mom sent me a text today saying, "Well, I joined Twitter like you asked me."  It was like, no, Mom, don't, don't join Twitter.  We will securely upload all - I'm glad it's secure that they've uploaded my contact list to Twitter.  Follow friends.  Okay, done on that one.  Invite...



STEVE:  And Twitter's never made a mistake with their security, so...



LEO:  Yeah.  So here's the one, this is the one that happens on the Android phone.  It's by default all are selected.  If I tap "done," an invitation will go out.



STEVE:  Ooh.  Wow.  Yup.  Little too easy.



LEO:  Yeah.  And I accidentally typed "done," like I'm done.  I don't want you to invite everybody.  Instead it said, oh, you're done, we're going to invite everybody.  So I apologize to all the people who received emails.



STEVE:  And the headline of my next topic is...



LEO:  I don't really want you to join Twitter, by the way.  Stop.



STEVE:  The headline of my next topic is "It's not a bug, it's a feature."



LEO:  Yeah.  Exactly right.  So go ahead.  Take her away.



STEVE:  That was Google's response last August when the blogger - remember we talked about this on the podcast - declared that Chrome was flawed because it wasn't masking the passwords that Chrome was saving, your website passwords that Chrome was saving for you.  And I defended Google, saying, "It's not a flaw.  Look at it.  It's the way they designed it."  Now, we could complain about the design, but calling it a flaw, the way this was phrased made it sound like it was a defect.  No, it was by design.  So Google said it's not a bug, it's a feature.  And then they said, okay, well, maybe we can do better.



So what they're doing is they're giving us what users, security-conscious users have apparently asked for.  For example, Safari on the Mac re-prompts for the machine's standard login password if you want to display your web browser passwords, which seems reasonable.  Firefox, as we know, by default allows you to set a master password, sort of a master password password, to protect the viewing of and access to your passwords.  And so Google said - their original position was, well, we just feel that that gives users a false sense of security.  We don't want to do that because, if anyone has physical access to their machine, well, that means there's no security.  And many people responded, saying, wait a minute.  And actually someone said, well, what about my crackhead brother?  It's like, okay, well, that's a little disturbing.  But, yes, we can understand that maybe you'd want to keep him from logging into your websites.



So in what's called the "Canary" version of Chrome for OS X on the Mac, which is not yet released into the mainstream, it's been noticed that Chrome has added the feature which, as with Safari, will re-prompt you for your Mac platform, your Mac OS X master password, if you want to view your passwords in Chrome.  So congratulations.  I think that's a good thing.  We haven't seen it across platform on...



LEO:  Well, you will.  Canary is the - so Canary is basically alpha.  There's a beta channel.  There's Chrome, Chrome Beta, and then there's Chrome Canary, which is an alpha channel.  But that means it will be migrating up, I'm sure, unless there's some problem with it.



STEVE:  And it ought to, yeah, it ought to.  It's like, that's a good thing.  Many people asked about a new app that appeared in the iTunes store just yesterday called Knock.



LEO:  Yeah, I thought this was interesting.



STEVE:  Yeah.  And so I spent enough time with it to familiarize myself with it, look at the security model, and then I tweeted, yup, they did everything right.  So here's what the deal is.  It's from some guys from Square, so they understand security and UI and things.  And so they said, okay, how can we improve the user login experience?  Their first version had an automatic login to your Mac OS when you approached your machine with your phone in your pocket.  And that was a little unnerving to users.  They said, you know, it just sort of has a mind of its own, and what if I'm just sitting down at Starbucks with a fresh cup of coffee, I don't want to unlock my laptop right now, well, it just unlocked for me.  So back off.  And they've been playing with this with about a hundred testers, I guess, for, like, six months.



And so they said, okay, how about if you have to go knock-knock on your phone?  They take advantage of the inertial sensor in the phone and make knocking twice on the phone in your pocket be the key to unlocking your laptop.  So be very careful, because it's not free, that you have the required compatible equipment.  You need - basically what this is is it takes advantage of the Bluetooth 4.0 or the so-called LE, the low-energy version of Bluetooth.  That has a reduced range, which is fine for unlocking your Mac; also a reduced bandwidth and data rate.  It also, though, has a reduced latency.  Whereas regular Bluetooth takes about half, or I'm sorry, about a tenth of a second to negotiate, this negotiates in six milliseconds.  So it's very suitable for quick little bursts of information, like here is the - and a privately encrypted key.



And when I said they did this right, what they did is they used 2048-bit standard RSA public key asymmetric encryption.  They encrypt the password using your private key on the phone.  So there's no way for an attacker who gets your phone or tries to take it apart or do anything to get anything useful.  They send that when you have a connection to your laptop and when you have tapped twice on your phone.  They send it over this Bluetooth low-energy connection to the companion app, which is free.  I should mention the iTunes app is four bucks, 3.99.  And it has, your Mac has your public key.  Does not have the password there, just the public key.  So again, it can't do anything because it doesn't have anything that it can use, until it receives the private key encrypted password.  Then it's able to decrypt it, use it, and unlock your machine.



So you do need an iPhone 4s and later, an iPad 3 or later, an iPod Touch 5 or later.  The mini has always had Bluetooth low-energy and iOS 5 as the operating platform, and later.  And Macs are a little confusing:  2011 MacBook Air or newer, a 2012 MacBook Pro or newer, a 2012 iMac or newer, a 2011 Mac mini or newer, or a 2013 Mac Pro.  They spell this out over on iTunes under "Compatibility."  Make sure you don't waste $4.  A couple people apparently have.  They've been unhappy, as they commented in the iTunes store.



LEO:  No refunds on the App Store.  That's...



STEVE:  Right.



LEO:  You bought it, you pay for it.



STEVE:  Yeah.  So anyway, so for people who are wondering, yes, it looks like they got the security right.  And they say they're going to do more things.  They're not Apple-only.  They're going to address Android when they can.  But the Android market is more fragmented.  There isn't the same uniformity of API, so it's a bigger challenge for them.  But kind of a cool idea.



LEO:  Well, the cool idea is Bluetooth LE.  That's really the cool idea.  And there are so many things we're going to see with that.  I'm just really excited about it.



STEVE:  Yeah, the energy is so low that a single-cell coin battery can run more than a year.  So...



LEO:  So people are putting beacons in - we could put a beacon in the Brick House, for instance, that your phone would sense and would automatically pull you to an informational website, or check you in, or whatever.  There's all...



STEVE:  And people have, like, plastic tags they're selling.  You can put tags on things, and you're able to...



LEO:  Never lose your luggage, I mean, just goes on and on and on.  This is - Apple's going to push this heavily because this is, I think, their response to NFC.



STEVE:  NFC, exactly.



LEO:  Yeah, they like this better.  And I think, given the security you just described, maybe it is better than NFC.  I think that this is all the, you know, the Fitbit Flex uses it.  A lot of the health bands are going to start using that.  It's just a natural.



STEVE:  Right.  So Ladar Levison wants to raise - and I don't know where this number came from - $196,608 is his goal.  Almost - just shy of $200,000.  So that's a chunk of money.  It's on Kickstarter, Lavabit's Dark Mail Initiative.  And he said, the description there says:  "The goal is to clean up and release the source code that was used to power Lavabit as a f/oss" - so an open source - "project with support for dark mail added."  The problem is I can find no documentation for Dark Mail.  And as far as I know, it doesn't exist yet.  I mean, it's an idea.  It's gotten a lot of press because of course this is the guys at Silent Circle are teamed up with Ladar on this.  He's got a ways to go, but actually he's doing pretty well so far.  He's got 1,082 backers when I looked this morning.  He'd raised nearly $50,000 pledged out of his $200,000 goal, with 21 days to go.  So that's the positive...



LEO:  He said on the interview with us, he didn't say details, but what they want to do is write a new mail server, not SMTP, but write a new mail server that has PGP encryption built in.  So he understands, I think he understood the issue.  I know he understood the issue of there's no such thing as secure email because SMTP servers, while they have encryption, don't generally use it.  So what they've said, I believe, is that they're going to use XMPP as the protocol, which does support, can support encrypted communications.  And then they're going to have GPG or PGP baked into both the clients and the server so that it uses it by default.



STEVE:  XMPP could support - I'm thinking OTP.  That's not what I mean.



LEO:  Perfect forward secrecy?



STEVE:  No.  There's the real-time...



LEO:  By the way, they say they want to implement that, as well.



STEVE:  Oh, yeah, they absolutely should.  OTR, Off The Record.



LEO:  Oh, yeah, OTR, yeah, yeah, yeah.



STEVE:  So XMPP, because it is real-time connection, could support Off The Record point-to-point encryption to get you to the server.  And then at that point you could use PGP there.  But then of course you've got to trust the server.



[Talking simultaneously]



LEO:  Well, I would hope they don't want to do that, yeah.



STEVE:  ...trust the client.



LEO:  I want Trust No One.



STEVE:  Yeah, exactly.



LEO:  Well, is that what Mailpile is?  Are you going to talk about Mailpile?



STEVE:  Not this week.  But Moxie Marlinspike, who really does know his security, did a posting where he was rather disappointed with this plan.  He didn't feature the idea that they were going to go a lot further, but he was responding to the idea of raising all this money to clean up the source code of something which never was secure.  I mean, Moxie was assuming that Ladar was only going to do what Lavabit did.  And so I created a bit.ly link called "lavanot," bit.ly/lavanot, all lowercase, if anyone's curious.  Because Moxie did do a nice job of breaking down why I was never impressed with Lavabit when I went to look, as soon as we heard that Edward Snowden had been using Lavabit, I ran over and looked.  And it was like, okay, well, this is nothing.



LEO:  Right.  You told me that.  I had subscribed for a year, and you said, well, sorry, Leo, but your money is wasted.



STEVE:  Yeah, yeah.



LEO:  But I used to use Hushmail in the day, which was Phil Zimmermann, PGP guy's PGP webmail.  Same thing; right?  Same problem.  I think.



STEVE:  Well, I don't know.  I mean, Moxie made a...



[Talking simultaneously]



LEO:  Well, go ahead.



STEVE:  Yeah, Moxie made a point of saying that webmail cannot be secure.  And that's not true.  I mean, with today's browsers, you really can have very good web browser-based client-side security that encrypts everything on its way to the server.  Now, the problem is the infrastructure.  Email itself resists encryption at every stage because, for example, it wants - it's inherently a store-and-forward system.  So you don't have a real-time point-to-point connection where, for example, you could use secure key negotiation to negotiate an ephemeral key on the fly, and then you both use that to exchange things.  I mean, all that technology exists.  But the problem is email bounces from one server to the next, sort of going towards its destination - excuse me.  Got a little bit of a tickle in my throat here toward the end of our podcast.  And so it's difficult - wow.  It's difficult to encrypt.  And it's resisting encryption.



LEO:  Right.  That's the point.  And that's why they want to write a replacement for SMTP that would by default, in fact, require point-to-point encryption.  SMTP can do it, but very rarely do people do that.



STEVE:  Yeah.  I don't know.



LEO:  Now, I remember.  With Hushmail they were clear about that.  They said, if you mail something from Hushmail to somebody else, all bets are off.  But if you email somebody within the Hushmail system...



STEVE:  Ah, within the system, yes.



LEO:  ...you're okay.  So that was a good way to do it, I think.  And that was...



STEVE:  Yup, that absolutely makes sense.  And that was my problem with Lavasoft is the moment - I mean Lavabit, sorry.  The moment the email leaves and is connecting to another server, well, it's decrypted, and the NSA says thank you very much.  And this was, of course, the same thing with them sitting outside of Google when they were able to do that.  As long as something stayed at Google.  I remember we were talking about how Petraeus was clever.  He used a folder in Gmail to exchange information with his illicit lover.



LEO:  His girlfriend.  But that makes sense, and that would work had he not then given his keys, his password to somebody.



STEVE:  Yeah.



LEO:  But if you don't - but that would work; right?  That system would work.



STEVE:  Yes.



LEO:  And that's what I'm wondering, if Ladar - remember what Ladar told us on the interview on Triangulation, it was a couple of weeks back, and you should listen to it - I'm not talking to you, Steve, but everybody else should listen to it.  What he said was that the feds wanted the SSL keys, just as you had surmised, which meant that then all the mail would be readable, would be in the - they'd be able to look at it in the clear all the time.  And I presume that would also include mail stored in a drafts folder.



STEVE:  Yeah.  His mail at rest was encrypted.  And Moxie explains this.  When email came in, the system looked up the user's - the system only had the user's public key.  So it used the public key to irrevocably encrypt, or irreversibly encrypt the email, which then was stored on the server.  They then did not have the ability to decrypt it.  The problem is, when the user logged in with their plaintext password to Ladar's server, it then used that to decrypt the user's private key, which it then used to decrypt the stored email and send it to them in the clear.  So it really did nothing.  So it's like, okay.  I mean...



LEO:  Had nothing been sent, though, had it been stored in the drafts folder, it would be secure because it was encrypted, unless the FBI says to Ladar...



STEVE:  Correct.  It was encrypted at rest, yes.



LEO:  ...give me the keys.  And one presumes that's what they were asking for.



STEVE:  Well, and it's true that Ladar did not have the keys.  That was the key.  By using asymmetric encryption, he was able to encrypt securely.  He could not decrypt until the moment that the customer asked for his email.  And then he did decrypt it.



LEO:  So that's why they need the SSL keys, because he doesn't have the keys for the stuff saved there.  But if you have the SSL keys, can you then intercept the...



STEVE:  Well, all the mail coming and going, yes.



LEO:  But could you read the drafts folder, too?  I mean, doesn't that get fed into my browser?  Or maybe not.  I don't know.  I don't...



STEVE:  Well, okay.  But Ladar didn't have a web-based email system.  He had a regular...



LEO:  Oh, he didn't, oh.



STEVE:  No.  Yeah, it wasn't web-based.



LEO:  Then it's moot.



STEVE:  Exactly.  Your client connects to his server...



LEO:  Got it, got it, got it.



STEVE:  ...and off it goes, yeah.



LEO:  But it would be secure for Gmail to do that unless you gave them your password.



STEVE:  Yeah.  Yeah.



LEO:  I'm not seeing it completely academically, you understand.



STEVE:  Yes.  And Gmail supports secure SMTP and POP and client and web, I mean, Google really is coming up to speed and has been a leader in encrypting these things.  And I think now we have a sense for a snapshot into how they feel about the fact that their encryption has been so badly dinged.



LEO:  Yeah, yeah, oy.



STEVE:  And that's really all I have to talk about.



LEO:  [Laughing] Wait a minute.



STEVE:  I do have some more things, but we'll do it next week.



LEO:  We'll save those.



STEVE:  Yeah.



LEO:  We'll save those.  Very nice.  Come on.  "Ender's Game."  Just one little thing.



STEVE:  Loved it.



LEO:  Yeah.



STEVE:  Loved it.



LEO:  I think if you read the book you loved it no matter what.  Because it really was fairly true to the book, with one minor exception.  And...



STEVE:  The problem I had was that, as always, I mean, this is true of anyone who's read a book and then seen the movie, is the book was so much richer.



LEO:  Yeah, of course.



STEVE:  I mean, I almost felt...



LEO:  But it has to be.  It has hours.



STEVE:  I almost wondered why we were even introduced to Peter.  I mean, Peter played a...



LEO:  For the sequel.



STEVE:  Yeah, well, yeah, good point.  Peter played a significant role in the first book, and we had him in one scene where he was just mean.  And it was like, okay.



LEO:  No, but they kept referring back to that.  They said the reason Ender knows how to fight back is because he had a bully brother.



STEVE:  True.  And Peter was washed out of the program because...



LEO:  Too vicious; right.



STEVE:  Yes.  He was, well, he lacked the empathy which - and it was Ender's empathy which made him a better commander because how many times did we hear that, when you really, really know your enemy, then that is to love them.  So...



LEO:  Right.  That - I was glad that they made that the key thread through this.



STEVE:  Yes.



LEO:  Because it does become important in "Speaker for the Dead" and the subsequent novels.



STEVE:  Well, yes.  And I was surprised that the movie kept going.  It went past the end of the first book into the beginning of "Speaker for the Dead."  It was like, wow, okay.



[Speaking simultaneously]



LEO:  ...sequel, it was pretty obvious.



STEVE:  I think that's very clear.



LEO:  I wonder what people - I really wonder what people who didn't read the book made of it.



STEVE:  I wonder, too, because the other thing is, I mean, it was a large story to make into a movie.  For example, I was telling Jenny, who did not read the book, but she saw the movie with me...



LEO:  Did she enjoy it?



STEVE:  Oh, very much.



LEO:  Oh, good.



STEVE:  She loves these kinds of movies.  I'm just like, how did I find her?  So, like, I mean, there was all of this battle competition where they were in a cafeteria in my mind's eye from reading the book where, like, there was a huge scoreboard showing all of the different teams and their rankings and placement.



LEO:  And they showed it for a second.



STEVE:  It just, like, barely blinked on the screen.  It was like, oh.



LEO:  But those of us who had read the book knew what we were seeing.



STEVE:  Yes.  They lived and died by that.



LEO:  I think they only - they only had one or two battles in the simulator.  Whereas in the book there are quite a few, and there's a lot more military strategy and all, it's...



STEVE:  Yes.



LEO:  So read the book.  I've told you this all along.  And I cannot talk with you on the air without really spoiling things about the one difference...



STEVE:  No, we would never...



LEO:  There is a significant difference that I cannot understand why the filmmakers decided to do it this way because it frankly lessens the impact of the movie.  We'll save it for another day.



STEVE:  And I will also say, and you'll get a kick out of this because I was thinking - in thinking about this afterwards I noticed that the strategy, the physical strategy Ender used in one of those battles is exactly what he used at the end.



LEO:  And it was nice to see that visually, envisioned, because I of course listened to it, and we envisioned it.  But to see it, I thought that the - what did they call the battle, the simulation, the gravity-free simulation, the battle - anyway, to see that...



STEVE:  Oh, the Battle Room, the Battle Room.



LEO:  To see the Battle Room brought to life was really great.  Normally I'm not thrilled by visualizations of something that I've built in my brain.  But the Battle Room is kind of hard to visualize in your mind.



STEVE:  Exactly what I imagined.



LEO:  It was beautifully done.



STEVE:  Where they had things, you know, 'bergs floating around...



LEO:  Everything's done perfectly.



STEVE:  Yeah, yeah.  Oh, and visually, oh, Leo, the visuals were just spectacular.



LEO:  Yeah, I was curious.  See, Lisa and Michael and I saw it, and neither Michael nor Lisa had read the book, much to my chagrin.  But I think they enjoyed it.  Not as much as I think - if you've read the book, it's really worth seeing it, I think, yeah.



STEVE:  Yeah.



LEO:  All right.  We're done.  The Battle Room is nothing like the ball pit at McDonald's.  That's another pit entirely.  Thank you, @bookery [ph].  Steve Gibson, as Steven Tiberius Maury Gibson, is the man in charge at GRC.com.  That's his website for Gibson Research Corporation.  You can follow him @SGgrc on Twitter, where he often tweets valuable links, as you can hear.  You can also go to GRC.com to get 16Kb audio versions of this show for the bandwidth-impaired; full transcripts written by a human being, as well.  You can also at GRC.com get SpinRite.  You didn't mention SpinRite this week.



STEVE:  I did mention - nope.



LEO:  It is the world's finest hard drive maintenance and recovery utility, and you must have it if you have a hard drive.



STEVE:  Keeps the drives alive.



LEO:  Keeps the drives alive.  And lots of other great stuff.  His passwords there and all that stuff, lots of insight.  It's a really wonderful site just to get lost in, to wander around.  You have so many links now, it's so deep now, it's really fun to go:  GRC.com.  We do this show on Wednesday at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC.  If you want to watch live, please do.  We love having you in the chatroom watching live.  I love just knowing you're there.  But if you can't make it live, we always have audio and video on-demand versions, high-quality versions on our site, TWiT.tv/sn, and wherever finer podcasts are offered.  I don't call it a podcast, but you understand.  Thanks, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.   



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#430

DATE:		November 13, 2013

TITLE:		Listener Feedback #178  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-430.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  It's a Patch Tuesday.  Steve will have - or it was yesterday - has some information about that.  Plus your questions and Steve's answers.  We've got a lot of questions and answers to get through.  So stick around.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 430, recorded November 13th, 2013:  Your questions, Steve's answers, #178.



It's time for Security Now!, the show that covers your security and privacy online, with this guy, our Protector in Chief, Mr. Steven - I want to say "Tiberius," but now I know it's Maury, kind of takes the fun out of it.  Steven Maury Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you.



LEO:  I should check your Wikipedia.  Has it been corrected, or...



STEVE:  So, okay.  So I learned something last week.



LEO:  Uh-oh.



STEVE:  Everyone likes having a little snippet at the beginning of the show, talking about what we're going to talk about.  But it's really bad if we tell them what we're going to talk about...



LEO:  Uh-oh, and don't.



STEVE:  And then don't.



LEO:  Oh.



STEVE:  Because among the things that I said I would share, and I,  because it was sort of superfluous, I pushed it out toward the end, was my favorite iPhone 5 case that I found after truly getting them all.



LEO:  Yeah, forget all the security stuff, Steve.  What about iPhone 5 cases?



STEVE:  And my Twitter feed went nuts.



LEO:  Did it really?  Oh, come on.  Really?



STEVE:  With people, as they were, in fact, throughout the week, as they were listening to the podcast, saying hey, you never told us.  And it's like, oh, okay.  That's true.



LEO:  Okay.  Come on now, 20 people at most.



STEVE:  Okay, 20, yeah.



LEO:  You've got 70,000 people listening to you; 20 people cared.  Let's not go overboard here.  So what is, what is...



STEVE:  Enough to tweet.



LEO:  Enough to tweet.  What is your favorite?  Are you going to do it now, or you want to just tease us?



STEVE:  No.  Actually, at the top of the show - I'm not making that mistake again.  At the top of the show I'm going to cover all the things that I promised to cover at the end of the last show, before we start the new show.



LEO:  Okay.  But before we do...



STEVE:  So we're pulling up the tail end of last week.  Then we're going to plow in, talk about the week's news.  So we have all of last week's tidbits.  We've got a Patch Tuesday, the second Tuesday of November in this case.  We've got great Q&A, a bunch of Bitcoin happenings, and good stuff to talk about.  So, yes, a great podcast.



LEO:  Yeah.  And you will, in moments, learn what Steve's favorite iPhone case is.



STEVE:  Mm-hmm.



LEO:  Before you do, just what coffee are you drinking tonight?



STEVE:  That's just mine.  That's Starbucks Espresso that I grind and then drip brew.



LEO:  But which Starbucks?  Which one do you buy?  What's the flavor?  Do you get Caf Verona?  Do you get the...



STEVE:  No, no, no.  There is nothing for espresso except espresso.  It's just espresso.



LEO:  Oh, okay.  They don't have a fancy name for it.



STEVE:  No, espresso.



LEO:  Okay.  [Untranscribable].



STEVE:  And you're going to have it.  When I'm up there...



LEO:  I know, you're going to...



[Talking simultaneously]



STEVE:  ...I'm making you a cup.



LEO:  Steve Gibson, Leo Laporte.  You want to start with the case?



STEVE:  Yeah.  Because that's what we didn't...



LEO:  We didn't do.



STEVE:  We didn't wrap up last week.  I said nothing was going to keep me from telling everybody.



LEO:  Ah, we've got another commercial, Steve.  Oh, wait a minute.  There's a fire, oh, no.  All right, go ahead.  I won't stop you.



STEVE:  Okay.  So for me, the case is really important.  One of the things, the first thing I noticed about the iPhone 5 is it desperately wants to leap out of your hands and fall on the ground.



LEO:  And you're talking a 5s.



STEVE:  The 5s, yeah, which I bought.  And I, as I've mentioned, I switched over from a BlackBerry finally.  I had a neat, sort of a really high-endurance rubber case for the BlackBerry that I liked a lot.  And several times it did get out of my control and drop on the ground, and there was no harm done, thanks to having a case.  So there's just no way I'm not having a case.  I mean, the iPhone 5 is just beautiful by itself.  But it's just dying to break.  I mean, as we know, nature hates...



LEO:  A perfect device.



STEVE:  Exactly.  Sharp edges and...



LEO:  It abhors a perfect device.



STEVE:  It absolutely does.  It's always going towards entropy, and it wants to turn my beautiful iPhone 5 into something far more entropic than Apple originally designed it to be.



LEO:  That's a good point.



STEVE:  I mean, I'm nervous holding it because it just feels like it's going to, again, just it's slippery.  It's gorgeous, but it needs a case.  So I set off on the quest, as I do whenever there's a new device, for a case.  And  the only way to really figure it out is to try them.  So I truly have about 50 that I got of all different kinds.  And I have a big box of them.  And other people will get, like, after - the cases that I didn't like, if they want a case for their iPhone 5.  I took the box to Starbucks one morning because there were a bunch of people who had iPhone 5's with no case.  And even their phones were making me nervous, just like 10 feet away I was worried about their phone because it's like, oh, my god, look at that.  It's gorgeous, but it's trying not to be.  So I gave them, I said, here.  It's like, remember in the old days when you used to go to the dentist.  You could pick a toy out of the big...



LEO:  Yeah, the treasure chest, yeah.



STEVE:  The treasure chest, exactly.  So I said, here's cases I'm not using.  Which do you like best?  And so happily now everybody at Starbucks has their iPhone 5's covered in a case that I'm not using.



LEO:  That's funny.



STEVE:  Which they're quite happy with because they love the price, which of course was free.  For myself, I settled on the ultimate case.  After trying all the cases that Incipio, I-n-c-i-p-i-o, that's the company - and actually I really like their cases in general.  They've got, I mean, they go way overboard, though.  They've got some that, like, are rated to 30 meters below the waterline.  You can dive with it.  Or it can fall in the toilet when you're using your phone at the wrong time, whatever.  Those, however, you feel like you can't even reach your phone any longer.  It's a miracle that the touchscreen works through this thing because, I mean, it's like dragging a tank around with you.  So we don't want that.  Other bad cases are flimsy, or there's a new trend.  I like the feel of rubber.  I don't like the feel of that silicone.  It's just a little too greasy feeling.  Anyway, so the correct case is the Incipio DualPro.  They call it a DualPro because it's actually - it's two parts.  It's got an inner lining, which is very silicone-y/rubbery, and so you fit that around the phone first.



LEO:  I hope you got the pink one.



STEVE:  For Jenny.  Jenny got the two-tone pink, that one, the one that's on the screen right now.  That's the one I got for Jenny.



LEO:  And you got, I'm thinking, black and gray.



STEVE:  No, I got black and black.  They actually have black on black.



LEO:  Oh, pardon me.  I was a little too fancy.  I'm sorry.



STEVE:  Yeah, well, black and gray, somebody else got that, someone I - I don't think it was Mark.



LEO:  I like the black and red.  I'd get that one.  So the inner case has color, and then the outer case a shell.



STEVE:  Yes.  And so the advantage is, first of all, it doesn't have that slippery silicone-y feel, which isn't grippy enough.  You want something that's going to - just sort of wants to stay in your hand, rather than escape from your hand.  And so anyway, that's the one.  The inner lining gives it good shockproofness, and the outer lining makes it feel firmer than if the whole thing was just shockproof.  So that's the one, Incipio DualPro.  Oh, and on Amazon it's, like, $8.



LEO:  What?



STEVE:  $8.34 or something.  It's very...



LEO:  Oh, the list is 30, which is fairly reasonable for a case.



STEVE:  I know.  Yes.  And Amazon has it for 8 or 9, like less than 9, I think it's 8-something.



LEO:  Excellent.  All right.



STEVE:  So that's it.  Now, the other thing that happened that I had in my notes from last week is that I was recommending the Calomel add-on for Firefox because those guys were - did you find it there for, like...



LEO:  $8, $8.05.



STEVE:  Yup, that's a bargain, baby.



LEO:  Wow.  That is a good deal.



STEVE:  Grab it.  It's a great case.  That's my chosen case.  Although now I'm looking over here, and these people we were talking about before, those Tylt people, the T-y-l-t people, they've got some, too.  So it's like, oh, darn it, got to get one of those.



LEO:  See, this is an addiction that never ends.  You might as well - seems a shame.  You've got such a beautifully designed phone.  Jony Ive's just got to roll in his grave.  Even though he's not dead.



STEVE:  I know.  Except, I mean, and it is, it is - in fact, every time I was changing cases, there was a moment where nature was conspiring against me.  Am I going to drop this gorgeous piece of...



LEO:  You know, my kids never have used cases, and they drop them all the time, and they smash them all the time.  And I beg them, I plead with them, I yell at them, I say you must.  Daddy won't buy you another phone, you know, everything.  But they don't want - the kids don't want cases.  They want to show off, I guess, what they got.



STEVE:  It is gorgeous.



LEO:  They dress like that, too.



STEVE:  And by the way, you know that the least, the least popular color of the iPhone 5 turned out to be the gold.  It's like, almost no one wants the gold.



LEO:  Of course, that's what I bought, and everybody I know bought.



STEVE:  Sarah got one, I heard she was saying that.



LEO:  Yeah, I have gold.



STEVE:  And black, black is more than half.  The, what is it, then white is like a third, and then gold is the remainder.  So, yeah.



LEO:  I didn't realize it was so - huh.  It might be too ostentatious for some.



STEVE:  So the Calomel add-on for Firefox is cool because it shows you about perfect forward secrecy.  It also rates GRC's security as, like, awful.



LEO:  Who?  Who?



STEVE:  It's like, ouch.  So after I recommended it, people began sending me email and tweets saying, hey, why is GRC's security so crappy?  And it's like, okay.  Unfortunately, a company that's going to be making a big deal about security is all about finding something wrong.  Because if it just says everybody is wonderful, you're going to start saying, oh, well, okay, why am I running this?



So here's the problem, is it's caught us in this dilemma.  We've been in this dilemma for a while, where you had to choose between perfect forward secrecy or being immune to the BEAST attack.  And it used to be that SSL Labs - so, first of all, none of this is really about what's secure or not.  I mean, the fact that we're not offering, that GRC is currently not using preferentially a perfect forward secrecy cipher doesn't mean that our security is crappy.  It means, like, nobody else is, either, but we're not.  And arguably, okay, GRC should be.



Instead, we've been protecting people from the BEAST attack, which is also, like, dumb because you have to send millions of connections and variable-size packets and go through all this ridiculous stuff to create this theoretical BEAST problem.  SSL Labs used to be rating people who did not prevent the BEAST attack poorly.  So I put a BEAST attack mitigation at the top of GRC's cipher suite so that SSL Labs would give me an A, which we now have.  Unfortunately, Calomel gives me an "oh, my god, why are you even bothering" rating because they rate perfect forward secrecy higher.



So I'm unable to keep everybody happy, except that SSL Labs just changed their rating and decided, okay, BEAST is not a problem anymore because all the browsers support it.  And in fact, with Mavericks, the Safari browser was the last holdout where the browser wasn't handling BEAST attack mitigation on its own, which it is now.  So that allowed SSL Labs to change things around at their end and downplay the importance of BEAST.



So GRC now needs to, again, play this ridiculous shuffling game of cipher suites to put perfect forward secrecy ciphers, which are the ones that use ephemeral Diffie-Hellman key negotiation, at the top of its list.  So I'm going to do that.  Except that I hate rebooting my server because it takes GRC offline for several minutes because servers are now so slow to reboot that that annoys me.  And I haven't had to reboot since sometime in March.  So I'm reluctant to do that, but I will.



So that's the whole story, for anybody who's worrying about why GRC apparently has crappy security.  We don't.  It's just that the Calomel people are very unimpressed with the fact that we're not offering perfect forward secrecy, and we are offering BEAST attack mitigation, although now all the browsers are doing that for the user so the server doesn't have to.  So I'll get it changed.



LEO:  How hard is it to implement perfect forward secrecy?



STEVE:  Nothing.  It's just - you just change your cipher suite order around so that the server agrees to offer those at its preference.  And then the browser says, oh, look, they're offering this.  So we'll take that.



LEO:  Awesome.



STEVE:  Yeah.  Not hard at all.  Also I promised last week to talk about my feelings about the iPad Air.  I love it.  I absolutely do.  I think it is great.  The mini went on sale yesterday, and I tweeted that news to everybody, and a bunch of people who were following me didn't know that, and so they ordered their mini.  I ordered one because I need to see which I like best, the iPad Air or the mini.  They have the same resolution in terms of pixel count.  The mini is just obviously smaller and lighter.  So I just - there's no way to know in the Apple store.  You hold it, and it's like, oh, look how small this is.  But you have to use it for a while to get a sense for that.  So I will let people know.  It's like five to 10 days delivery they're quoting when I ordered it.  So we'll find out.



And last on my list, actually second to the last, is a couple weeks ago I mentioned SpinRite's real-time data viewport that allowed you to actually see the data on your drive.  And it was a cool way to determine whether the drive had been wiped because on a non-wiped drive, you'll actually see the data flashing by the window.  Many people commented that they had never realized that and liked that fact.



So I just wanted to follow up and mention that you can also, one of the features of SpinRite 6 is you can tell it at what percentage of the drive you want it to start, which allows you to use this viewport window, and that, to quickly check, like, the middle of the drive and toward the end of the drive, just to make sure that it all got scanned.  Because remember we were detecting lazy employees who were not scanning the whole - who were actually not scanning the drive at all, they were just eliminating the partition table and maybe the directory or something at the beginning of the drive.  They were doing some small little delete at the beginning which was not protecting their employer's data.  So you could interrupt SpinRite and then restart it at 50%, take a look, like look through the little window, the magic looking glass, to see what the drive looks like there.  Then interrupt it, go to 99.9, and look at the end of the drive just to see whether the whole thing was wiped out.  So a little usage tip for people who like that little viewport.



And finally, I also promised that I would give people an update on the SQRL project.  We're a week further along.  We're continuing to come along beautifully.  Pretty much everything has been agreed to in the group.  We wrapped up the questions of what we were going to do for v1.0 for phishing and man-in-the-middle attack mitigation.  The format of interchanging arguments back and forth has been arrived at.  And now I'm working on updating GRC's web pages to be current to what has been agreed.  We only then need to resolve the detailed interaction protocol, and then it's time to start writing code.



There is a wiki which is up that is being independently maintained by a bunch of the guys who are participating in the newsgroup, but also sort of doing sort of a more formal-style specification than I am.  I'm sort of more tutorial and more graphics and sort of expository approach to this is how it works and what it does.  So we are continuing.  It's got my fulltime attention.  We're working to just nail down the final aspects of the specification, and then I and everybody else who wants to do their own versions will be writing code to support this logon system.  And everyone is quite excited about it.



LEO:  That's neat.



STEVE:  And I had in my notes something that I didn't get to last week because it was also sort of at the end.  And I wanted to thank our listeners on Jenny's behalf because apparently they were just wonderful with, like, following up on the news of the book that she had published.  Remember that she had a book published, actually, and I talked about it when you were on vacation, Leo, titled "Is God Real or Pretend?"  And one of our listeners - she got a bunch of email from listeners mentioning the fact that they were listeners.  And I guess she has her email address, like, at the end of the book.  And so they were writing to her.  And she asked if they would be so kind as to post those as feedback on Amazon.



And so one of them I just wanted to share from a listener because it was so neat.  Someone, whoever you are, said - their title was "No wonder this is a bestseller."  This was dated October 23rd.  And they wrote, "'Is God Real or Pretend?' is such a brilliant concept to begin with, and so smartly executed.  To have a young boy searching for the answer to this age-old question with members of his own family having vastly different opinions is a fantastic premise.  On top of that, Ms. Horsman has written a book for everyone that she so cleverly camouflaged as a children's book," our listener of Security Now! said, "I learned several things I never knew before.  I've never read a children's book that deals with such an incredibly heavy topic, let alone written in such an easy-to-understand style, with commonsense conclusions."  And this reviewer goes on.



But anyway, I just wanted to thank our listeners on Jenny's behalf for being so neat about that.  I really appreciated it, and she did too.  News, my friend?  You ready for some news?



LEO:  Yeah, why don't we - I detected the pause.  And I think this might be a good time.  We have questions.



STEVE:  We do.



LEO:  We've got news.  Why don't we, yeah, let's do the news.  I have two more commercials.  I have an Audible and a proXPN.  So I think after the news we'll do the Audible.  How about that?



STEVE:  Okay.



LEO:  All right?



STEVE:  Okay.  So this is important.  I tweeted this a couple days ago.  This is a growing problem that Microsoft did not deal with yesterday in their second Tuesday of the month, Patch Tuesday.  And that's this tagged image file format zero-day flaw which is ramping up rapidly in the level of exploitation.  I wasn't aware, but you were, Leo, and many of our listeners were, that the TIFF file format is in such heavy use now.  I'm just sort of seeing, I guess, GIF and JPEG, or GIF, depending on how you pronounce it, and PNG file formats.  But obviously TIFF is still very popular.



Writing for Information Week, Mathew Schwartz said:  "Warning:  Attacks against a zero-day vulnerability in Microsoft Office are more extensive than first believed.  That finding further reinforces security experts' recommendation that businesses install an emergency mitigation technique released by Microsoft as quickly as possible."  We did talk about it last week.  I wanted to remind people that I created a bit.ly link, bit.ly/notiff.  That will take you to the Microsoft page where there is one of their little, quick, one-click Fixit buttons, which simply adds a line to the registry, making it very easy for anyone to do.  And that line disables the TIFF format codec.



So what's happening is we didn't get a fix yesterday for that.  We did get a different IE zero-day fix that I'll talk about in a second.  But this one is still a problem.  So if you're not a person who is using TIFF format images, it's probably a good idea, there's really no reason not to disable it.  When Microsoft does their patch, they will remove this temporary fix from the registry and fix the problem.  And I'm sure we'll get that in December's Patch Tuesday, if not before.  I mean, they may do an out-of-cycle update because this thing is really causing problems and is ramping up.  So that could certainly happen.



But for now I wanted to tell people that the security community is getting more and more concerned about this because we're seeing the incidences of this happening.  And it is trivial to exploit.  That's the problem.  All you have to do is get an image to be seen.  So email with a TIFF image embedded in it; Office documents with a TIFF image.  I'm not sure about drive-by IE.  But people are just being too vulnerable to this.  So disabling that would be a good thing.



And we are second Tuesday of the month.  We got eight patches from Microsoft addressing 19 vulnerabilities.  Thirteen of those 19 were the worst kind, remote code execution, high priority, no action required on the part of the user.  So it would be a good idea to update yourself.  One of these things was something we haven't seen for a long time.  That was a WordPad exploit.  It was in the GDI, the Graphics Device Interface layer, which unfortunately Microsoft, as we've talked about before, moved down into the Windows kernel for the sake of efficiency, but which makes it much more prone to exploitation.



So you want to just - essentially, this is not a big set of patches, but they are important.  And one for IE addresses a brand new zero-day flaw which was just disclosed, but yesterday the exploit details appeared on Pastebin.  So the fact that the exploit itself is public worries people a lot more, and they're expecting to see this also ramp up very quickly.  So the advice in the security community is do not delay on implementing these any more than you have to.  And Microsoft is now prioritizing these, and the IE patch is among the top three highest priority recommendations because it's expected to be seen in high exploitation soon.



We got also a Flash Player update from Adobe.  We're now at 11.9.900.152.  IE10 and 11 on Windows 8 will update automatically.  We know that Chrome updates automatically.  To check whether you're updated you want to go to Adobe.com/software/flash/about.  In Firefox it showed me that I was not at .152.  I was at .11 something.  So I will need to get myself updated.  And people who are not protecting themselves, the only reason Flash ran for me, because I'm running NoScript, is that I'd already trusted the Adobe.com site to run things in it, so it did.  People who are protected by NoScript really don't - they have less to worry about.



Bitcoin.  Gosh, lots of news.  Have you seen the value of a bitcoin, Leo?



LEO:  Last I checked it was 260 bucks.  What's it now?



STEVE:  Seven...



LEO:  What?



STEVE:  I'm sorry, not seven, 417.  But I just...



LEO:  Oh, I see 429 was a high.



STEVE:  Yes, 428 was when I looked.



LEO:  Holy cow.  What is going on?



STEVE:  It's not clear what's going on.  It was 350 on Friday.  Now we're at 428, 429.  It's really cranking along.



LEO:  I've got to look in my wallet.  You've got 50?



STEVE:  My 50 bitcoins are worth something now.



LEO:  But like any investment, the timing's everything.  Do you sell now and watch it go up, or do you...



STEVE:  Well, that's just it.  It's always worth noting.  I think some - maybe someone - I think somebody quoted Kevin as saying, you know, our Kevin, as saying that he was selling at 350.  I think that might have been what it was.  And of course now we're at 429.



LEO:  We have a bitcoin donate box, as you know, on the front page.  And I haven't checked in a while.  My balance is now 7.3 bitcoins.  So I'm rich.  I'm sorry.  Wow, that's crazy.  Of course now that I'm off the meth, I don't really - and Silk Road, you know, is closed, I don't really have anything to do with them, but...



STEVE:  Yeah.



LEO:  I guess you could buy cupcakes in San Francisco with bitcoin, so that's a lot of cupcakes.



STEVE:  Or you can use them to donate.  The EFF takes them again.



LEO:  That's right, that's right.



STEVE:  So that's a nice thing.



LEO:  I already give, I can't remember what it is, a couple hundred bucks a month to EFF, so...



STEVE:  Here's the problem.



LEO:  In real American dollar.



STEVE:  Bitcoins have become money, and people are having a hard time holding onto them online.  There was a major breach last week, $1.2 million, which is now 1.5.  So they didn't denominate it in bitcoins at the time.  It was 4,100 bitcoins.  And this was an online exchange called Input.io.  Now, the problem is we know that it's difficult.  I mean, security is hard.  That's the overriding topic of this podcast.  Now you've got the typical problems, I mean, we had a lot of fun at Adobe's expense last week.  And, I mean, they deserved it because their password technology was so lame.  I mean, it was so badly broken.  But this is Adobe.  So here we've got some random Input.io bitcoin exchange.  Who knows who they are, what their security policies are, how good their backend stuff is.  Well, apparently it wasn't good enough because they lost 4,100 of their customers' bitcoins.



LEO:  Whoops.



STEVE:  Whoops, yes.  And the guy said, I'm sorry, but I don't have that many bitcoins.  I will do what I can to make the best of this.  I've got 1,540, and I'm willing to pay my customers back, what, a quarter or so.



LEO:  Wow.



STEVE:  But that's all they could do.  So then a frequent tweeter friend of the show, Ian Beckett, sent me a note about [a news item from] PandoDaily.  [GBL] is a fraudulent bitcoin exchange, a Chinese bitcoin exchange who cost clients - and this was, again, this is not in bitcoins, but this was in dollars.  At the time, this was I think yesterday, or maybe the day before, might have been Monday, $4.1 million in fraud.  So this was a fraudulent exchange that set up shop, said, hey, we're a bitcoin exchange, put your bitcoins here.  And at the time that they had $4.1 million worth of them, they just went off the 'Net.  They said thank you very much, and they disappeared.



LEO:  It's like a honeypot, really.



STEVE:  So the lesson, yes, the lesson is do, I mean, everybody, store your own bitcoins in a machine, preferably not one on the 'Net.  I mean, this is real money now.  This is becoming serious.  So you do not want your wallet, I mean, there are, like, online wallets.  Bad idea.  Do not trust an online company with your wallet.  Unless your mother is a security genius, and you would trust your mother with your money.  But you're just not - you don't want to trust some, I mean, this is real money.  It's one thing to lose your identity.  It's another thing to lose, you know, what are my 50 bitcoins worth now at $430.  That's serious coinage.



LEO:  Yeah.  Wow.



STEVE:  So, yeah.  I would say to everybody it's becoming serious when bitcoins are worth real money.



We had some humor from the Twitterverse that I wanted to share.  A Kevin Meagher, M-e-a-g-h-e-r, tweeting as TheKevinMarr, M-a-r-r, he said, referring to last week's Adobe password fiasco, he said:  Steve, you have answered the age-old question:  Ginger or Mary Ann?



LEO:  Okay.



STEVE:  And you have to be of a certain age to understand the reference to the question.



LEO:  We're talking the two comely women on "Gilligan's Island."



STEVE:  "Gilligan's Island," yes.



LEO:  One who was a movie star, the other who was a country girl.



STEVE:  Yup, Ginger or Mary Ann.



LEO:  And Ginger is the movie star, Mary Ann the country girl.



STEVE:  So Kevin noted that Ginger made it onto the list.  Ginger was 94, and Mary Ann was nowhere to be found.



LEO:  Just like in the show's opening theme.  "The movie star, the professor, and Mary Ann."  They had to add that later.  It used to be "and the rest."



STEVE:  So, and our frequent contributor, this is not related to the podcast, but Simon...



LEO:  These are in passwords?  People were using Ginger and Mary Ann in passwords?  Or was it Ginger and not Mary Ann?



STEVE:  Yeah, Ginger was a password.  Yes.  Ginger made it.  She was 94.  Not as popular as Monkey, so...



LEO:  I'm thinking Ginger is somebody's dog's name, and that's why it's so popular.



STEVE:  That's probably it.



LEO:  Sounds like a dog's name, doesn't it?



STEVE:  If you name your dog Monkey, there's probably something wrong with you.



LEO:  And not many people have dogs named Mary Ann.  Ginger, though.



STEVE:  Ginger is probably a more popular dog name, yeah.  So Simon Zerafa, just out of nowhere, I don't know where he comes up with this stuff, he said @SGgrc, so he mentioned me in his feed, he said, "As a child, I was obsessed with the difference between sine and cosine.  As I got older..."



LEO:  That's one weird kid.



STEVE:  Yeah.  He says, "As I got older, I realized it was just a phase."  So...



LEO:  John didn't like that joke.



STEVE:  And I always have...



LEO:  Geometry humor, there's nothing like it.  Trigonometry.



STEVE:  Yeah.  Well, and then I told him, I said, "I think I'm going to use it on the show, Simon."  And he says, "Well, just don't go off on a tangent."



LEO:  Oh.  Oooh.



STEVE:  Ba-doom-boom.



LEO:  Ba-dum-bum.



STEVE:  Yeah.  So I did get, and I haven't shared with listeners for a quite a while, a testimonial.  This was a good one that I thought was interesting, and there's a moral to the story also.  This is from a listener of ours, Tyson in Texas.  I ran across it this morning dated the 9th of November, so it was last Saturday.  And the subject was "SpinRite saves the year."  And I don't quite understand the subject line, but he wanted to get my attention, and he did.



He said, "Hi, Steve.  I just wanted to share with you an interesting little SpinRite story of mine.  I purchased a copy of SpinRite a few years ago after hearing you talk about it in an early episode of Security Now! and have used it many times since to bring failing hard drives back to life.  On one occasion, a friend brought his laptop to me, saying that it would no longer boot into Windows.  In fact, it simply said 'No bootable device.'  He said that this was his work laptop, which contained all his documents and files pertaining to his business.  I asked him if he had a backup of these files somewhere else, and he said that he did not.  Oops.



"Of course I knew immediately that I was going to run SpinRite on the drive, but wanted to first back up any files that I could access in case the drive was so far gone that the very act of running SpinRite might push it over the edge, and it would be gone forever.  The drive did appear in the BIOS, so I booted the laptop using a Windows recovery CD and tried accessing the drive through a command prompt to see if I could at least verify that his files were still intact.  But the drive was nowhere to be found.  I tried again using a bootable Linux CD.  No hard drive found.  I then removed the drive from his laptop and attached it as a slave to my desktop PC.  Windows would not even acknowledge that the drive existed.



"Finally, I loaded up SpinRite.  It saw the drive and began running very, very slowly.  After several hours, SpinRite had not even completed 1% of the drive, but the bits were still churning away, so I knew it must be doing something.  I told my friend that the only option I could see at this point, having tried everything else, were to either give SpinRite all the time it needed to attempt recovery, or say goodbye to his files forever, for which there was no backup.  He agreed to let me keep his laptop until SpinRite either completed the process or got stuck trying.



"We set the laptop aside in the corner" - oh, and so he put the drive back in his laptop and then restarted SpinRite on his laptop.  He didn't specifically say that, but that must have been what happened, letting it just run in the corner of the room - "and left it to run overnight.  When I came in the next morning, to my surprise, SpinRite was still running and had now completed about 2% of the drive.  Nevertheless, the status showed that the bits of the data were still being read, so I continued to let it run, day after day after day.  After about two full weeks of continuous operation, SpinRite had churned through about 50% of the drive and showed a TON [he has in all caps] of red, unrecovered sectors.  With nothing to lose, I continued to let SpinRite run, glancing over its progress every day or two.



"Finally one day I walked over to the laptop and saw SpinRite had actually completed.  The process had taken just over one month.  I restarted the computer and held my breath.  To my amazement, it booted straight into Windows without ANY [he has in all caps] trouble, and ALL [in all caps] of my friend's business documents were present and undamaged.  I quickly backed everything up to a flash drive and then burned a second backup to a CD.  I advised my friend to buy a new hard drive since this one was bound to give out at any moment, and also suggested that he start making backups of everything from now on.



"After this experience, Steve, more than ever, I am a true believer in SpinRite.  It may have taken over 800 hours of continuous operation, but it COMPLETELY [he has in all caps] recovered a hard drive that appeared to be totally dead and hopeless.  Not only did it recover the important documents, but even allowed the system to boot as if nothing had ever gone wrong in the first place.  Thank you for this amazing program.  I'll be buying your new upcoming version of SpinRite as soon as it's available."  Actually, it's going to be free for him since the next version will be a free upgrade for everyone.  And he signed it "Tyson from Texas."



So I just wanted to say to people that that kind of lengthy recovery is very unusual.  Typically it's a few hours, not hundreds.  And the other thing is, I mean, this is an instance where the first thing I think of is, oh, my goodness, if this person had only been running SpinRite from time to time, this level of catastrophic damage would have never had a chance to accumulate.  A laptop is a rough environment for a hard drive.  It's just inherently getting bounced around.  And if there were this kind of damage spread across the entire drive, again, running SpinRite every, like, every quarter, every three months, would only take an hour or two and fix problems before they have a chance to get this advanced.  It is the case that if it is in this horrible condition, and you've got time, SpinRite will typically repair it, as Tyson found out.  But, boy, preventative maintenance, especially for a laptop, really does make sense.  And here's another instance of SpinRite doing the job.



LEO:  To the rescue.  We have questions; you have answers.



STEVE:  Two things.  Somebody tweeted while you were doing the Audible sponsorship.  They were asking, with all of these bad bitcoin exchanges out there, what do I - are there any good ones that I would recommend?  And the advice is to use the exchange for exchanging between bitcoins and currency, but do not use it to store your bitcoins.  That is, pull them out and essentially take them offline because you really need virtual currency to be kept somewhere under your control, and preferably in a machine that's not even on the Internet because, as we all know, malware, I mean, there's no question that malware will start looking around in machines for bitcoins.



LEO:  For bitcoins.



STEVE:  That's just too valuable.



LEO:  And all they need - what do they need if they wanted to steal my bitcoins?  How would they steal my bitcoins?  They steal the file?  Because there are certain files associated with my wallet.



STEVE:  Yeah, and the wallet is encrypted, and so, yeah.  If you have a good password, that's the other thing you want is you want a very, very strong password.  We've got a great question we're going to get to.  Remember I mentioned last week that I was tempted to call the episode "256 Bits Is the New Black."  That's another thing we didn't get to, but I used the question in today's Q&A.  So we'll be talking about why 256 bits is enough bits because bitcoin, a user's bitcoin address, essentially, is 256 bits.  That's also the BitTorrent sync address, and it's also the strength of the master key in SQRL.  So I've looked at 256 bits and what that means extensively.  And we're going to once and for all put that one to rest.



But I also wanted to mention, and I forgot, a really interesting report that was just published, it was actually on the blog of the Backblaze people.  Backblaze is a major - and you may want to click on that link in the show notes, Leo, if you can, and bring up - they've got some great charts, really interesting analysis.  Backblaze is a major cloud storage provider.  They're unlimited cloud storage.  They've been, over the course of several years, they've put 25,000 drives online, which they now have spinning, so they've been able to acquire a really good, evolving set of statistics, very much the way Google has with Google's big indexing project, of the life of drives.



And what they found, they've got some - there's a really cool graphic that shows sort of like three stages:  Year 1, Year 2, and Year 3.  And what they've determined is that 80% of drives last four years.  Which is to say that 20% of drives will die during the first four years of life, and 50% of drives die by year six, is the other thing that they have found.  And there's an interesting - they also graph over the first three years.  By the way, the link is long.  If you went to blog.backblaze.com I'm sure you could find it because it was 11/12 [2013] is the date of their blog.  Yeah, there's a neat chart there that you have on the screen now showing the nature of infant mortality where drives die frequently when they're new, but then they sort of burn in, and their death rate drops.  And then, as they get older, their death rate goes up again.



[blog.backblaze.com/2013/11/12/how-long-do-disk-drives-last]



LEO:  This matches pretty closely Google's results on its longitudinal drive study.



STEVE:  Yes, yes.  And that other - the chart that I really like shows the three years - Year 1, Year 2, Year 3 - where in the beginning of Year 3 the rate of death begins to go up again.  Drives begin dying.  But I did think it was also interesting that 50% of drives die by year six.  And again, I would love to take SpinRite into their facility and get some sense for the nature of drive death, what do they mean by that, because we do know that preventative maintenance performed on drives is fabulously successful.  I've got, you know, obviously I've been selling SpinRite now for more than 20 years.  And there are people where, very much like people who take Vitamin D and they no longer get sick, although everybody around them is sick, there are people who are using SpinRite on their drives, and theirs never die.  Whereas they're, like, fixing other people's drives all the time because they're not running SpinRite.  So it really is effective preventative maintenance.



LEO:  Yeah, but you've got to figure a company like Backblaze, it's not worth their time or the risk of trying to recover drives.  If a drive...



STEVE:  Exactly.



LEO:  And that's why these numbers are skewed a little bit by their lack of tolerance for any failure.  Any error at all, they're going to throw it out.



STEVE:  They yank it out and slide a new one in.



LEO:  I'm sure Google does the same thing.



STEVE:  Yep.



LEO:  Google's results very, very, very similar, if you look at their annualized failure rates, broken down by age groups.  They maybe say it starts dying a little sooner.  It sounds like Backblaze says four years.  Google says that the drive failure rates start to go up pretty rapidly after two years or three years.



STEVE:  And you know, Leo, I'll bet that the reason is Google probably works the heck out of their drives.



LEO:  Oh, yeah.  They're on fulltime, yeah.



STEVE:  Yes.  So a big, well, a global indexing system is probably thrashing its drives; whereas a cloud storage facility, the drives are probably just spinning, but not moving fast.



LEO:  Unused, yeah.



STEVE:  Yes.



LEO:  That's a good point, yeah.  Although Google does correlate utilization rate with failure rate.  So there's some interesting stuff.  Both of those are really worth reading.  I'll leave it to you to summarize what they mean.  I'm not sure.  Do you have a favorite drive manufacturer?



STEVE:  You know, they keep getting bought.  I loved Maxtor.  I loved Quantum.  They're both gone.



LEO:  It's basically Western Digital, Hitachi, and Seagate.  Those are the three companies now.



STEVE:  Yes, yes.  And Hitachi bought IBM.  IBM had really good drives.  I think Hitachi's very good.  I have an anti-Western Digital bias that I cannot justify, and it's not fair.



LEO:  You're not alone, by the way.  A lot of people share that.



STEVE:  Yeah.  I think they're the most consumer - I don't know.  I just - I don't use Western Digital.  I buy Seagate or Hitachi.  But I don't think that's fair.  I mean, it's not - I know I will hear from people saying I've never had a Western Digital...



LEO:  Each of them have problems.  Western Digital had some really bad BIOSes for a while that were a real problem.  And I think that soured a lot of people on Western Digital.



STEVE:  Yes.  And there have been, you know, all of them go through phases where they've got, like, some process problems, or they'll have like a batch of bad ones that hurt people.



LEO:  I think it's a commodity at this point.



STEVE:  "Commodity" was the word I was looking for.



LEO:  Yeah.  I think that there's not much - they're like pork bellies.  One's pretty much like the other.



STEVE:  Yeah.



LEO:  I have questions. 



STEVE:  Yay.



LEO:  Do you have answers?  Let's find out.



STEVE:  We do.



LEO:  Mr. Steve Tiberius Gibson.  By the way, they took that out of your Wikipedia entry.  Now it just says Steve Maury Gibson.



STEVE:  That's probably good.



LEO:  Hey, did Tiberius show up in that list of passwords?  Probably not.



STEVE:  But I wouldn't use it.



LEO:  Not for you.



STEVE:  What that shows us is you have to get a random source.  I use the junk that LastPass generates.



LEO:  Yep.  It's so good.



STEVE:  But all of my WiFi passwords I got from GRC.  I just copied a string off of passwords.htm at GRC, and that's what I use because nobody is ever going to reproduce that.  Nobody.  It's impossible.



LEO:  I use very weak WiFi passwords.



STEVE:  It is a pain the ass, though, setting up a new machine.



LEO:  Yeah.  I use really weak, really weak passwords.  They're not monkey123, but I use weak passwords on my WiFi because nobody - how are you going to attack that?  You have to be in physical proximity.  I'll see him sitting on the curb going let's try this, let's try this.



STEVE:  Well, yeah, but for me, I can't let anybody into my network.



LEO:  No, you're different.



STEVE:  Yeah.



LEO:  Bob Hart, Medford, Oregon, writes:  Hi, Steve.  You always provide an entertaining and informative show, and last week's was great as always but left me with a question.  So now I know that Adobe's poorly encrypted password database and source code was compromised, but the encryption key that they used is still secret.  I can see that a string of encrypted data was the same in a lot of cases, but how do we know that "Monkey" corresponded to that string without encrypting it using Adobe's encryption key?  I must have missed something.  Clarification would be nice.  And thanks for SpinRite for keeping my disks healthy.



STEVE:  Okay.  So we do not know that "Monkey" relates to the encrypted string because, as Bob comments, we do not know what the key is, and we probably never will.  We have to assume that Adobe chose a really good random number just one time, and that's the static key for their crypto.  We know that there's only one key because we can see the correspondence between people's encrypted version and their hints because the hints were not encrypted.  They're in the clear.  Which is dumb, really, because obviously Adobe, since it's reversible encryption, Adobe could have encrypted the hint and then decrypted the hint when it was necessary to provide it to the user.  But, I mean, there's no understanding what Adobe was thinking when they created this.



So the way we know that it is symmetric cipher is the hints correspond to the same cipher text.  The reason we will never know what the key is, although, wow, we would love to because there's lots of hints that are not clear or blank hints, and if we knew what the key was, we would instantly have every single password, even the really strong ones.  Remember, the only passwords that we have are the ones that were so weak that they were used so often that we could then jump across and use the hints that people used to link all of them together.



So the reason we will never know what the key is is that, if our assumption is correct, that it's 3DES, and that's a reasonable assumption, the block length being 64 bits is the giveaway because DES is a 64-bit block, they couldn't have used a single DES.  That would be crazy.  That would just be a 56-bit key because that's the key length of the 56-bit block encryption DES.  Probably they used 3DES.  So that's three 56-bit keys, one of those 56-bit keys for each round, each usage of or application of DES in turn.  So that's 168 bits.  That's a lot.



We'll be talking in a little bit here in a minute about 256 bits and how big that is.  But 128, it might as well be - it's out of reach.  Remember that AES itself, the AES cipher that was recently standardized on is often used with a 128-bit key.  So that is regarded as as strong as we need.  So 128 bits is already beyond cracking.  168 bits is 40 more than 128.  40 more means 2^40 stronger.  Well, 2^40 is about 10^12.  So that's a million million times stronger.  So 168 bits, which is what Adobe's probably using, if they use 3DES, is a million million times stronger than 128 bits.  And that's already strong enough for SSL and for, like, all the things that we're currently protecting with the Rijndael AES cipher.



So we're never going to know, unless Adobe leaks it, or it was in their source code or something, we're never going to know what the key is.  So for really, really strong passwords, we have no clue.  But for the weak ones, since so many people reuse the same password...



LEO:  Well, and their password hints gave it away.  This is where the failure was.  The password hints were in the clear.  And it turns out, apparently, there's a misunderstanding about a password hint, a widespread misunderstanding that the password hint perhaps should contain the password [laughter].



STEVE:  Or the hint should not be "Rhymes with assword."  That's a bad hint.



LEO:  But so many of them said "The password is...."



STEVE:  Yeah.  And apparently this was not a high-value account, by the way.



LEO:  Well, somebody pointed that out.  A lot of people said you had to make an account if you wanted to download trial ware.  So people didn't care.



STEVE:  How dumb.



LEO:  Yeah.



STEVE:  Yes.



LEO:  So we don't know, out of the, what was it, 130 million accounts that were leaked out, how many of those were high value.  My account was because I had a credit card associated with it because I bought stuff from it.  But I used a strong password, so...



STEVE:  The problem is that what the guys were getting was your email address and often a password because somebody else was leaking your password by virtue of their bad hint on the same encryption.  Then people - in fact, Facebook did this.  I never had a chance, I saw this pass by, but I didn't have a chance to track it down.  As I understand it, Facebook was looking at that repository, seeing whether they had the same email address as somebody whose password was leaked, and then telling you you had to change your password or something.  I didn't - did you follow that, or see what that was, Leo, that Facebook did?



LEO:  No, but that's clever.  I didn't know that they had done that.



STEVE:  I thought that was very proactive of them.



LEO:  Yeah.  Go out and look and see if an email address is the same as a member's email address; and, if it is, send them a note saying you might as well change your password.  They didn't do it to me, but - hey, by the way, I did get an email from Joe Siegrist at LastPass.  Because remember last week we gave out the very nice feature that LastPass did at LastPass.com/adobe, where you could search the database.  But what Joe did that maybe he didn't, you know, wasn't thinking about it, was it would then, if you were found in the database, send you an email at that address.  Well, of course any email address could arbitrarily be entered into that search, and mine was, by many others.  So I got a lot of emails.



STEVE:  To see whether your email address was part of the database.



LEO:  Right.  People were checking my email address, probably, you know.  So Joe said, "Just wanted to apologize we hit you with spam.  It won't happen again.  Love the show, guys.  It was a good one yesterday, and thanks for the continued support."  So thank you, Joe.  That's - yeah.  And you know me, I love LastPass.  There's no worry about that.



STEVE:  And I'll mention, Leo, that I had a lot of feedback saying that they really liked last week's podcast.  Last week's was one of those, just so much news to talk about, where we went, did a lot of depth on a lot of topics.  And when we do that, it's the time I see the most positive feedback.



LEO:  Oh, sure.  We have a lot of geeks in the audience who want to know, and they care, yeah.



STEVE:  Well, we got one now.



LEO:  Here's your geek.  Are you ready?  From Twitter, Wayne T. Taylor.  He's a 140-character geek.



STEVE:  Whoops.



LEO:  Is that wrong?  Did I skip one?



STEVE:  Yup.



LEO:  Well, let's not skip two.  That was Question 1.  Bob Arles, @metaRobert on Twitter.  @SGgrc:  BitTorrent Sync - I love it.  They have to do this in such cryptic form.  BitTorrent Sync problem?  If I start guessing secret keys, am I not effectively trying it against all clients with each try?  Yes, you are, of course.  Yes.



STEVE:  Yes.  Now, this is where I wanted to talk about 256 bits.  It unnerves people, the idea that BitTorrent Sync has for your address a randomly chosen 256-bit token, and that's your identity.  That's what I'm using, as I mentioned before, for the user's identity on SQRL, my proposed login replacement.  That's what Bitcoin uses as your identifier for Bitcoin.  That's your unique thing.  And so people say, yeah, but what if there's a collision?  What if I get the same one?  Then I'm going to have access to all of those files of the other person who has the same one.  And it's like, okay.



So that's true, first of all, absolutely true.  If two people share the same, exactly the same, not one single bit different, exactly the same 256 bits, then for all intents and purposes, for BitTorrent Sync, for Bitcoin and for SQRL and anything else using 256 bits, you're the same person.  There's a collision.  So this is the so-called "birthday attack."  The point of a birthday attack is it asks the question, in a population of people having some number of possibilities, what's the chance, the probability that any two of them share the same birthday?  If we're in the case of birthdays, with 365 days in the year, what's the chance of a birthday collision?  In the larger case, in the case we're discussing with 256 bits, that's a lot.  There's a lot of possibilities.  So the question is, what's the chance of a collision?  And I want to, for all time, we're now going to coin some standards here so that we put this issue to rest.



Okay.  So there is a - the actual math, the statistics, is amazingly complex.  Wolfram has a page with equations you can't even believe that, like, works to explain, to give you an exact value for this.  But a useful approximation of the probability of a collision is n^2, "n" where that's the number of people, the number of accounts, the number of - like the number of people in the pool.  So that number squared over 2 to the number of bits plus one.  So like 256 bits plus one, 257.  So the number of people squared, divided by 2^257, would apply.  And this is true so long as the number of people in the pool, the number that we're checking for collision, is very much smaller than 2 raised to the power of half the number of bits, or 2^128.  Well, since 2^128 is really, another one of these really huge powers, yes, "n" for reasonable numbers, like a billion people or seven billion people on the planet, for example, very much smaller.  So that inequality is satisfied easily.



Okay.  So plugging this in, plugging these numbers into this equation for a population of a billion users.  So we have a billion BitTorrent Sync users - obviously we're never going to have that many.  But say, just for the sake of argument, a billion.  Or a billion bitcoin users, one tenth the population of the planet are using bitcoin.  Or a billion SQRL login users.  A reasonable number.  Okay.  A billion.  The chance of a collision is one in 4.3 times 10^60.  One in 4.3 times 10^60.



Now, the problem, okay, that's a very big number.  Very, very low probability of collision.  But not zero.  Okay.  Well, so we need to get - I want to develop a sense of scale for how small the chances are and how much concern we should give this.  Okay.  So let's compare this to something that we can get behind.  And that is an extinction-level event caused by a major meteor strike on the Earth.



LEO:  Okay.



STEVE:  Okay?



LEO:  Yeah.



STEVE:  One of those, an ELE, an ELE, an Extinction-Level Event, is estimated to occur, on average, about once every 30 million years.  Okay, so that's how often it's going to happen, once every 30 million years.  Now, what that means is the chance of it happening within the next second, okay, there went one.  Whoa.  There went another one.  Oh.  There went a third.  Okay.  The chance of it happening, of an extinction-level event, of this question no longer being relevant to us because we're all gone.



LEO:  Or the weather's really crappy, yeah.



STEVE:  One in 10^15.



LEO:  Okay.



STEVE:  One every second.  One in 10^15 chance that we no longer have this as a concern because we're gone.  Okay?  A meteor struck the Earth.



LEO:  Right.



STEVE:  That is 10^45 times more likely to happen than a collision between any two people with a billion users of Bitcoin, BitTorrent Sync, or SQRL.  10^45 is a trillion trillion trillion billion.  So every second that goes by there's a one in 10^15 chance that we're all obliterated.  Oop, there went another couple seconds.



LEO:  Yeah, but Steve...



STEVE:  Every single...



LEO:  It could happen.  But Steve.  It could happen.



STEVE:  It actually couldn't.  It actually cannot.



LEO:  No, it could happen, though.



STEVE:  It actually cannot happen.



LEO:  And I can win the lottery tomorrow.



STEVE:  There's a trillion trillion trillion billion times more likely that in the next second we will all cease to exist, and this will be the last thing on our minds.  This will be a problem, I mean, believe me, whether your bitcoin wallet is full or not, it's not what you're worrying about.



LEO:  But there is a chance it could happen [laughing].  I'm sorry.  I'm just teasing you now.



STEVE:  It's actually zero.  It's actually, I mean...



LEO:  It's so close to zero as - yeah.



STEVE:  If zero fell off the end, yes.



LEO:  But it could happen.  I'm sorry.  Our next question is another tweet from Wayne T. Taylor, @RamblingGeekUK.  He asks, Mr. G., is there any point to having a security certificate on my site in light of the revelations about NSA spying?  Wow.  That's an interesting question.  Wow.



STEVE:  Well, you know, it's like should I give up or not.  I mean, I can understand that.  And so, and I thought it was an interesting question because there is a lot that SSL provides somebody.  Even if you use one of the cheesy free certificates that doesn't provide any verification of your domain name, I mean, SSL, for example, provides privacy through encryption and, presumably, authentication, which prevents phishers, phishing attacks from being effective because your certificate is being vouched for by a certificate authority whom your browser trusts.



So in an open WiFi environment, which is like all Starbucks hotspots and airports and so forth, where you have no logon at all, as we know, all of the traffic is decrypted.  Everybody is essentially, I mean, there is no encryption on the traffic.  It's in the clear.  So anyone doing passive eavesdropping, just like the Firesheep little add-on for Firefox that was instrumental in forcing companies to encrypt themselves, this is why, is that you can't do session state management securely without encryption.  You can't give somebody a cookie for them to hold to identify them as they move around your website without encryption because otherwise everything they're doing is in the clear.



So it's unfortunate that you have to go to a certificate in order to get encryption.  But certificates now, for like a one-year expiration, are available for free.  I think StartSSL is a source for those.  So absolutely, there's lots of reason, irrespective of whether the NSA is able to get your key from the certificate authority or go to some extreme lengths to crack your encryption.  For the benefit of your customers in the typical everyday use, SSL provides all kinds of absolutely worthwhile benefits.  Definitely worth doing.



LEO:  Question 4 from Aberdeen, Scotland.  Kyle wonders whether Knock is really secure:  As always, insert Leo's blah blah blah praises.  But I need to say that I do actually appreciate all the good work you do, and the amount of knowledge you help me understand is just amazing.  There's no one, and I mean no one - oh, come on, blah blah blah - not even at the university at which I graduated, who can explain these topics as well as you, the Explainer in Chief, Mr. Steven "Tiberius" Gibson.  I can't thank you enough.  And I, too, will thank you with purchases of SpinRite in the near future.  Do that in a Scottish accent, I dare you.



So, Steve, after having looked at the Knock app, which really does work just fabulously, it got me to thinking about how secure it really is.  Are you familiar with this app, Steve?



STEVE:  Yeah, we talked about it last week, actually.



LEO:  Oh, all right, yeah.  I understand it's technically speaking totally secure, as I trust your explanation in last week's podcast.  But physically speaking - and by the way, I can give you some real-world feedback on this because I set it up with a surprising result myself.  But physically speaking or implementation-wise speaking, is it secure?  I mean, a knock-knock on your phone doesn't represent you in any way.  It's not a password, not a fingerprint.  It's not even a unique knock-knock.  I understand this app is to make things totally convenient, but I wouldn't use it just because anyone could easily fool the system to be you.  I just thought I'd get your thoughts on this, as it's interesting to think that sometimes even the most technically secure systems are broken if their implementation is weak.



I mean, really, it's pretty obvious - so just for those who don't know, this is an app for the Mac and for the iPhone.  You put it on the iPhone, and you put it on your Mac.  It uses low-energy Bluetooth, Bluetooth LE.  And when I approach my Mac, it senses my phone.  That happens anyway.  And now the app on the iPhone, if I knock on the iPhone twice, unlocks the Macintosh, it says on here.  And of course the only authentication you're using is the fact that you have the phone.



Now, I will give you a real-world issue that came up for me.  I set it up here in the studio.  Unfortunately, Sarah also has it on her phone.  And for reasons I'll never understand, both times I set it up, it set up to work with Sarah's phone, not mine.



STEVE:  Oooh, boy.



LEO:  Even though I was sitting right next to it.  It doesn't obviously care where you are.  In fact, it was within range of two phones.  It chose Sarah's twice.  And she's currently still set up to knock-knock unlock my laptop.



STEVE:  Okay.  So that's disturbing in the extreme.



LEO:  Oh, but there's no way to reject another Bluetooth LE.  It doesn't give you a choice.  It just - it does it.



STEVE:  So that's a bad implementation.



LEO:  Yeah, they should give you a choice.



STEVE:  Yes.  It should absolutely, you know, we talked once about the only vulnerability of Bluetooth being the moment of pairing, and that somebody who was really concerned should go walk into the middle of an empty parking lot, maybe like a stadium or shopping center sometime where no one is within 30 feet of them, the typical Bluetooth range, and do their pairing then.  Because it's only in that instant that there's any vulnerability.



LEO:  Well, and Bluetooth LE has a hundred feet.  I mean, it has a much larger range.  Sarah Cake 5s is the phone that can unlock my...



STEVE:  Unbelievable.



LEO:  And it never gave me that choice.  It never says whose phone do you want to use?



STEVE:  That's disturbing.  So...



LEO:  Gosh, when you pair a Bluetooth thing, these things jump through hoops.  Oh, make sure the pairing number's the same.  Are you sure you're seeing it?  Nothing.



STEVE:  Yeah, well, these guys, I'm disappointed.  What I was responding to was the crypto architecture, not the implementation.  And several other people also said that they were worried because, for example, they didn't even have to knock their phone twice.  They could bump into the counter, and it would unlock their machine.  So again, I wanted to follow up and explain that I wasn't thinking that this was, like, good security.  This was...



LEO:  Interesting.



STEVE:  ...good, this was correct crypto.  But obviously these guys have huge implementation problems.  We've always talked about security and convenience being at odds.  I'm shocked that they didn't do a "enter a code on each end" so we can figure out which is your phone.  That's just crazy.



LEO:  Too much trouble [laughing].



STEVE:  Wow.  That's disappointing.



LEO:  That is sad, isn't it.  And by the way, you could do this with Bluetooth.  There's an article here on Lifehacker from last June on unlocking your computer just by sensing the Bluetooth, in a variety of apps that do this, as you walk into the room.  This is Windows or Macintosh.



STEVE:  And actually that's Question No. 5 we have following up.



LEO:  Well, there we go.  I'm already ahead of you.  All right.  Let's move on now, then, to - thank you, Kyle.  Thank you for the kind words, too.



Stuart Ward in Maidenhead, U.K. - you're big in the British Isles - notices that Bluetooth unlocking is nothing new.  Oh.  Linux users have had this for a number of years.  Yup.  Have a look at BlueProximity.  It's a SourceForge project.  There's no function on the phone, so any device that will accept a Bluetooth connection can be used.  The security is based on Bluetooth pairing, so you have to pair the device to your computer for it to work.  I've used this for a few years.  The only caution I would make is if you're away from your computer, but still close enough to make a Bluetooth connection, this can drain your phone battery more quickly because the phone will need to transmit at full power.  When near, the dynamic power of Bluetooth means that the ping connection is not a significant battery drain.  So if you're close, it's not a problem.  It's only if you're kind of right at the edge of the 10 meters.



STEVE:  Well, and that's one of the reasons that these guys who did Knock chose...



LEO:  LE.



STEVE:  ...to use Bluetooth LE, yes.  It's far - they brought the bandwidth of the connection down and deliberately used the low-energy variant that's in Bluetooth v4.0.  What happens with Bluetooth, similarly to cell phones, is they dynamically change their transmission power based on a report they get from the other end about the received signal strength.  So as you stretch out the length of your connection, the receive signal strength that is reported from the other end drops, and so they put more juice into transmitting in order to keep the signal strength up.  So LE solves that problem to a much greater degree.  And I just wanted to say, yes, there have been other Bluetooth connection suggestions.  Hopefully they have been done, well, with more security in mind, with more actual practical application security, rather than just the low-level crypto, which is sort of free because Bluetooth gives it to you.



LEO:  Right, right.  Moving along to another tweet, this one from Economic Mayhem, probably thinking of the fact that the folks at TrueCrypt are about to undergo a security audit, wants to know:  Shouldn't you advocate audits before getting 100% behind a product like Threema or OTR?



STEVE:  And I saw this, and I thought, okay.  Let's talk about this for a minute because in a perfect world, yes, we would like to have everything audited.



LEO:  But look how long we've been using TrueCrypt without an audit.



STEVE:  Yes.  And the fact, I mean, people say, well, I'm not using anything that I don't know exactly what it does.  Well, but you're using a processor chip.  You're using an operating system you did not write yourself from scratch.



LEO:  Yeah, all the time, yeah.



STEVE:  You want to have your eyes open, certainly.  And look at the people that just lost tons of bitcoins because they were using some bitcoin exchange that they had no direct personal knowledge or control over.  So all we can do is have our eyes open and use our best judgment.  Does everything we see from the people of Threema look right?  And I'd say yes.  Their FAQ and the details they provide all look correct, and nothing raises a red flag to me.  And they want a dollar for their device, to use their product so that they can pay for the infrastructure that they have to create.



In the case of OTR, the Off The Record protocol, that's been heavily cryptanalyzed by people to understand how it works, and it's been well vetted now, so we know we can use it.  My problem with BitTorrent Sync, all of their words they're using sound good, but they're really being vague about what they do.  And it's like, okay, wait a minute.  Is it open source?  Is it open protocol?  What are they going to open?  And we just don't know.  But I would imagine that they did security right.  They understand security.



So there are clearly situations where we can look at what we're told, like when we did the review of cloud storage providers.  About half of them were wrong, and we could say, okay, this is not TNO.  This is clearly not correct.  In the case of Apple, for example, with iMessage, they've said, and we know, that they did not do the protocol correctly, and it's closed.  So we can say, well, they have good intentions, but they're not telling us what they're doing in detail, so it's hard for us to trust them completely.  So unfortunately, security requires absolute knowledge to have absolute security.  And we're not going to have absolute knowledge unless we go make our own chips and write our own operating systems and write all the applications that run on it, which no one is able to do now.



LEO:  Yeah, so we have to just live in a world where we trust people.  But I would say you can trust open source a little bit better because at least in theory it's on display.



STEVE:  Yes.  Well, and look at the intent; look at the background of the people; look at what their goals are.  For example, I will be writing an SQRL client for implementing that protocol in assembly language.  And talking about the protocol, it'll be open.  We'll be using open libraries.  And everyone will understand that I have no ulterior motive other than creating the most secure implementation I am capable of creating.  And I believe people will trust me.



LEO:  Yeah.  And if they don't, they don't have to.



STEVE:  And if you put your coinage in a Chinese...



LEO:  BitLocker...



STEVE:  ...bitcoin exchange, and it turns out they're fraudulent, well, gee, maybe that wasn't the right place to put the money.



LEO:  But to be fair, you coined the term Trust No One, TNO.



STEVE:  Yes, TNO.



LEO:  But that wasn't a call to action.  That was a description of a certain kind of thing.



STEVE:  Yes.  It was an acknowledgment, an explicit acknowledgment that we have the technology.  That's the key.  We can do TNO.  And in fact that leads nicely into the next question.



LEO:  No. 7, from Steve Davidson in Eastern Massachusetts.  He wants to know what you think of iCloud Keychain, the new feature Apple's offering in Mavericks, OS X 10.9.



STEVE:  And in general in iOS 7, too; right?



LEO:  It comes with 7 and Mavericks, that's right.  He says it looks to be a lot like LastPass for the rest of us.  I use LastPass, but I'm a listener to Security Now!, so I can't be called normal on the geeky scale.  LastPass requires a bit of technical skill to use, and the willingness to use a special browser on an iPad.  I'd really like for my octogenarian father and other non-technical relatives to have a good, easy-to-use password vault.  iCloud Keychain does seem to be the right thing.  Or is it?  What does Steve think of the security model?  Of the one or two setup options, which makes the most sense to our guru and advisor Steve Gibson?  I'm not as worried about NSA snoops as I am about protecting them should Apple ever be compromised.  Could you please weigh in on this?  Thank you.  Steve Davidson.



STEVE:  So here we have a problem, and that is that Apple doesn't document their stuff.  Apple is easy to use and gives us nice little switches that we can turn on and off.  And we have to take them at their word.  Now, again, I tend to be trusting.  That is, if someone says this is what we're doing, for me it's like, okay.  The consequence of them not doing it, of Apple lying to us about what they have deliberately engineered for iCloud, would be catastrophic.  And we know, for example, that Apple has now, what was it, their canary policy, where they're going to preemptively tell us periodically that they have not been served with a letter from the NSA because they're unable to tell us when they have been, which is sort of clever.  It's like, okay, they're sounding like their heart's in the right place.



So what do we know from Apple, what has Apple stated about iCloud Keychain?  They have said that it is encrypted, the keychain data, encrypted in transit and when stored on their server.  They've said they use 256-bit AES encryption.  Now, remember that the AES encryption is a block cipher whose block length is not changeable.  It's always 128 bits.  But the key is what is changeable.  So when we say 128-bit AES, we mean a key of 128 bits.  Theirs is double that.



Now, here we are.  That's my favorite new number, 256.  256-bit is the new black.  And so they're using this level of encryption which is a trillion trillion trillion billion times stronger than the chance of us all being wiped off the earth in the next second.  So we're fine.  So long as that's the only - so long as brute-force guessing is the only vulnerability.  So they're using that encryption to store and transmit passwords and credit card information.  They also use elliptic curve asymmetric crypto and key wrapping.  So they're sounding like they're doing all the right things.  They have written that iCloud Keychain encryption keys are created on our devices.  So this is the model where - this is TNO.  This is the model where an asymmetric key, they're saying they're using elliptic curve asymmetric crypto, as am I, for example, with SQRL, because that's the right one now.



Now, we don't know which, but there aren't known problems with elliptic curves, even if you use the standardized elliptic curves.  As far as we know, they're okay.  I'm using Dan Bernstein's curve because I'm just a little afraid of NIST and their past affiliation with the NSA.  But still, Apple's doing the right thing.  TNO.  So the keys are created on our devices, and Apple can't access those keys.  Only encrypted keychain data passes through Apple's servers.  And Apple cannot access any of the key material that could be used to decrypt that data.  So they're saying that the private key stays on the device, and the public key, presumably, is what's encrypted and exchanged.  Maybe.



I mean, again, unfortunately, we don't know what the architecture is.  They do, they continue to say only trusted devices that you approved can access your iCloud Keychain.  They say advanced settings allow you to choose an iCloud security code longer than four digits - oh, and my goodness, please do - or have your device generate one for you.  And they said you can choose to disable keychain recovery, which means that iCloud Keychain is kept up to date across your approved devices, but the encrypted data is not stored with Apple and cannot be recovered if all of your devices are lost.



So if we reverse-engineer this, this says that, if you allow Apple to store your iCloud Keychain data on their servers, and you lost all of your devices, so that you didn't have your own local database, then you could go to their web page, or maybe get another iCloud device, put in the same security code, and it would download it and then decrypt it locally on your device.  So that says they do have the keys, that is, all the keys, including - again, we don't know what they're doing with asymmetric crypto.  This is what's so frustrating about not having any protocol documentation is that we have to, like, from what they say, kind of guess and reverse-engineer.



But they are saying, I guess, that if they store a copy of your iCloud data, that you can recover it with your encryption code, whatever they call that somewhere here, even if you lost all your devices.  So you want that to be very good.  Otherwise - because that's what you're relying on.  And for safety you probably don't want them - you want to disable what they're calling, what was it, keychain recovery.  So disable keychain recovery, then they're not storing a copy on their servers.  Because to me that does not seem safe.  If they're storing it, it must be that it's only protected by your password, and that doesn't seem safe.  So disable keychain recovery, they don't keep a copy, but then it's up to you to make sure you don't lose all your devices.  And again, that's the best we can do with what little we know.



LEO:  Yeah.  If you're going to give it to an octogenarian parent, the default settings need to be sufficiently adequate.  Are they?  Yes, you can make it more secure.  But it sounds like the default settings aren't the best.



STEVE:  Oh, no.  Their default is the four-digit code, which is insane.  No, I can't...



LEO:  And storing it for recovery.  So to really, to answer his question, he's saying, look, is this for the rest of us?  If you're smart, you're using LastPass.  Is this good enough for the rest of us?  And to me that means using the defaults because the rest of us...



STEVE:  I'm using iCloud Keychain with an insanely strong password and no keychain recovery.



LEO:  Right.  And that's the right way to use it.



STEVE:  To synchronize - yes.  And that's the way I'm using it.



LEO:  But most people will not use it that way.



STEVE:  And I am trusting Apple.



LEO:  Right.  You're still trusting Apple.  But most people will not use it that way.



STEVE:  Well, I'm trusting Apple's description.  I'm trusting that what they've told me is true.  If I turn off keychain recovery, they're not storing a copy on their servers, in which case we're only linking across devices, and they have no copy of it.



LEO:  Would you say that LastPass's implementation is preferable?



STEVE:  Not for the octogenarians.



LEO:  But again, I think octogenarians are going to stick with the defaults - four-digit codes and letting Apple recover it for them.



STEVE:  Well, yeah.  They'll die before anyone decrypts their data.



LEO:  Well, I'm just saying the tyranny of the default.  I didn't know that there was an option not to use a four-digit code.  I'm going to have to look into that.  I have a four-digit code on it because I didn't know there was an option not to.  They don't expose that information.



STEVE:  Yeah, the tyranny of the default, as you say.



LEO:  Right.  So I'm using Keychain in an insecure fashion, just because I didn't even know there was an option.  Finally, Peter Chase in Columbus, Ohio wonders whether he can drop NoScript if he's using Sandboxie.  We talked about Sandboxie last week:  I reinstalled Firefox on my wife's laptop - it's a Windows 8.1 device - as part of the process of getting rid of some AVG toolbar she'd inadvertently installed and that was causing serious havoc, by the way.  NoScript does not cooperate with Firefox Sync, so I have to laboriously re-approve all of our commonly used websites for NoScript.  I've written to NoScript asking if they would consider having NoScript work with Firefox Sync so I wouldn't have to do this.  He's approved certain sites, or she's approved certain sites, and Sync doesn't sync those sites.  You have to enter it each time.



STEVE:  Right, exactly, right.



LEO:  My wife's laptop is getting all of its bookmarks and add-ons restored from my main machine via Firefox Sync.  NoScript never responded to his email.  After hearing last week's episode of Security Now!, I took this as an excellent time to install Sandboxie.  Hence my question.  If some scripting mischief occurs, wouldn't it all stay within the sandbox?  Our e-mail is web-based, so sandboxing the browser should help things a lot.  Your thoughts, please.  Thank you.  Listener since No. 1, dittos, et cetera, SpinRite owner.  Thank you for your service to humankind.



STEVE:  Yeah, I'm glad we talked about Sandboxie last week.  Sandboxie is very mature.  It really works well.  And if you're using web-based email, by all means put your browser in Sandboxie.  And for someone like your wife, I mean, I like the control that NoScript offers.  But for a less technical user, wrapping Sandboxie around your browser makes absolute sense.  It's necessary, then, it's a little trickier, you have to, like, drag things out of the sandbox if you download a file that you want to keep because that'll be stored in the sandbox.  You need to manually drag it out of the sandbox.  But for someone just using webmail in this current world where something like CryptoLocker is such a threat, again, I think Sandboxie is a terrific solution for someone using web-based email, or even just email.  You can certainly run Sandboxie, not on just a browser, but you can Sandboxie your email client, as well, so it doesn't have to be web-based.  Yes, yes, yes.



LEO:  Yes, yes, yes.



STEVE:  I think Sandboxie deserves another look for those who looked at it once and haven't looked at it since.



LEO:  Isn't it compatible with 64-bit now?  Somebody wanted to know.



STEVE:  Don't know for sure, but it must be because it's still cranking away.  It's cranking away...



LEO:  Yeah, I don't think you can - I don't think there is a 32-bit version of Windows lying around.  My friend, Steve Gibson, the time has come for us to say goodbye.  You have answered all the questions I have in our little box here.  It's empty now.  Thank you, Steve.  We do this show every Wednesday afternoon, 11:00 a.m. Pacific, that's 2:00 p.m. Eastern time, 19:00 UTC, on TWiT.tv.  Please tune in and watch live, if you can.  If you can't, though, on-demand audio and video is always available.  Steve has 16Kb audio for the bandwidth-impaired and handwritten, personally crafted by Elaine Farris, transcripts so you can read along as you listen.



All that's at GRC.com along with SpinRite, the world's best hard drive maintenance and recovery utility, and all the great freebies Steve offers.  GRC, Gibson Research Corporation, dotcom.  You can also follow Steve, @SGgrc on Twitter.  You'll get lots of links throughout the week by doing that.  And of course we have full-quality audio and video at our site, TWiT.tv/sn.  Or you could subscribe because this is everywhere.  This is one of the oldest podcasts in the world.  And so that means it's on every list, everywhere.  Hey, Steve.  Thanks so much.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#431

DATE:		November 20, 2013

TITLE:		What Is RADIUS?  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-431.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up on another whirlwind week of really interesting Internet security news, Steve and Leo provide a brief overview of "RADIUS" - the 22-year-old pervasive, but often unseen, protocol and system for providing wide area network user authentication and accounting.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson with a lot of security news.  We'll talk about that Coin wallet idea.  And he'll also explain what RADIUS is.  A lot of people asking, how come proXPN only allows 12 characters on a password?  And is that insecure?  No.  Turns out it's very common practice.  Steve explains why it's not a problem, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 431, recorded November 20th, 2013:  What Is RADIUS?



It's time for Security Now!, the show that protects you and your loved ones, your privacy, your security online.  The Explainer in Chief, the King of Security Now!, Steve Gibson is here.  He's actually in-studio with me.  We just give him a little box to look through, a little window so it feels like he's onscreen.  No, he joins us from his Fortress of Securitude in beautiful Irvine, California each week.  Hello, Steve.



STEVE GIBSON:  We've been having day-long scheduled power outages down here.



LEO:  What?  How dare they?



STEVE:  It's, well, you know me.  I'm pretty much SOL.  When there's no power, it's like, okay, well, thank goodness Kindles last a long time.  So I've been doing some reading and then working on catch-up stuff.  So we've got one more next Monday, and that ought to finish it.



LEO:  What are they, power washing the nuclear plant or something?  I mean, why would you have day-long outages?



STEVE:  No, well, Irvine is all underground power, as all modern metropolises these days, metropoli.  And I've been here since '84, and there's never been anything like this.  And we just have old equipment.  And so I think they're having to do huge upgrades.  And they're also pulling, I'm seeing big truck-mounted reels of, you know, everything is 440 volts underneath the ground.  And then they have local subterranean transformers that drop it to 220 and to 110.  And so these massive cables are being pulled.  So I think they're probably increasing capacity, maybe just rotating out old cable for new.  I've been curious enough, and certainly I've had some time on my hands when all the lights are out to wander down and say, okay, so what is this?  But it doesn't look like there's anyone really to talk to, so...



LEO:  They don't know.  I don't know.  Yeah, just putting that line in there.



STEVE:  Yeah, just they said draw this over to here and then connect it to that, yeah.  There were a couple guys out in front the other day, and they looked like that.  They were listening to some radio with their feet up on the dashboard.  I thought, okay, I'm not going to get the whole story from these guys, so.  But the power came back on, and everything's fine.



LEO:  What do they say?  What is black and orange and sleeps eight?  A CalTrans bus.



STEVE:  Yeah.



LEO:  It's a bad joke.



STEVE:  So a number of people have complained, over the months that proXPN has been a sponsor, that proXPN's password length, their maximum password length is 12 characters.



LEO:  Hmm.  That's usually a bad sign, isn't it.



STEVE:  Well, but it's not in this case.  And that's why I thought something we've never talked about is RADIUS.  RADIUS is a 22-year-old technology that was first - there was an RFI that was put out, like almost pre-Internet, for developing distributed or wide area network authentication.  And so the rules that apply to a RADIUS-based authentication are very different from everything we've been teaching everyone for the last couple years about a website should never be able to show you your password in the clear; and if it's a fixed length, that means they're not hashing it, you know, blah blah blah blah blah.  And but proXPN allows you, when you stop to think about it for a second, you can connect to servers all over the world, wherever you choose to connect to, and somehow that server knows you have an account with proXPN.  And our end-users, our listeners, will have encountered this.  We've never talked about WPA2 Enterprise.  What is that for WiFi?  And that's WiFi where you don't use a preshared key, but where the router looks up your credentials on the fly.  And that uses RADIUS.



And so anyway, our topic today, if we get to it, because there's also - there's so much news and really interesting things that I want to talk about.  Well, that's nominally the topic.  But if we do it next week, well, so be it.  But I wanted to explain to people why this wasn't a problem that proXPN - I mean, I'm not defending proXPN.  They can take care of themselves.  But there's a misconception that the only way to do passwords is the way we've been talking about.  And actually, if you have very different needs, which is what a global network has, then the rules are a little bit different.  So I wanted to cover that.



And the other thing that I thought was funny was, it's like, wait a minute.  All a proXPN account is doing is authenticating you to access their servers.  They're the ones who want it to be strong.  We really don't care.  I mean, it's like you could give your - you wouldn't want to give your credential to somebody else.  But, I mean, you could.  You would never do that with cloud storage, where someone would have access to your stuff.  But here it's really reversed.  It's proXPN that would want secure authentication.  But you don't really care.  I mean, who cares if, like, someone gets your credentials and is able to have access to their networks.  They're the ones who want the protection, rather than the user.  So it's sort of turned around anyway.



But anyway, we have a ton of stuff to get to.  We had the 9th Annual Podcast Awards.  I didn't find out about it until 24 hours before they were closing.  I want to talk about that.  GRC is now full Perfect Forward Secrecy operational.  There's been news on the CryptoLocker front, of course.  Bitcoin has had a wild ride.  There was news that concerned a lot of people that came out last week about the OS underneath the smartphone OSes that apparently isn't very secure.  Two really interesting new payment systems have surfaced.  A bunch of miscellaneous tidbits.  And, as I said, if we ever get to it, we'll talk about RADIUS.



LEO:  Holy cow.



STEVE:  So Calomel SSL Validation.  It's funny because I installed the shortcut after thinking that I would probably now get the big blue shield that we had not been receiving until now.  And on the Welcome page in Firefox, I found us.  It said "Special thanks to Steve Gibson and Leo Laporte for mentioning the Calomel SSL Validation Firefox add-on in Security Now! Episode 428 and also Security Now! Episode 430."  And before long it'll probably be edited to say "and also in Episode 431," because that's this one.  And sure enough, we are now the blue shield, which is as good as you can get.



LEO:  Who are these guys?



STEVE:  So, okay.  What happened was, the reason I started talking about them in Episode 428 is that, with the move to Firefox v24, which is already a version ago, they - I think it was for 24.  Maybe it was 25.  I think we're at 25 now.  But an add-on had access to granular detail about the connection security.  And so the Calomel, that's C-a-l-o-m-e-l, add-in, it installs a shield icon to the immediate left of the URL bar in Firefox.  And it's blue or kind of orange or I'm not sure what colors.  I've seen like Google's not looking so good.  They were, when I went to my  Google Drive to set up the document to send you, Leo, I got only like a kind of a pukey-looking yellow color.  And I don't remember exactly why.  But if you click on that, you get in-depth details.  In fact, if you scroll down on my notes, Leo, I took a screenshot of GRC's current Calomel SSL validation.



Anyway, the point of this is it gives you very granular readout on the connectivity Firefox has with the server.  And, for example, it shows that we're using an Extended Validation certificate.  I kind of wish it gave me a little more credit for that because that's nonspoofable; whereas regular domain validation, DV certificates, can be spoofed with a man-in-the-middle attack.  And that's one of the extra benefits of Extended Validation.  But Calomel doesn't give us any credit for that.  They just note it, that it is there.  And so then it ranks the site.  It shows the cipher suite you're actually using between the browser and the server, the type of key exchange.  And you can see in GRC now we have ECDHE.



We talked about ephemeral Diffie-Hellman key exchange some time ago on this podcast [SN-328].  And that's the kind of key exchange where you're not using the server certificate both for authentication and to establish key agreement.  You do the key agreement separately.  You only use a certificate for authentication.  And that's what allows - that's what prevents a future compromise of the certificate from being able to decrypt past encrypted conversations.  So if you don't have Perfect Forward Secrecy (PFS), as a consequence of having an ephemeral key, that is, a key that's negotiated on the fly between the endpoints, if you don't have that, then captured traffic can later be decrypted if the certificate ever falls into the wrong hands, the [cough] NSA [cough] or anyone else.



Anyway, so we're now blue shield because we have Perfect Forward Secrecy, at the expense of being technically vulnerable to the BEAST attack.  The reason I hadn't set us up this way a long time ago was that we were getting dinged for being vulnerable to the BEAST attack.  But now that Safari has updated themselves, and in fact they're the last browser to do so, all the browsers now provide client-side protection against the BEAST attack.  And that was an attack against the CBC.  The CBC-style method of using a cipher was prone to some exploits if the browser didn't take measures.  I think Opera was the first, and then Chrome and IE and Safari.  Now all the major browsers are providing that themselves, which allows me then to put the CBC ciphers back at the top of the list and move RC4 all the way down to the bottom.



Now, in an interesting little side effect, I broke GRC's email.  Neither myself nor Sue nor Greg are any longer able to establish an SSL connection to our own server.  But that's because we're using an ancient version of Eudora still.  And when I updated all the servers over the holidays last year, that was the first time we were able to establish SSL connections into email.  It's not a big deal because we establish point-to-point connections to GRC.  But if, like, Sue's out traveling and wants to use open WiFi, it'd be better for our email to be encrypted and not in the clear, as it otherwise would be.  So it must be that the cipher suite that Eudora is looking for, I removed inadvertently.  Oh, and my iOS devices won't connect, either.  None of my iPads or my iPhone will now connect securely to GRC.



So anyway, I haven't figured that out.  I just did this last night.  And I immediately sent texts to Greg and Sue saying, uh, I can't send you email because I just broke email.  So you guys are going to have to step back from using SSL briefly until I figure out in detail what I broke.  So I'll have to add back a cipher suite that Eudora wants and then see what's going on with iOS.  So I, you know, I'll figure that out.  But that's always sort of the - it's a consequence of sometimes tightening up security is you break things, which is why we've talked often about various companies only inching forward slowly to make sure they don't break things.



And in fact, perfect case in point is our next topic, and that's Google, who has completed its intended and early announced migration to full 2048-bit SSL certificates.  They were saying by the end of 2013.  They decided to increase the priority of doing that and stepped up - they have now - they announced yesterday, I think it was, that they are now 100% 2048-bit SSL and Perfect Forward Secrecy cipher suites throughout.  Which we know matters because we know they're one of the targets of PRISM and other efforts by the NSA to perform data collection.  So they are now working furiously to do the same thing, to bring up strong security among all of their inter-datacenter links, which they believed were secure and private, but found out that there have been taps installed.  So that they're working on also.



And Marissa Mayer announced that Yahoo! will be following suit.  And I did see some reaction to that announcement, essentially sort of yawns from the security community saying, oh, Yahoo!'s going to be making themselves more secure?  Yeah, okay.



LEO:  Well, that's good.  Why is that, I mean...



STEVE:  I guess it's just that it's like...



LEO:  They were being snarky.



STEVE:  Yeah, they were.  It was like Swiss cheese deciding it wants to have fewer holes.



LEO:  Oh, really?  Yahoo! is not so secure?



STEVE:  Oh, my.  Oh, my god, Leo.  Oh.



LEO:  Oh, okay.  So SSL is the least of it.



STEVE:  Exactly.  It's like, okay, well, that'll be nice.  But that only leaves 12 other ways we can get in.  So...



LEO:  I see.  Okay.



STEVE:  So, yeah.  So Yahoo! said they, too, are going to encrypt all the data between their datacenters.  And it's like, ah, okay, fine.  And they're going to offer users an option to encrypt all of the data flow to and from Yahoo! by the end of the first quarter 2014.  Which of course everybody else has been doing now for a year.  They're like, oh, well, you know.  Yeah, uh-huh, yeah, we, too.  So that'll be nice.



CryptoLocker:  The top of the news there is just sort of random.  I don't know why this picked up so much traction.  But a random police department in Massachusetts, in Swansea, S-w-a-n-s-e-a...



LEO:  Swansea, yeah.



STEVE:  Yeah, Swansea, Massachusetts.  They got had by CryptoLocker and paid the ransom.  Which, based on the bitcoin value at the time, they had to pay two bitcoins for a total of $750.  And but then in their press announcement, I'm not really sure what the sequence was or why they even mentioned it.  Because, I mean, it really got a lot of traction, the idea that a police department got had by this.  And they were saying, oh, but, you know, don't worry, we're completely secure, and there was no exposure of any of our data.  To which I did see a comment from Brian saying, uh, yeah, yawn, sure, okay, yeah.  But they've paid their ransom and apparently got their data back.  And they must not have been backed up because of course having a current backup is a way to thumb your nose at these guys.



LEO:  Well, also the police authorities are saying don't pay these guys because it just encourages them.



STEVE:  Well, yes.  And...



LEO:  But you see the problem.



STEVE:  Yes.  Easy for them to say.  And that's just it.  When I see people saying this, it's like, yeah, okay, well, easy for you to say.  But it doesn't always work out that way.  I mean, I owe my existence, I mean, the reason I'm here able to do the podcast with you, Leo, I mean, to take the time to do that, is thanks to SpinRite, which is recovering people's data which they don't have backed up.  So it's like...



LEO:  Right.  If people backed up, you'd be out of business.  So...



STEVE:  Yeah.



LEO:  Yeah.  So stop it, people.



STEVE:  So we're beginning to see some sense of how pervasive CryptoLocker is.  BitDefender Labs has reverse-engineered, as have many others now, the domain name generation code which is how the CryptoLocker virus or malware - I guess it's really not a virus because it doesn't spread itself so much as it does - you pick it up phishing, malicious websites or ads or whatever, or phishing email.  We've talked about this before, how based on the date, a cryptographic algorithm is used to generate a large, I mean, many hundreds of random-looking domain names, and so there's like a spray.  And the client will then start making DNS queries of all of these domain names, trying to find the one from among them that the bad guys have actually preregistered and set up a server on.



This is sort of - this is security through obscurity.  It's not perfect, but it works.  Because the only way to prevent this would be for some authority to go and register, preemptively register all of those hundreds of more domain names, which is a real problem.  Also, because it's many different top-level domains.  It's not just in dotcom, but it's many other dot prefixes, or suffixes, rather, that we have talked about in the past.



So what this means, though, is that CryptoLocker is trackable.  You may not be able to intercept it, but you can track it because security researchers would merely have to register one or two domains in the future and then set up sinkholes to monitor the DNS queries to those domain names.  That wouldn't allow them necessarily to block CryptoLocker because they can't respond to it affirmatively.  But they can measure it.  And that's what's been done.



So here's a metric from BitDefender Labs, who did this, and it is chilling.  In less than a week, less than one week of monitoring, they detected 12,016 individual IP accesses, individual IP queries, to a DNS domain that they were monitoring.  Now, you multiply that by two bitcoins, which is the ransom, and it's hard to say what the value was at the time.  But say that it was $500 because it's certainly there now.  That's $12 million in ransom in less than a week, Leo.



LEO:  That's, like, hard to believe.  That's why they do it.



STEVE:  And, well, unfortunately, it's why it will never go away.  It's why, as I said when this first happened, this is really bad because this means they can make money.  And if they can make money, this is all anyone will ever do again.



LEO:  And that's why law enforcement says don't pay them.



STEVE:  Yes.  But unfortunately...



LEO:  We've said the same thing.  Don't buy - you know, spam has a very low cost of entry.  And it must work well enough to make it work because even though we say again and again, don't - what, are you crazy?  Don't buy Viagra through an email.  But it must work, and it's the same thing.  You know?  The cost of doing this is so low that...



STEVE:  Now, what's really interesting is that, since we have IP addresses, we can now determine where the infections are coming from.  And Microsoft's TechNet blog, for some reason they wanted to give it their own name.  They call it Crilock, C-r-i-l-o-c-k.  But they've got a really interesting chart...



LEO:  Looks like spray paint.



STEVE:  Yeah, in their blog, which I have here in the show notes if you want to bring it up, Leo, which demonstrates a phenomenal weighting of infection by country.  That big blue pie is the U.S.



LEO:  79% U.S.



STEVE:  Yes, is leading everyone, is leading the researchers to believe that these are highly targeted attacks.  For whatever reason...



LEO:  Oh.



STEVE:  Yes, that's the point.



LEO:  Interesting.  So it's more like spearphishing.



STEVE:  Yes, exactly.  And, I mean, I've been accumulating what I assume is CryptoLocker viruses.  They're being sent in ZIP files.  And I have a hex viewer that I can look at safely.  And so I'll right-click on the file that is an attachment in email, like any ADP payroll, that's the one I seem to be seeing a lot.  And if I right-click on it, I can see the first two bytes are PK, which is old Phil Katz, who designed the format.  But then inside, in the clear, is the filename in the PK ZIP format, in the ZIP file, and I can see that it's .pdf.exe.  So it's pretending to be a zipped PDF.  It's actually executable.  And I have these sitting in a folder, and I've been wondering if anyone would want to, like, deliberately infect themselves to have the experience or see it work or whatever.



LEO:  See it work.  No.



STEVE:  Yeah.  It's a little bit dangerous.  But...



LEO:  So you've been getting it.



STEVE:  I'm getting it in one of my - because I also have honeypot email accounts that I've created over time.



LEO:  So it's targeted in what sense?  I mean, what is it about your honeypots that are attracting attention?



STEVE:  I mean, they've just been around for a while.  They're longstanding...



LEO:  So anybody could get this.  It's not targeted in the sense that it's you.



STEVE:  Correct.  And obviously police departments are getting it.  All kinds of people are getting it.  So it is email that is sending you this loader virus, or this loader malware, which then goes and picks up the rest and installs it and does its dastardly deeds.  But clearly not just global surfers running across Internet pages.  This is why it's 80% of the infections are U.S.  They are highly targeted.



And I got a note in Twitter from someone named Abe, who said - he said, "@SGgrc Do you think the recent surge in the price of bitcoins has anything to do with CryptoLocker?"  And he was one of many people who were speculating.  And I don't think so.  I think the reason we saw this bizarre, I mean, it jumped, bitcoin jumped up to $900 at one point, even north of $900.



LEO:  What?



STEVE:  Yes.  Earlier this week it was $900.



LEO:  You should have sold.  That's 45 grand you had there, Steve.



STEVE:  I know.



LEO:  I should have sold.  I got seven or eight bitcoins.  Holy cow.



STEVE:  It was Congress.  U.S. Congress was holding hearings about the nature of virtual cyber currencies.  And the testimony was far more positive than people expected.



LEO:  I see.



STEVE:  It was less kneejerk morons talking and more smart people saying, well, you know, yes, bad guys are using this.  But there are some serious benefits to virtual currencies.  And bitcoin just took off like a rocket, up to north of $900, and stayed there for a while.  And then it's come back down.  But still, it's in the 500s, I think, at this point.



LEO:  $570, last I checked Mt. Gox.  Is Mt. Gox the place you look for value?  Because they say $700-some is the peak.



STEVE:  I found a neat app that I like called ZeroBlock.  ZeroBlock is an iOS-only app, but it has a very nice screen that shows you what's going on.  You're able to tap up at the top to change exchanges.  You can pull down, and it will do a running computation of your number of bitcoins at the current price and show you how much you're worth.  You can also slide to the side and look at year/month/day charts of various sorts.  It's free.  And if you want to - I think it's 99 cents, and then you can get the charts in color.  So anyway, it's a very nice little app that I like, that I'm running.



LEO:  I'm surprised you can still use it.  Apple's been blocking bitcoin apps on the App Store for reasons nobody really...



STEVE:  Interesting, because I got a few of them, and then chose this one from all of them.  So, yeah, $565 at the moment.  And it was almost twice that not long ago.  But it was a consequence of, I mean, I think people are nervous.  I don't have a good feeling long term about the future of any virtual currency.  I just think our government is going to be unable to resist stomping on it.  Then it becomes a pirate currency, and that's going to hurt it some.  And certainly all the attention that CryptoLocker is getting...



LEO:  Yeah, well, it'll grow, too.  So far, from the governmental point of view, the people who are using bitcoin are criminals.



STEVE:  Right.



LEO:  At least there's two prominent examples.



STEVE:  Right, right.  And there was also some news in this last week that assassinations can be purchased in bitcoin now.



LEO:  Yeah.  We talked about that on TWiT, the bitcoin assassin.  Because didn't Ross Ulbricht or whatever his name is, the guy who is allegedly the mastermind behind Silk Road, apparently he tried to hire an assassin using bitcoin.  With no result.  I don't know what kind of assassin you'd get using bitcoin, but...



STEVE:  It must be that there are bitcoin miners who are pretty happy.  I mean, I just...



LEO:  You are.



STEVE:  I just got 50 back in the day, and it's like, wow.  That's, like, you know.  But, I mean, but seriously, there were a lot of people who invested a lot of money in hardware, and they were cranking out bitcoins when they could.  And I'm sure there must be wallets that are stuffed with them right now.



LEO:  Somewhere.



STEVE:  So that's very cool, yeah.  So, okay.  A second OS hiding within every mobile phone.  This was another topic of great interest over the past week.  Here's what's going on.  We all focus on Android security and iOS security and passwords and encryption of the ROM.  Do you use a four-digit code or a long password?  How do you make sure that your memory in your iPhone is strongly encrypted when you're not using it, blah blah blah blah.



All of that is only one OS in a dual-OS architecture.  There actually is a second operating system.  And this is the so-called "baseband" operation, where the actual cellular protocol is managed.  iOS has none of that.  Android has none of that.  They all just buy it from Broadcom or Qualcomm or one of these "com" companies.  They're typically using an older ARM processor.  Generally it's, like, v5.  And, for example, in the case of, I think it's Qualcomm, there's 69 threads running on this ARM processor that actually manages the cellular dialogue, the cellular protocol, the connectivity to the cell tower, the handoff, the signal strength measurement, the whole underlying cellular tech.



Now, this is stuff from the '80s.  And what's happened is it hasn't changed much.  And basically, it's like, it's what's in the dumbest cellular phone you can get.  So when you add brains to a dumb phone to turn it into a smartphone, what you're doing is you're just putting this blob of UI and much more power on top of - you're sort of hooking it to the buttons that were on the dumb phone.  But so there's still a dumb phone underneath all of our smartphones.  And the point is, it is riddled with security problems.  Back in 2010 a security researcher messed with his GSM phone, and he reverse-engineered the code in the so-called baseband processor and found all kinds of problems.



And in this last week, the reason this sort of came to everyone's attention is OSNews.com did a story about the so-called second operating system hiding in every phone.  And the guy who wrote, Thom Holwerda, he wrote:  "The insecurity of baseband software is not by error; it's by design.  The standards that govern how these baseband processors and radios work were designed in the '80s, ending up with a complicated codebase written in the '90s - complete with a '90s attitude towards security."  Enough said.  I mean, we know what a '90s attitude toward security is.  It's like, yeah, my password is "monkey" and so forth.



And he says:  "For instance, there is barely any exploit mitigation, so exploits are free to run amok.  What makes it even worse is that every baseband processor inherently trusts whatever data it receives from a base station - in other words, a cell tower.  Nothing is checked.  Everything is automatically trusted.  And lastly, the baseband processor is usually the master processor, whereas the application processor, which runs the mobile operating system, is the slave.  So we have a complete operating system," he writes, "running on an ARM processor, without any exploit mitigation, or only very little, if any, which automatically trusts every instruction, every piece of code and data it receives from the base station you're connected to.  What could possibly go wrong?"



LEO:  I mean, this is - I think this has been more widely known than you realize.  A lot of times when you jailbreak a phone or modify a phone or hack a phone - the baseband software is the radio software.  So basically you often have to modify the radio software.  So, and I think that's one of the reasons you can do it is because hackers take advantage.  Hacking and jailbreaking, rooting and jailbreaking, rooting for Android and jailbreaking for iOS, almost always take advantage of security flaws.  That's what makes it easy to do.  And I think often the security flaws in the baseband are where they attack.  So while this is a revelation to some, I think this isn't such news.



STEVE:  Well, what I think we're going to see, I mean, so people were asking me, what does this mean?  And my take, I mean, I understand what you just said, Leo, but we're now seeing enabling technologies we haven't had before.  We've talked about software radios, which have really come up in capability and down in price.  That will enable individuals to trivially set up malicious fake cell towers.  And so it's been one thing for the software running on the phones to be insecure.  But once what's running on the phones is understood, we're going to see next-generation exploits of evil cell towers, so-called base stations, set up.  And people's phones will connect to them because they will look exactly like a Verizon or an AT&T or a Cingular or a Sprint or whatever, and the phone will connect to it.  I mean, these things still had the Hayes instruction, the Hayes command set.



LEO:  Yeah, ATDT, yeah, yeah.



STEVE:  It's like, oh, my god.  That's all in there.  And I think we're going to - we haven't, I mean, even though the vulnerability's been understood, as we know, ease of exploitation matters, and cost to exploit matters.  And when the software programmable radios mature, and people start writing exploit kits and starting posting them, we're going to start seeing problems that we haven't seen before.  So my take is I don't think anyone's going to - maybe the people doing the radio software are now understanding they need to wake up.  And I hope they are because, if they don't, this will be the next frontier.  Even though it's an old one.  And really, things that are being exploited are typically been around for a long time.  But it's like, oh, look, we can do this now.  And so people are going to start.



LEO:  It's definitely in the interests of Qualcomm and these companies to secure this stuff.



STEVE:  Yeah.  So HTTP/2 has also been in the news a little bit.  We're now at HTTP/1.1.  And HTTP/2, there is an organization, and if you want to just have your eyes cross, Leo, look at tools.ietf.org/wg/ - "wg" is for working group - /httpbis.  That's the page where they're managing - yeah, there it is.  And, I mean, it just - it's like, oh, my lord.  This is what it takes in terms of committees and interacting and working groups and so forth to move something that is as big and as huge and powerful as HTTP to its next phase.  And HTTP/2 is where we're wanting to go next.  So one of the...



LEO:  That's what "bis" means.  It means the second.



STEVE:  Yes.  So one of the things that is high on the agenda, more so now than ever, is essentially binding security much more tightly into HTTP than before.  Everyone knows that we have HTTP and HTTPS, where the "S" means secure.  With HTTP/2, the discussion is should there be nonsecure HTTP?  That is, they're seriously looking at making HTTP/2 secure always.  That is, if you are HTTP/2, that is, HTTP v2, you are secure, period.  Now...



LEO:  SSL style.



STEVE:  Exactly, SSL style, yes.



LEO:  And we now have the processor power to do that, and that seems completely sensible.



STEVE:  Yes.  Now, but the problem is how do we get there from here because, for example, lots of sites don't have and don't feel they need privacy, that is to say, encryption.  They're just random pages.  It's like Wikipedia hasn't had it until just recently.  It's like, hey, this is just all public knowledge.  This is just - we're just a big database serving pages.  Why do we need security?  Well, people want not to be eavesdropped on as they poke around Wikipedia because now we know everyone's being profiled.  When you were talking about what ISPs are doing, ISPs can see, if you're not using a VPN, everywhere you go because you're technically using, typically, you're using their DNS servers to ask for the IPs of every website that you look up.  So they know everything about you.



So one of the possibilities is known as "opportunistic encryption," or also known as "relaxed TLS."  And the idea is that - remember that SSL provides two things.  It provides authentication of the server, typically - you can do the client, but typically the server - and also privacy, thanks to encryption.  But those two things are separable.  They're technically not the same.  In fact, we were just talking about how what Perfect Forward Secrecy does is it makes the key agreement separate from the authentication so that authentication doesn't govern, isn't used directly for controlling the key and thus allowing traffic capture to be later decrypted if the key was known.  So authentication and privacy are separate.



So relaxed TLS says we can establish - and here terminology is very easy to get wrong, but important.  We can establish a private encrypted connection without certificates.  And that's the case because the certificate is really only asserting the identity of the server.  And we could use Perfect Forward Secrecy without a certificate just by setting up, and we've talked about it, a Diffie-Hellman handshake does allow two endpoints to establish a secure - to agree upon a key which is then used for ciphering, where a passive man in the middle, completely observing their communication, is unable to determine the key that they each can.  But it doesn't protect you from active man in the middle.  That is, if you don't have authentication, then somebody could insert themselves actively in your connection, and you would establish a key with them, and then they would establish a key with the other endpoint and be able to decrypt your traffic.



So this is why there's been discussion in the working group.  It's like, well, okay.  So, yeah, it would be better to encrypt everything, except how do we explain this to people?  Because, see, right now when we talk about a green title in the URL, meaning that you're encrypted, you're secure, that security assertion currently means we verified the server's identity.  But if we're going to do opportunistic encryption, as it's called, or relaxed TLS, then we're not going to be verifying the server necessarily.  Sort of there'll be like a second grade of security.  It's like, well, it's not encrypted, but - oh, I mean, sorry.  It is encrypted, but it's not authenticated, which means passive eavesdropping, like in a Starbucks open WiFi, I mean, that's useful to not have everything in cleartext.



But so anyway, so you can see that this is a very complex issue.  What does this mean, essentially, if we - how do we convey this, and what do we want HTTP/2 to be?  What they're suggesting is that v2 will be like HTTPS is now.  And only if you're v2, you're secure, meaning you have privacy from encryption and you have strong authentication of the endpoint.  And but then, of course, clients that didn't support HTTP/2, or servers that were not offering an SSL certificate, wouldn't be able then to claim, in their handshake, they would not say I support HTTP/2.  They'd be supporting v1.1, which is what we have now, and offering no certificate.



So then the question is, well, okay, is there then a place for relaxed TLS?  And part of this dialogue, this argument, is no, let's just - HTTP strict transport secrecy or security, remember we've talked about STS, Strict Transport Security, provides a lot of strength.  And listeners will remember when I asked Google to, and Google agreed, to add GRC into Chrome so that Chrome will never accept a nonsecure connection to GRC.  It is wired into the browser.  So even the very first connection, which technically represents a tiny window of vulnerability, even that is protected from being eavesdropped on.  And that would allow an attacker to get a wedge in, essentially, and cause other connections to the website not to be secure if the first one is allowed not to be.



Anyway, we've covered all this in the past in our podcast about HSTS, HTTP Strict Transport Security.  So anyway, v2 of HTTP is coming along, and I'm glad.  And I'm also glad that, again, this is another - more fallout from Snowden is a much heightened focus on privacy of HTTP web connections by default.  We're not sure how we're going to get that yet.



And Elaine sent me an interesting link.  She ran across in her travels a court order which was using Freedom of Information to compel the government to tell us what it has in the way of an Internet kill switch.  And the term "Internet kill switch" has come up from time to time.  And it's like, okay, really?  Is there such a thing?  And apparently now it's unequivocal that something, a facility like that exists.  I got a kick out of the fact that it's known as "Standard Operating Procedure 303," because the first thing that came into my mind was, which apparently results in the generation of 404s.



[popularresistance.org/court-demands-how-does-government-turn-off-the-Internet]  



LEO:  I don't think they were thinking about that.



STEVE:  I don't think so either.  But as I understand it, and as the documents they're trying to get imply, our government, through Department of Homeland Security, does have the ability to shut down both public and private carriers of traffic on the Internet in the event of some emergency.  And...



LEO:  Hard to imagine what that emergency might be.



STEVE:  I just think that's a bad idea.  I just, I mean, it's like, the more we depend upon the Internet, the less it's possible to understand.  I mean, it makes us feel like a Third World country to have the ability to, like...



LEO:  Yeah.  I mean, first thing you think of is what happened in Egypt and Syria when the...



STEVE:  Precisely.



LEO:  When people were rebelling, they immediately turned off the Internet.  I think the theory is that one kind of cyberwarfare would involve a concerted attack, let's say on our electrical grid, and if it were felt that the only way to protect the electrical grid would be to turn off access.  And it might be, I mean, who knows where that kill switch lies?  It might be saying no access outside the U.S.  Or it might be let's just shut down the Internet.  I mean, it's not clear what that is.  But let's say it says, look, nothing outside our shores can come in on the Internet.  That might be a reasonable response to a cyber attack on our grid.



STEVE:  It absolutely must be, Leo, that there is the facility to sever the trunks.



LEO:  Right.



STEVE:  The submarine cables, all those optical cables, and probably satellite backup.  There's got to be the way, there's got to be the means to isolate the U.S. from the rest of the globe.  I'd be shocked if that didn't exist.  I hope it doesn't extend to "intra," as opposed to "inter."  That is, intra-U.S. I would sure hope stays connected.  I mean, I think it would, really, I mean, I don't think the government even knows now what would happen if they tried to kill the Internet intra-U.S.  Can you, I mean, can you imagine how dependent we are on our connectivity?



LEO:  Yeah.  I'm sure the argument goes something like, well, if they kill the grid, the Internet does down anyway.  So let's protect our grid by shutting down the Internet temporarily.  But what it does raise is the specter of these countries that decided that instead of allowing criticism and open conversation, they would just shut down the ability to social...



STEVE:  Well, yeah, and we can no longer question whether or not hostile, potentially hostile foreign states...



LEO:  And we know that's going on, yeah.



STEVE:  ...have cyberwarfare initiatives, and we know we do.  Which still seems like science fiction to me.  It's like, okay.



LEO:  Given the cozy relationship that the government has with Sprint, AT&T, T-Mobile, and Verizon, they're probably - the companies that run the backbones, chiefly Sprint, they probably have a - they can make a call and say, hey, could you just shut down the backbone for a little bit?  We're having some trouble here.  Right?



STEVE:  Yeah.  No, I'm afraid that's true.



LEO:  I'm sure that exists.



STEVE:  Yeah, yeah, it has to.  Here's a little random tidbit that I got a kick out of.  This was actually thanks to Simon Zerafa, a frequent contributor to my Twitter feed.  It turns out that some researchers at MIT were curious about what the optimizer in the very popular GCC compiler - what's the GCC stand for?  Probably GNU something compiler [GNU Compiler Collection].  Anyway, it's the compiler that everybody in the, I mean, that's the compiler that the whole open source community operates on.  It turns out that the compiler that is currently operating everywhere, that everyone is using to compile open source code, has been discarding what it considers to be ambiguous or do-nothing code.



But it turns out those are deliberately created security-relevant checks, including those things we talk about here all the time, null pointer checks and pointer overflows.  And you can imagine how this could happen because a sufficiently clever compiler stands back and looks, it's like it's processing the flow and, to what degree it can, understanding what's going on in the code.  And so it sees something that is, like, checking to see if a pointer is zero or not.  And but then nothing happens, like with the result.  I mean, an exception gets raised, but it doesn't see that there's a clear effect.  Or a pointer is being checked for bounds, but when in its less than infinite wisdom it looks to see what effect that has downstream, it says, well, this has no downstream effect, so it removes it.  So it turns out that the actual object code that has been generated for some period of time, I mean, substantial code, doesn't contain the security checks which the source code authors deliberately put in. 



LEO:  I'm not sure how that could happen because this kind of optimization, as you say, it takes out loops that do nothing.  Well, I can't imagine any optimization that does nothing.  Is it instrumentation that's not turned on that...



STEVE:  No, it's present.  But, see, you might argue that this optimizer needs to be fixed, and one certainly would.



LEO:  Or that the security code has to be written better.



STEVE:  It's looking at the downstream consequences to see whether the code has an effect on the outcome.  And arguably, security checks don't.  I mean, they're doing something.  They're validating assertions.  But they do not affect the outcome.  And that's the point.  And the optimizer says...



LEO:  Yeah, I'm not sure I buy that.  I mean, don't you put in test code all the time that doesn't affect the final outcome, but would throw a flag if there were an error?



STEVE:  Well, there is a really...



[Talking simultaneously]



LEO:  Bad optimization is what it is.



STEVE:  There's a really nice PDF that I linked to in the show notes from the MIT guys.  They've gone through and found thousands of packages in the current Debian repository...



[pdos.csail.mit.edu/~xi/papers/stack-sosp13.pdf]



LEO:  It's ironic, isn't it.



STEVE:  ...that have all been ruined by this.  So, yeah, I mean, it's definitely real.  In fact, there's their comment in that SecurityCurrent page talking about it, with a link to the study.



[securitycurrent.com/en/research/ac_research/mot-researchers-uncover-security-flaws-in-c]



LEO:  So they give as an example null pointer checks.  But you don't want to optimize out null pointer checks.  You always want to check for null pointers.



STEVE:  Yes.



LEO:  That's not - that's a bad optimizer.  Or pointer overflow checks.



STEVE:  But my point - es, yes, it is.  But it is in the GCC compiler.  It is doing this.  So it's a good thing they found out that we need to remove that and then recompile everything.



LEO:  Yeah.  Undefined behavior and unstable code.  That's just a - that's a bug.  I think that's a bug in the optimizer.  That's terrible.



STEVE:  Well, it was - someone wrote it in there and thought, oh, look, this will remove something that doesn't have - this doesn't have a consequence, yeah.  Okay.  Two really interesting new payment systems that I received a lot of information about.  And that...



LEO:  I know where you're going with one of them, and I think you might have fallen prey to a very good publicist.  This Coin thing.  I would love to hear about the security implications of it.



STEVE:  Well, okay.  First of all...



LEO:  Do it in order because, I'm sorry, I didn't mean to...



STEVE:  No, it's okay.



LEO:  But I've never seen more publicity in one day.  It all happened in one day.  And people came into our chatroom and said, "What about Coin?  What about Coin?"  And I think there was a very good, concerted effort to raise attention and awareness to something that is a nonstarter.  But go ahead.  Let's talk about it.



STEVE:  Yeah.  So here's what it is.  And anyone who's interested, it's OnlyCoin.com, and - beautiful website, and a minute-and-46-second video which explains it.  And it's intriguing.  And I think I know how it works.  That is, knowing how it would have to work.



LEO:  The theory is that a credit card uses a mag stripe reader, and that you could have in one credit card a programmable mag stripe.



STEVE:  No.



LEO:  No?



STEVE:  No.



LEO:  Okay.  Because, by the way, this is a nonstarter in every country but the U.S. where they use Chip and PIN.



STEVE:  Correct.  So the way it looks like it would work, Leo, is what you said.



LEO:  Right.



STEVE:  And what it actually is, I think, is very clever.  Which is why I take my hat off to these guys.  So what you get is you get this credit card that looks exactly like the - remember the VeriSign one-time password card?  It was a credit card-size thing that had a button on it.  And when you pressed the button, it would give you a six-digit output.  So this credit card has - it's got an eInk display and a merged-in battery that lasts about two years.  It runs Bluetooth 4 LE that we were talking about last week, the low-energy version, and it ties to your cell phone.



So in operation you have a credit card reader, very much like Square, the little fob that plugs into your earphone connector, or earphone and mic connector, on a smartphone.  And then you scan your various cards one at a time through this reader gizmo into your smartphone.  And then there's all your credit cards in your smart phone.  And then through Bluetooth LE, your smartphone, they say, loads all of those credit cards, however many you've got, maybe 40 credit cards, into a single card.  Now, you then - there's a button on this single card where you press it, and it cycles through which credit card you want this to be.  And then you're able to swipe that stripe through a standard mag stripe reader, and that card gets billed.



Now, you would think, I mean, from what I just described, you would think this is some amazing card because, as you press the button, it's like reprogramming the mag stripe.  Well, okay, that can't - we don't have that technology.  That's nano stuff with Spock and Kirk.  And it doesn't have to do that, which I think is why this is so brilliant.  This is all sort of a user interface.  This is just my theory.  This is all just a very clever UI where the card appears as you press the button, and the eInk display changes to show you which card it is.  This is a little sleight of hand.  The card itself is statically programmed with their own credit card.



LEO:  Ah, that's what it is.  That's what it is, yeah.



STEVE:  And so they are a proxy for all these credit cards.



LEO:  This is not new, by the way.  There are companies that do this.



STEVE:  I think it's - oh, no, I did not know that.  That's cool.



LEO:  They don't do it with all the sleight of hand.  They just have you have a credit card that you charge everything through, and then it splits it out into whatever you choose.



STEVE:  Ah.  And so what these guys have done is they...



LEO:  That makes sense.



STEVE:  Doesn't it?  I think it's so cool.  So as you press the button on the credit card, it cycles through showing what card it's going to be.  It tells your phone using its Bluetooth link.  Your phone tells them using your WiFi or cellular link up to their cloud-based service.  Then, when this card gets swiped, the charge - and they've established themselves as a merchant, as a credit card company.  So the charge goes to them.  It sees what the current setting of the card is, and then it acts as a proxy, sends the charge off to BofA or Chase or whomever.



And all of this happens in real-time.  I mean, remember, I wrote an eCommerce system for SpinRite processing, so I've done all of this.  This happens in real-time.  That comes back to them.  They then bounce it back to the merchant and say accepted or declined or whatever, and charge the card.  So anyway, I just think it's just - I assume that's what it's doing.  It's not reprogramming the mag stripe on the fly.  We don't have the ability to do that.  That would just be crazy.



LEO:  I didn't even think about that, but of course you're right.  That's nuts.



STEVE:  Yeah.  But it's just like - and I do think it's a little weird because, I mean, I love the idea that you press the card, and it shows the change.  But then you hand it to the waiter to pay your bill.  How do you know he's not going to press the button, too?



LEO:  Right.  And...



STEVE:  And they say, oh, we made it so it's not easy to press it by mistake.  It's like, eh, okay.



LEO:  And now you know the waiter is going to say, what the hell's this?  Give me a credit card.  And it's not going to work outside the U.S. because chip and PIN.  And, I mean, the problem I have with this is that they're really lobbying people to give them money now.  If you do it now, you'll get half off.



STEVE:  Yup.  You have 23 days left of 50% off.



LEO:  Which means giving them $55 for something that, if you ask me, will never see the light of day.  So I just would warn people to be, I think, cautious.



STEVE:  Yeah, oh, yeah.  I should say I'm not endorsing this except I just love the hack.  This is a clever hack where...



LEO:  Yeah, I like that part.  I think your - and you're so good at reverse-engineering this stuff.  That makes a lot of sense.  And in fact that kind of thing exists.  There are these special cards that are kind of, you know, allow you to have a variety of affinity cards.  But you do it online.  It's a little bit slower.



STEVE:  Yeah.  And are there some, like, with an iOS interface, so you just set the card on...



LEO:  No, no, no, no.  They're all just plastic.  You would then - I should find it because there's a couple of these out there.  Somebody sent me a link.  My real problem is this was - I smelled something funny because I've never seen such a successful one-day campaign to get attention.  And everywhere, from the Christian Science Monitor, USA Today:  "Coin reinvents the wallet."  "Coin changes the wallet."  And I see...



STEVE:  Well, and it's a slick video, Leo.  You watch that video, you know, because it pulls the sleight of hand.  It makes you think that you've got a programmable credit card.  It's like, wow.  That's not how they do it, but it's the way it looks.



LEO:  And that bothers me, too.  In fact, Kickstarter's banned these slick videos.  They say you have to have an actual prototype in your video because - and this is not on Kickstarter.  And they bill you immediately.  This is their own website, and because they don't have the rules of Kickstarter, they don't have to tell you anything negative about it, like the fact that the credit card companies - Visa, MasterCard, et cetera - could immediately clobber this because it...



STEVE:  True.



LEO:  Saying no, nice try, boys.



STEVE:  You're right.  They could easily say we're not accepting charges from you, and it's game over.



LEO:  Yeah.  I think there are security implications, especially if you're sending this through Bluetooth LE.  



STEVE:  No.  I see no security problem at all.



LEO:  Because it's in your phone.  All the data's in your phone.  It's never anywhere but your phone.



STEVE:  No, it is also in the cloud.  All the cards need to be in their facility in order for them to be able to proxy those cards on behalf of their card.



LEO:  Yeah.  So if you trust Coin...



STEVE:  Yup.



LEO:  Which is a big if, they're saying...



STEVE:  On the other hand, well, yes, your debit cards are at risk.  Remember that your credit cards are always backed up by the credit card company.



LEO:  And they've changed the law on the debit cards, too, so that there's a limit on how much you can lose.



STEVE:  Ah.



LEO:  I think it's 50 bucks.



STEVE:  Good.



LEO:  Nevertheless, I just think this is a nonstarter, and you're giving 55 bucks to a company that's going to disappear.



STEVE:  I wanted to talk about it because I thought it was clever...



LEO:  And I love it that you figured out how they do it.  And I think that's, you know, I'll tell you where I failed is I just read it and go, oh, yeah, reprogram the mag stripe.  Of course.  



STEVE:  Okay, that's No. 1.  No. 2 is on Kickstarter.  And it's called Loop.  I have a problem with the fact that they acknowledge it only works 90% of the time.



LEO:  Oh, boy.



STEVE:  So it's like, well, okay, but that's bad.  But what it is, is again clever.  So what we know about a mag stripe reader, and I'm sure all of our tech-y listeners know this, you look in that little slot, and you see a magnetic recording, or in fact reading...



LEO:  Read head.  A read head, yeah.



STEVE:  A read head, yeah.  And you can see it.  And so that, I mean, I often look in to make sure I've got the card oriented right because you want the stripe side of your card to be facing the read head.  So what we know about - and people who remember that animation I did, that JavaScript, when I was playing with JavaScript animation, showing magnetic flux reversals and so forth, and obviously I've spent some time thinking about the way hard drives read and write.  You have, on the stripe, you have reversals of magnetism on that stripe.  And that induces a magnetic field in the windings of the read head.  This read head is like - think of it as a very sensitive magnetic microphone.  And so the completely passive, simply magnetized stripe is able to essentially send a signal into the read head, which it picks up.  But so could an inductive coil.  And that's what these guys have done.



LEO:  Ho ho.



STEVE:  So they have either a back that you can add to an iPhone containing an inductive coil, or a fob that you plug on, again to the headphone/microphone connector, that contains the inductive coil.  So the idea is you, again, you select a credit card.  And so now you're at the supermarket, and you're standing in front of the little swipe-your-card terminal.  Instead, you bring your phone within an inch of the slot and press a button, and it sends the magnetic signal that the card being swiped would send magnetically across the air gap to the head, which picks it up.  So, very clever.



LEO:  Yeah.  That's neat.



STEVE:  Yeah.  Now, the problem is...



LEO:  Only works some of the time.



STEVE:  Yes, 90% of swipe pay terminals.  So they say, oh, now you don't have to carry your credit cards with you.  Well, yes, you do, for the 10% when it doesn't work.



LEO:  Well, and the 50% of the time when the clerk says, "What are you doing?  Get away from my terminal with your phone."



STEVE:  Well, and you can't give it to the waiter in the restaurant.  You don't want to hand your phone to him.  Oh, it's unlocked, and here you go.  Go hold this near the terminal.  It's like, uh...



LEO:  The other problem I have with both of these is it's kind of solving a problem that doesn't exist.  Is it really such a pain to have a credit card?  I don't...



STEVE:  Well, that's just it, too.  I have a main card and a couple backups.  But that..



LEO:  Yeah.  You carry a wallet anyway; right?  Just keep a credit card in your wallet.  What are they solving?  What massive problem - and I can't believe they raised $123,000 on this.



STEVE:  I know.



LEO:  This is my big problem with Kickstarter.



STEVE:  They wanted a hundred grand.  They got 123,788 when I checked.



LEO:  Unbelievable.



STEVE:  Apparently it's two veteran charge card guys.  One of the guys pioneered mag stripes.  It's like, that's - maybe he's looking for...



LEO:  Well, that's neat.



STEVE:  Yeah.  I mean, so they've got their tech down.  Anyway, it's cool on Kickstarter.  It's Pay with Loop, for anyone who's interested in taking a look at it.  And of course the other problem is that you need to then have this bulky back, you have like this bulky case for your iPhone which doubles as, like, a backup charger because they thought, well, let's give it some more functionality because otherwise we're asking a lot.



LEO:  Which is worse, carrying a wallet with some credit cards or a bulky back on your iPhone?



STEVE:  I know.



LEO:  I just am baffled by...



STEVE:  I know.



LEO:  And this is my problem with Kickstarter is I think people are a little bit suckered sometimes by this stuff.  But anyway, okay.  Well, thank you for the analysis.



STEVE:  Yeah.  So we've got two interesting...



[Talking simultaneously]



LEO:  ...to know about it.  Yeah, they're interesting.



STEVE:  Two interesting payment solutions.  Oh, a bit of errata from last week.  Elaine wrote:  "Steve, you may have had feedback on this already, but you accidentally named PandoDaily as the fraudulent bitcoin exchange, rather than as the high-tech newsletter than ran a story about the fraudulent Chinese bitcoin exchange GBL."



LEO:  Oh, golly.  Sorry, PandoDaily.



STEVE:  Yes.  So sorry, PandoDaily.  She said, "I played with it in the transcript" - so thank you, Elaine, for correcting it preemptively.  She said, "but you might need a verbal correction."



LEO:  There you go.



STEVE:  So, done.  She said, "Just mentioning it now because I'll have forgotten all about it by tonight when I send the transcript."  So she sent me a little piece of email right when she encountered it and said, whoops, might want to fix that.



My iPad mini arrives in two days, Leo, on Friday.



LEO:  Wow.



STEVE:  So I'm excited for that.  I've not seen any mini retina, so I'm very anxious.  I did go by my local Verizon store and look at the current mini, which, boy, does it look grainy.  Oh.  We're all - that's just like how did we ever look at this and think this was good?  Wow.



LEO:  I have two minis.  I like them a lot.  Although it's interesting, the guys at DisplayMate have done color accuracy analysis, and because Apple's decided to go with this indium gallium zinc oxide technology, IGZO, instead of a more traditional LCD technology, they say the color gamut's not so good.  In fact, they're beaten pretty handily by the Nexus 7 and the Amazon Kindle Fire HDX.



STEVE:  I don't care about that at all.



LEO:  I don't think you care about that.



STEVE:  No.



LEO:  The crispness is very nice.



STEVE:  Oh, I can't wait.  And, now, I also just yesterday picked up the rumor of next year a 12.9" display iPad.  You've no doubt seen word of that?



LEO:  Yeah, we've heard the rumor, the iPad Maxi, or the maxi pad.  But, you know, I'm not sure I buy that.



STEVE:  Well, and for me, the use case would be, I mean, I've got one of my iPads sitting next to me, like where I watch TV.  And I'm grabbing it all the time to look things up or to check things, or what's the weather, what's the movie schedule, blah blah blah.  So I could see a larger pad that was deliberately non-portable.  I mean, it almost doesn't need to have a battery in it.



LEO:  Yeah, but you bought Kindle Fire DXes, too, which have since been discontinued because nobody else wanted them.



STEVE:  Oh, I love my DXes, Leo.



LEO:  Yeah, but I don't think anybody bought them because Amazon's not making them.  So, yeah, I think this is a rumor.  But you know with Apple rumors one never knows.



STEVE:  So I wanted to also just mention that my recommendation of Incipio DualPro case got a huge amount of positive feedback.  They began to arrive, apparently from my mention last week, people started getting them in the last couple days.  And many people said thank you, thank you, thank you.  One person, Rick, tweeted, and his Twitter handle is @slartibartphast, or so...



LEO:  You know where that comes from; right?



STEVE:  We know where that comes from.  And he said:  "Steve, oh, Steve, iPhone since 3, never a case, never dropped."  And then he said, "I also hate plastic on couches."



LEO:  That's what I liken it to, but...



STEVE:  So, I mean, and I totally understand.  The phone by itself is just exquisite.  But I just - it is trying to leap from my hands.  It's trying to increase its level of entropy.  So I just don't want to let it.  I did have some people saying, asking me, what do I like for the iPad?  And something I've never mentioned before that I really like is something called a GelaSkin, G-e-l-a-S-k-i-n.



LEO:  Oh, yeah.  You sent me one.



STEVE:  Yes.  I'm a huge fan, huge fan of the GelaSkin.  It is an - I even - here's one on my iPad 1 that I have.



LEO:  Pretty.  That's Keith Haring.



STEVE:  Yup, exactly.  They have real artists, a huge selection of skins.  And so what this is, for people who can't see, it's a sticky, but it's removable, a relatively thick and tacky backing.  So I put it on the backs of the Pads, and I have it on my Kindles.  You can get it for phones, Kindles, iPads, iMacs, all range of different devices.  So it gives it a really interesting sort of - you can be making a statement with it.  "Stay calm and carry on" is one that they've got, and many others.  But it's grippy.  So it gives you some sort of a tacky back.  It's sticky enough that, for example, you could just hold - you just put your hand behind an iPad, and it'll just stick to your hand without slipping, which the metal backing wouldn't otherwise.



Anyway, so check out GelaSkins.com.  They're not inexpensive, but they last forever, and you can peel them off and remove them.  So it's not like political bumper stickers that you end up advertising the candidate who lost, to your embarrassment, for...



LEO:  You sent me, yeah, you sent me these for my Kindle, way back when.  But they didn't do cases back then.



STEVE:  Right.  And so I like those guys a lot.



LEO:  Yeah, neat.



STEVE:  And, oh.  I also wanted to mention, just for people who don't follow me on Twitter, I often get questions from people that I'm happy to respond to except I have, I don't know, many thousands of listeners now, 30-something, and so I just can't do @ mentions back.  I don't feel like I can do that, or my Twitter feed becomes conversations with people rather than sort of announcement stuff that I want to keep.  So for what it's worth...



LEO:  Little tip, though, Steve.  Little tip.  If you have at the very beginning of your tweet the @ sign, if that's the first character, then the only people who will see your @ reply are people who mutually subscribe to both of you, and of course the person you're responding to.  It does not enter your general feed.



STEVE:  Oh, no kidding.  So when people are sending me @SGgrc's, that's not going out on...



LEO:  If it's the first character.  If it's the first character, it's only seen by people who subscribe to the two of you mutually, and both parties.  That's why sometimes you'll see a tweet with a dot @.



STEVE:  Yes, yes.



LEO:  That's intended to make it public.



STEVE:  Oh, because then the @ sign is no longer first.



LEO:  If the @ sign is first, that's what happens.



STEVE:  Okay.  Well, thank you.  Thank you, thank you.



LEO:  Now, of course you can, if you - yeah.  But that's, now, if you go direct...



STEVE:  So why have a DM, then, if you have that, which seems the same?



LEO:  Well, DM is a step farther because DM's only seen by the two parties at either end.



STEVE:  Ah, purely, purely private.  Okay.  So people sometimes respond to me.  I'm unable to DM you.  And I'm thinking, well, yeah, sorry, but I'm not following you.



LEO:  Because you have to follow them; right.



STEVE:  Okay, cool.  Well...



LEO:  You don't want DMs.



STEVE:  Now I'll be able to reply to everybody without worrying about it messing up my Twitter feed.



LEO:  Yeah, it's kind of - that's what Twitter did kind of for exactly this reason.



STEVE:  Neat.  I like that.  So Mike Willis, tweeting as @mikewillis, or Wills, sorry, Mike Wills said:  "Based on @SGgrc recommendation, I'm running SpinRite on my wife's laptop to get the HD in prime condition again.  And I just - I thought this was a perfect segue because I did see, I think, an increase in SpinRite sales after talking last week about, first of all, sharing the testimonial where that hugely damaged drive, that laptop was recovered by SpinRite, and got back data, corporate data that was otherwise in great danger.



But this notion of preventative maintenance, I also, in the last week or two maybe, there was someone who was running SpinRite on a brand new drive.  Oh, I remember, it was forwarded to me through Greg because he had some other detailed questions about SpinRite, so Greg forwarded it on to me.  But he bought a brand new drive and didn't - he hadn't run across the SMART page.  In the last few months I wrote - well, more than that, but relatively recently, I did a couple pages that it clearly explains SpinRite's SMART monitor, the Self Monitoring Analysis and Reporting Technology, SMART, and how there are some bars which get pushed down to reveal red.  And that's not good when that happens.



And so this guy had a brand new drive that he ran SpinRite on, and three of the bars got pushed down.  And it seemed to be generating lots of seek errors and lots of corrections, more than he felt comfortable with.  So he returned the drive.  It was replaced with one.  And when he did the same thing, the bars did not get pushed down.  So this is one of the coolest things, I think, about SpinRite 6, is that it's nice to have the SMART stuff there.  But it really only means something when the drive is under load, when the drive is being asked to do work.  That's when the drive notices that it has problems that it wouldn't otherwise notice.



And so what you want is you want this nice synergistic combination of SpinRite putting the drive under load, constantly reading the drive's SMART feedback, and showing it to the user.  So the drive is seeing that it's having problems because SpinRite's asking a lot from it.  And the drive is - these bars that are being pushed down are the SMART parameters which are being suppressed, or depressed, by the work.



So if people already own SpinRite, and you haven't run it for a while, I mean, it is tremendous preventative maintenance.  But while it's running, or maybe after it's been going for a while, switch to the SMART screen and make sure that you've got green, or I think it's maybe cyan all the way across, and no red showing, because you want to get the red out.  You shouldn't have red there.  And if you're interested for more, I do have some documentation on GRC.com that shows a screenshot of this that I've highlighted sort of with, like, callouts, showing where all these things are and what they mean.



But anyway, this guy replaced his drive.  And when he did the same thing, the second drive did not have its bars depressed because that drive's SMART system was not being surprised by the drive's brand new condition being untrustworthy.  So many people say they run SpinRite on brand new drives before they deploy them, which this is exactly why you would want to do that.  So it certainly does make sense.  And we hear from people all the time, SpinRite owners, of course you can't prove a negative, but they're saying people's hard drives all around them are dying, but they run SpinRite preventatively, and they've never had a hard drive die on them.  So we don't know that it's SpinRite, but it seems pretty likely that it is.



LEO:  All right, Steve.  RADIUS.  This came from a question about another one of our sponsors, proXPN.



STEVE:  Well, actually - yes, yeah.  Many, many - I'm sorry.  I didn't mean to cut you off.



LEO:  Go ahead.  Go ahead.



STEVE:  Many people have - I've seen tweets where I've been mentioned in Twitter where they've been responding to proXPN saying, wait a minute, 12 characters?  What kind of security is that?  Come on, get real.  I'm using proXPN for security, and you guys apparently have lousy security.  And proXPN responds and says, well, no, we're using RADIUS.  So that's a limitation of the RADIUS setup, but that's not bad.  And so finally I thought, okay, look, I'm just - let's talk about this because it's something we've never discussed on the podcast.



To give you an idea of how venerable RADIUS is, it is an acronym.  RADIUS stands for Remote Authentication Dial-In User Service.  So this dates back 22 years, to 1991.  And probably the best way to think of a RADIUS server is sort of similar to DNS, in the same way that DNS is used by clients to look up the IPs of websites using their domain name.  And in that sense the DNS service is centralized, that is, people all over the place can use that server to perform their lookups.



RADIUS provides an authentication service, a username and password authentication service.  And again, it's centralized.  It uses UDP protocol by default, just like DNS does.  And there is a packet-level specification.  And the one place users may have seen it is in their own routers because, for example, in a corporate environment, a corporation might have WiFi routers scattered all over the facility, many of them, on all the different floors, in order to get blanket WiFi coverage.



Well, it's obvious - well, several things are obvious.  First of all, in that setting, you would not want to have a single username and password or a shared key because then all the employees would have to be using the same shared key, preshared key.  And changing it would be horrendous, if you ever needed to change it for some reason.  And when an employee left the company, they would leave with the knowledge of what the preshared key was that they had to put into their laptop once, and that's a problem.



So there's a different model, for example, in this mode of how to authenticate users to WiFi.  And that is, every single one of those individual WiFi routers, running just like the WiFi routers we all have at home, instead of using a preshared key, you use RADIUS.  Sometimes it'll say RADIUS and give you a field to put in the RADIUS IP.  And this is exactly like DNS, where you put in the DNS server IP.  Or maybe it'll say WPA Enterprise, or WPA2 Enterprise.  And what that Enterprise typically is, is code for a centralized authentication service.



And so what happens in this mode, in this multi-floor corporate environment, is somebody walks in with their laptop, and they want to associate with the router, the WiFi router nearest to them.  The router doesn't contain, itself, a database of every username and password within the whole system.  And so obviously, if we're going to move away from everybody having the same preshared key, what we do is we switch over to a model where everyone has their own username and password for logging into the corporate wireless network.  But now you have another problem.  If every user has their own username and password, and a given user is at a single access point, what is it going to have?  The database of the entire company directory?  No.



And first of all, these are little tiny underpowered sort of embedded devices.  They don't have the local storage to store the whole database in order to provide local authentication of every corporate customer who might come to them.  Instead they pass that on.  In the same way that they don't have all of DNS, they don't have any, in fact, of the accounts for the corporate environment.  They use RADIUS.  RADIUS is the standard in the industry.  Routers understand RADIUS, switches, port forwarders, all kinds of equipment knows RADIUS.



There is something called FreeRADIUS - it's probably .org, but if you just Google "FreeRADIUS" you'll find it - which is a terrific open source implementation, and free, obviously, of this RADIUS service, which has grown over the last 22 years.  And, I mean, it's RFC-crazy, with a whole series of RFCs that have been updated over time as the technology has evolved from the original dial-in approach to VPNs and networks and tunnels and crypto and everything that we've got.



But so, and back to our corporate model, somewhere IT manages a single RADIUS server which is on the front of a database.  And this could be a SQL database.  It could be LDAP.  It could be a flat file, any kind of database that RADIUS understands.  And today's RADIUS servers understand how to talk to all of these.  And so the user wants to authenticate with their own unique username and password.  That's given to the local WiFi router or hotspot.  It then knows the corporate IP of the corporate RADIUS server.  It encrypts the username and password because it has a preshared key with the RADIUS server.  So it encrypts that over the network.  The RADIUS server receives it.  It turns around, does a database query to say is this user authenticated, and there's lots of granularity.



And this thing is, like any spec that's been around for 22 years, it does all kinds of other things, too, that the IT may want.  It also does accounting, is another facility, not just authentication and authorization, but also with accounting of how much bandwidth or how much time and so forth, depending on what the company wants.  So the RADIUS server looks it up, turns around and sends another packet back to the endpoint saying, yes, this user is authenticated, or no, they're not.  And the connection goes from there.



So now the same model, exactly that model, similarly makes sense in a global setting, where any entity like proXPN that has servers deliberately scattered around the world has a single customer base, that is, a single set of authorized users who are able to log into any of those VPN endpoints.  Identical model.  So proXPN manages this single database, which is their customer or account database, that has a RADIUS server on it.  And similarly, all of the access points spread around the globe, when an individual connects to it, they authenticate with their credentials, their username and password, for proXPN.  The radius client that's running in that VPN endpoint sends a UDP packet, after encrypting it, down to the centrally located RADIUS server which looks the user up and then decides whether this is somebody they know, sends it back to the RADIUS client, that then authenticates the user and allows them to establish a VPN tunnel to the endpoint.



So with a 12-character maximum length - which I won't defend the fact that that's not long.  We all know that's not long.  But the nature of the lookup process means that anyone trying to attack this is necessarily, unless they were to hack proXPN's backend database, is inherently doing an online attack.  So you'd have to guess the password, and then that goes to the VPN endpoint that sends the UDP packet down to the server, which makes a database query, looks it up, says nope, wrong, bad guess, sends that information back to the VPN endpoint that then says, sorry, we can't authenticate you.  There went one guess.



Well, so that just makes brute-forcing RADIUS-based passwords virtually infeasible because it's got to be an online attack.  They allow upper- and lowercase of alpha AZ.  So that gives you 52 characters, plus 09, so that's 10 more.  So now we're at 62, plus !, @, #, and $.  So that's four more.  So we're now at 66-character alphabet.  So a 12-character password with a 66-character alphabet, assuming good entropy, that is, that you arrived at it randomly, gives you 6.8 thousand billion billion passwords.  Which is a lot of passwords. That's 72.53 bits of entropy, which is not 128, but 72.  And for online attacks, that's way more than enough.  It's certainly the case that they need to have good security and protect their backend and their database.



But finally, I'll just remind everyone, as I did mention at the top of the show, that this is more to protect them.  Users are not storing anything in a proXPN account.  This is them, this is the user gaining access to the account.  And if the worst happened, and someone was abusing a password that escaped from them, well, they could change their password, or they could contact proXPN and say I think my account's been hacked, set me up with another one.  So the whole notion of logging in with an authenticated account is to protect proXPN from abuse of their global network, rather than the user.  Again, it's not like the model where you're wanting protection against cloud access to all of your cloud-stored files.  All you're doing is you're saying this is really me, somebody who has an account.  So let me connect to your server.



But anyway, so I wanted to clarify that, to respond to all the tweets that I've seen from people who are annoyed by the fact that there's a 12-character limit.  I don't know any details about the backend database, the details of RADIUS, why they chose a 12-character length.  Probably it's just that they recognize an online attack is infeasible.  They've got sufficient security for their own needs on the back end.  And using RADIUS is what's going on.  It's very different from a single website which is, as we know, storing characters, or could be storing characters in an insecure fashion, and damage could be done to us if our account were hacked on that one web server.  Instead, RADIUS is used to distribute authentication.  And we're using it to gain access to their VPN network.  So it's not a problem, although it's something we've never talked about before.  So I just felt like it was a loose end.  And that's how RADIUS works.



LEO:  Is it widely used?



STEVE:  Oh, my god, Leo, it is everywhere.  I mean, it's funny, too, because we see DNS because it impacts end-users.  I think we've never talked about RADIUS because it's just never had an impact on most of our customers.  And in fact that's why I was moved to talk about it was because it's RADIUS, remote authentication, or distributed global authentication, which is like poking itself out into the user's experience through proXPN's use of it.  But otherwise, yeah, we just never encounter it.  I'm sure that lots of our listeners who are in IT go, oh, yeah, we got RADIUS.  That's the way everything authenticates within our entire corporate network.  Probably every corporation, if they're not using some proprietary Microsoft active directory solution, RADIUS may well be what they're using.  And because, I mean, it is the standard.



LEO:  It's a Cisco solution.



STEVE:  Cisco adopts it.  Nobody owns it.  So Cisco's just one of many people who have it.  In fact, I have a note here in my notes where I was looking up, just sort of getting a sense for it.  Cisco says:  "DHCP Server RADIUS Proxy."  They said:  "The Dynamic Host Configuration Protocol (DHCP) Server RADIUS Proxy is a RADIUS-based address assignment mechanism in which a DHCP server authorizes remote clients and allocates addresses based on replies from a RADIUS server."



So there's an example where RADIUS is the backend, and the DHCP server is making RADIUS queries to a RADIUS server.  And so essentially RADIUS is the database that DHCP is drawing on, rather than DHCP server having the database itself.  I mean, so this is just pervasive within enterprise-class IT.  RADIUS is what everyone is using.



LEO:  And is it the case that a bank wouldn't want to use it, or somewhere where you are trying to protect something behind that password?



STEVE:  Oh, yeah.  I would think banks probably are using it to authenticate all their own employees.  But it wouldn't make sense to expose it to the world.



LEO:  On the web, yeah.



STEVE:  Exactly.  Exactly.



LEO:  So this is a specific reason, is because you're logging into an account at proXPN.  You're actually getting on their network, in effect.



STEVE:  Yes.



LEO:  So that's a logical thing for them to use.



STEVE:  Well, and if they didn't do this, then they would have to have some database replication technology.



LEO:  Which could be, as we have learned from Google, more of a problem.



STEVE:  Exactly.  Where every one of their globally located VPN endpoints would have to have the entire database of all their customers, and then they'd have to be keeping that current all the time.  Whereas, by using RADIUS, their database is in one location.  And when, as customers come in and go out, they're immediately authenticated or deauthenticated across the entire network.  It's just - it's very cool.  And that's - it's been going on silently in the background of the Internet for 22 years.



LEO:  Wow.  Steve Gibson explains all.  He knows all.  And you can follow him at GRC.com, that's his website, where SpinRite lives, the world's finest hard drive maintenance and recovery utility, and all the freebies he gives away all the time.  You can also follow him on the Twitter, @SGgrc.  You can also ask questions at GRC.com/feedback.  Next week, if all goes well, a Q&A episode.



STEVE:  Unless something catastrophic happens.



LEO:  Unless the world ends.  Or something less than that.  What else?  Oh, yeah, if you go to GRC.com, Steve has 16Kb audio of the show, the smallest version of audio for the show, as well as transcripts, which are the smallest version of all, for your perusal.  We have higher quality audio and video available at our site, TWiT.tv/sn.  You can watch us do the show live, every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, that is 19:00 UTC.  And it will be changing, as I mentioned.  January 8th we will shift to a new time.  Tuesdays at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC will be our new time starting January 8th.  Just a little program note.  What are we doing for the holidays?  You said you had something planned, I think.  Last year we did the Portable Dog Killer or something.  No, you played a tape, an old tape.



STEVE:  Yup.



LEO:  So start thinking about it.



STEVE:  Yeah, I will.  I have all of the original appearances that I made on The Screen Savers.



LEO:  That would be fun.



STEVE:  You and Kate Botello and...



LEO:  Yeah, Trouble in Paradise.



STEVE:  Kevin was about nine years old.



LEO:  Click of Death.



STEVE:  Uh-huh.  Yeah.  So I thought maybe I'd put those together, and that would be fun.  Another blast from the past.



LEO:  We're trying to get to know our users.  Don't forget our survey, TWiT.tv/survey.  And if you've taken it already, our hearty thanks to you.  And we are looking for people for New Year's Eve.  We're going to do a 24-hour of New Year's.  Steve will be with us in-studio for that, at TWiT.tv/nye, if you'd like to participate.  We want countdowns all over the world for 24 hours.  Thank you so much, Steve.  Always a pleasure.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#432

DATE:		November 27, 2013

TITLE:		Coin, CryptoLocker, Patent Trolls & More  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-432.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Following another week overfilled with interesting security-related news, Steve and Leo spend an hour and a half diving deeply into an updated (and likely very close to correct) understanding of the Coin payment card, news on the CryptoLocker front, a close look at a patent troll case that has so far gone the wrong way, and much more.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, and there's so much security news that we're going to defer the question-and-answer segment for an episode or two and just get to some of the big stories, including a second look at Coin, Bitcoin - the other coin - and a whole lot more, all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 432, recorded November 27th, 2013:  Coin, Patent Trolls, and More.



It's time for Security Now!, the show where we explain your security, your privacy, and how the Internet works and all that jazz with this guy right here, the Explainer in Chief, Mr. Steven "Tiberius" Gibson, creator of SpinRite, the world's finest hard drive and maintenance utility; coiner of the term "spyware," author of the first antispyware tool.  He's a maven; he's a connector; he's a Grand Poobah.  I'm wondering how long I can keep talking without him saying, all right, enough.



STEVE GIBSON:  Okay, Leo.



LEO:  [Laughing] Hi, Steve.



STEVE:  Hi, Leo.  So this is another one of these weeks.  As I was putting things together, I thought, why do I feel apologetic that we're not having a Q&A, when we have just too much really interesting stuff to talk about?  I threw away about half of the things I wanted to talk about - actually I pushed them into next week to see how that goes because there was just - there was too much that happened.  And as I was looking at some of these things, there are some things I want to really spend some time on.  And I really think the podcast serves our listeners better if we do fewer things in greater depth...



LEO:  I agree.  I agree.



STEVE:  ...that you can only get here, rather than just...



LEO:  Shallow you can get anywhere.



STEVE:  Right.



LEO:  Let's get deep.  Let's go deep.



STEVE:  Right.  So we got some really just, you know, a great podcast, nominally a Q&A, but, sorry.  What's happening is I did follow your advice, by the way, and have completely fouled up my entire Twitter feed.



LEO:  I saw all those @replies.  Did anybody get angry at you?



STEVE:  Only a couple people were grumpy because they liked using - they liked to be able to use my feed as sort of an archival...



LEO:  There's a setting that they can - oh, well, I'm not going to - they can figure it out.



STEVE:  Yes.  And but the overwhelming majority of people really like the fact that I'm doing @replies because...



LEO:  It's so cool that you're responding.



STEVE:  Well, I mean, I always have been.  I've been doing this, but I've been doing it with DMs, so no one was ever able to see the fact that I was actively replying to questions that were coming in.  So, yeah.  I think this is an improvement.  It does foul up that cool timeline that someone was maintaining.  So what I'm going to end up doing is, once I get SQRL and SpinRite behind me, something I want to do then is to put up a filter page, essentially a filter page at GRC so that my statements in Twitter can always be found in once place.  So that way we sort of solve the problem.  As I understand it also, verified accounts have the opportunity of having that setting you were talking about, Leo, but not the...



LEO:  Oh, you're not verified.  Oh, ho ho ho.



STEVE:  Nope, never been.  So that's the other thing I want to do is see if I can get Twitter to verify me, in which case people would be able to use that setting in order to not see the conversations.



LEO:  Right, right.  With me they can leave off the @replies.  Got it.  I didn't realize...



STEVE:  It's because you, Leo, are...



LEO:  ...I have something special.



STEVE:  You are one of a kind.



LEO:  You can always, well, there's also Gina Trapani's ThinkUp, which will allow you to track stuff.



STEVE:  Well, any client, any client will allow you to do this, too.  I mean, it's only people who are looking at the raw feed, looking at my so-called "timeline," that now see all the interaction.  But, I mean, really it's been a huge win.  And I was just teasing when I said I followed your advice and fouled up my timeline.



LEO:  Well, there's a lot on it now, which is good.  Which is good.



STEVE:  And it was always there, it was just all private.  And now it's public.  And people are loving the fact that they can follow conversations that I'm having with other people.  So it's like, yeah, I've been this active, but it was just on the DL.



LEO:  Yeah.  Sure, yeah.



[Talking simultaneously]



STEVE:  So today...



LEO:  ...bother me, but I guess...



STEVE:  ...we're going to talk about Coin again, Take 2 of Coin because now I've figured out what they're actually doing.  And that picture that you can see on the page reveals it.  We've got a big CryptoLocker update.  And GRC is now offering CryptoLocker for forensic experimentation and download.



LEO:  Oh.  You have a few lying around, huh?



STEVE:  The EFF is tracking who's encrypting what.  There were massive man-in-the-middle attacks on the Internet, or not, maybe.  Who invented public key encryption?  And a look at a very high-profile patent troll case, and much more.  So a great podcast.



LEO:  I know where you're going with that one.  All right.  Where should we start?



STEVE:  Okay.  So we've got to revisit Coin because I was wrong in my clever guess...



LEO:  Such good detective work.



STEVE:  ...about the idea that they were proxying.  If it was impossible to change in some manner the signal that the strip, the mag strip is generating, then my approach was the only feasible one.  Turns out that there is something that you can do.  You're not actually rewriting the mag strip because that seemed unfeasible.  But I ran across a photo of the very first prototype that Coin's inventor created.  And it's in the show notes.  You can show it during the podcast now, Leo.  And the moment I saw that, it's like, oh, okay.  Now I know how it works.  Even complete with an Arduino sitting there wired up next to it.



LEO:  Coin is really a sideline to what they were planning as a startup.  They wanted to license this Arduino technology.



STEVE:  Oh, okay.  Well, it makes sense.  I bought one for 50 bucks, prepurchased.  You've got 17 days now remaining for their 50% discount.  Then the price doubles to a hundred dollars.  And I don't have a need for it, which is why I'm not as excited about it as other people.  I will probably delaminate mine just because I want to completely end the mystery, and I'll show everybody the inside of mine.



But so the idea is that there is a coil in the card, and probably, maybe, there are some contacts in the card, maybe an inertial sensor so that it knows when the card is being moved and to what degree.  But so essentially it's very much like the second Loop product that we talked about last week, where those guys had a magnetic coil, thus a loop, attached to a smartphone, and they would bring it within proximity of the reader, and it worked in 90% of the readers.  Basically, it was an induction coil inducing a sympathetic current in the read head, which the point-of-sale terminal could not differentiate from the card being swiped.  So this is essentially the same technology, but they've bundled it into a credit card format and given it battery power that lasts a couple years and some smarts.



So the idea is, as you swipe it, it uses an alternating electrical field through a coil to produce an alternating magnetic field across the entire extent of the strip.  And that's sort of the clever part is it doesn't really matter physically where the card is.  The whole strip is simultaneously generating the same magnetic field.  But if it were a fixed set of reversed magnetic domains, then you would have to be moving the card.  Here you don't technically have to be moving the card because the whole strip is generating the same field.



Well, now, that, then, as I was reverse-engineering this with scant documentation, then the question is, okay, wait a minute.  A card actually has three stripes, that is, there's one large magnetic strip, but within that are three tracks, in the same way that a cassette tape used to have - it would have two stereo tracks on one side of the tape and two other stereo tracks on the other side, so a total of four tracks.  And so you'd listen to stereo on one side of the cassette, then you'd flip it over and listen to stereo on the other side.



So these magnetic tracks are - they're immediately adjacent to each other.  They're .11" apart and .11" wide.  So the question is, wait a minute.  If the card has three tracks, that is, a regular magnetic card has three tracks, but we only have the ability to essentially simulate one, how does the mag strip reader know which one we're generating, and how do we determine which one we want to generate?



Well, it turns out I tracked down the ISO IEC specification.  It's ISO 7811-2.  And there's, like, 7811 is the overall spec, and then there's dash one through, I think, six or seven, which are sort of the sub-specs because all of this is covered with a set of standards so that all the credit cards are the same size; they're the same thickness; you have interchangeability; there's broad global agreement, thankfully, so that we have, like, one standard for those so-called ID cards.



And in fact, immediately upon hearing my original theory for how this worked, a listener wrote back, tweeted me and said, wait a minute, that could work for major credit card companies, but how would you handle loyalty cards and essentially local use of cards, not global financial clearinghouse?  And they were, of course, completely correct because the idea is that this can do all of that.  So these three tracks differ dramatically in their density and format, the type of data they contain.



There's an alphanumeric track, so-called Track 1, which is 210 bits per inch of data, carrying 7 bits per character, where that's 6 data plus a parity bit.  And that basically gives you uppercase alphanumeric and a whole raft of special symbols, some of which are reserved.  And as the spec says, the maximum character count consists - or the stripe contains data, control, start-and-end sentinel characters, and then a longitudinal redundancy check character, that altogether will not exceed 79 characters.  So we have an alphanumeric strip, 210 bpi, that can hold 79 characters.



Then there's a numeric track which is a lower density at 75 bpi, so essentially a lower frequency of recording.  And that's strictly numeric.  That's 5 bits/character, and it's allocated as 4 bits of data plus parity.  Of course 4 bits of data only gives you the numbers plus a few special characters, all of which are reserved for control characters.  That's the second track.



Then the third is a higher density, but also numeric track.  So that's back up to 210 bpi, 5 bits/character, 4 for data, plus one for parity.  And that can contain 107 characters.  So that's the largest number of characters because they've sacrificed the number of bits per character running at just 5 rather than 7, as is the case for the first track.



So three very different track formats.  Each of the characters has a parity.  And then the key is there's this - there's error detection.  We have, as I said, within each character, we have a parity bit.  But then at the end of the entire track, there is what they call a "longitudinal redundancy check," an LRC.  And it's nothing but even parity for all of the bits in that bit position.



So, okay.  So visualize it this way.  Imagine that we took the characters, whether they're 7 bits or 5 bits, and we printed them out in binary, 01, 110, 011 and so forth, and then stacked them on top of each other so that we created a matrix of ones and zeroes, where the characters are on the horizontal, running down vertically.  But that would mean that the parity bit would be the parity for the row.  Well, then, the longitudinal redundancy check is the parity for the column.  So it's one character at the end which creates even parity for the column.  And here's the key:  If the terminal doesn't see an error-free read in both horizontal parity and essentially longitudinal or vertical parity, it simply rejects that track.  Which means that the transmitting technology is able to decide which one of the three tracks it wants to send, and then it arranges the error correction, both senses of parity, so that it's correct for that track.



Well, there's no way it could ever also be correct for the other two.  So essentially all three tracks will receive the same data.  But it will only be error free for the one it was designed to be targeted to.  Thus this single card is able to generate data for any of those three tracks.  And I don't know whether cards ever use two tracks at once, that is, for alphanumeric and numeric at the same time.  They wouldn't need to.  For example, just Track 1, which is alphanumeric, that could contain your name, the card number, the expiration data and so forth, easily, all together, just on a single track.  So it's probably the case that Track 1 solves the problem.



I didn't go any further to look into the international standards of actually what type of service used which tracks.  But that answers the question convincingly, I think, about exactly how this technology works.  It's basically very similar to what Loop does, but they manage to cram the whole thing into a credit card that lasts for a couple of years, which I think is very cool.  And whereas Loop is only able to achieve 90% compatibility, this presumably could be your hotel keycard, your loyalty cards, virtually anything.  It's able to emulate the magnetic strip on standard ISO format cards.  So I think now we know.



LEO:  Yeah.  I still wouldn't spend a penny on it; but, hey, whatever.



STEVE:  Well, it's just, yeah, it's not a problem that I have.  I've got one card, and it works just fine.  And many people said, wait a minute, mag strips are old news.  Chip and PIN is where the world is going, and this doesn't do that.  So it's like, yeah, that's true.



LEO:  Yeah, although we were also going metric about 30 years ago.  I mean, the U.S. has a long history of being resistant to how everybody else in the world does it.



STEVE:  Yes.  And it's like, okay, what - I guess my reaction to all the people who pooh-poohed this because it wasn't Chip and PIN compatible was, well, I don't have a single Chip and PIN card.  I don't own one at all.



LEO:  Supposedly that's going to happen in 2015.  But again, like I said, we also were supposed to go metric in 1972.  So I don't know.  I don't know if that'll happen or not.  It should happen.  It's a much more secure way of doing things, it's a much preferred way of doing things, and it's how everybody else in the world does it.  But so was metric.



STEVE:  Well, okay, now, if you did Chip and PIN, that is, if you did - how do you solve the problem of giving the waiter your credit card to pay your check?



LEO:  The bill.  In Europe, what they do is they come to your - and I think this is also a very good idea.  They come to your table with a card reader.



STEVE:  Ah. 



LEO:  And you have to enter the PIN.  It's actually - it's called dual-factor authentication, I believe.



STEVE:  Ah.  What a concept.



LEO:  You know, to me, and I've said this before, I'm not going to belabor it, it's a scam.  They're taking a lot of money.  They're spending that money on advertising.  You'll see Coin advertisements all over Federated Media sites like 9to5Mac, everywhere.  Which it's like a pyramid scheme.  I don't think they're ever going to ship a card.



STEVE:  I am also somewhat skeptical, frankly, having looked at the spec, having looked at their - there was one site that I linked to.  Oh, I forgot to tell everybody who's listening that the show notes will return to GRC's Security Now! page.  Now that I've sort of screwed up, and I shouldn't really say that, now that I've changed...



LEO:  Your Twitter.  You screwed up your Twitter.  Go ahead and say it again.  Now that Leo has ruined your Twitter feed...



STEVE:  I'm not longer able to say go look at @SGgrc's Twitter feed because now it's all full of my responses to people who are tweeting me.  Whereas I used to do DMs, now I'm no longer doing that.  So I'm unable to post links in my Twitter feed and use it as my means for communicating show-specific, episode-related links.  Now, it may be that the guy who's aggregating my feed, the guy who's at - I've created a bit.ly for it, bit.ly/SGgrc.  That used to be really cool because he would aggregate them by Security Now! episode.  That's all blown to hell, too, but maybe he'll fix it because he could certainly filter them as I intend to eventually get around to doing at GRC.  So but in the meantime, I'm going to now, since you're showing the show notes anyway on the air, Leo, I might as well post the PDF on the site.  I used to do it a long time ago.



LEO:  That's a great idea, yeah.



STEVE:  But that way everybody gets the links.  So links that I refer to, you can get them by getting this PDF from GRC at GRC.com/securitynow, where everybody knows we have the small versions of the podcast and Elaine's fabulous transcripts.



What didn't fit into the show last week because we had, like, a two-hour podcast, and it ran off the end, but I wanted to mention it because it was a little bit of an update on SQRL also, I got a nice note from a Rick Brooks, who's a listener in Columbia, South Carolina, sharing from October 18th, just last month, his very short note.  He said, "Steve, I just purchased a copy of SpinRite 6 to use on a MacBook Air."  So we know what that means.  That means an SSD.  He said, "...on a MacBook Air that had a dead SSD drive that I had already tried every type of scan I could find and could not get any data.  The machine would not boot up, and the Mac drive utility failed to do any repairs.  This was a friend's machine, and she had her life on the drive with no Time Machine backup.  She was really upset.



"After getting an adapter to convert the drive to use on a SATA interface, I ran SpinRite.  I put the drive back in the machine, and it booted up.  Wow.  I completed a Time Machine backup today, and the laptop is running great.  Thanks for the great software.  Signed, Rick."  And he said, "P.S.:  Please get back to SpinRite ASAP.  I know you're out saving the world via SQRL, but you've got me waiting on the new release.  So please hurry now."



So anyway, I wanted to let everybody know.  Some people have asked, where is SpinRite?  Well, SpinRite is on hold, that is, SpinRite 6.1 is on hold while I nail down the final details of SQRL, this login technology.  That continues to be proceeding very nicely.  We have the syntax completely nailed down and agreed to, and we're now working on the semantics side, the specific, like, error message numbers and the details of the interchange between the client and the server.  As soon as that gets done, I will write a reference implementation that everyone can use to check their own, in their own other languages and so forth.  And then I'm done and back immediately to SpinRite 6.1.  Rick, who owns 6.0, and everybody else who owns 6.0, or who purchases it in the meantime, will get 6.1 for free.  So, and the good news at that point is he won't have to remove the SSD drive from a Mac in order to run it on a PC.  He'll be able to run it natively on the Mac.  And again, free upgrade for everyone.



So, but there's only me, and right now I'm spending full time on SQRL.  And then I will be back to the next phase of SpinRite 6.1, which will be adding the AHCI compatibility so that it runs across all Intel-based machines, and then we'll get it out the door.



LEO:  Neato.



STEVE:  Yeah.  There was an interesting story that got a lot of press and generated a lot of upset that I'm somewhat skeptical of.  We've never covered Border Gateway Protocol (BGP) in detail, mostly because it hasn't been necessary.  We've sort of been able to explain what it is.  What it is, is it's the language which BigIron Internet routers use for exchanging their routing tables and routing table updates.  We've talked often about, in a broad sense, how the whole Internet works by just being this loose coupled interconnected network of routers where, when a packet that is addressed to a certain IP arrives at a router, the router looks at its routing table, and basically the router is like an octopus.  It's sitting there in the middle with a bunch of links going to different places.  And a packet comes into it across one of these links, and the router simply refers to a table that tells it which link to send the packet out of, sort of to send it on its way.



Like the idea is the routing table has a coarse understanding of which link is like the destination lies down.  So because we, for example, with IPv4, we've got 4 billion IPs, there's no way to have, there's no practical way to have an entry for every single IP.  But we don't need that because we know that IPs are allocated in chunks.  So, for example, Comcast will have a big block of IPs.  All of their customers are within a big block of IPs.  So when a packet with one of those IPs lands in a router far away from Comcast, all that router has to see is that, oh, that's owned by this larger aggregator from which Comcast buys a smaller portion of their IPs.  So it goes - so it sort of aims it at that larger aggregator.  So my point is that these routing tables are very coarse for a large percentage of IPs, and only fine-grained when the router is physically closer to the ISP.  It then makes finer grained decisions about where to send it.



So the news that came out was that there was, like, massive man-in-the-middle traffic hijacking going on. Now, unfortunately, this was from a company, Renesys, that sells monitoring and sort of like detection protocol and service for detecting this.  So putting out this press release was sort of like Symantec telling us how bad viruses are.  It's like, yeah, okay, we know that's bad.  But it's also a little self-serving.



Ars Technica picked the story up, which is why everyone was aware of it.  And our illustrious reporter, Dan Goodin, he said, "The ease of altering or deleting authorized BGP routes, or of creating new ones, has long been considered a potential Achilles' heel for the Internet."  And he's certainly right about that.  He said, "Indeed," and we'll remember this because we covered it on the podcast, "in 2008 YouTube became unreachable for virtually all Internet users after a Pakistani ISP altered a route in a ham-fisted attempt to block the service," that is, YouTube, "in just that country.



"Later that year, researchers at the DefCon hacker conference showed how BGP," what we were just talking about, the Border Gateway Protocol routes, "could be manipulated to redirect huge swaths of Internet traffic.  By diverting it to unauthorized routers under control of hackers, they were then free to monitor or tamper with any data that was unencrypted before sending it on to its intended recipient with little sign of what had just taken place."



So what we have is we have relatively good security for BGP, but not perfect.  One of the reasons that we want unpredictable TCP sequence numbers is that routers establish TCP links.  Border Gateway Protocol runs over TCP.  And one of the ways of hacking into a TCP connection is if you're able to guess the sequence numbers in TCP.  Then you can spoof traffic from one or another router, which it will trust because the trust is simply the point-to-point connection between two routers.



But you could, if you can spoof the source IP, which you can do with raw sockets, and if you knew where the sequence numbers were, you could essentially insert your own data into a router's table.  And in fact that was done historically.  It's the weakness that early TCP stacks had, that they had predictable sequence numbers in their TCP communications that allowed this kind of tampering.  So it is inarguable that this is, as Dan writes, one of the Achilles' heels of the Internet even today.



So the evidence, however, because what Renesys wrote was that, since February of this year, 38 distinct events they have detected using their technology, their monitoring technology, in which large blocks of traffic were improperly redirected to routers at Belarusian or Icelandic ISPs.  When they inquired what was going on, they initially didn't receive any response.  And then later, as they were putting this formal announcement together, they tried again, and the response they got was, oh, yeah, sorry about that, we had some bugs in our routers, and we've updated them, and the problems went away.



So I think that's probably the truth.  But whether or not it is, I mean, it seems very unlikely because, I mean, this is very easy to see.  If you did a so-called "traceroute" while this was underway, you would see your packets heading off to Belarus and then coming back onto the Internet and going about their business.  So it's not like this is anything that you can do stealthfully.  This is very obvious to anyone monitoring where packets go on the Internet.



But the takeaway is, yes, we need HTTPS everywhere, all the time, because any nonencrypted traffic is definitely subject to this kind of a BigIron router, not little home routers, but routers that are out there in the middle of the Internet, moving all of this traffic around.  The whole routing table technology, it works, but it was probably meant to be replaced and no one's gotten around to it because it's really not as robust as it could be or, arguably, in this day and age needs to be.



Along the lines of security on the Internet, we've got the news, the good news, welcome news from Twitter that they have implemented forward secrecy for Twitter.com, api.twitter.com, and mobile.twitter.com.  And we know what that means.  That means that somebody decided this would be a good thing to do and, just as I did last week, they reordered the cipher suites which their servers are offering so that they would preferentially offer the ephemeral Diffie-Hellman key agreement suites over the non-use of that, the non-ephemeral suites, which do use the server certificate in order to encrypt the key.



And what they found was, immediately upon making this change, 75% of Twitter's connections began using elliptic curve Diffie-Hellman key agreement.  So that is to say that there were all these clients out there, already using Twitter servers, that were ready to work with that cipher, but they required Twitter to make the change in order for forward secrecy to come up to speed.  And it's now only older clients of various stripe which, you know, 25% making connections which are not using ephemeral Diffie-Hellman key agreement.  So another company takes security more seriously as a consequence of, I mean, a direct consequence of this general hardening that we're seeing throughout the industry.



Which takes me to my next bit of news, is Microsoft has joined the group of corporations who are visibly tightening their security.  Just yesterday the Washington Post carried the story saying that:  "Microsoft is moving toward a major new effort to encrypt its Internet traffic amid fears that the National Security Agency may have broken into its global communications links, said people familiar with the emerging plans.  Suspicions at Microsoft, while building for several months, sharpened [last month] in October when it was reported that the NSA was intercepting traffic inside the private networks of Google and Yahoo!," which of course we've covered extensively, "two industry rivals with similar global infrastructures.  They said top Microsoft executives are meeting this week to decide what encryption initiatives to deploy and how quickly."



And as we'll remember because we've talked about it here, we did see signs of this in the various slides that Snowden caused to be released.  We know, we saw mentioned that Hotmail's address books were being collected.  There were signs of a Hotmail message referenced in one of the slides.  And apparently also Windows Live Messenger was one of the social networking technologies that the NSA were saying that they had access to.  So we don't have any timetable yet, but Microsoft has decided, whoops, we need to follow along.



LEO:  Of course Google's doing it already; right?  I mean...



STEVE:  Yes.  Google, well, Google, they're now working to encrypt their internal links.  I think everybody is scrambling to do that.  It's not an easy thing to do.  But Leo, bring up this chart in the next link here, the EFF?  They have produced a really nice summary of who's encrypting what:  www.eff.org/deeplinks/2013/11/encrypt-web-report-whos-doing-what.



LEO:  This is great.



STEVE:  Yes, anyone can find it, if you google the phrase "encrypt the web report."  So the EFF calls it their "Encrypt the Web Report."  And they are maintaining it.  They've had two updates so far as of this podcast.  And it's a really nice visual grid showing what types of encryption are being done and by whom.



LEO:  You use Level 3, don't you.



STEVE:  Yeah, they're my - I'm in a Level 3 datacenter, yup.  They are.  And they have been implicated in - essentially they're implicated because they are the largest top-level Internet major bulk traffic carrier.  But anyway, so what's interesting to me, for example, I don't know why, but for example in this grid the EFF has a lot of "undetermined" under the forward secrecy column.  They show "encrypts data center links," so who does that; who supports HTTPS, meaning any encryption at all; who supports the strict transport secrecy or security, HSTS; who supports forward secrecy; and, for email, who supports STARTTLS.



And what I don't understand is why they've got so many "undetermined" under forward secrecy because it's trivial to determine that.  I mean, you could just put the various websites into your browser, watch the protocol, or any of the SSL, like the SSL Labs checking website, and you'll immediately determine whether forward secrecy is supported or not.  So that column should easily be filled in with either yeas or nays all across.  But anyway, so it shows Amazon, Apple, AT&T, Comcast, Dropbox, Facebook, Foursquare, Google, LinkedIn, Microsoft, MySpace, Sonic.net...



LEO:  I think that the reason that they say "undetermined" is because these companies haven't responded to the survey.  They're doing this based on asking the companies.



STEVE:  Ah, okay.



LEO:  We've asked the companies what they are doing.  And so if the company doesn't respond, they don't know.  So they're not doing any research on their own.  They're just - this is responses to their survey, EFF's survey.



STEVE:  So better than nothing.



LEO:  Yeah.  Yeah, I mean, I think now that we know Level 3 provided backdoor links, or at least supposedly provided backdoor links to Google and Yahoo! to the feds, and Google and Yahoo! are encrypting datacenter links, I imagine everybody will do the same.  And if they don't, well, that tells us who do.



STEVE:  Well, and this is why I was so bullish from day one on the Snowden leaks.  It's like, okay, this is not good for the NSA, but we need to know what's going on.  And we're seeing the upshot.



LEO:  I mean, you don't have - so the links, we've talked about this before, the datacenter links are database replication, things like that.  No company like Google, of Google's massive size, is in a single datacenter.  So you have to replicate your databases from your datacenter in Seattle to your datacenter in Dallas to your datacenter in Singapore.  And those transports go across the, well, I don't want to say the public Internet.  They go across leased lines from companies like Level 3.  And if the NSA says to Level 3, hey, let's just put a little tap in here, a little fiber optic splitter, oh, and by the way, you can't tell anyone we're doing this, they're going to get everything.  You figured this out, I want to give you credit, long before this came out.  You said they must be upstreaming.



STEVE:  This was the way to do it, yes, exactly.  If, I mean, and this further demonstrates, I think, that those companies were telling the truth.  I mean, there's still this unknown about some of the language in some of the slides which implies that the companies were working, were knowingly working with the NSA.  I don't think we are ever going to know definitively what was actually going on.  But from the outcry from these companies - and remember we've also talked about some of the reactions that the employees have had.  I mean, they were furious when they learned that this was going on.  I mean, they were using words we can't say on the podcast.  So, yeah.  And as far as I know, Google is not yet encrypting their inter-datacenter links.  They are on it.



LEO:  Oh, I thought they were.



STEVE:  No.  No, because that's a big deal.  I mean, they're absolutely working on it hard, as we reported, I think it was last week.  But it's going to take a little bit of doing because it's a big problem.



LEO:  I love it.  And this is always the case, that our local Internet service provider, Sonic.net, my good friend Dane Jasper runs that...



STEVE:  Yeah.  Green all the way. 



LEO:  Green all the way.  And also SpiderOak, which you've recommended before as a Dropbox alternative, green all the way across.



STEVE:  Yes, yes.



LEO:  Yeah, that's good.



STEVE:  And, but on the other hand, so is Dropbox.



LEO:  Yeah, good for Dropbox.  Late to the game, but they did it 100%.  Of course they still have the keys to your data, so...



STEVE:  Yeah.  They are not TNO.  And that's the other thing I wish.  Oh.  Wouldn't it be nice...



LEO:  Where's the TNO?



STEVE:  I know.  Wouldn't that be nice, to have a TNO column there.  But no.



LEO:  Would be nice.



STEVE:  That would be nice, yeah.



LEO:  That's what people have to listen to this show for.



STEVE:  I think at some point I'm going to have to revisit the cloud storage.  I mean, it's a huge amount of work, frankly, to pull all that together, as I did once when we did the big cloud storage provider podcast.  And people are now asking me constantly about this or that instant messaging because, I mean, exactly as we predicted, the upshot of these privacy revelations is a huge influx of new secure services that are being offered.  So it's like, uh, okay.  And people are saying, well, what about this one?  What about this one?  I mean, the problem is it takes serious work to determine exactly what people are doing.  And when you've got someone like BitTorrent not telling you what their protocol is, although there is an open source BitTorrent client...



LEO:  For BitTorrent Sync?



STEVE:  ...for BitTorrent Sync, yes.



LEO:  Ah.



STEVE:  And so that's going to give us - they're reverse-engineering the protocol, and so the open sourceness of the BitTorrent Sync client will give us a wedge into how Sync is working.  I don't think they have it done yet, but they're on the way.



Okay.  So, patent trolls.  We've talked about patents...



LEO:  This made me so sad.  This is the Newegg trial?



STEVE:  Yes.



LEO:  They had Whit Diffie coming in, saying, "I invented public key cryptography."



STEVE:  Oh, well, actually, I sent a link when Ars reported that.  And I said to my Twitter followers, read down at least until - down to.  Anyway, so here's the background.  We've got this guy, Erich Spangenberg, who is - he sets up shell corporations.  He's got nine of them that he owns and apparently a total of 22 of them owned by family members.  And so this one is known as TQP Development.  And it owns the rights to one patent, which has long since expired, by the way.  It's no longer even a valid patent.  So the technology it protects, which was for - it was for modems, back in the modem days, a means of cryptographically protecting the data that modems were exchanging.



And so what's sad here is all of the evidence viewed by somebody, I mean, like viewed by the industry, that knows what's going on, is that the patent was never valid, that what it - the rights that it had granted were already in use and in the public, well, they were already actively in use, thus constituting prior art.  And prior art renders a patent invalid.  I mean, it's prior art technology cannot be patented.  It's why I immediately published the fundamental, and I have continued to publish, all of the protocols that SQRL is using because the act of publishing it renders it unpatentable.  It's now in the public domain.  Nobody can have it.  Which is the way something like this should be.  Okay.



So this company, this Erich Spangenberg with his TQP Development, purchased the patent from its originator for three quarters of a million dollars.  So, okay, that's a chunk of money.  He has then gone around and sued nearly 140 different companies, generating a total of $45,370,000 because the companies have capitulated rather than challenging the patent.  His claim is that this patent covers the combination of using the RC4 cipher with SSL.  And as we know, until recently, when RC4 has fallen into disfavor, many companies were using RC4 and SSL.  So even though this patent is expired, his suit alleges that Internet commerce, that the inventor foresaw the whole future of Internet commerce, back in the - this was a Rockwell modem that this thing was - it was a way of retrofitting firmware in a Rockwell modem to just create a secure point-to-point link.  Nothing to do with the Internet.  Nothing to do with packet-switching technology, I mean, nothing to do with commerce at all.  So he's saying that any large Internet commerce companies were infringing the patent before it expired, and therefore owe them money.



A mutual fund, Dodge & Cox, was sued and paid a little over $25,000.  The Pentagon Credit Union paid $65,000.  QVC paid $75,000.  MLB Advanced Media paid $85,000.  PetSmart paid $150,000.  PMC, $400,000.  Cigna paid $425,000.  Bank of America, $450,000.  First National, $450,000.  Visa paid half a million dollars.  Amazon paid this guy half a million dollars.  UPS, $525,000.  IBM, three quarters of a million dollars.  Allianz Insurance, $950,000.  And Microsoft paid them a million dollars.



LEO:  Notice that all these sums are less than the estimated million and a half it cost to fight it.  And that's one of the reasons patent trolling works.  These companies, they just made a simple business decision.  Well, even a million dollars is less than it would cost to defend it.  And I'm thrilled that Newegg, despite the fact that it's cost them millions, and now they have lost for another couple of million, decided to fight it.  But you understand why it's a bad business decision.



STEVE:  Yes.  It exactly is.  The good news is they have a T-shirt we can buy to help support their cause.  But to give you an idea, so now how does this work for the patent troll?  They're called patent trolls, first of all, because they're not using the patent.



LEO:  Non-practicing entities is the...



STEVE:  Yes, exactly.



LEO:  ...more official term, I guess.



STEVE:  Yes.  This guy, this Spangenberg, bought the intellectual property rights simply to have grounds to sue, not because he was using the patent and wanted exclusive rights to what it was protecting.  I mean, it's obsolete, has been for a long time.  And there were many other ways to skin this cat than using RC4.  So the deal with the original inventor, the inventor gets - get this, Leo - 2.5% of any money recovered, plus $350 an hour as a consulting fee.  So far, the inventor has made $588,000, while Spangenberg keeps the rest.



LEO:  More than $40 million that he's keeping, that's his.



STEVE:  Yes, yes, exactly.



LEO:  So now you know why people do this.



STEVE:  Exactly.



LEO:  You could swallow a lot of ethics for $40 million.



STEVE:  So Newegg says no.  Newegg has been sued before, and has always said no, they won't do this.  So the drama here, which occurred just recently, is when expert witnesses whose job it was to explain the technology to the jury - this was a jury trial as opposed to just explaining this to a judge - they took the stand.  First we have Ron Rivest, the "R" of RSA, who testifies via a videotaped deposition about how he invented the RC4 cipher while he was at RSA Security in 1987, two years prior to the TQP patent application.  So then we get former Microsoft CTO, the Chief Technology Officer, Ray Ozzie, who described demonstrating Lotus Notes to Bill Gates in '88.  And Lotus Notes used the same technology.



Alan Eldridge, who worked on the Notes product, flew down to Marshall, Texas - this is where this was happening, in East Texas - in person, and wasn't paid, because he felt he was doing his civic duty to keep this travesty from happening.  He flew down to describe how he put Rivest's RC4 cipher in the Lotus Notes software.  So it was in a product in use, practically, and in commerce, all of which invalidates it being the subject of a patent.



Okay.  Finally, on Friday of last week, Newegg's star witness, the person we talk about often, Whitfield Diffie of Diffie-Hellman fame, the Diffie-Hellman key agreement, the key cryptographer takes the stand.  Diffie's goal was to knock out the so-called "Jones patent" because this was some guy named Jones was the guy who added this.  And I have to say, I've looked at the patent, and I mean, it is nice technology.  It's not junk.  It is honest-to-goodness really good encryption for a point-to-point connection between two modems.  It's good.  But it wasn't first.  And that's the key.  And what it patented and what they're suing everybody over was already in use before.



So, and Whit Diffie, there's a picture, I don't think - there's a link further down, Leo, to the Ars Technica story, I think it's the "Newegg trial crypto legend Diffie takes the stand."



LEO:  Yeah, Whit looks like a mad wizard, I think.



STEVE:  He does.



LEO:  You shall not pass.



STEVE:  If you put Endeldorf's or whatever his name is cap on his head, it's totally convincing.



LEO:  Endeldorf?  Gandalf.



STEVE:  Gandalf.  Oh, okay.  I don't know what I'm talking about.



LEO:  I like Endeldorf, though.  We'll have to create a character.  He's the guy, Whit Diffie's the guy on the left, by the way.  The lawyer's the guy on the right.



STEVE:  Oh, yeah.  You can tell who's the attorney and who invented public key crypto.



LEO:  But, now, I have to tell you, in Marshall, Texas, that is a little bit of a strike against him.  He looks like a hippie.



STEVE:  Well, he looks like an eccentric genius.



LEO:  What I've been told about these juries, and one of the reasons these companies pursue this in East Texas, they're very conservative juries.



STEVE:  Yes.  Yes.



LEO:  And they really want to help the little guy against the big companies.  That's really where this is coming from.  So they feel like the little guy is getting ripped off, you know.



STEVE:  Yup.  So the attorney, Albright, for Newegg, says:  "We've heard a good bit in this courtroom" - I'm quoting from the transcript - "a good bit in this courtroom about public key encryption," says Albright. "Are you familiar with that?"  And Diffie says, "Yes, I am," in what surely qualifies as the biggest understatement of the trial.  And then Albright says, "And how is it that you're familiar with public key encryption?"  To which Diffie replies, "I invented it."



LEO:  Yeah, that's good.



STEVE:  And then, I mean, you would just think, it was like, okay, this is done.  So then the plaintiff attorney gets up, Mark Fenster, who's the lawyer for TQP, and says to Whit Diffie, "You never completed a master's degree, did you."  And Diffie says, "That's correct."  "Other than the honorary degree, you don't have an earned doctorate or PhD; correct?"  And Diffie says, "That is correct."  And even though he taught a few courses, "You never had a real professorship; correct?" asked Fenster.  And Diffie says, "I never had a full-time academic job, no."  So, and then Fenster of course notes that although Diffie was testifying in court for the first time, he had other expert witness work lined up.  His rate varies from $500 to $600 per hour, and it's $700 for testifying in court.



And Newegg lost.  And this, Leo, is why I've stopped agreeing to be an expert witness.  I did that for a while, years ago.  And it was this kind of event.  I would only testify if I was on the side that, like, should win, because that's me.  And the most annoying lawsuit that I was involved in, I testified on behalf of NEC, who had the famous MultiSync display.  And they were being sued by Princeton Graphic Systems because NEC's advertising was saying this is the last monitor you'll ever need to buy because, because of the MultiSync-ness of it, it could handle whatever different resolution you gave it, which was phenomenal at the time.  Now we just sort of take it for granted.  Back then, that was a big deal.  So Princeton Graphic Systems was suing NEC for their statement because the PS/2 had just come out, and you didn't need to buy a new monitor.  You could use the old MultiSync that essentially just worked because it was smarter. 



And so I very carefully tried to explain to the judge - this was not a jury trial.  This was just me and the judge, who had a green oxygen tank next to him, and he remembered when horses pulled carriages.  So I was trying to explain to this guy why the way this worked meant that NEC's ads were correct.  And they lost.  And I just was like, okay, I'm not doing this anymore.  This is just too annoying, the fact that the system is that broken.



So in this - back to Newegg's trial.  The plaintiff was claiming $5.1 million in damages and who knows what.  I didn't look at the detail of the suit, so it may have been damages and other forms of upset.  They were awarded by the jury 2.3, so a little less than half.  But still, $2.3 million.  But as I said, Newegg has lost before, and they have always won on appeal.  So they are going to appeal this.



LEO:  Because that moves it to a different venue, moves it out of Marshall, Texas.



STEVE:  Exactly.  And then saner heads prevail.  But anyway, I liked this.  I wanted to share the details of this because we've talked about patents and patent trolls, and here's a - it's a classic example.  I mean, you couldn't - basically this brought the industry's top gurus out of hiding.  Diffie's never testified in court before.  This was his first testimony as an expert witness about what he did and when.  And it didn't matter.  So I think it will because, yes, I think...



LEO:  Yeah, I'm glad they're fighting, yeah.



STEVE:  Oh, absolutely.  And it is the case that at Newegg they have a T-shirt you can get which is neat.



LEO:  They don't have Extra-Large, though.  They only have skinny sizes.



STEVE:  Ah.



LEO:  Whoops.  They need more - maybe they sold out already.



STEVE:  I bet you - I was just - you took the words out of my mouth.  I bet the big ones are sold out, yes.



LEO:  Yes.



STEVE:  So over the weekend - over the weekend?  I guess it was.  No, this week.  Where are we?  This is Wednesday.  I guess it was over the weekend, late in the weekend, and at the beginning of the week, it occurred to me that we've been getting a huge number of questions about CryptoLocker.  Will it affect a drive that has, like, what level of drive mapping?  If it has a drive letter?  What if it's available, but it's not mapped?  Does Sandboxie in fact protect us?  What kind of a virtual machine do I need, blah blah blah, I mean, there's a huge amount of anxiety because it's a huge problem.  And I finally decided that we have a super-savvy audience of listeners.  People would probably like to play with it.



So first I put it up in a non-public directory on GRC and announced its availability through Twitter and then sent people back links.  And there was a lot of interest there.  So I decided to formalize this and to make an old version and a new version available on GRC.  So if anyone wants to experiment with CryptoLocker, I mean, this is deadly.  This is not neutered, or it's not - it hasn't had its fangs removed.  This is the live CryptoLocker malware, both an early version, which is highly detected by existing antimalware software, and the most recent one, which is not yet very well detected.  I think it's 7 out of 47 antimalware that virus total tests detect it, but the balance don't.



So anyway, GRC.com/malware.  That will take you to a page where I explain what's going on, and the dangers.  And I have in text, not clickable links, the location of three different ZIP files because I also threw in the banking trojan, Zbot, or Zeus, that we've talked about often, which is a rootkit trojan that I thought people might want to experiment with also.  They are in encrypted ZIP files, so you must use a password in order to decrypt the ZIP file, in order to get access to it.  My only, I mean, I recognize this is a mixed blessing.  This is dangerous.  But based on the feedback I got through Twitter, I know that a chunk of the listenership of this podcast would love to set up a Sandboxie.



Already Jason, who tweets from @aliencg, and there's a link to his report from the weekend [www.aliencg.com/journal/2013/11/24/CryptoLocker], he played with it a lot.  And I got a whole bunch of other feedback from people who were enjoying the opportunity.  Many people wanted to verify that their antimalware would detect it.  The good news is, for example, Microsoft Security Essentials detects this.  It doesn't detect it in the ZIP because the ZIP encryption is very good.  As we know, something that is well encrypted is pseudorandom noise.  There is nothing to lock onto in an encrypted ZIP, which is why this is one of the ways it's being distributed.  But the second it emerges from the ZIP, if you've got real-time monitoring on in Microsoft Security Essentials, it just nails it.



I was playing with it myself on a completely isolated computer in order to create these ZIP files and to get their SHA-256 hashes and so forth to put this page together.  So I was pleased to see that it is being caught immediately.  So you'll need to turn off those defenses if you want to watch it go and see it do its stuff.  But I thought it was, on balance, more useful to let people verify their defenses and also experiment with containment.  As I was mentioning, Jason verified that Sandboxie does indeed protect from CryptoLocker.  What he found was that encrypted copies of the files that existed on his system were appearing inside the sandbox, exactly as we would predict.  So any time Sandboxie detected that a right was trying to be made, it essentially created it in the sandbox so that CryptoLocker saw the encrypted file, but nothing outside was affected.  And when you deleted the sandbox, you completely deleted all of the encrypted files.



So anyway, GRC.com/malware.  If I get in trouble from search engines for having that there, as some people have cautioned me I might, then I may have to take it down.  But I hope - I don't think I will because they are not - there are no active links on the page.  You have to manually copy and paste and then remove spaces that I've put on either side of the forward slashes.  And only then do you get a completely safe to download ZIP.  And that you need to use a password to decrypt the contents inside.



Oh, and I say it on the page, but be sure to delete the decrypted executable once you're through messing with it.  Do not leave it around.  I did not change the name of the EXE because executables can check their own name.  And I wanted to leave it as it was received in case the executable did check to see whether its own name had been renamed to something like horrible-cryptolocker-virus-do-not-run, that kind of thing.  Which I would have liked to do, but it might have changed its behavior, so I decided not to.



There is a new version of CryptoPrevent over at the FoolishIT.com site.  I linked to it in the show notes, if anyone's interested:  www.foolishit.com/vb6-projects/cryptoprevent.  Or you can probably just put CryptoPrevent into Google, and it will find it there.  And interestingly, the file format has been reverse-engineered now, that is, the format of the encrypted files.  One of the things that many people have asked is, if you ran CryptoLocker on an already encrypted file, would it double encrypt it?  Would it reencrypt it?  And it looks like the authors have been careful to prevent that.



The other thing we heard, remember that there was that service they were offering, "service," unquote, where you could pay them more, and you uploaded a copy, or you uploaded one of the encrypted files, and it would then provide you with what you needed in order to decrypt it.  Or I guess maybe it would decrypt it itself.  I don't remember exactly how it worked.  But the fact that they wanted a copy of the file told us that there was a header of some sort on the file which it could use, that is, it wasn't just the file encrypted, otherwise it couldn't do anything with it.



And sure enough, this has now been reverse-engineered.  There is a 20-byte cookie in the form of an SHA-1 hash, a 160-bit hash, on the front of the file, followed by that file's AES key encrypted with 2048-bit RSA.  So again, this is very good cryptography, unfortunately, which CryptoLocker has employed.



LEO:  I think the patent trolls should sue them over that.  That's terrible.  That's an infringement of TQP's patent. Go after them.  Go, boy.  Sic 'em.



STEVE:  That's a good way to spend their [indiscernible], yes.



LEO:  Well, we know they're deep - these guys, on the other hand, have deep pockets; right?  Making lots of money on CryptoLocker.



STEVE:  So a pseudorandom key is generated per file, which I didn't realize, but that's, again, that's the way you'd want to do it.  A pseudorandom key is generated per file.  That key is encrypted using the public key.  And that's stuck that the front of the file.  So the encrypted files will all grow by, I don't know, like about 256, maybe 266 or so bytes.  And that header is crucial for decrypting the file.



So anyway, the point of this is there is now a third-party decrypter.  Someone named Kyrus, K-y-r-u-s, has reverse-engineered the CryptoLocker malware to determine how the file format works and has built an open source decryption engine.  Now, you still need to go get the key, and you have to pay for it first.  But we've heard reports of, for example, the decryption process crashing before it's finished.  And we were joking that they weren't as worried about creating a bulletproof decrypter as they were an encrypter.



So this Kyrus-Tech.com does have a free open source decrypter which also fully documents the file format and shows the reverse engineering of the encryption process to create decryption.  So if anyone only got a partial decryption of their documents, this would probably handle the balance very well, I would think.  And I noted also, since the podcast, the latest versions of CryptoLocker have decreased the ransom to half a bitcoin in response to the...



LEO:  Still going up, though.



STEVE:  Yes, the massively crazy price of a single bitcoin.  And I don't know if we talked about it on the air or not.  But for the first time today, Leo, it went north of a thousand dollars per bitcoin.



LEO:  Why is that, do you think?



STEVE:  I don't know.  I think it's legitimacy.  I think it's - only thing I can think is that it is beginning to acquire legitimacy.  Because people selling bitcoins would tend to drive the price down.  People buying them would tend to drive the price up.  And so it must be that people are believing that there is a long-term future, and so they're moving cash into bitcoin, looking at - purely speculatively.



LEO:  Yeah.  So it could be a bubble.



STEVE:  Yeah.  Although, if you look at it over the last month, it has spiked.  And then there has been a drop-off as people have been liquidating their bitcoin assets, driving the price down.  But it continues to recover.  And I think we're about two days away from a difficulty increase.  The whole system is going to reevaluate itself and reset the difficulty level for this.



LEO:  So now is the time to get your bitcoin miner fired up.



STEVE:  But really, Leo, really, think of all of the people who have some serious money because they were mining early, and with any luck they were holding onto their bitcoins.  Oh, my goodness.



LEO:  You saw the guy whose hard drive had 7,500 bitcoins on it, and he threw it away, and now he's going through the landfill?



STEVE:  It's a landfill.  And the guys at the landfill think, well, it's probably three or four feet down based on when you think it was.  And it's like, oh, good.



LEO:  Four feet of rubbish.  But it's worth, what, three quarters of a million dollars.  No, more than that.  7,500 bitcoins, wow.  That's $7.5 million; right?



STEVE:  Ooh, yes.



LEO:  I'd look through some landfill for 7.5 million.



STEVE:  Oh, ouch.



LEO:  Wow.



STEVE:  And did you hear the story?  His girlfriend was complaining that the laptop was making too much noise.



[Talking simultaneously]



LEO:  7,500 bitcoins created in 2009.



STEVE:  Yeah.  So back in the early days, when a laptop running by itself had a chance.  And remember, I just had my one machine, and like on the third day I came out and said, oh, look, there's 50 it made for me.  And of course I reported it on the podcast.  Look, Leo, I got 50 bitcoins.  They were worth 450 bucks at that point.



LEO:  $50,000 they're worth now.



STEVE:  Wow.



LEO:  Wow.  Anybody wants to give me bitcoins, I'll take them.  We have a bitcoin donation QR code on our front page.  I have seven.  People have donated seven bitcoins.  That's good.  That's good money.  I'll take it.  Seven grand.



STEVE: A total of, yes.



LEO:  The problem with all of this stuff is you don't know when to see it.  Is it at its peak?  Is it just beginning?  Are you going to be like the guy who bought the pizza pie for what is now worth several million dollars in bitcoins?  Or are you going to be the guy who rides it all the way down?



STEVE:  I think it's a legitimate currency.  I think that's what we're seeing.  I think, I mean, as I've said before, these radical fluctuations are just because...



LEO:  It's very volatile.



STEVE:  ...it's so young.  It's very young.  Nothing has really established the price.  It just needs more inertia behind it.  So, yeah, wow.  Fun.



Now, our old friends at Pogoplug - we were using Pogoplug for quite a while - have a new product which is kind of cool.  It's called Safeplug, and it is $49, and it's a little box.  It's an appliance.  It's TOR in a box.



LEO:  Oh, that's interesting.



STEVE:  Isn't that cool?  GigaOM carries the story.  I looked for it over on Pogoplug's site, and all they wanted to do was get me to log in, and they didn't have any other information that was visible.  But I know a few things about it from the GigaOM story.  It's $49.  It is a little appliance, like a little - one of these like a little Apple TV box or a little random Internet appliance.  So you plug it into your router.  And essentially it's got Linux running in it, and Tor, all preconfigured and ready to go.  So you then - you run your network through it, then to your router, and you're anonymized.



Well, and remember, we need a - that's why I'm a little concerned about them overselling this, because remember that anonymity requires more than just bouncing through Tor because, for example, cookies will deanonymize you.  And you need to have cookies in order to maintain persistent state with a site.  So you have to...



LEO:  You know what would be interesting is if each of these Safeplugs were a Tor node itself.



STEVE:  Actually, they are.  You can also set them up so that they are a Tor node.



LEO:  Because the risk with Tor is the feds co-opting a Tor node.



STEVE:  Yes.



LEO:  An entrance or an exit point particularly.



STEVE:  Yes.



LEO:  But you've got the entrance point.  It's yours.  And if it's a random set of - if they sold a million of these Safeplugs...



STEVE:  I know.  It would massively expand the Tor network and make it so diffuse that it would no longer be feasible to watch exit nodes.  They'd all become exit nodes.



LEO:  Right.  Yeah, just pick a random Safeplug as an exit node. 



STEVE:  Yup.  I like the idea.  So in order to solve the problem of some sites balking at using Tor, for example, banks often tie their authentication to your IP address.  So if you suddenly appear to be coming from somewhere, some other country than you're known to be in, the bank will say, uh, no.  So there is software that they include that allows you to whitelist based on URLs.  So, for example, you're able to not - you're automatically, your traffic will automatically not go through Tor if you're going to any of your whitelisted sites.  And what's very cool is you can whitelist by browser.  They use the user agent...



LEO:  Oh, that's a good idea.



STEVE:  ...the user agent header to either route through Tor or not.  So you could set up Firefox, for example, to be your Tor-based browser, and Chrome would be direct high-speed access.  Because that's the other thing is running through Tor does slow things down.  You can't stream video conveniently and so forth because it just - there is a lot of temporal overhead associated with bouncing from one node to the other, as we've discussed before, and all the crypto work that's being done on the fly.  So anyway, Safeplug, 50 bucks from the Pogoplug people.



LEO:  It also has ad-blocking software built in.



STEVE:  Yup.  Yup.



LEO:  Which it would have to, right, because that could be a way of tracking you.



STEVE:  Yeah.  I mean, I would say you want to use a clean browser.  You'd want to run your browser in Firefox...



LEO:  Incognito mode, yeah.



STEVE:  Exactly, in incognito mode, with a fresh instance.  And it's going to flush its stuff away and so forth so that you don't - if, you know, depending on what level of anonymity you want.  But I think it's very cool.



LEO:  Neat.



STEVE:  Now, I don't know, Leo, how this escaped me.  But here's the warning to our listeners who like science fiction.  Give yourself three hours.  Do not watch the first episode, there's only three so far, in any situation where you do not have time because you will not have any choice.  I am stunned by the quality of this.  It's got an 8.6 rating on IMDB.  Nothing is 8.6 on IMDB.  It's Fox's new series, "Almost Human."



LEO:  Really.  I thought it was for kids.



STEVE:  It is fabulous.  No.



LEO:  No, not for kids.



STEVE:  It's fabulous.  It's set in the near future, the year 2048, which of course is nice because that's a nice power of two.  So, and it's not feasible that we're going to have androids in 2048, but they do.  But oh, my goodness.  All you have to do is watch the first one.  If you watch the first one, you will have no choice.  It is really good.  So it's - I don't know how they're going to keep it up.  In fact, the reviews I've read of the first one, the reviewers were saying, if they continue this - it's the guy - JJ Abrams was involved, but it's not JJ.  It's someone else who's, like, tied to JJ.  I didn't do the research to figure it out.  But, I mean, it's a win.



So three episodes have been aired.  It airs Monday nights on Fox.  The three episodes, as you would imagine, are well available on the Internet.  You can use the Fox app in order to view them.  It's all over the BitTorrent seeding, so it's easy to find these.  And, wow.  The first one will - you will absolutely be addicted.  I'm just - I watched all three last night, deliberately.  I wanted to know whether it could be as good as I was reading, and I wanted to know for the podcast.  And it kept me up too late because I was like, okay, I just can't stop.  So the good news is you're limited to a three-hour binge at this point, and then I think it'll be on everyone's must-watch list.  It's just - it's really good.  And I'm not going to give any more away except that it's a police procedural with a human and an android, but it's just done really well.  The writing is great.  It's very clever.  I love it.



And while I'm on the topic, in Miscellany, I'll just say that I've heard from other people who are glad that I mentioned the Showtime series "Masters of Sex," which is a somewhat, apparently, accurate story of William Masters and Virginia Johnson, the Masters & Johnson story.  But it's turning out to be a really well-written, worthwhile series on Showtime.  So I'll recommend that, too.



And Leo, following your recommendation of using the @replies, I did some more research because I wanted to understand what was going on.  And I found a man, a so-called "man page."  We all know what...



LEO:  Which is terrible [laughing].



STEVE:  Which?



LEO:  There's a man page for how to use Twitter.



STEVE:  Yes, yes, a man page for Twitter.  I created a bit.ly link, bit.ly/tweetfmt, so all lowercase, t-w-e-e-t dot - I'm sorry.  Bit.ly slash t-w-e-e-t-f-m-t, tweet format.  And I found it useful.  It's very concise and condensed.  And actually I tweeted it, and I got a bunch of replies saying, hey, there's some stuff here I never knew about.  So there is some cool stuff there.



LEO:  That's cool, yeah.



STEVE:  And that's our podcast.



LEO:  It says a man page.  Because that makes sense to people like you.  Everybody else looks at it, goes what the hell [laughing].  Steve Gibson is at GRC.com.  That's where he puts all his stuff, all his hard work including SpinRite, his bread and butter.  If you want to get a copy of SpinRite, I highly recommend it for anybody who uses hard drives.  GRC.com.  He also has the podcast.  There's 16Kb audio, smallest audio version made available, as well as transcriptions in human-readable and human-writeable text at GRC.com.



If you do have a question for Steve, he does questions and answers whenever time allows at GRC.com/feedback.  We also have high-quality audio and video at our site, TWiT.tv/sn or wherever your favorite netcasts are aggregated.  Check it out at iTunes and places like that.  We do the show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC on TWiT.tv.  You can watch live.  We will be moving come January 8th to - actually to January 7th, to Tuesday, right, at 11:00 a.m. Pacific.  2:00 p.m. Eastern time.  So that's the first week of January, our new time.  And I think that's about it.  I thank you, Steve Gibson, for being here.



STEVE:  Elaine is going to be digesting turkey, so she said that her transcript may be a day late.  Because I want to put all these links up and make them available, as soon as I have access to the audio here in a few hours, I will make a point of getting the entry for the Security Now! page for this podcast, 432, up on GRC, with the return of the show notes as part of our weekly offering so that people can scroll through and follow the links that we provide.



LEO:  Excellent.  And a correction, it is 1:00 p.m. Pacific, 4:00 p.m. Eastern on Tuesday, after MacBreak Weekly.  I got that wrong.  1:00 p.m. Pacific, 21:00 UTC.  Starting in 2014.  Thanks, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#433

DATE:		December 4, 2013

TITLE:		BULLRUN:  Breaking SSL  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-433.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with the week's more interesting security news and Steve's miscellany - such as NASA working on an FTL Warp Drive! - Steve and Leo take a closer look at "BULLRUN," the NSA's code name for their encryption-cracking initiative, to speculate upon just what the NSA might be doing (and be capable of doing).



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here with lots of security news, including that nuclear code that was eight zeroes.  And we'll talk about something called BULLRUN, perhaps a threat to SSL security.  Steve has the details next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 433, recorded December 4th, 2013:  Breaking SSL.



It's time for Security Now!, the show that covers your privacy, your security, your health and wellness online.  Here he is, Mr. Steve Gibson, the Explainer in Chief.



STEVE GIBSON:  Mental and physical health.



LEO:  Yeah, we do it all, from Vitamin D to honeypots and more.



STEVE:  Oh, and we've got a variety today.  We have launching nuclear weapons with the passcode of all zeroes.



LEO:  I have an email from somebody about this, somebody who actually was there.



STEVE:  It was a tweet frenzy all week about this.  We have the annoying return of air gap-jumping malware hysteria.  I wouldn't say "hysteria."  That's overstating it.  But the people at Fraunhofer, the people who did the MP3 encoder, the original audio psychoacoustic guys, have demonstrated a network that functions, so that's freaked people out a little bit.  We have the not-so-portable car killer.  I have to talk about Amazon's Prime Air service just briefly.  And speaking of moving through the air, NASA actually has an experiment for a true warp drive, Leo.  There's been a breakthrough..



LEO:  Wow.



STEVE:  ...in faster-than-light travel.  I'm going to talk a little bit, briefly, about a seasonal driven bedside quest of mine, and a discovery that I want to share; two interesting Kickstarter projects; and then of course our main anchor topic is to talk about BULLRUN.  We learned about BULLRUN for the first time, which is the NSA's codename for their breaking SSL project, or breaking encryption, how do we break the encryption of the Internet?  And Matthew Green, who's a cryptographer we've talked about often who's at Johns Hopkins, he's been involved in an alternative to Bitcoin called Zerocoin, which I'll probably take a look at on the show before long.  It's still evolving.  But he pulled himself away from that because he wanted to get back to addressing sort of what he felt was a loose end, which is what could they be doing?



So he did this really neat sort of brainstorming tinfoil blog post on Monday.  And I thought that it's perfect foundation for us talking about what are the things that the NSA could be doing?  Because they've talked about, like, having compromised SSL.  And that, of course, upset everyone.  And so we're going to take a look at, from Matt's post, what's possible.



LEO:  Good.  Boy, there's a lot to do.  Steve Gibson, Leo Laporte, and eight zeroes.



STEVE:  Okay.  So, yeah.  So the idea of this is just so bizarre.  The story broke that for 20 years the U.S. was using eight zeroes as the so-called "nuclear launch codes" for the nuclear arsenal.  And this came from a site called TodayIFoundOut.com.  And the title of the posting was "For Nearly Two Decades the Nuclear Launch Code at all Minuteman Silos in the United States Was 00000000" was their deal.



So the background here is that we originally had no protection for, I mean, other than all of the sort of standard - these things are not out on the street corner.  They're in highly secure bunkers and silos.  But JFK, our U.S. President at the time, in 1962 he put out a National Security Action Memorandum 160, which required that there be some, essentially, passcode, password protection on nuclear weapons, and that they be really functional.  They're a thing called a PAL, P-A-L, and that stands for Permissive Action Link.  And during my research I found a really interesting, I mean a really interesting paper.  You can see the link in the show notes, Leo, that www.cs.columbia.edu link, where they discuss what is known in the open community, not triple-top-secret and so forth, about this whole PAL technology, that is, this whole notion of controlling the accessibility, essentially, of a nuclear warhead's explosion.



And what's interesting about this, I think, is that, well, first of all, where the 00000000 came from was that the military commanders, specifically the people at SAC, the Strategic Air Command, were miffed at the idea of the politicians telling them how to do their job.  So what we learned from the story is that shortly after the politicians oversaw the fitting of launch codes with the very first PAL technology, they reset the codes to all zeroes.  So it is apparently true that, in fact, for two decades this extra interlock - I mean, this is not the only way of, obviously, getting to arming and engaging these bombs.



LEO:  No, in fact, according to what I've read, it doesn't in fact engage the warhead.  It merely allows the rocket to be launched.  And there were separate codes for the warhead.  In fact, we got an email from a guy who was running a silo.  His name is Joseph.  I probably shouldn't give his last name.  I think it's okay.  He says, "Your story about the nuclear codes is ridiculous.  I was a launch crew member on Titan 2 missiles in Kansas."  Now, he said, "Minuteman may be different, but our codes weren't numbers at all, they were letters."  And I think the confusion, I've asked him to clarify, is that the letters were used to arm the warheads.  The numbers were used merely to launch the rockets.  He says, "As you can see in the photo, and also in the manual" - he sent me some pictures which I'm going to show you.



"Also there is my own set of launch keys I got from my site after deactivation.  I've included the launch checklist and the entry for the code add in the BVL, the butterfly valve lock."  And he also has a picture of himself at the nine-megaton warhead that he was monitoring.  Let me just show you some of these images.  And I'll send these along to  you so you can read them.  Because it's been deactivated, these are no longer - there's the butterfly valve lock.  And you see, I think you can see where you would insert the key.  I'm not sure.  Here's where you'd enter the code.  And this is the manual.  Here he is in front of his, what did he say, nine-megaton warhead.



STEVE:  Yikes.



LEO:  And there's the two keys.  Remember, there are two keys.  Each member of the combat crew, there's two of them, has to have a key to turn, and they must turn them simultaneously, and one person can't.  They're separated enough.  So I think that's pretty cool.  But he disputes it.  But I think we're talking about different things, is what I think.



STEVE:  Yes.



LEO:  I've asked him to clarify.



STEVE:  That's just what I was going to say because I'm absolutely certain that what this was, was actually about the bomb being able to be detonated.



LEO:  Really.  All right.



STEVE:  Yes.  In the documents they show schematics and talk about specifically how the systems were designed.  And what intrigues me is this is a classic security problem.  And in fact it was concern about our warheads being on foreign soil, I mean, like deliberately on foreign soil, where we - it wasn't...



LEO:  Well, it started with the Cyprus problem in the early '60s, '62, where the fear was that NATO missiles would be used by the combatants against each other, even though they're both in NATO.



STEVE:  Yes.  And so this was meant to be an interlock that would prevent the nuclear bomb from detonating.



LEO:  Now, this story comes from 2004, as you know.  So this is - a lot of people will say, and you'll get emails saying, oh, we've known about this for years.  This was originally written about in 2004.



STEVE:  Yeah.  And I'm just addressing the fact that it was the most tweeted thing I saw this week.



LEO:  Yeah.  Oh, no.  It got to be a big story, yeah.



STEVE:  Yeah.  So but from a security standpoint, I mean, this is the kind of thing we've talked about often.  And think about the dilemma.  The reason the Strategic Air Command commanders set this to all zeroes was their concern that they wouldn't be able to get some random code when they absolutely needed it.  And the point was this wasn't the only thing you needed.  Everything you just talked about with the two-key interlocked, being twisted at the same time, the stuff we've all seen in the movies, that was all in place, too.  So there was a whole series of things that had to happen.  But the tension from a security standpoint is that you both absolutely never want there to be a mistake and a warhead detonate anywhere that you don't absolutely want it to.  And that's in tension with the idea that, if you want it to, you absolutely want to make sure that this huge list of things that all have to happen in order for that to occur, all do.



So, I mean, there's a real problem.  Again, you absolutely don't want a false positive.  But when you want it to occur, you want to be sure that it's going to.  So it's really a dilemma.  And one of the problems was solved by simply, essentially, zeroing out one of the interlocks, actually on the physical weapon itself.  In this Columbia.edu paper, they really go into - it's a fascinating paper, for anyone who wants to read it.  I've got it in the show notes.



And, by the way, I do have - the show notes are already posted on GRC.  I just tweeted the link a few minutes ago before we began the podcast [www.cs.columbia.edu/~smb/nsam-160/pal.html].  And I got a lot of great positive feedback from my posting of last week's notes.  So I'm going to - that's what I will do from now on.  I wasn't always making sure, like sometimes I had people's email addresses and things in that I would never want to disclose by mistake.  So I'll make sure that they're postable from now on.  But anyway, it's really...



LEO:  It's a great story.  And not at all - to me it made perfect sense.  It's exactly what you'd expect, frankly.  It was kind of a pragmatic approach.



STEVE:  Now, of course we had badBIOS, and we talked about that a couple weeks ago.  This persistent rumor-cum-belief, whatever, that one security researcher has been plagued by this weird BIOS that affects - or, I'm sorry, this weird malware that apparently affects, is able to infect BIOSes and, he believes, jump into completely disconnected computers.  And the only channel he was able to find, since it wasn't networked, there was no Bluetooth, there was no WiFi, I mean, it was "air gapped," is a term, is that he believed that a laptop was still getting infected until he physically disconnected its microphone and speakers.  And then, oh, thank goodness, it was no longer - nothing was able to get to it.  And it's like, okay.



And as we talked about it at the time, it's like, yes, in theory, except there are all kinds of problems with that idea.  First of all, the bandwidth is going to be low.  The microphone and speaker really have narrow acoustic bandwidth ranges, so it's going to sound like a modem, and so forth.  So this all kind of quieted down, and then unfortunately a story just surfaced a couple days ago about, as I was talking about at the top of the show, the Fraunhofer folks have developed a network that does this.  That is, and they have an interesting diagram where they talk about - it's in Ars Technica, and our friend Dan Goodin posted this:  "The topology of a covert mesh network that connects air-gapped computers to the Internet."



And the reason you need a mesh network is that, of course, the distance is going to be extremely limited, actually farther than you might think.  The guys at Fraunhofer were able to operate 65 feet between two Lenovo laptops using the built-in microphone and speakers.  Now, reality begins to hit here.  They were able to get 20 baud, that is, 20 bits per second, which is not surprising because it is audio, and so you're going to have to have some sort of a carrier.  And I guess they were able to get it out of audible range so it was technically ultrasonic, or it had to be very low ultrasonic to still allow the microphone and speaker to function.



But so, okay, yes.  Technically you can use acoustics to allow two in-proximity laptops to talk to each other.  To get greater distance, then, they use a mesh network, which is to say essentially it's like the Internet, where one hops to the other, hops to the other, hops to the other.  So as long as there are any two that - or as long as there is any path where two are within distance, then they can all be synchronized, all be at 20 bits per second of data rate, which is a little slow in terms of contemporary networking technology.  But, again, all it can be used to do is allow previously infected machines to communicate.  And that's the key.



And that's why - and it's not like an infected laptop at Starbucks is going to be able to reach out and propagate itself to all the other laptops within 65 feet of it acoustically because a microphone can't take over a laptop unless there's already an infectious agent, something malicious in the laptop listening on the microphone for instructions.  So, yes, it could be used for persistent communications, stealthful, low-baud, persistent communications.  But not to just reach out and take something over.  As far as we know.  As far as we know there isn't any way that just whistling to a microphone can cause a buffer overrun and install code.  And, if so, it'd be prohibitively slow.



LEO:  Interesting stuff.  Nothing to worry about.  Nothing to fear.



STEVE:  Nothing to worry about.  So, yes, now we have some sense of - if anything, it gives us a sense of scale for what can be done in an acoustic network, if that were actually what was going on in this badBIOS situation.



The friend of the show Simon Zerafa, in Wales, sent me a link.  He called it the "portable car killer," of course, playing off the well-known portable dog killer experience in my youth and episode that we did by that name.  However, this is not so portable.  It is 772 pounds.  But it is a vehicle.  It is, I mean, it is functioning.  There's a company called E2V has developed this.  It is a nonlethal device, unless maybe you have a pacemaker, in which case maybe it's not so nonlethal.  But it can shut down a vehicle at 165 feet, at 50 meters.  So basically it is a mobile EMP, electromagnetic pulse, transmitter.



What it does is essentially it takes advantage of all of the technology that we have in contemporary vehicles.  If you had some old Rambler from the '60s, such an old-school car would just ignore the electromagnetic pulse.  But the guys who develop this note that, in the frequency band they're using, which they call the L and S band, a contemporary car's wiring loom has runs of wire of about a meter, which make them a perfect antenna.  And so they're able to generate a signal from 165 feet away, which at that distance will essentially scramble the engine's management technology and cause the car to stop.  And they're claiming that, after their press release of this, they have had interest from 15 different countries; and, I mean, like dramatic interest in, okay, we want one.  Where do we send our money?



And so far they've installed this 772-pound thing in a Nissan Navara and a Toyota Land Cruiser, just to make their demonstrations feasible.  I have a picture of it and links in the show notes, if anyone's curious.  But nothing most of us have to worry about.  And I have to say that it would unfortunately knock Amazon's Prime Air delivery drone right out of the sky.  It's pretty clear that it would scramble its avionics, too.



LEO:  And you don't really want something that could be knocked out of the sky.



STEVE:  No, Leo.  I mean, actually what I loved was Paul Thurrott's tweet.  Paul tweeted, I think this was just yesterday, he said, quote:  "The sheer amount of free PR that Amazon's CEO Jeff Bezos got for his," as Paul said, "BS 'drone delivery system' is awe-inspiring.  Media, you just got played."



LEO:  Yeah, yeah.



STEVE:  And, I mean, and I'm sure everyone listening has heard about this.  If not, just Google "Amazon Prime Air," and you'll see it.  And I don't know what to make of it because you can't have this thing with eight exposed high-speed rotors spinning.  I mean, it would shred the family dog that would definitely go chasing it and barking at it and wouldn't see the rotors spinning and would, I mean, there would be fur flying.  It's just crazy.  I don't know what they're thinking.



LEO:  There are lots of, well, and I think even Jeff was pretty clear that this was a long-term R&D project, not something they'd definitely like to do.  And it would save them a lot of money.  You know, it has been used in Haiti.  Something similar has been used in Haiti to deliver medical supplies.



STEVE:  For delivering.  Oh, interesting.



LEO:  So it's not out of the...



STEVE:  Oh, Leo, it's technically - I think it's clearly feasible.  We have the battery efficiency now.  We have GPS that is ubiquitous.  The cost is low enough.  No, I mean, it's absolutely something you could do.  And wouldn't it be fun to just look up and see these little autonomous bots.  It's unfortunate that they got labeled "drones."  I kept seeing this word "drone."  I thought, oh, goodness, that already has so many negative connotations associated with it that you really don't want that to happen.



LEO:  One could come up with a lot of issues.  But it has been used in the past.  There's an article in the MIT, what do they call it, the - MIT's Technology...



STEVE:  Yes, Technology Journal.



LEO:  Yeah, about it and about how it's been used in the past.  And it's not completely infeasible.  There's just some big problems that would have to be solved.  But it's, yeah, I mean, the fact that Charlie Rose said, "Oh, my goodness," and completely uncritically, "Wow."



STEVE:  No, I mean, no, Paul's right.  I mean, the media was saturated with this.



LEO:  Jumped on it.  It's a great story.



STEVE:  It was a fabulous video that they produced where it was basically a few moments in the life of our next-generation drone delivery system.  It was like, oh, my god.



LEO:  I enjoyed it.  And you know it was a great interview and, you know.  What the hell.



STEVE:  Now, I hate to follow that with this next story because - okay.  And first when I saw this I thought, okay, is it April 1st?  No, it's not April 1st.  Okay, how do I explain this?  So this is NASA actually has a project.  And I have a link to - and if the PDF weren't being hosted by NASA.gov, again, I wouldn't believe it.  But it is.  They actually have - now, okay.  That's just the - I think that's the...



LEO:  It's an artist's rendering.



STEVE:  No, that's a Vulcan something or other, the very first image is, yes, and an artist's rendering from the Star Trek world.  But that one you're showing now is actually what this thing might look like.  Okay.  So first of all, for the listeners who aren't seeing these pictures, the article begins - this is in io9.com, by the way.  "A few months ago, physicist Harold White" - who's the author of the PDF at NASA, at JPL, or some propulsion organization.  I'll get to that in a second.  He "stunned the aeronautics world when he announced that he and his team at NASA had begun work on the development of a faster-than-light, i.e., FTL, warp drive."



Now, okay.  We have to just pause and give kudos here to Gene Roddenberry because, I mean, we're calling this a warp drive.  It actually works by warping space-time.  And we had that in Star Trek in the '60s, thanks to Gene Roddenberry.  I mean, that was the technology.  That's how the Enterprise moved at faster than light.  So, incredible.



So "[Harold White's] proposed design, an ingenious re-imagining of" a drive known as the, and I'm going to kind of mangle the name, I'm afraid, Alcubierre.  He's a Mexican theoretical physicist, Miguel Alcubierre.  I was trying to pronounce it before the podcast, but now I forgot.  "[The] Alcubierre Drive may eventually result in an engine that can transport a spacecraft to the nearest star" - okay, Leo, to the nearest star - "in a matter of weeks."



LEO:  Well, we need that because otherwise it takes too long.



STEVE:  Exactly, "all without violating Einstein's law of relativity."  And I've said on the podcast that one of the problems I think that NASA has and that the whole space process has today is that we've been spoiled by Star Trek and by all of the sci-fi movies.  No one is able to generate much enthusiasm about a slow wagon train to Mars.  It's like, who cares?  I mean, no one is going to fund that.  You're just not.  But oh, my god, going to Alpha Centauri in a couple weeks?  That's a game changer.  Now we're talking.



So anyway, so about Miguel.  He's got a Wikipedia page.  And back in '94, okay, so 20 years ago - Miguel's about 48 or 49 now, so he was at the prime of his physics inventing age back then, 20 years ago - he published a paper in the Classical & Quantum Gravity journal, so serious...



LEO:  That's the right place for it, I think.



STEVE:  Yes, theoretical physics.  So Wikipedia says Alcubierre is best known for the proposal of "The Warp Drive:  Hyper-fast travel within general relativity."  And that's the key because the problem, of course, is acceleration.  You can't accelerate very quickly because we have no way yet of suspending inertia, or humans are turned into goo, and that's not good.  So anyway, continuing with Wikipedia, "which appeared in the science journal Classical & Quantum Gravity.  In this he describes the Alcubierre drive, a theoretical means of traveling faster than light that does not violate the physical principle that nothing can locally travel faster than light.  In this paper he constructed a model that might transport a volume of flat space inside a bubble of curved space."  So Leo, we have a warp bubble.  I mean, again, we have lots of science fiction about this, but now we actually have theory.



"This bubble, named as hyper-relativistic local-dynamic space, is driven forward by a local expansion of space-time behind it, and an opposite contraction in front of it, so that theoretically a spaceship in the middle would be placed in motion by forces generated in the change made in space-time."  Okay, now, this is 20 years ago, and nothing happened much because the theoretical amount of energy that is unfortunately required to warp space-time is quite literally astronomical.  Space-time, it turns out, is very stiff, and actively resists being warped.



LEO:  Dammit.



STEVE:  I know.  It's been a big problem.  But what happened was...



LEO:  We're so close.



STEVE:  And we have such great pictures.  Unfortunately, we have no way of producing that much energy.  So Dr. Harold White at NASA's Johnson Space Center was putting together a presentation recently where he was going to talk about this problem.  And his PDF is titled "Warp Field Mechanics 101."  And if we were able to build this, this would transport a spacecraft to Alpha Centauri in two weeks.



LEO:  Perfect.  Just right.



STEVE:  Even though the system, even though Alpha Centauri's system is 4.3 light-years away.  So we're talking about 4.3 light-years in two weeks.  And oh, my god, I mean, now we're talking.



LEO:  Now we're cooking with gas.



STEVE:  Yeah, exactly.  If we could generate the insane amount of energy required.  Well, and that's the breakthrough.  What happened is, while preparing this report, he did a sensitivity analysis of the equations, and he believes he found a way of dramatically reducing the amount of energy required.  And so in his paper it says, "It takes advantage of a quirk in the cosmological code that allows for the expansion and contraction of space-time and could allow for hyper-fast travel between interstellar destinations.  Essentially, the empty space behind a starship would be made to expand rapidly, pushing the craft in a forward direction. The passengers would perceive it as movement, despite the complete lack of acceleration."



And he said, "In terms of the engine's mechanics, a spheroid object would be placed between two regions of space-time, one expanding and one contracting.  A 'warp bubble' would then be generated that moves space-time around the object, effectively repositioning it.  The end result is faster-than-light travel without the spheroid, or spacecraft, having to move with respect to its own local frame of reference."



So essentially you create a bubble.  This thing is in the middle.  And you sort of rotate the bubble.  And the craft moves through, essentially is pushed out of our normal space-time constraints and is then able to travel without inertia being a problem and without even something pesky as lightspeed, the speed of light, being a problem, and just zip wherever it wants to go.



LEO:  Zip.



STEVE:  Zip, yeah.  So anyway, we'll keep our eye on this.  But, I mean, it's real.



LEO:  We'll be around for a while; right?



STEVE:  They're now doing - well, no.  But the energy problem just stopped everyone cold.  I mean, it was absolutely - it required an absolutely infeasible amount of energy.  And it's been reduced by billions of orders of magnitude.  I mean, it's, like, been reduced - if this new understanding is correct, and what they're actually doing now is building an interferometer to test the warp bubble theory because they now believe, I mean, other people have looked at it, and NASA has looked, I mean, NASA's guys have said, wow, this could work.



LEO:  I love it.



STEVE:  And so they're going to start with an interferometer in order to see whether they can actually create a warp bubble with this radically lower level of energy input required.  And I haven't had a chance to read the PDF.  I just found it this morning.  I tweeted it.  It's already in my Twitter feed.  It's in the show notes.  So, yeah.  Wow.  This would change everything.



LEO:  In our lifetime, you think?  Nah.



STEVE:  Oh, yeah.



LEO:  Really?  Think so?



STEVE:  Oh, Leo.  I was looking at this, you know, there was all of this JFK's 50-year event in the last week.  I remember where I was on that Saturday morning.



LEO:  Who doesn't?  Anybody alive does, of course.



STEVE:  Yes.  And I didn't really understand what was going on.  But I knew from the expression on my dad's face that something really bad had happened.  We'd been out sailing in the Bay, in San Francisco Bay, all day.  And so we were coming back, we came back to the dock in Marin County, and my sister and I were hosing off the sailboat.  Dad had gone to the shore.  And when he came back, someone on shore had - so we'd been out of touch with the news as a consequence of being sailing.  And Dad found out when he was ashore and walked back to the boat.  I mean, I'm just like, "Dad" - or Daddy probably at the time, I think I was eight, it would have been 50 years ago - "what happened?"  Anyway, so the point is that seeing the film from then, look how far we've come in 50 years, Leo.  I think we forget how incredibly rapidly technology moves.  I mean, that was not long ago.  That was 50 years.  And...



LEO:  But Steve, I know you're bullish about your Vitamin D and your low carb; but I don't think we're going to last another 50 years.  You think?



STEVE:  Well, oh, my goodness, yeah.  I have a T-shirt that says "Future Centenarian."  Yeah.



LEO:  Right on, Daddy-o.



STEVE:  Absolutely.



LEO:  I don't see myself getting to 107.  But maybe.



STEVE:  It's not going to take 50 years.  It's not going to take 50 years.  Look at the Large Hadron Collider.  I mean, that thing is science fiction.  Have you seen the pictures of that?  It's like, we're building something like that.  We can easily build a starship.  All we need is the warp bubble.  And apparently that's just down the street now.



LEO:  I say start building the starship.  And then, if you build it, maybe the bubble...



STEVE:  Give it a big - give it a nice big engine room, and we'll figure out what to put in there.



LEO:  We'll figure out the rest.  Yeah, exactly.



STEVE:  Exactly.  And we have Elon Musk, you know, so he's not going to let anything stop him.



LEO:  We've got Google.



STEVE:  We do.



LEO:  Yeah.  They seem to have a vision for the future, moon shots.



STEVE:  No, this is exciting stuff, Leo.  I mean, this is - what's exciting is that now we can actually go somewhere in a reasonable amount of time.



LEO:  Right.



STEVE:  And if we can do it in a couple weeks, then life support problems are solved, inertial problems.  We don't have to freeze people.  We don't have to, I mean, we don't need all this other stuff we don't have.  All we need is the warp bubble, and apparently we're going to have that soon.



LEO:  The only thing I would raise at all is that, if we could figure this out, not being the most advanced race ever, why haven't others visited us?



STEVE:  Actually, I'm reading a rather daunting sci-fi series at the moment.



LEO:  We may be the only ones.  Is that what you...



STEVE:  Yeah.



LEO:  Is that what you were going to say?  I find that hard to believe, as well, when you have as many planets, potential planets as you must have, that no life has ever developed on any of them.  Seems unlikely.



STEVE:  Well, for one thing, we really are way out on the fringes.  We're not, I mean, we're on the wrong side of the tracks, galactically speaking.  And so there may be a lot more going on somewhere.



LEO:  Yeah, but if there's a warp drive, we're not as out-of-town as we thought.  We might be closer.  It's the Fermi paradox; right?  I mean, it's the classic paradox.



STEVE:  Yeah.  Alistair Reynolds has a series called the Revelation Space series.  It's rather dark science fiction, and I'm reticent to recommend it.  He's also not as good a storyteller as Peter Hamilton, yet his books are just as big.  And so I find myself sort of dragging myself through this, like, okay.  I mean, I have to find out where this goes now.  But, boy, it's not nearly as delightful.  I'm on the third of the trilogy.  And he answers this.  And I can't say much more about that because I'd be spoiling it.  But he posits in this series an entirely feasible, well, within his universe, explanation, which is interesting.  It's not more true than the warp drive, but yeah.  I mean, I don't care if nobody else has figured this out.  But you're right.  If it's this simple, why isn't everybody doing it and visiting each other?



LEO:  Why aren't we getting more looky-loos?



STEVE:  More traffic, yeah.



LEO:  You've got some nice real estate here.  How much you want for the planet?  You know?  Moving along.



STEVE:  So I'm getting a huge amount of positive feedback from my Leo-precipitated change in the way I use Twitter.



LEO:  Oh, good.  I was feeling bad about it last week.



STEVE:  No, it's okay.  Everyone is liking the fact that they can see my replies.  I don't think anyone knew I was replying to everyone because I was using DMs.  The problem I mentioned has already been fixed with that really neat filter, or that chronology of my timeline.  Remember that bit.ly/sggrc, all lowercase, took us over to Simon Paarlberg's page, where he was monitoring the feed in real-time and tying those posts to Security Now! episodes because I often tweet links as I'm preparing for the show, just so people have access to them.  And I've always been saying, oh, I just tweeted this.  Go check out my Twitter timeline, you can find the link.  The problem was, since I was now using @replies, my timeline was hugely cluttered because I've been so active with that.  Anyway, Simon immediately fixed that, and so now we're back.  So bit.ly/sggrc is cleaned up again, and anyone can use that to immediately find only my broadcasts to my Twitter community.  Which, by the way, topped 40,000 the other day.



LEO:  Congratulations.



STEVE:  So I'm not where you are, Leo, but I'm...



LEO:  But you say good stuff.  I say nothing.  So that makes you valuable.



STEVE:  Well, I also tweeted about this.  Now, okay.  This is a complete diversion, but bear with me for a second.  Last year the radio station I use on my bedside clock radio switched to Christmas music the day after Thanksgiving and was playing Christmas music for a month.  And I thought, no.  I cannot have Christmas music for a month.  I'm not a Grinch, but there actually is some Grinch song which is really nauseating, and I kept hearing "Mr. Grinch" and all this.  I thought, no, I just can't put up with that.



So as the holidays were approaching, I decided to get preemptive here and needed to replace my wonderful clock radio with something.  I do subscribe to XM Radio.  I have a lifetime subscription to Sirius XM in my house.  So I was thinking, okay, that would be a possibility.  And of course we've got Pandora, we know about Pandora and so forth.  But what about the device?  And what I finally realized is I had an unused iOS device.  I had an iPhone 4.  And of course I've moved to the 5.  And many people, it occurred to me, have previous versions of iPhones or older iPads that they may not be using.



What I found, and the reason I bring it up, is that it's just an incredible bargain, is an amazing little dock for an iPhone or iPad, which is also a speaker and a charging station.  What I like about it is that it was - it's been discontinued, so there's existing inventory that Amazon has.  It used to be $80.  It was originally $79.99.  Now it's $19.99 or $19.95.  I've got a link in the show notes, if anyone's interested.  It's the iLuv, i-L-u-v, iMM190.  They call it the App Station Alarm Clock Stereo Speaker.  Anyway, it's, for the price, it's terrific.



And then I went on a search for the right app to use on my old iOS device.  And believe it or not, I can't find one.  I've settled on something called The Clocks in the iTunes Store, which is very close.  And I've written to the guys, or the guy who is the author and suggested that this would be perfect if he only made the following changes, and he said that several of them are on the way of the changes that I suggested.  So if anyone's interested, they have an old iOS device for a really amazing price.  And I forgot to mention that it sounds amazing.  It's a bass-ported little speaker box that sounds fabulous.  So it allows you to repurpose something that you may no longer be using for a very good price.  So just a little hint for the holidays from me.



And finally, I just wanted to bring to our listeners' attention two interesting Kickstarter projects.  Obviously, there's a huge interest in coffee.  There is something on Kickstarter called the Temperfect Mug, T-e-m-p-e-r-f-e-c-t Mug.  The interesting thing about it is that the guy who designed it, he's got a lot of experience with making mugs.  He's been making them for years and years.  He notes that coffee starts out being too hot to drink, and you then need to wait for it to cool.  And in a thermally insulated mug, any traditional thermally insulated mug, there's a certain taper to the rate at which it cools.  And if you scroll down, Leo, you'll see way down he shows the temperature versus timelines of his solution for...



LEO:  The guy is obsessive.



STEVE:  Oh, no, he really is.  And there are some beautiful - you can spend $280 on one of these things that are like some amazing titanium oxide coating that you can get on one.  Yup, there it is.  Anyway, so the point is that a typical thermal mug slows down the rate at which the coffee gets cool.  But you have to wait for it to get down to drinkable temperature, and then it drops out of that ideal zone pretty quickly.  So what he's done is he puts something with a great deal of thermal inertia directly around the coffee-containing area.  And then that's vacuum insulated from the outside.  So the point is, when you pour hot coffee in, the temperature of the coffee immediately drops to the sweet spot of drinking temperature because that high thermal inertia, and I don't remember what it is that he's wrapped around there, but that takes the heat immediately out of the coffee, bringing it down to drinking temperature.  But then it holds it there for, like, an hour and a half.  So a really interesting idea.  And I thought I would let our listeners know.



LEO:  I like it.



STEVE:  Yeah, I do, too.  I do, too, very much.



LEO:  Seems a little bit like a perpetual motion machine or something.  But if it works...



STEVE:  No, but, see, that's just it.  The way it works is it rapidly drops the temperature of the coffee by heating up the liner that is immediately adjacent to the coffee.  And then that liner holds the heat and keeps the coffee warm.  So it drops it down.  Instead of, like, waiting for half an hour for it to cool off enough, I have these - I really like - you keep seeing this thing.  This is a Contigo, C-o-n-t-i-g-o, which I absolutely love.  They're at GoContigo.com.  And this thing will keep my coffee warm for a couple hours.  But I transfer it into another cup because I can't drink it out of here.  It's too hot to drink.  And so transferring it allows it to get cool.  And then the thermos keeps it hot itself.  So it's a standard aluminum vacuum thermos.



LEO:  So for 40 bucks you can get the regular mug.  For 160 bucks you get the black oxide.  And if you want titanium, it's $280.  Which one did you order?



STEVE:  I did go the titanium one.



LEO:  Of course you did.  The flat blue-black ultra-hard coated mug with an uncoated droplet logo.



STEVE:  Yup.



LEO:  Hmm.  Now, they're saying summer of next year before you get this thing.



STEVE:  I am not in a hurry.  I'm, you know, I've got other stuff.



LEO:  Actually, I am so tempted.



STEVE:  I'm convinced that the guy's got his physics right.  The physics makes sense.  He's clearly a perfectionist.  He's got pictures, I mean, this does not look to me like one of these things that'll never happen on Kickstarter.  It looks like a deal.  And for 40 bucks you still get the same performance for a somewhat less cosmetically over-the-top mug.  I love the idea of it immediately dropping it down to drinking temperature and then holding it.



LEO:  The Titania doesn't perform any better.  It just - it's a look.



STEVE:  No, it's pure - yeah.  It's pure...



LEO:  Problem is it's either orange, pink, or blue, if you don't spend the money.  Oh, I'm going to get the orange one, what the hell.  You can have the fancy one.



STEVE:  Yeah.  I'll show it to you next summer.



LEO:  Yeah.  Bring it with your coffee setup.



STEVE:  Okay.  Last thing.  Wackiness.  But again, intriguing.  I just wanted to make sure our listeners knew.  A really interesting smartphone, Bluetooth Low Energy, controlled paper airplane.



LEO:  [Laughing] Okay.



STEVE:  Now, what's so cool about this is that what - and it's just $30.



LEO:  By the way, they've raised half a million almost, so they're doing all right.



STEVE:  I was just going to say, the goal was $50,000.  They have $434,000 pledged because - and in my notes here I said, "Just the guts, ma'am," because all you're getting is this cute little armature, essentially, a little cockpit in front where the Bluetooth radio and batteries are, and a little rod that runs to the back with a rudder and a propeller.  And so you get...



LEO:  You supply the plane.



STEVE:  Yes.  You supply the plane that you attach this to.  And so it's like build your own plane system.  I just love it.  And it's $30.  So no wonder that they're going crazy, pledge-wise.  I didn't want our listeners to miss out on it.  So I think you could, let's see, you would Google "smartphone-controlled paper airplane," that's in the URL of Kickstarter, smartphone-controlled paper airplane.  Oh, that's the other thing.  You twist your smartphone back and forth, you use the inertial sensor of your smartphone in order to steer your paper airplane.



LEO:  It'd be fun to enter your paper airplane into some contests and let people see this thing.



STEVE:  Yeah.



LEO:  It really flies.  They have a video of one, a prototype, and it's pretty impressive.



STEVE:  Yeah.  I don't know what the timing is.  It'd be so great if it were available as a Christmas present for our listeners to give their sons and daughters.



LEO:  Yeah, yeah.  Price is right.



STEVE:  This is a tremendous, neat little - oh, it is.  A great little concept.  I love the idea of this is - we're only going to give you and sell you the part you can't make.  And anyone can fold paper.  And so, have at it.  Create, I mean, like it brings paper airplanes back to life.



LEO:  Remember that?  You probably - we're of the same vintage.  You probably had that book.  Remember they...



STEVE:  Yep.  I know the book.



LEO:  Everybody's nodding.  Yeah, we know that book.  That was very popular in our youth.



STEVE:  It was, yeah.



LEO:  I wonder if they still - I should look, I'm going to look on the Amazon.



STEVE:  Oh, it's got to be around.



LEO:  You think?  It's not out of print?



STEVE:  So speaking of bringing things back to life, I got a really nice note from a Caleb Allen that I wanted to share with our listeners.  He's in Turlock, California, a listener himself.  And he said, "SpinRite helping elementary schoolchildren read."  And this is something I hadn't seen before.  He said, "Dear Steve.  I work at a small, poor, elementary school district in California's Central Valley."  That's where Turlock is, sure enough.



And he said, "About two years ago I convinced my boss to purchase a SpinRite site license" - I'm sorry - "to purchase a site license for SpinRite 6 to use in our shop after I heard about it on Security Now!.  Last week," and this he sent to me, by the way, on Halloween, on October 31st, so just about a month ago.  "Last week one of our librarians told me of a problem where her library kiosk terminals were taking five to seven minutes to log on.  It was so bad that most schoolchildren, many of whom were only given five to seven minutes to run to the library at all, just abandoned the PCs.  This was a huge problem because these PCs are how the students look up book titles in the subjects they're interested in."



So I guess, back when I was in high school, we had a card catalog.  But obviously that's all gone online now, as would imagine.  So he said, "After an hour or so poking around the multipoint server install," he said in parens, "(the kiosks are terminals all running off one host machine)," he said, "I took it back to the shop for further work.  The message stated that the user profile service was busy.  I scoured the Microsoft network and Internet forums, trying to find a solution to the problem.  Finally, in desperation, on the off chance that the problem might be hard-drive related, I ran SpinRite on Level 4 over the weekend.  On Monday morning I came in and tested the PC, and the login popped right up and took me to the desktop.  I returned it to the library, and now four students at a time are able to do research and look up books, thanks to SpinRite.



"As a poor district, we've used SpinRite for a whole host of problems.  It's gotten to the point where, in most cases, we just run SpinRite on Level 2 before trying anything else.  It's helped us keep our existing equipment running in the sometimes chaotic environment of elementary school classrooms.  Kids are rough on the equipment, and our hard drives take a beating.  With SpinRite's help we've decreased downtime, kept older equipment running, and recovered vital files such as grades, parent reports, and special education evaluations.  I don't know if a student in our district will someday be inspired because they had access to a PC we've gotten running again with SpinRite, but I'd like to think so.  Thank you so much for a great product.  Caleb."



LEO:  Tremendous.



STEVE:  And, wow, thanks for the great summary and report.



LEO:  What have you got there?



STEVE:  So I was just checking my Twitter feed on my little mini while you were talking, and I have an update about coffee.  Then we'll get to BULLRUN, I promise, everyone.  So this was tweeted by @ChemGuy60223.  That sounds like a zip code, maybe.  And so he sent two tweets.  He said, "Steve, for an alternative to your coffee temp controller, check out Coffee Joulies, available on Amazon now."



LEO:  They don't work.



STEVE:  He says, "I'm...."  Huh?



LEO:  They don't work.



STEVE:  Oh.



LEO:  Well, I've used them for whiskey.



STEVE:  Okay, I don't think that's quite the right technology, Leo.  He says, "I'm a chemist."  And of course his Twitter handle is ChemGuy.  He says, "I'm a chemist and have these.  Use as a class demo.  They really work.  Uses a phase-change material to..."



LEO:  It's the same idea.



STEVE:  "...absorb/release heat at the proper temperature.



LEO:  So they're little metal beans that go in your coffee.  People do these for whiskey, as well, to keep whiskey cool without watering it down. 



STEVE:  Oh, okay.



LEO:  Get the idea?



STEVE:  Yeah.



LEO:  But the people I know who've used these have not been crazy about this as a solution, so...



STEVE:  Yeah, I don't want any beans.  I want - yeah.



LEO:  We both bought that mug, if they put it out.  If they don't, we'll try the Joulies.  I've been aware of these for some time.  I'm not convinced they do the job.  Anybody in the chatroom has a better - has experience?  There's the guy in Twitter.  He's a chemist.



STEVE:  Yeah, no, and the theory works.  And so he's probably using it in order to demonstrate...



LEO:  Same idea.



STEVE:  ...that concept in his classroom.



LEO:  Right.  It's a heat and energy storage device.



STEVE:  Yeah.



LEO:  You know, it may be - I wonder if his handle is his zip code.  That would be Chicago area; right?  What is it?



STEVE:  60223, he said.



LEO:  60223?  Yeah, Midwest somewhere.  Or maybe it's a chemical something.  That's what I would guess.



STEVE:  Could be.



LEO:  My college roommate and good friend just passed away at the age of 56.



STEVE:  Oh, how - why?  So young, Leo.



LEO:  I know, so young.  Pancreatitis.  It was unexpected.  But he was the guy in Oregon for food safety and tracked down many famous cases of food safety, and he was the guy who got almonds irradiated for the future.  But the main reason I thought about this is because his license plate was, and I don't know if anybody will recognize this, 0157H7, which is the deadliest strain of E. coli.  It's a common culprit in food-borne illness.



STEVE:  Ooh, what a happy plate.



LEO:  Bill was quite the character.  When we were in college he used to sell T-shirts with parasites.  He had a picture of a fry cook, and it said, "How would you like your eggs?"  And all the eggs were parasite eggs that were common in human parasite infections.  So not a best-selling T-shirt.



STEVE:  Yeah, that one was one that raised eyebrows.



LEO:  Bill was a great man and a real loss, Bill Keene.  Yeah, very young fellow.  But, boy, he saved a lot of lives.  So he had a good life.  But in better news, continuing - oh, yeah, there's an article about him in USA Today.  I didn't see that.  That's good, yeah.  Go ahead.



STEVE:  Okay.  So, BULLRUN.



LEO:  What is BULLRUN?



STEVE:  BULLRUN is the codename.  And, boy, have we been learning about codenames, creative codenames that the NSA generates like crazy in the last few months, ever since Edward Snowden dropped the first of many bombs.  BULLRUN surfaced about a month ago in another release of slides.  And there was a slide that referred to the BULLRUN Project.  And it raised a lot of concern because it discussed the NSA's active work to decrypt the Internet's encryption.  And all the headlines that flashed were "NSA Breaks Internet Encryption."  And of course my take at the time, and even now, is, well, okay.  As Bruce Schneier has said, trust the math.  And we do trust the math.



But when a cryptographer sees that, and the cryptographer spends his life thinking about these problems, it creates a psychological dilemma.  It's, well, okay.  If that's true, and I, a cryptographer, pride myself in teaching cryptographer and knowing everything there is to know about cryptography, how do I square that?  And so that's exactly what Matthew Green did in his latest blog on Monday, December 2nd, two days ago.  His blog posting - he posts in CryptographyEngineering.com is his site, and his blog post was "How Does NSA Break SSL?"



And so he had been bugged about this briefing sheet, but has been pulled away.  He had intended to spend some more time on this, but has been pulled away by his own project, which has been taking up his time.  Anyone looking at his Twitter feed can see that he's talking about Zerocoin, which he's very excited about.  He's come up with an alternative virtual currency technology, not Bitcoin, not Litecoin, but Zerocoin, which it's on my radar, and I just haven't gotten into it yet because it's still very much evolving.  So I'm going to wait for it to settle down, and then we'll doubtless talk about it.



So Matt starts out by explaining.  He said:  "First, I'm well aware that NSA can install malware on your computer and pwn any cryptography you choose.  That doesn't interest me at all, for the simple reason that it doesn't scale well.  The NSA can do this to you, but they can't do it for an entire population.  And that's what really concerns me about the recent leaks:  the possibility that the NSA is breaking encryption for the purpose of mass surveillance."  Which of course is an entirely different problem.



So what he does is to essentially brainstorm, first sort of reasonable things, and then, a little bit later, admittedly, more of the tinfoil hat sort of things.  So we'll follow along a little bit and talk about this.  The first up that Matt looks at is the concept of just outright theft, or acquisition somehow, of the raw RSA keys.  And of course this approach, just the NSA getting keys is so obvious and easy that it's somewhat difficult to imagine the NSA spending much effort or resources on hyper-sophisticated attacks because we know from reports that have been published that GCHQ in Britain and our own U.S. NSA are completely comfortable and have suborned U.S. providers overseas.  And even within the U.S. they've demonstrated a willingness to obtain SSL keys using their subpoena powers and gag orders.



And we, I mean, one of the observations we've made is the insane number of certificate authorities that our browsers trust.  So any of those are able to mint SSL keys on demand.  And who's to say that that hasn't happened?  So unfortunately the whole public key infrastructure is a fundamental weakness that we talk about often on this show because that's one of the things we talk about is fundamental weaknesses.  And that's like first and foremost, which he talks about.



Now, the other thing that's a little bit of a concern is the idea of, as Matt puts it, suborning hardware encryption chips.  The New York Times recently ran a story where their headline was "Documents Reveal NSA Campaign Against Encryption."  And the illusions in the slides which The New York Times showed, which we also covered at the time on the podcast, noted that a significant fraction of encrypted traffic on the Internet is produced by hardware devices such as SSL terminators or accelerators.  The slide that we talked about a week or two ago with Google, it showed that before anything went into their own network, on their border was SSL equipment, well likely to be hardware, in order to speed this up.  SSL accelerators are often what companies use on their front end of their networks to essentially deal with the otherwise high computing cost of negotiating a public key with all of the people connecting to their site.  And those use hardware chips.  Those hardware chips come from somewhere.



So the question is, okay, what does "suborning a hardware encryption chip" mean?  And so in brainstorming, Matt suggests, he says:  "The obvious guess is that each chip encrypts and exfiltrates bits of the session key via 'random' fields such as initialization vectors and handshake nonces.  Indeed," Matt writes, "this is relatively easy to implement on an opaque hardware device.  The interesting question is how one ensures these backdoors can only be exploited by the NSA and not by rival intelligence agencies."



So what he's positing there is that, if the hardware performs the entire handshake, the whole protocol setup, and you want that all in hardware because that's where you get the performance boost, then things like initialization vectors, which should be one-time-use nonces - they can be publicly known, but they have to always be unique - and handshake nonces, which exist in the protocol.  If some of the bits from the session key were, for example, scrambled and stuck in the nonces, an observer looking at the packets would think everything was fine unless you really analyze every detail of the handshake, looking for cross-item correlation.  But if the NSA knew that such-and-such a chip were used, or just the NSA knew that chips were out there which misbehaved in ways that they had participated in engineering, then that could immediately remove, for example, half of the session key length, dropping it from 128 to 64, which is then much more feasible to brute-force.



So we don't know that that's not going on.  But apparently we have evidence that the NSA has been involved in this sort of pressure against encryption chips, and Matt suggests, if so, this is how it might be done.  And it's chilling.  And of course he's right.  It isn't at all clear how you prevent that from being, I mean, this is exactly the kind of backdoor which people in the know are worried that the NSA might have installed and be entirely relying on the secrecy of it not being broadly known.  The problem is, once it's discovered, if it hasn't been discovered by others, once it's discovered, then all of this hardware that's out there is compromised.  So that's horrifying and - if true.  So, yikes.



Next class of attacks against SSL could be side-channel attacks.  We've talked often about various sorts of side channel attacks.  Something like the operating time, the resource consumption, cache timing, or radio frequency emissions are all things that have been demonstrated to leak information.  Of course all of those require, typically require proximity.  I mean, something like cache timing, you really can't determine the cache timing at the other end of a connection, or any outside the machine at all.  But Matt notes that anytime you virtualize TLS servers, SSL servers in a cloud setting, and if spyware is able to be running in a virtual process on the same hardware, then it's sharing hardware resources.  And it's entirely feasible to imagine then that malware could be watching the shared cache of the process in order to find weaknesses and try to determine the keys that are in use.



So those are very chilling.  It's one of the reasons, actually, that I was very happy with the work that Dan Bernstein had done on the elliptic curve crypto that I chose for the SQRL authentication login technology because he really verified, his algorithm specifically guarantees that no secret information is involved in any timing or memory access at all.  So all of the memory accesses that are done, any timing decisions, branches, never involve anything that is supposed to be a secret.  So that's one of the ways you work to protect side-channel attacks.



But fundamentally we're looking at just a problem with the implementation of cryptography on platforms that are doing other things at the same time as crypto.  So the argument is that's one reason that you would use hardware is that, by encapsulating, for example, the entire SSL handshake in a single chip, then nothing else can get to it.  Except, as we just saw, if the NSA gets to the chip, then we're back having a problem.  So the problem is all of our technology is arguably sensitive to many different types of attacks.



And another one that we've talked about is weak random number generators, which Matt brings up again.  He says weak random number generators are a problem because the crypto that we're using absolutely depends upon the quality of random number generators.  We use those on the client side during the RSA handshake.  We've done a podcast about how SSL handshake works [SN-195].  The first thing that happens is the client generates a random value, which it sends to the server as part of its initial client hello SSL handshake.  And that absolutely has to be random.  It's called the premaster secret.  And if an attacker is able to predict the output of that client random number generator, then it's possible to decrypt the entire session from that point.



We also use client- and server-side randomness as part of the Diffie-Hellman handshake.  Both sides, remember, generate as random a number as they can, and then they use a variant of that or something derived from that which they exchange with each other.  And when they each receive what the other sent, they're able to combine that and arrive at a shared secret, which they then use from then on.  But that is extremely sensitive to the randomness of the content that they're each generating.  And if either one of them is not sufficiently random, that can compromise the handshake technology.  And, finally, long-term generation of random numbers.  We've already seen where this has been a problem, for example, the generation of RSA keys that are used in server certificates.  Remember that the EFF has a project called the EFF SSL Observatory.



And what we found, we the industry found, to our shock, was that there was actually duplication of private keys among many online services.  They independently arrived at certificates that were using the same private key because they were all using, I hate to think, maybe the BSAFE random number generator from RSA that was by default using a known buggy random number generator.  Thus the prime numbers that they were arriving at, thinking that they were pseudorandom, weren't as pseudorandom as they believed.  The consequence was that there was a lot of collision among these certificates.  And so that's certainly worrying.  Thus we really do need strong random number generators.  And though there's no proof of it, there is some reason to believe that the NSA was acting in order to get a bad random number generator out into the NIST specification.  And even though everyone who knew anything thought nobody would ever use this, turns out that that was the default random number generator in RSA's BSAFE library, across their entire product suite.



LEO:  Why not?  You know?  Make it easy.



[Talking simultaneously]



LEO:  ...all the work, you know?  Let's just...



STEVE:  Just unbelievable.  And then lastly he suggests that there could be, even though we've all fallen in love with perfect forward secrecy, for good reason, there could be esoteric weaknesses in perfect forward secrecy systems.  He notes that one of the things which SSL does in order to minimize the burden of establishing the initial handshake secret is session resumption.  We've talked about that often, too.  The idea is that, when the endpoints already have - when the endpoints have previously agreed on a set of public key base parameters, the client will offer, essentially, a ticket of that session to the server when the client notices it's connecting to the same server it had connected to before.  If the server is caching its sessions, then it'll look up, it'll use that session ticket to find the matching ticket and say, oh, and basically short-circuit the most time-consuming process.



Now, the problem is that, while that's neat, if you're just connecting to machines, what do you do if you're connecting to a server farm?  Now the problem is the client could be reestablishing a connection with a different machine in a huge server farm.  So now you've got to come up with a way, essentially, of moving all of the session information and session tickets out to the front, where there's some way to sort of offload that from all the individual servers.  And it turns out it just creates a huge architectural headache for people who are trying to use resumption tickets, and it can be a problem.



And then Matt also notes that the Diffie-Hellman parameters, which are increasingly being used because we're all liking Diffie-Hellman as opposed to RSA for our crypto, they must be chosen with care.  That is, the so-called elliptic curve parameters must be chosen with care, and that using curves which are not safe can quickly destroy the entire system's security.  So in general, Diffie-Hellman is fragile and requires proper behavior from both ends of the handshake, for reasons that we've already talked about.  So those are sort of the standard, not going to raise any eyebrows sorts of problems.  And it's a summary of the issues that we've talked about throughout the podcast in the past.



Under what Matt considers "tinfoil hat concerns," or maybe regard them as thought experiments, the what-if sort of stuff, he talks about just what about breaking RSA keys?  And Matt notes in his blog, he says:  "There's a persistent rumor in our field that NSA is cracking 1024-bit RSA keys."  He says:  "It's doubtful this rumor stems from any real knowledge of NSA operations.  More likely it's driven by the fact that cracking 1024-bit keys is highly feasible for an organization with NSA's resources."



Okay, now, wait a minute.  "Highly feasible."  To get a calibration on that, back in '03, so 10 years ago, a decade ago, encryption researchers Shamir (the S of RSA) and Tromer estimated it would cost $10 million for a purpose-built machine that could factor one 1024-bit key per year.  Okay, but that was 10 years ago.  An updated estimate this year, in 2013, Tromer relooked at this and estimated that the numbers would be about a million dollars for cost for a machine to factor 1024-bit keys in hardware, and it might be significantly lower, which of course is pocket change for the NSA.  But remember, that's a year.  So we're still talking about a really substantial amount of work to do this.



But anyway, so summing it up, Matt says, why is this considered tinfoil hat?  And bringing it sort of back to some reality, he says:  "Because as far as we know, nobody's ever done it.  Not even once.  Not even at 1024 bits.  So all the entire crypto community has are rough guesses."  He says, since it's never been done, guesses could be dramatically too high or dramatically too low.  He says and 1024-bit RSA keys - he notes that 1024-bit RSA keys are now being rapidly phased out.  For example, when I renewed my certs and went to EV certs, what, about two years ago because I'm about to come up to renewing them again, I went to 2048.  In fact, that was the default that Digikey was then recommending.  And of course Google famously updated all of their connection technology to 2048-bit, ahead of their end-of-year deadline, which is what they were planning.



So, and we do know, what is it, 768-bit keys have been cracked.  But remember that this scales exponentially.  So 1024-bit is not one third harder than 768.  It is dramatically, exponentially harder.  And we've already doubled the key length to 2048.  So everyone believes that we are secure and are going to be.



Okay.  What about RC4?  And this is still in tinfoil hat mode, Matt feels, the notion of cracking RC4.  So it turns out that, and we've talked about cipher suites often, there's a large suite of ciphers available.  Servers have their batch; clients have their batch.  And they negotiate to find the strongest, or really what happens is the client gives the server the dump of all it knows about, and from among those the server chooses, in the order it wishes, what it wants.



And so, for example, GRC, my site, had been using RC4 until a few weeks ago because it was the only one that would rate me as well as I wanted to be over on SSL Labs.  I didn't see any danger in it.  And Matt argues that there is really no danger.  But in tinfoil hat mode, he also notes that, first of all, 50% of all HTTPS traffic is still being secured with what he refers to as "creaky old RC4."  And admittedly, it's starting to show its age.  Remember that the attack that we covered a few months ago was done by some of the RSA guys where the way RC4 works is it uses a scrambling algorithm where it has two arrays of 256 bytes.  The key sort of prescrambles the array, and RC4 generates a pseudorandom bit stream coming from the dynamic continual scrambling of the array.



So the idea is that it gets better as it goes along.  But the researchers discovered, if they really looked more carefully at exactly the way the arrays were being scrambled, there was a greater lack of randomness among the choices that the system made than they previously believed.  So basically they pushed the original known weakness out further, and further worried everybody about the strength of RC4.  Still not to the point that it would be a real problem, but worrisome.



And so Matt writes that we don't know of any attack that would allow the NSA to usefully crack RC4.  Even given all of this, with all these weaknesses, there still isn't a way, as far as we know, to usefully crack it.  And he says:  "The known techniques require an attacker to collect thousands or millions of ciphertexts that are either (a) encrypted with related keys" - and that was the WEP problem that was one of the reasons we did abandon the WEP WiFi protocol - "or (b) to contain the same plaintext."



And Matt reminds us that the best-known attack against SSL using RC4 takes this same plaintext approach.  It requires the victim to establish billions of sessions.  This is the BEAST attack.  And it's why BEAST was really never anything to worry about.  And even then it only recovers fixed plaintext elements, like cookies or passwords, occurring at the front of these billions of identical queries that browsers make.  So it was at worst a theoretical attack.  And it's why I kept RC4 where I had it.  Now I've moved it down, and we're using perfect forward secrecy.  And of course everybody else is famously moving to that very rapidly because BEAST is just no - actually, BEAST, I'm sorry, BEAST was the cipher block chaining problem.  Was it CRIME, I think, that was the RC4 attack?  Anyway, so fundamentally, in tinfoil hat mode, we could argue that RC4 is crackable.  But practically, Matt's feeling is, eh, not so much.  And certainly it's in the process of leaving.



And then just out of the blue he says, well, you know, if we're going to have our tinfoil hat on, how about some sort of other side-channel attack, something that we can't imagine or don't know about, because fundamentally our cipher technology is vulnerable to those.  So if you like tinfoil, you like the idea that maybe there's some way of leaking secret information that we haven't picked up on, but that the NSA knows.



So, and then finally, of course, does the NSA have secret and completely surprising quantum computing capabilities.  Well, nobody thinks so.  I mean, nobody seriously in academia believes that the NSA is that far ahead of us.  And they would have to be radically far ahead in order to have actual quantum computing technology to crack crypto.  But if we have our tinfoil hats on, who knows?  And I just note that, with all of the certificate authorities that our browsers now trust, how do we know that one of them isn't the NSA?  I mean, literally, a covert, from the beginning, certificate authority that is wholly co-opted, I mean, that actually is an NSA front and has a convincing set of credentials and is doing business and all of the browser vendors believe it's whomever, and it's not.  I mean, that's, if I were the NSA, that's one of the things I would do.  So I hope I just didn't give away one of their secrets. 



LEO:  Oh, do you really.  Wouldn't it be funny if it were the Hong Kong Post Office?



STEVE:  Oh, goodness, yeah.  Well, I would imagine it's something really hiding in plain sight, actually.  But Matt wraps up by saying that one bright spot is that the NSA GCHQ disclosure, the disclosure that we saw, does describe their present capabilities as, quote, "extremely fragile."  So that implies that the things we are already doing have significantly changed the game for them.  And I think that makes absolute sense.  I think that they were noting that, yes, there were things they could do, but those were fragile, meaning that a whole bunch of things had to come together in just the right way for them to be able to decrypt.  And that might have been storing up traffic and then arranging to get an expired key, that we've talked about on the podcast, that kind of thing, the idea being that they recognized, if the world switched to perfect forward secrecy, so that you could no longer determine what the session key was, use the server's private key to decrypt the session key because of using ephemeral Diffie-Hellman handshake, all of that that they were using was then obsolete.  And their fragile system was hurt.



So there's no question in my mind that deep within the bowels of the NSA they are not happy about - essentially the upshot from what Snowden did has clearly mobilized the entire security industry to speed up our game, basically, take this much more seriously than they were.  And because what the NSA was doing was arguably fragile, doing things like tapping Google's unencrypted links between datacenters, well, Google's going to fix that.  So that's a perfect example of something fragile which has now been taken out of their grasp.



LEO:  I think this was all in response to that in the first place, that they were most - the thing they were really afraid of was the already widespread use of encryption and so forth, and that they were staring at a dark Internet.  And while they had great capabilities with analog circuitry and telephones, they didn't have that same kind of capability.



STEVE:  Well, but we were also complacent.  I mean, Google assumed that their private fiber was secure.  They made that assumption.  And it turns out, I mean, so we all just sort of didn't recognize what was going on.  And that's the other thing, too.  The Snowden leaks have been so powerful because it hasn't been one fact that got out, it's been a tsunami of revelations about just how aggressive the NSA's policies have been, which has touched every corner of the security industry and has said to people, okay, we need to change things.



LEO:  Yeah.  Well, now what?  Now what are they going to do?



STEVE:  Leo, there isn't anything they can do.  I mean, they're going to have to appeal to the law.  They're going to have to end up using subpoena powers and national security letters in order to get the things they need.  They're going to have to demand the keys from companies or from the companies those companies trust, meaning the certificate authorities.  I don't see any other solution.  And so that means we need to adopt technologies that are purely, that are entirely TNO.  We need to Trust No One.  That is one of the fundamental concepts of my SQRL login technology is there is no third party.  It is fully TNO.  You are trusting no one else.  Unfortunately, the entire Internet infrastructure with websites means we have to trust the certificate authority.  So that's its point of weakness.  That's where the NSA will go.



LEO:  Well, you've been right on all along with your calculations about how these things are working, so...



STEVE:  It's because ultimately it's technology driven.  And we understand technology.



LEO:  Yeah, if you understand how it works, it's apparent where the attack surface must be.



STEVE:  Yeah.



LEO:  Steve Gibson is at GRC.com.  Yeah, that's the place where you can find SpinRite, the world's finest hard drive maintenance and recovery utility.  You can also find all his freebies, his Perfect Paper Passwords, all the great things he does.  And while you're there, the 16Kb version of the audio, the smallest audio made available, and full transcripts so you can read and search.  It's very helpful.  I was searching the other day for something you mentioned.  And because all those transcripts are there and online and Google indexes them, it's very easy to find what you need through those transcripts, so thank you for doing that.  We have full-quality audio and video available at our website, TWiT.tv/sn for Security Now!, and of course wherever netcasts are aggregated.  We have feeds for all of those, as well.  Are you going to do a Q&A next week?



STEVE:  I don't know.



LEO:  Maybe.  If you've got questions for Steve, at some point we will do a Q&A.  Go to GRC.com/feedback.  Do not attempt to question him in any other form.  Actually, I guess you're answering people on Twitter, so...



STEVE:  I am.  And, I mean, it's a mixed blessing.  I love the social network that we've established.  I like being able to answer people.  I feel a little bit of an obligation to do that, so sometimes it's a little disruptive when I'm deep in brain mode.  But I know people will understand if I don't get back with them immediately.  And for what it's worth, I mean, please do continue submitting questions to GRC.com/feedback.  I would love to do a Q&A.  We're driven by the news.  And so if the news overwhelms us, we've got to cover the news.  But we always have our listeners' questions to fall back on.



LEO:  Right on.



STEVE:  Yeah.  And a lot of, I mean, a lot of what I talk about now during the week is coming to me in real-time through...



LEO:  Through Twitter.



STEVE:  ...the Twitter, yes. 



LEO:  Well, then in that case let's mention that you are @SGgrc on Twitter.



STEVE:  Oh, by the way, Leo, somebody, just for some reason they checked, they did a search of posts to @Sgrc. Do not do that.  It turns out people have been mistweeting me to @Sgrc, and there's a whole collection of people that I never saw, and I never replied to.  So don't use that.  Use SG, as in obviously Steve Gibson; GRC, Gibson Research Corporation:  @SGgrc.



LEO:  S double GRC.  And look for the guy in the fancy derby or whatever.



STEVE:  Nancy, my sister, took that of me over the holidays when I was up there a couple years ago, yeah.



LEO:  The scarf and the beret.



STEVE:  Yup.



LEO:  Thank you, Steve.  We'll see you next Wednesday.  We do this at 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC, every Wednesday, live, if you want to join us live and visit through the chatroom.



STEVE:  And next year we'll be switching to Tuesday at 1:00 p.m. Pacific time.



LEO:  4:00 p.m. Eastern, 21:00 UTC, that starts January 7th.  So be prepared.  Be aware.  Thank you, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#434

DATE:		December 11, 2013

TITLE:		Listener Feedback #179  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-434.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's got questions; he's got answers.  We'll see if we can get through them.  Lots of security news, too, including Patch Tuesday notes.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 434, recorded December 11th, 2013:  Your questions, Steve's answers, #179.



It's time for Security Now!, the show that protects you, your lived ones, and your privacy online with the man, the myth, the legend, James Tiberius Gibson.  No, wait a minute.  I'm confusing you with Captain Kirk.



STEVE GIBSON:  James Caffeinated Gibson.



LEO:  Steve Caffeinated Gibson.  Well, wait, hey, everybody take a drink of caffeinated coffee.  Mmm.  Hi, Steve.  I guess we're getting a little close to the holidays here.  Happy holidays to you.



STEVE:  Yeah, it's been cold.  Wow.  I mean, like, really cold.



LEO:  We've got winter in Irvine.



STEVE:  Of course you and I are pussies, Leo.



LEO:  I know.



STEVE:  It's like, 50 degrees, oh, my goodness.



LEO:  I'm freezing.



STEVE:  No, it's negative something in [indiscernible] right now.



LEO:  You should be in Minnesota right now, where the wind chill is -27.



STEVE:  So the fates have sort of been good to us because this week did not overload us with stuff to talk about.  That is to say, we actually have time for some Q&A.  So I'm not sure how much, but we'll certainly give our audience a great probably two hours, if we go the way we have been lately, or nearly that, a hundred minutes or so of podcast, full of interesting stuff and feedback from our customers.



We've got a Patch Tuesday from Microsoft and Adobe.  We've got a new release of Firefox.  The NSA was found, in another drop of Snowden's never-ending dribble of slides, to be apparently using Google's own cookies to track users. So we'll talk about that.  There was a major botnet control center discovered with 2 million passwords, which gave us an additional look into the passwords people are using.  FreeBSD, which is the UNIX that I use, has decided to stop trusting hardware random number generators that have recently appeared in chips, for reasons of the NSA.  A French Certificate Authority was found to have issued an intermediate certificate that was being abused.  Whoops.  A bunch of miscellaneous stuff, and Q&A.  So, I think, a great podcast today. 



LEO:  Busy, busy, busy, Mr. Gibson.  Okay.  If you take a drink, I have to take a drink.



STEVE:  And I've been putting this together since 5:00 a.m.



LEO:  Holy cow.



STEVE:  I got up at 5:00 to work on the podcast.  So six hours of production.



LEO:  We are very grateful for the work you do.  By the way, you've inspired us, because of the transcriptions you get done from Elaine, we've decided to do transcriptions of many of our other podcasts because it's just a great way to kind of find stuff in the podcast.  It helps with searchability.  I use it all the time.  I'll Google something that I know you mentioned because it will pull up a transcript, and it'll pull me right to that part of the podcast.  It's a really great way to do that.  So thank you for inspiring that, and we'll have more information on that later today on our Inside TWiT show.  Which reminds me that somebody has very kindly offered to, and I know you probably have it in the notes a little later on, but I just want to mention this...



STEVE:  Yeah, we should now because I don't say much more than that.  But go ahead.



LEO:  Bob Noble is launching a project early next year.  He wants to - the series has been flagged for translation into, get this, sign language by IndieUnite.com.  That's a free service provided by 1 BillionHex, which is a great name for something.  There is a concept demo on YouTube, but it's very rough, and it doesn't include the actual sign language yet.  So the rigging and the animation of the sign language, they don't use human hands, they use animation.  It's time consuming.  So he's working on a way to get this done.



STEVE:  So they would take the audio podcast, and I think he said starting from No. 1, and they felt because it represented such a repository of knowledge that it ought to be available to people who could not hear them.



LEO:  He's going to animate each episode from scratch.  So instead of using picture-in-picture - but it sounds like a lot of work.  Anyway, Bob, thank you.  It is a great project.  The guy was an IT guy, and he said, "Nine years ago I tried to incorporate some art and acting into my work."  And he's always been an advocate of accessibility.  So he started by doing talking books for the blind.  He got a degree in performing arts with an emphasis on voice acting.  Some health problems got him in a wheelchair, unfortunately.  And he became the chief of a small, or the chair, that's a good name, the chair of a small charity dedicated to helping indies and organizations better themselves through media and content publishing.



STEVE:  And he mentioned that, because we have Creative Commons copyright license, that this kind of reuse is permissible.



LEO:  Right.  We encourage this.  Our license - and somebody else asked me if he could rebroadcast our show.  I said yes, just look at the bottom of every page on TWiT.tv for our Creative Commons license.  Shorthand for it, it's noncommercial, free for noncommercial use.  You must give us attribution, and you must reshare anything you do in the same license.  Share-alike, it's called.  Now, that way somebody can't take this, put sign language on it, charge for it, or put a paywall behind or whatever.  And I think that's really, really great.



Anyway, Bob, thank you.  We really appreciate it.  1 BillionHex, that's his handle on SoundCloud.com.  He also has a CD Baby ShowLink.in/Bob, so he does music, too.  Really neat guy.  Bob, we'll be in closer touch.  But a heads up, look for that coming, and we'll talk about it when it comes out, coming next year.



STEVE:  And we ought to mention also, we talked about this before we began the podcast, Leo, that I spent the weekend assembling the special holiday episode.



LEO:  Oh, baby.  I'm excited.



STEVE:  And for whatever reason, well, first of all, I mean, it was a big deal for me 15 years ago when you and I met for the first time.



LEO:  Big deal for me.



STEVE:  I have it on tape.  It was June 17th of 1998.



LEO:  Holy cow.



STEVE:  Fifteen years ago.  My hair was dark and...



LEO:  My stomach was small.



STEVE:  Well, so we'll call these our "time capsule episodes" because I took three episodes, the very first three that I had, June 17th of '98.  And then a little bit later, actually December of '99, and we were talking about the Click of Death back then with the Iomega Zip and Jazz drives.



Then in December, about this time in '99, your co-host, Kate Botello, discovered ShieldsUP!.  I had just put it up on the 'Net, just created it.  And she was over there looking for SpinRite, and she said, what's this?  And it turns out that I knew her name and saw her hard drive, and she was completely exposed, I mean, which was what happened to everybody in the beginning because everyone's hard drives were out on the Internet, which was what prompted me to create ShieldsUP!.  So that episode is her showing it to you because nobody knew about it.  And you were like, wait.  Our Steve did this?  Gibson?  And she says yeah.



And then a little bit later, March 3rd of 2000, I was on your Call For Help show and demonstrating it.  And we were talking about personal firewalls, which no one really knew about.  No one had them.  And I made the prediction back then that someday personal computers were going to have them built in because they were so important.  It was like, really?  You think so?  It's like, yeah, I think so.  So anyway, fun commercials from back then.



Anyway, it's an hour where I just clipped out, like, the good parts.  And some stuff were kind of dumb, but there's like a newscaster predicting that someday - that Nokia made a prediction that somebody handheld phones may be connected to the Internet.  It's like, oh, my god.  So I think everyone's going to get a kick out of it.



LEO:  I can't wait.  That is a lot of fun.  All right.  Well, we have lots to do today.  It's a busy day.  We've got a Q&A, first time in a month.  And of course I should mention that show will air on Christmas Day, December 25th, in place of our regular show, at the usual time.



STEVE:  And like last year's, it's really one, you know, you could listen to it; but, boy, the visuals are something you're not going to want to miss.  So since people will be home, maybe they can break their regular commute cycle and watch this one.



LEO:  Download this one on video, yeah, yeah.



STEVE:  Yeah.  This one you're going to want to see.



LEO:  11:00 a.m. Pacific, as always, 2:00 p.m. Eastern time, 19:00 UTC, Christmas Day.  Get up in the morning, open your presents, and watch Security Now!.  Believe it or not, Steve, there are people that will do that.



STEVE:  So is that what you're going to do?  You're going to air these specials and best-ofs and things at the same timeslots they would normally be live?



LEO:  Yeah.



STEVE:  Okay, cool.



LEO:  I think that's the plan.  You know, I haven't asked, but I think that's what we will - normally that's what we do, yeah.  So if you're in the habit - and a lot of people don't observe Christmas.  So if you're in the habit, and it's a Wednesday, it's a normal day for you, and you tune in, you will get Security Now!, just a very special Security Now!.  And many of our other shows are doing best-ofs.  And of course don't forget the following week is New Year's Day.  We're doing our 24 Hours of New Years.  I've been trying to convince the staff for years to do this.  They finally acceded.  Now that I'm an old man, I don't know how I'm going to do it.  But starting 4:00 a.m. Pacific, 7:00 a.m. Eastern on New Year's Eve, that is 20, no, I'm sorry, that's 12 Noon New Year's Eve Day UTC, and then going to 4:00 a.m. New Year's Day.  So 4:00 a.m. New Year's Eve...



STEVE:  And you and I will be...



LEO:  And you're going to come up; right?



STEVE:  You and I will be together, yep.



LEO:  So we've got two - we've got a normal Security Now! next week, and then it gets weird.  Christmas Day and New Year's Day.  It's going to be a lot of fun.  And I should still be alert by that time.  I won't be passed out yet.  Or actually, wait a minute.  New Year's, no, you're New Year's Day.  So I don't know what we're going to do for Security Now! on that Wednesday.  I will have gone home.  I'll be fast asleep.



STEVE:  Yeah, we're doing it on Tuesday.  We talked about this before.



LEO:  So we'll do it ahead of time, and then - yeah.



STEVE:  Right.



LEO:  Okay.  All right.  The best part of this, though, is you're going to get 26 five, four, three, two, one countdowns, Happy 2014, because we're going to start, and I think it's Papua, New Guinea, whatever the Western, or is it Easternmost, whatever the...



STEVE:  You said there were some half-hour time zones, too.



LEO:  There's some 15-minute and half-hour time zones.  I'm told there's 27 time zones in the world.  And we're going to try to hit each one and count down each one.  That's a lot of champagne, 27 glasses of champagne.  Wow.  You know, I've got to...



STEVE:  I'll be bringing...



LEO:  Go ahead.



STEVE:  I was going to say, I'll be bringing my coffee-fixing stuff up, and we'll have you tasting...



LEO:  We'll have coffee.



STEVE:  We'll see, yeah, we'll...



LEO:  I think a lot of coffee, yeah.



STEVE:  I think so.



LEO:  And I think I may not drink champagne.  I might drink Martinelli's Sparkling Apple Cider.  It just looks like champagne.



STEVE:  Yeah, because, you know, you need stability to be on that ball, Leo.  The ball, you need...



LEO:  Oh, I ain't doing 24 hours on a ball.  I'm not nuts.  All right, Steve.  What's the news across the nation?



STEVE:  Well, we are here on our second, we just passed the Second Tuesday of the Month.  It's funny because when we announced the podcast will be moving to Tuesday, I got a bunch of tweets from people saying, wait a minute, does that mean you won't be able to do Patch Tuesday anymore?  Because we're taking advantage of the fact that we're one day later than Patch Tuesday sometimes.  But Microsoft does release this information in some mailings that I subscribe to, so I think we should still be okay with our - we'll be a little more current, in fact, with Patch Tuesday.  It won't be yesterday, it'll be today that those patches are available.



We have some important things, both from Microsoft and Adobe, because they're zero-day fixes, meaning that they were discovered because bad guys were found already doing them in the wild before the vulnerability was known.  So these are, as always, you want to stay current.  There are 11 patches fixing 24 vulnerabilities.  So that's kind of medium size, relative to what we see on these monthly updates from Microsoft.  Twelve of them, 12 of the 24, so half of them, were remote code execution vulnerabilities.  Those are never good.



You have eight elevation-of-privilege vulnerabilities, which is where, if you run an unprivileged account for security, which of course is always what people should do, this is a way of essentially getting admin privileges when the sandbox essentially that you're running in with deliberately limited privileges doesn't allow those, so those are not good.  Eight of these are being fixed.  And they call them denial-of-service vulnerabilities in two cases.  They're not what we think of like in terms of a bandwidth flood.  They're basically a crash.  Something is able to crash some software, thus denying you the service of that thing it crashed, whatever it is.  So two of those got fixed.



An information disclosure vulnerability, that's one that people are considering worrisome because it involves the cloud services and the way Microsoft's cloud services function, which would allow account information to escape.  So you want to pay attention to that one, too.  I think that was 104.  And then a security bypass vulnerability.



So what Microsoft is now doing is ranking these, as we've talked about before, in the order in which they should be done if for some reason you can't do them all.  And they're sort of sequential:  96, 97, 98, 99, and 105.  They skip a bit.  Those are the, like, if you only can do some, do those to immediately prevent exploitation by attackers.  And then 96 of that, the very first one, is the critical zero-day vulnerability in Windows and Office; 97 and 99 of that group fix a dangerous scripting problem in Windows.  And Microsoft has said, of those three, of 96, 97, and 99, they're expecting active exploits immediately, and in some case that's already happened.  So those need to get done.  And then the lesser important ones - 100, 101, 102, 104, and 106 - should be ASAP, like as soon as possible.  And then 103 is like, eh, at your earliest convenience, says Microsoft.  So anyway, do them all.  End users certainly should.  And I guess admins who don't have a choice, do the important ones.



LEO:  Right.



STEVE:  Adobe's updated Flash and Shockwave, fixing two security holes, including one that is in the wild now, being actively used in attacks, malicious Shockwave Flash .swf files are being attached to Microsoft Word documents and emailed to people.  And the curious who open the Word doc get themselves exploited immediately.



LEO:  Is that using a macro?  How are they doing that?



STEVE:  It's just an attachment.  And I guess the act of opening it when it's attached to the DOC file will cause it to get executed.



LEO:  Wow.



STEVE:  So that's a question.  It may well be a macro that is saying, oh, run this.  So the DOC says run the attachment, and then the attachment says, oh, thank you, and takes over your computer.



LEO:  The reason I ask is because Word now won't run a macro automatically.  It'll have to - it'll say, do you want to run this macro?  I wonder how they're doing that.  It's interesting.



STEVE:  Yeah, they probably get around that.



LEO:  Yeah, maybe they got around that.  Yeah, there you go.



STEVE:  You know, it's like the address space layout randomization, that malware just says, okay, yeah, well, you have that on, but we're going to get around that.



[Talking simultaneously]



STEVE:  We have a new Firefox.  That happened a couple days ago.  I announced it to my Twitter followers.  Not a big deal.  The one really nice thing - this is v26, so anybody who wants it, who just, like, leaves Firefox running all the time, as I do, go to About > Help, or Help > About, rather, in your Firefox menu, and up comes the About box, and you'll see that it immediately kicks it into downloading the update.  And then you need to restart Firefox.  Which is fine because it, like, brings all your tabs back, and you'll have the latest and greatest.



What they did was all Java plugins are now click-to-play.  So I don't know what took them so long.  But that's now in v26.  That's a big change there.  So that, if any Java is part of a web page, it will not run by itself.  Which, yay, that's absolutely what we want.  You have to - it'll show it to you disabled, and you have to explicitly click on it in order to run it.  Which is a reasonable tradeoff.  We know that there are sites that depend upon Java, that won't run without it.  But running without intervention is a massive, as we've often talked, security vulnerability.  So now you just have to click on it in order to run it.  So it's like, hey, that seems reasonable.



They've also updated their password manager so it now supports script-generated, that is, their built-in password manager in Firefox, so it now supports script-generated password fields which it just wasn't aware of before.  They made some changes to the way Update works with Windows, so that the user running the update no longer requires write permissions as long as they have, like, a Mozilla maintenance service which runs in the background.  Because it's a service, it's able to have system-wide rights.  And so they've arranged for the non-privileged code, which sees the update, to communicate with the service and get the service to do the update so a non-privileged user is able to get their Firefox updated nicely.



They added also H.264, which of course is now the new standard video codec for Linux, which didn't have it in Firefox before.  And then there's a bunch of developer improvements and miscellaneous fixes.  So anyway, it's a good thing to get, and it's easy.  Just restart Firefox after you go to Help > About.



Okay.  So disturbing news from the next Snowden dribble.  And I have to just take my hat off to the strategy because, first of all, it is, when you think about it, it is phenomenal how much Edward got before he left, the fact that even now we're still getting new revelations from the data that he collected.  And it's been so much more effective than if he'd just dumped it out on the world and said, "Here," because we would have been overwhelmed.  It would have been, oh, my god, and the news would have been significant for a week, and then it would have been forgotten.  So this is the way to do it.



What we've learned, and the Washington Post covered it a couple days ago, is that in a slide that was recently released, that it made reference to the NSA and GCHQ, the equivalent agency in the U.K., using cookies, and specifically the Google PREF ID cookie, and this slide says to enable remote exploitation.  And it is not clear how that exactly works because, again, a lot of interpretation needs to be done of these slides.  But the Washington Post wrote, they said:  "The agency's internal presentation slides, provided by former NSA contractor Edward Snowden," which is the standard byline now for these, "show that when companies follow consumers on the Internet to better serve them advertising, the technique opens the door for similar tracking by the government," essentially piggybacking on the tracking that other trackers are doing.



"The slides also suggest that the agency is using these tracking techniques to help identify targets for offensive hacking operations."  And it talks about enabling remote exploitation.  So my take on this, as I started saying, is, well, okay.  We have to assume, because all the evidence now demonstrates that what can be done is being done, the NSA are full of really smart people, and so they're as able to look at traffic on the Internet as hackers can.  And they can look at this, I mean, and their bosses are saying, "We want you to track everything.  You know, everything.  So do that."



So they're seeing users' browsers sending out cookies with every query that the browser is making.  And they're saying, well, okay, why can't we track these?  And the answer is they can.  If they're sitting here looking at a big pipe, and they're able to obtain nonencrypted, which is to say non-SSL, standard HTTP queries, then all of those queries are containing cookies wherever they're going.



I mean, I'm sure you're aware, Leo, how pervasive Google's Analytics are on websites?  I mean, Google Analytics is, like, everywhere because a phenomenal number of sites use it. Well, that means that there is Google script running pervasively across the Internet, and that script is making queries to Google which are sending the Google Analytics cookies back to Google.  And anybody sitting on the Internet looking at all the unencrypted traffic can absolutely track users as easily as Google can.  They're getting all the information that Google is, and potentially all the information that all the tracking advertisers are getting.  I mean, so why wouldn't they be doing this?  It makes perfect sense that that's what someone would be doing in order to aggregate this.



This sort of makes the NSA like this super cookie tracking organization because it's cross organization whenever the connections are unencrypted, which unfortunately is still a lot of the time.  We've got a question later on from someone who installed Calomel and was a little shocked by how many sites had no encryption whatsoever.  He just assumed that everybody was doing it.  But many sites are still not doing it.  So it's like, yeah.  Again, we ought to assume what can be done, the NSA will be doing.



And the fact is there's so much use of nonencrypted traffic, where encryption is still only used during password negotiation, when you negotiate the password.  And the problem, of course, as we know from our coverage of Firesheep earlier, and if any listener doesn't know about Firesheep, go find that podcast because it is still happening [SN-272].  Anytime you use a secure connection to log in, but then your browsing and your movement around the site subsequently is not SSL, that means that the way you are maintained, your login is maintained, is a cookie is going back and forth to the server in the clear.



And what Firesheep showed was how easy it is to obtain those cookies in any open WiFi setting because anyone on the WiFi, it's like you're on a hub on a network.  You're on a shared network.  And you can see all of the cookies that everyone is using.  That is their logged-on session.  And so it is trivial for someone to just start making queries to the same server and giving it that cookie.  They're logged on, too, as the person whose cookie they stole.  And this is still very pervasive.  So, I mean, it really does say that we need to get HTTPS all the time, everywhere.  And some major websites, as we'll find out later in this podcast, are still not doing that.



LEO:  By the way, Snowden one of 10 people nominated for Time magazine Man of the Year.  Didn't win it.  Pope won it.  There was some pretty tough competition.



STEVE:  That's pretty stiff competition, yeah.  He seems to be a neat Pope, too, so...



LEO:  He's a good Pope.  I probably would have preferred Edward Snowden, but it's not up to me.



STEVE:  That's a little dicey because...



LEO:  Well, remember, Man of the Year is not a good man, necessarily.  Hitler was Man of the Year.



STEVE:  Oh, okay.



LEO:  It's just the most important person, newsworthy wise, that year.  Right?  So it doesn't have to be good.



STEVE:  In that case I agree, Leo.  I think, with that criteria, Snowden really does deserve it.



LEO:  You tell me.  Here's the candidates:  Bashar Assad, President of Syria; Jeff Bezos, Amazon; Ted Cruz, Senator from Texas; Miley Cyrus.  I don't know how she got on that list.  For good or evil, I don't think she made a difference.  Pope Francis; President Obama; Hassan Rouhani, President of Iran.  You see, it doesn't have to be somebody good, just somebody who made a big difference; right?



STEVE:  Yeah, yeah.



LEO:  Kathleen Sebelius, Secretary of HHS.



STEVE:  Whoops.



LEO:  Not Man of the Year, I don't think.  But Edward Snowden, NSA leaker; and Edith Windsor, the gay rights activist whose Supreme Court case cleared the way for gay marriage.  So those are all very important.  But, boy...



STEVE:  Wow, that's some stiff...



LEO:  Edward Snowden's, to me, on the top couple or three.



STEVE:  Yeah, because of the nature of the way he did this.



LEO:  He's changed the world.  This changed the world.



STEVE:  Yes.  Yes.  I didn't cover, because it just didn't seem, I don't know, quite relevant enough, but Silicon Valley is really getting together now and saying we've got to put together a coalition to fight this, to fight this pervasive surveillance.  And they've put together, I guess, a letter and sign-up sheet and so forth in order to begin to act.  But the NSA was critically hurt because it turns out that what they were doing, as we know, was way more than people feel they really had a license to do.



LEO:  Yeah.  By the way, even Time magazine calls it Person of the Year.  I'm going back in time when I call it Man of the Year.  I don't know when they changed it to Person of the Year, but it's Person of the Year.  Or Human of the Year.



STEVE:  Wasn't there going to be a machine?  Was it Watson?  I thought there was...



LEO:  For a while I think Watson was the - what is the history of Time magazine's...



STEVE:  Entity of the Year, Leo.



LEO:  And why Time magazine gets to decide this, I don't - just because they say they do, I guess.  Let me see, the Person of the Year.



STEVE:  Well, yeah, and Forbes has their 500 and their 100 and that.



LEO:  It started in 1927, Charles Lindbergh.  Last year it was the President.  The Protestor was, because of the Arab Spring and Occupy Movement, in 2011.  Mark Zuckerberg in 2010.  That makes no sense.  Ben Bernanke of the Fed, 2009.



STEVE:  Although remember Facebook was a big lot of noise back then.



LEO:  Yeah, yeah.  Good Samaritans in 2005:  Bono, Bill Gates, and Melinda Gates, kind of a triumvirate.  The American Soldier, 2003.  You know, in 2002, Whistleblowers were the Persons of the Year.  And I think that's what Snowden is; right?



STEVE:  Oh, my goodness, of course, yes.



LEO:  So let's just say he won in 2002 for - collectively.  The Pope was picked, Pope John Paul II, in 1994.  So it's not the first...



STEVE:  Oh, no kidding.  But a different Pope.



LEO:  Different Popes.  Francis was just a twinkle in the eye of the College of Cardinals.  I'm sorry.  I'm going straight to hell.  Continue.



STEVE:  So a security research group, Spider Labs, discovered a massive database of usernames and passwords.  And so this is different than the typical vulnerabilities or disclosures that we've seen before.  Typically what we report on is a given website has lost control of their database.  And so we're looking at the passwords of that website.  In this case, what was found was the repository from a botnet.  So this is - it's called the Pony, P-o-n-y, the Pony Botnet because it uses - the botnet controller is identified as the Pony controller.  And I guess the controller itself is now open source, or the source has been published.  And it was by looking at the source that they were able to find this one controller of one botnet.



And so there are bots installed on people's machines, that they're clearly not aware of, that are collecting - the bots are spying on them, collecting account information, their credentials, as they log into various accounts.  And so 1,580,000 website login credentials were found; 320,000 email account login credentials; 41,000 FTP account credentials; 3,000 RDP, remote desktop, Windows remote desktop credentials.  And that's bad because that means that anybody who's got that can log into your remote desktop, which is full access - typically those are servers - full access to your machine then.  Three thousand secure shell account credentials stolen.



So first of all, you've got nearly 2 million login credentials found.  But then, as is always interesting to security researchers, they look at what these are.  And no surprises.  The password 123456, ever the most popular password, was used in 15,820 cases.  In fact, I've got a little table there from the breakdown.  Second most popular, little bit longer.  People thought, well, I'm going to make this password longer.  So they added 789 to the end of 123456.  Then third most were the little more lazy people.  They only went as far as 1234, and then they said, ah, you know, who cares about the 56.  That's obvious, so we'll just leave that off.  And then the word "password" is No. 4 on the hit parade.



LEO:  It always is, rhymes with "assword."



STEVE:  Exactly.



LEO:  Yup.



STEVE:  And then 12345, that made No. 5 on the list; 12345678, they didn't go as far as 9, but they went a little further than 6, and so that was No. 6.  I mean, and so forth.  I mean, this is - and I don't know, 1,224 sites accept the numeral "1" as a password.  So this is just...



LEO:  Wait a minute.  One digit?



STEVE:  One digit.



LEO:  Just one?



STEVE:  One, the numeral "1," and whatever it is says, okay, that's your password.  That's fine.  That must be email, dumb email servers.  I just, you know, wow.  So anyway, interesting list.  It generated enough news that KTLA TV had me on.



LEO:  I heard about that, yeah.



STEVE:  Last Thursday, I think it was.  And Rick Romero is their consumer guy.  And his mission, which is why he brings me back and reminds people about Password Haystacks at GRC, is just trying to get people to stop doing 123456, just for their own good.  Please do anything but that.  And so, which is why he likes the Haystacks idea because I'm just saying, just do something more.  Add a bunch of something to it.  Do something.  Doesn't have to be hard to remember.  Just get off this list because that's better than nothing.  And it's easy to do.



LEO:  You've seen the HaveIBeenPwned website; right?  It searches that database.  So you can enter in your email address.



STEVE:  Yes.  Nice.



LEO:  And the one that I - when I enter my email address, it says Adobe because, of all of the accounts that were hacked, that's the one that - and I knew about that.  So, yeah.  So if you want to know, it's HaveIBeenPwned.com, HaveIBeenPwned.  And, now, I don't know these guys, and it's Troy Hunt.  I don't know if he is saving the passwords or whatever, but I...



STEVE:  Oh, Troy's a good guy.  I would trust Troy completely.



LEO:  Yeah.  It's fun to look.  And you should never use the same password everywhere.  What is the - the bitcoin's gone down, hasn't it.



STEVE:  I think it was at nine something last time I looked.  But it seems to have stabilized.  I mean, it didn't, like, crash all the way back down.  It dropped down into the eights or sevens.  And so it seems to be sort of holding.



LEO:  Good.  Good, good, good.  As a holder of 50 bitcoins, you probably pay a little bit of attention to this.



STEVE:  Well, I do love that ZeroBlock app on iOS.  Every time - I sort of see it on my list, or in my little screen of apps every so often.  I go, oh, where are we now, and I tap it and go, oh, okay.  Just sort of, I mean, I'm never going to sell.  I'm just going to ride this wherever it goes.  I mean, I didn't do anything to earn them.  They just sort of appeared magically, back in the days when you could actually have a PC mint for you.  Now, I guess, I heard some news that China's getting very interested in bitcoin because they like the idea of a non-state-controlled currency in transactions.  But they're, like, setting up warehouses with mining machines.  It's like, oh, there goes the neighborhood.  So...



LEO:  Ugh.



STEVE:  Yeah.  It's getting to be - and apparently there's - I did see someone, there's an organization, a mining pool group that said...



LEO:  I saw that.



STEVE:  ...they owe their existence to us, to Security Now! and...



LEO:  Oh, I didn't see that.  Really.



STEVE:  ...talking about, yeah, to talking about bitcoin on the show.  That's what created it.  So I thought that was cool.



LEO:  By the way, somebody in the chatroom's saying you can use OpenVPN on iOS.



STEVE:  Yes, I thought that was the case.  I thought they were now...



LEO:  They have both, so Android and iPhone.  Sorry.



STEVE:  So my UNIX is FreeBSD.  Brett Glass told me about it years ago.  You remember Brett probably from the old days.  He's still around.  And he said that's the one you want.  That's the one I went with, and I've never been unhappy with it.  It's what runs our news server, and I use BIND for my DNS server back at the server farm at GRC.  And that's my choice.  So Ars Technica carried a story that indicated that the next release of FreeBSD, v10, they are backing off of their endorsement and use of hardware random number generators which have recently been incorporated into chips.  Which, I mean, it's sad, but I completely understand it.  We know that the NSA has attempted to influence chip design.  We know, we really suspect, we have to suspect that the NSA influenced an organization as important and significant as RSA to choose the worst, I mean, the known defective pseudorandom number generator as the default for all of their cryptographic library packages.  We have to assume that's why they would have done that.



And so here Intel comes out with a much ballyhooed hardware quantum-level uncertainty, I mean, beautiful pseudorandom number, actually true physical random number generator - I'm so used to saying "pseudo."  This is not pseudo, it's truly random, and now we can't use it.  I mean, it's so sad.  But it's true.  We can't.  So actually what they're doing is they're assuming that it can't be trusted.  So they're falling back to what they were doing before, which is to use Yarrow.



Yarrow was designed by our buddies Bruce Schneier, John Kelsey, and Niels Ferguson at Counterpane Labs, Bruce's group.  It's a very beautifully designed pseudorandom, software-based so therefore necessarily pseudorandom, number generator, but it works on the concept of a pool of randomness, which is the standard way you do really good random number generators now.  I looked into it carefully when I was doing - I needed a really good pseudorandom number generator for the Off The Grid project that I worked on where I used Latin Squares in order to generate web name-based, domain name-based passwords.  And I didn't use it because I needed even more entropy.  It uses by default a pair of SHA-1 hash contexts.  An SHA-1 context is 160 bits.  So essentially it sort of bounces back and forth.  It uses one while it's building the entropy in the other one.  And once the entropy is used up in the one it's using, it sort of ping-pongs.  It switches over to the one which has been building up entropy and then begins rebuilding entropy in the other one.



But the problem is you're actually, I mean, that's really good randomness, but I actually needed more.  Remember that I had what I called a UHE PRNG, Ultra-High Entropy Pseudorandom Number Generator, that I developed.  It uses 1536 bits.  And the reason was there were, like, that many Latin Squares.  And so if I used any lower entropy random number generator, then I couldn't get to all of the Latin Squares that were possible.  So I had to do that.  But that's way beyond most systems' needs.  They just need, you know, give me a chunk of entropy.



So what FreeBSD is doing is they used to be using a purely software PRNG.  Then they switched to a purely hardware PRNG, or sorry, RNG, not pseudo, really, really fabulously random, true random.  But now they're having to back off of that.  So the hardware randomness and other sources, since they can't purely trust the hardware random number generator, that will all then feed into Yarrow, which is good because all of these things are, like, hungry for entropy.  When we talk about entropy being used up, the good pseudorandom number generators sort of keep track of how much randomness has been taken from the pool.  And at some point they decide it goes below a threshold, that's when they switch over to one which has been collecting entropy while the other one's been dispensing it.  And so they ping-pong between.



So anyway, this is probably a trend we're going to see.  These guys are right.  We cannot simply trust the hardware because it is subject to really subtle manipulation.  And subtle manipulation is, as we know, all you need.  Any deviation from randomness is not good for crypto.



LEO:  Somebody in the chatroom is saying you could build your own hardware true random number generator with a few chips and a reverse-bias transistor.  That would be a great project.  Is it true that it would be effective?



STEVE:  Yeah.  You can use, for example, a reverse-bias diode.  And what happens is electrons migrate absolutely randomly across the reverse-biased PN junction of a diode.  And then you amplify that and count them, and it generates entropy.  Sometimes the problem is it's not generating it rapidly enough.  And so that's one - what Intel did was they actually used cross-coupled inverters which could never be in a stable state because they would just - entropically it couldn't be stable.  I guess it was three in a row.  And it was just, like, screamingly fast.  And then you sampled that and got really good entropy.



I would, I mean, I tend to think Intel's probably hasn't been warped, but we can't know.  But it is the case that you could absolutely build - there's lots of different approaches now to build that.  And there's something called the "entropy key" I've been trying to buy from an outfit in the U.K. now for quite some time, just for some reason it's difficult to get, and they've stopped making it available.  But it was just a little USB plugin dongle.  And in fact even Yubico has in their - and here, I happen to have it in front of me.  This thing is their - I can't remember what they call it.  It's one of their gizmos.  It's a USB device.  It's got crypto in it.  But it also has a hardware random number generator built in.



LEO:  Is it, like, true random number?



STEVE:  True random number, yeah.  True, based, in hardware.  And of course I would trust Stina till the end of the world, not to be...



LEO:  So I could plug that in and run some command, and it would spit out a random number.  It probably has a program on it; right?



STEVE:  Yes.



LEO:  That's something special, those.  That looks like a USB key.  I have a bunch of YubiKey stuff.



STEVE:  Yeah.  If we go to Yubico.com, you'll see it's an acronym, HMS or something or other.



LEO:  All these Yubico things.  I have to figure out which one - this one you press a button and it does something, so that's the normal Yubico.  I don't know.  I'll have to figure - and then I have one with NFC in it that's really cool, that I just tap stuff to.



STEVE:  Yup, yup.  And in fact Google has announced that they have their U2F, I think, Universal Two-Factor project.  So, yeah, this news was a couple weeks ago that Google and Yubico have, like, officially teamed up.  Google's using it in-house now.  And it uses the NFC-equipped YubiKey to do two-party, two-factor authentication.  Of course there's still username and password, so it's not - it doesn't have the same goals that I have with SQRL, which is to completely replace username and password.  You'll probably see a gizmo there, if you find it.



LEO:  I'm looking through all the different products.



STEVE:  It's their hardware something for their server.



LEO:  I didn't realize they have a dedicated LastPass YubiKey.  That's a cool thing.  That is neat.



STEVE:  Yeah, they're doing great.  It's really neat this came up...



LEO:  They're making relationships with a lot of different people, which is really, really cool.



STEVE:  Yeah.  Now that Stina is over here in Silicon Valley, she's got access to people.



LEO:  Yeah.  The NSA can't hack those.  That's the good news.



STEVE:  I would really trust...



LEO:  Well, if you built your own with a reverse-bias diode, then you know it's okay, unless the NSA got to the diode manufacturer.  I don't think that's going to be...



STEVE:  No, actually they...



LEO:  They haven't yet gotten to physics.  God is not on the NSA's side, thank goodness.  I just emailed Iyaz and Father Robert Ballecer and said let's do this on Know How as a project.



STEVE:  That'd be a great idea.  I'm sure if you Google "build my own hardware random number generator," you'll find a bunch of stuff there.  You'd probably - you'd do a simple little reverse-bias junction.  Sometimes a tunnel diode is used.  And then you'd, like, run that through an Arduino.  So it would generate noise.  You have to do post-processing.  You need to whiten it and balance it and then, like, run your own routine to verify that it's producing good stuff so that it can, like, shut it down if it's not.  But it can definitely be done.  I'm sure people have done that.



LEO:  And this is the - you were talking about the Yubi, it's called the YubiHSM.



STEVE:  That's the one.



LEO:  Hardware Security Module.



STEVE:  Yeah.  And the idea being that you would plug this into a server, and it's able to then - it cannot be - it's like Apple's Secure Store in iOS.  It's a deliberately read-only, you can't write to it sort of thing.  And all you can do is ask it questions.  And so it creates a secure boundary such that you can keep your secrets there, and no compromise of the server is able to compromise it because it's just - it's standing outside with a clearly defined serial interface through USB to the rest of the device.  So you can store secrets and things in it.



LEO:  Five hundred bucks, so...



STEVE:  Yeah.  Yeah.  Okay.  So this was a bit of spin from the French government.  The news hit on Saturday, on December 7th.  Google's online security blog said:  "Late on December 3rd," so this was they were blogging after four days - "we became aware of unauthorized digital certificates for several Google domains."  Now, remember, this is one of the very cool things that Chrome is doing is Chrome knows what certificates are authentic.  And so the instant you try to use Chrome on a site with a certificate that says it's from Google and it should be trusted, Chrome will say, uh, wait, where did you get this certificate, we never produced that, and immediately phones home and raises flags.  So this is very cool feedback that Google has built into Chrome.



So Google says:  "We investigated immediately and found the certificate was issued by an intermediate certificate authority linked back to ANSSI, a French certificate authority.  Intermediate CA certificates carry the full authority of the CA, so anyone who has one can use it to create a certificate for any website they wish to impersonate."  So that's - we'll talk about why this was done versus the normal way in a second.



And Google continues, saying:  "In response, we updated Chrome's certificate revocation metadata immediately to block that intermediate CA, and then alerted ANSSI and other browser vendors.  Our actions addressed the immediate problem for our users.  ANSSI has found that the intermediate CA certificate" - now, that's what they issued.  So they issued this with full recertification authority because they could constrain any certificate they issue, but they said we're issuing an intermediate certificate that can itself issue its own certificates.  So that was deliberate.



They said it "was used in a commercial device, on a private network, to inspect encrypted traffic with the knowledge of the users on that network.  This was a violation," they're now saying, "of their procedures, and they have asked for the certificate in question to be revoked by browsers."  Uh-huh.  "We updated Chrome's revocation metadata," says Google, "again to implement this.  This incident represents a serious breach and demonstrates why Certificate Transparency, which we developed in 2011 and have been advocating for since, is so critical.  Since our priority is the security and privacy of our users, we are carefully considering what additional actions may be necessary."



Now, separately, same day, ANSSI posted on their site - this is the Agence nationale de la scurit des systmes d'information, so that's where ANSSI comes from.  They said:  "As a result of a human error," which we'll discuss in a minute, "which was made during a process aimed at strengthening the overall IT security of the French Ministry of Finance, digital certificates related to third-party domains which do not belong to the French administration have been signed by a certification authority of the DG Trsor (Treasury) which is attached to the IGC/A.  The mistake has had no consequences on the overall network security, either for the French administration or the general public."  Well, the general public might beg to differ.  But they continue:  "The aforementioned branch of the IGC/A has been revoked preventively."  Yeah, because it doesn't work anymore because no browsers will honor it.



LEO:  Preventative revocation.



STEVE:  Yes  "The reinforcement of the whole IGC/A process is currently under supervision to make sure no incident of this kind will ever happen again."  Okay.  My comment:  This could not have been human error.  Human error is when it doesn't work the way you want it to.  Deliberate function is when it does.  This had to be deliberate.  What we know is...



LEO:  Ah, whoa.



STEVE:  It had to be deliberate.  There are two ways that an appliance can function, and we've talked about them.  The way you do an appliance which wants to have visibility into the network traffic is you have only two choices.  You install your own certificate into every browser which will trust that appliance.  And of course that's burdensome.  That means everyone who wants to use the network will have to install a certificate to trust the certificate that the appliance has because it has to mint certificates on the fly which it signs, so you need every browser to trust the certificates it mints.



Well, gee, that's awkward.  Wouldn't it be nicer if instead we minted certificates that a trusted intermediate authority is issuing, and it's trusted because a true root authority that all browsers already trust are trusting?  And the answer is, well, of course that would be much nicer.  Then we don't have to install anything in everyone's browser.  So somebody deliberately configured this appliance to work that way.  This cannot possibly have been a mistake.  If, I mean, whoever did this knew exactly what they were doing, that they had somehow acquired an intermediate certificate with full certificate signing authority, which gave it completely unrestrained ability to create certificates.  So now everyone behind that appliance was having their traffic inspected, full spying on all their traffic with no warnings from their browser and no need to install a certificate.  Any corporate environment that is behind such an appliance must have, must trust the certificates that the appliance is minting.  So it's got to accept that in its browser.  This avoided that.



So this wasn't a mistake.  This wasn't inadvertent.  They got caught is essentially what happened because somebody ran Chrome inside that network.  And running Chrome is all you have to do to shut that down instantly.  Chrome will scream home to Google that somebody has given it a Google cert that did not come from Google, and that's end of the game.



LEO:  Wow.



STEVE:  Yeah.  Very cool.  Yeah, but not a mistake.  They got caught.



LEO:  Fascinating.  And they didn't admit it, which really...



STEVE:  No, absolutely.



LEO:  I think that breaches trust, and I think...



STEVE:  Pure CYA.



LEO:  Yeah.  And it's a shame.  I mean, when you get busted, just admit it.



STEVE:  I don't know how they could, though.  I mean, again - and of course this is why none of us believed the heartfelt "We're not spying" after the first round of NSA revelations.  It's like, well, you have to say you're not.  You don't have a choice.



LEO:  And of course you assume that no one is going to be sophisticated enough to call you on it except Steve Gibson and a few others.



STEVE:  You read this, it's like, oh, okay, that sounds fine.



LEO:  Yeah, the normal media is just going to go, oh, yeah, wasn't their fault, must have been a...



STEVE:  Somebody pushed the wrong button somewhere.



LEO:  Just pushed a wrong button.



STEVE:  Yeah.  So Forbes had an interesting story, and I don't know what to make of this.  But Apple just rolled out their new iBeacon technology.



LEO:  Oh, we've been talking a lot about this, yeah.  I wanted to get your security take on this, for sure.



STEVE:  Yeah, makes me very nervous.  I mean, just Bluetooth is - I don't like Bluetooth, and I don't like NFC because radio is scary.  I mean, radio is very powerful when you use it right.  But it's like, I mean, and Bluetooth I love.  We've talked about Bluetooth.  The technology is solid.  But it just - you have to be very careful.



LEO:  And this uses Bluetooth LE, which is - to me it's interesting because it doesn't require pairing.  One of the security features of Bluetooth was you have to have explicit pairing between two objects.  You can exchange passcodes.  You really have some form of security.  But Bluetooth LE doesn't work that way.  If you have a Bluetooth LE device in an application, you launch the application, it sees the device.  And that's how iBeacon works.



STEVE:  Yes, exactly.  So the idea is like all over the store you've got little beacons.  And so as you walk to them with your phone, your phone is able to receive information from them.  It's like, oh, look.  And so what was interesting was that Forbes noted that in the Objective-C interface description for the iBeacon framework, it says this technology, this framework allows you to scan for Bluetooth accessories and connect and disconnect to ones you find.  That we know.  It also says you can vend services from your app, turning the iOS device into a peripheral for other Bluetooth devices.  And it says you can broadcast your own iBeacon information from the iOS device.



LEO:  That was, to me, what was fascinating is that Apple stealthily had included this in all iOS devices since the iPhone 4s.  I mean, this is hundreds of millions of iOS devices.  Now, it has to be enabled.  It's an API.  I mean, it's not like all of a sudden your iPhone's going to say hello, hello, hello.



STEVE:  And so what Forbes is proposing is that what will follow iBeacon is iWallet, and that Apple will end up producing an immediately pervasive electronic payment system based on...



LEO:  Sure.  Walk into a store.  You'd have to opt-in.  You have to turn it on.  You'll have to run an app.  But you could walk into a store, and they go, "Here's your coffee.  Thanks.  See you, Leo."  And it's done.  The transaction is done.  I think that's - now, remember these iPhone 5s's have fingerprint readers.  They could tie it to that for authentication.



STEVE:  Yup, yup.



LEO:  Are you worried?  I mean, what is the implication of this?  Isn't it possible to lock it down if it's implemented properly?



STEVE:  I guess I - yes.  I would say, as long as the user receives something on their screen, and they look at it, and it's not spoofable, and it can't be intercepted, and they affirmatively acknowledge it, and...



LEO:  I mean, you could just do a PIN.  But I think the point of all this is friction-free.



STEVE:  Yeah, you want low friction.



LEO:  You don't want to have to make the user do anything.  They walk in, they take their coffee, and they walk out.



STEVE:  Yeah.  Right now with our iPhones, of course, at Starbucks you show the scanner the barcode on your Starbucks app on your iPhone, and that debits it from your account.  So I like the fact that there's that kind of, that level of interaction.  Radio is a little more spooky.  I mean, and we've seen it being exploited.  So we'll see.  I mean, if nothing else, maybe a privacy concern because somebody else can be monitoring this.  We'll have to - I've not looked closely at the spec and what they're doing.  But I agree with you it's going to be popular.



LEO:  Oh, yeah.



STEVE:  Real quick, I ran across a list of two-factor authentication websites.  I just wanted to share it with our listeners because it's kind of cool to see it.  I created one on my short bit.ly links:  bit.ly/2falist.  2fa is two-factor authentication.  So 2falist, all lowercase.  That'll bounce you over to Evan Hahn's site, where he's just, as his own little project, been maintaining a list of major popular sites that support two-factor authentication right now.  And we can assume that will be growing over time.  So sort of disturbingly short list.  I don't know if it's extensive.  Maybe if anyone knows of any others they could drop him a piece of email and say, hey, add this.  But certainly the ones that he's got are ones we know about and that we've talked about on the podcast.  So it's nice to have that, just sort of to browse through.



LEO:  Yes.  But you're right, it is.  It's kind of surprisingly short.



STEVE:  It's not that long.



LEO:  But you know what, it's good.  He has links to enable it underneath each.  So you can go through and see which ones of these services you use, and at least if they have it you can enable it from there, which I think is great.



STEVE:  Yeah.  Okay.  So now miscellany things.  I'll run through these quickly because it would be fun to get to some questions.  I have been experiencing failure of Touch ID.  And it's been annoying me for the last couple weeks.  And I was so glad then to run across many other reports.  It's happening to many people.  And when I tweeted about it, I got lots of followers who said, oh, yeah, me, too, me, too, me, too.  So it's a phenomenon.  One of the things that I noticed is that it seems to be, for me, temperature sensitive.  On a cold day, where the phone is cold and my hands are cold, it's much lower recognition level than when everybody's warmed up.



So I had a couple ideas, and then I've seen them elsewhere.  One was, if in fact you don't get recognition when your finger is cold, record/train Touch ID in a different slot.  Because you've got five, train the same finger in a different slot under the cold conditions in order to have it recognize that.  Or, if nothing else, just do multiple trainings of the same finger in multiple slots to give it more samples.  And other people have found that maybe the polar rotation orientation isn't working as well, and so to deliberately record a straight-up finger and record a 90-degree angle finger one way and then a negative 90-degree angle finger, again, all in separate slots.



LEO:  If you retrain, like you just delete that fingerprint and retrain, it gets better; right?  That fixes it.



STEVE:  Yes, it works again, yes.



LEO:  So strange.



STEVE:  So I'm calling it "finger fade."



LEO:  Finger fade.



STEVE:  Apple iTouch Finger Fade because - and, see, I would - I don't know what the logic is.  Were I designing this, and I decided that the finger I had just seen was the finger I knew, but it was also giving me new information, I might be trying to mature my knowledge of that finger over time.  That is, I recognize enough that I believe it.  And, oh, look, I'm getting some more on the side here that I hadn't seen.  Let's add that.  So if there is an algorithm, where they're hoping to further evolve their finger ID, maybe it's not working right.  Maybe it's like that that evolution is going sour.  Who knows.



LEO:  It's not possible your fingerprint is changing over time.  Dr. Mom says this is - because they use this in hospitals a lot for access to meds and things like that.  She says this is not an uncommon thing with all fingerprint readers.  I don't have enough experience to know that.



STEVE:  We know that fingerprints themselves don't change over time because you have a huge...



LEO:  Not substantively.



STEVE:  Right.  We know that you can take fingerprints when you're young, and they're still valid when you're old.  That's Forensics 101 of law enforcement is your fingerprints are your fingerprints are your fingerprints over time.  What we're hoping, I mean, all of the hype said that the capacitive technology was ignoring surface dirt and was like reaching into and looking at the meat of your finger.  I just think training it under different conditions is probably a good thing.  And filling up all five slots with the same finger, you know, why settle for one?



Oh, there was someone, I did read that, if you fill up all five slots, then recognition takes longer.  And that certainly makes sense that it would have to, like, if it didn't find it on the first one, then try the second one and so forth.  And so if it's going to be unhappy, it's going to take longer to be unhappy if it's got more cases.  So anyway.  Also, real quick is what looks like an actually usable keyboard for the iPhone.



LEO:  Oh, no.  Not Ashton Kutcher's keyboard.  You're going to get this?



STEVE:  It's on - no, it's Ryan Seacrest's.



LEO:  I'm sorry, Ryan.  I confuse the two.  They're equally vapid.  Really.  You think this is good, huh?  It looks just like...



STEVE:  Look at it.  It looks...



LEO:  ...a BlackBerry keyboard.



STEVE:  That's, hello, yes.  I mean, my BlackBerry is on the sidelines right now being sad.  If I could have the BlackBerry keyboard on the bottom of my phone - the other thing this does, and I thought that it was an interesting point, is as is the case when you have any keyboard attached to your iOS devices, the software keyboard no longer deploys.  So you get...



LEO:  Which is good.  Much more screen room.



STEVE:  Yes, much more screen real estate because in some cases, in some apps and uses of the iPhone, it just scrunches your screen down to nothing because the keyboard takes up so much space.  Anyway, this is TypoKeyboards.com.  Anyone who's interested, TypoKeyboards.com.  It's a case.  So something comes down from the top and plugs in at the bottom.  You still get your Lightning connector on the side.  It uses Bluetooth to talk to the phone.  Maybe, I'm not sure.  Maybe, if it's going to plug into the Lightning, in fact, I'm not even sure that uses Bluetooth.  The screen shot shows Bluetooth on.  But iOS keeps turning it on every time you update Bluetooth, which is annoying.  So it sort of comes in from both sides.  And anyway, it's supposed to be middle of next month, middle of January.  So I'm jazzed.  I will have one.  And I will report.



LEO:  How retro.



STEVE:  Because, boy, if I could have a real keyboard on my iPhone - because I'll tell you what I've found, Leo?



LEO:  What happens to the Home key?  Because it covers the Home key.



STEVE:  Yeah, it does.  Good question.



LEO:  I guess the...



STEVE:  Must be there somewhere.  Oh, there it is.  I see it in the far lower right corner.



LEO:  Next to the - yeah.



STEVE:  That looks like a Home key.  If you look at the big picture in the show notes.  So, oh, maybe.  That would be cool.  What I have found is, of all the keyboards - iPhone Portrait, iPhone Landscape, iPad Portrait, iPad Landscape - my very favorite is the mini in portrait.  So the mini, the iPad mini, held upright in one hand, that keyboard is just the right size for me to type on.



LEO:  Well, you can thumb type, too, because it's narrow enough you can hold it like you would a BlackBerry and thumb type.  And I presume that's why you like it.



STEVE:  Yeah.  And splitting the keyboard doesn't work for me, either.  I'd like it all together.  So anyway, maybe we're going to get a cool keyboard for the phone.  I wanted to let people know.  Also I have found and am loving something called FocusAtWill.com.  It is curated music for people who want to work.  And so it is much like the Liquid Mind stuff.  It is $35 a year, but you can try it for free. For free you get a 300-minute or five-hour loop of the same music, so after a while it's going to be repetitive.  But someone tweeted me about it.  I tweeted it out after using it for a day and loving it.  And I've had a ton of feedback from my followers who have tried it and are completely addicted.



You can choose between Classical, what they call Focus Spa, Up Tempo, Alpha Chill, Acoustical, Cinematic, Ambient, and I like ADHD Beta Test, whatever that is.  I haven't been moved to go there yet.  And then in each of those you choose low, medium, and high intensity.  So you have a wide matrix of music.  And it's just really good.  I mean, it's completely pulled me off Pandora and everything else.  I really like it.  And for free, you can try it for free.  There are iOS and Android apps.  It'll also run in any browser.  So you can just - a browser will play this, and you can see what you think.



So it was Leif Jantzen who tweeted this.  And so thank you, Leif.  It's changed what I do.  And lots of people are saying they love it.  A little bit cheaper than Pandora.  And, no, not nearly as much flexibility.  But if this is what you want, it really does deliver it.



LEO:  I'm going to play a little bit of it right now.  Just relax.  This is the Classical.  Actually, nothing's coming out.  I don't know if I've done something wrong.  Seems to be playing, but I don't hear it.  Oh, I have the wrong...



[Music]



LEO:  So this is actual classical music.



STEVE:  Yeah.  But it's not like huge tympanis going bang, bang, bang.



LEO:  There's no boom, boom, bada boom.



STEVE:  There's never any lyrics, but...



LEO:  What do you listen to?  You like Alpha Chill, Acoustical, Cinematic?



STEVE:  Alpha Chill is nice, so try that.



LEO:  All right.  Let's see some Alpha Chill.  I like - you know what, I might get this because I do like instrumental music in the background.  I prefer classical, myself, but...



STEVE:  And I've been listening to Classical.  It's really nice.  Also Acoustical.  Try Acoustical.



LEO:  Yeah, I like acoustic music, actually.  Whoops.



STEVE:  It'll be a little piano and something, a little...



LEO:  By the way, what we're listening to is free.  Right?



STEVE:  Yes.



LEO:  Yeah.  So I don't know what the limits are on the free version, but...



STEVE:  Oh, I do.  There are no limits except it's just a five-hour loop.  So after five hours...



LEO:  Oh, it repeats.  Yeah, yeah, you said that, yeah, that's not bad.  Five hours is enough for anyone.



STEVE:  So listen to this.



LEO:  This is beautiful.  And you use this for programming and writing and stuff you need to...



STEVE:  Yes.  When I'm writing or when I'm coding, and when I want to block out background noise and just zone in.  And, I mean, there's all this bull [bleep], oh, excuse me.  There's all this...



LEO:  I can see this music has really relaxed you, Steve.



STEVE:  There's all this other stuff they've got where it's like, all the science of psychoacoustics and...



LEO:  Okay.  I want to see the ADD stuff.  Let me see.  ADHD Beta Test.  So this is the AD - oh, this is like trying to - trying to...



STEVE:  Oh, my lord.



LEO:  I'm ADHD.  I need other stimuli to keep my brain - see, the whole thing with ADHD, you wouldn't know this, is that we actually, those of us who have this, our frontal lobe is under-functioning. 



STEVE:  I guess I don't have that.



LEO:  You don't have it.



STEVE:  That would just make me nauseous.



LEO:  And so the reason people are ADHD is they need to stimulate their front lobe.  And if they can keep their frontal lobe stimulated, then their mind works like yours does.  So this, I guess the idea is stimulate the frontal lobe.  I'm a little over-stimulated, frankly.



STEVE:  Just shoot me now.



LEO:  [Laughing] Wow, that's Focus...



STEVE:  FocusAtWill.



LEO:  ...AtWill.com.



STEVE:  And also, again, iOS and Android.  So you can put it on your phone.  You can put it on your Pad.  And it's just there.  It's just, I mean, I've just been having a fabulous experience with it.  So I know that not everyone follows me, or some who do follow so many people my note of it might have been lost.  So I wanted to let our people know, our listeners, that it really looks good.



LEO:  Hmm.



STEVE:  I found, after we talked about our faster-than-light drive, the warp drive last week, there is a one-hour video presentation that Dr. Harold White did following his paper, that we had the PDF last week.  There is a YouTube presentation.  And a couple people, first of all, we've provided entertainment for a subset of our listeners who apparently were laughing so hard they fell off their chair.  But that's fine, too.  And one person tweeted, saying, he said:  "More like less impossible.  The solution described essentially requires several tons of exotic matter having negative mass."  So okay, Leo, maybe you were right, that it won't be anytime soon.



LEO:  Oh, well.



STEVE:  And someone else did correct me.  We talked about going to Alpha Centauri in two weeks, which actually just came from text that I read about it.  It turns out it's 0.43 years to Alpha Centauri.  So that's 157 days, or 22 weeks.  So maybe someone dropped a "2," and they went from 2 to 22.  It's 22 weeks.  But even that's practical, if you can find a couple tons of exotic matter.  So maybe we can get the Large Hadron Collider to create the exotic matter for us.  Then we'll stick it into our warp drive spaceship, and off we go.  And really, a couple good Hamilton books will get you to Alpha Centauri.  That's really all you need.



LEO:  That's how you measure time passing now?



STEVE:  Exactly.



LEO:  That's 4.3 Hamiltons.



STEVE:  That's 4.3 Hamiltons [laughing].



LEO:  I like it.



STEVE:  Also, a quick sci-fi update.  "Almost Human," that I talked about on Fox, I'm getting a ton of positive feedback from people who were thank you, thank you, thank you for putting me onto it.  I got a note from someone who tweets as @weckman, who said:  "SGgrc, did you know Fox is 'pulling a Firefly'?"  Now, the moment I saw that, I thought, oh, no, no, no, don't cancel this.  And he said - but he says:  "They've released the episodes out of order for unknown reasons."  Apparently what they've released is 1, 5, 6, 7, 8, 3.  And I thought, huh.  And Monday's was really good.  And so it motivated me to again remind everybody that "Almost Human" on Fox is, I mean, it is - I would say it's the quality of "Firefly."  And we haven't seen anything like that for a long time.  And of course everyone's nervous because Fox killed "Firefly" for, like, I don't remember what Joss said was the reason.  But let's hope that "Almost Human" survives.  I'm really liking it.  It's the best thing I've seen for a long time.



LEO:  I watched the first episode.  I did enjoy it.  I was a little disappointed because the first android he got was such a dud.  And I thought, is this really the show?  And then I realized, oh, no, that's not the android he's going to get.



STEVE:  Oh, and last night's, if you want to just jumpstart, you could watch last night's out of sequence.  Apparently it was the third one made.  It's the best so far.  More character development.  Just I'm impressed by the writing.  They did extra things they didn't have to do that you don't normally see.  Anyway, it's definitely on my must-see list.  And people have been reminding me about "Continuum."  I saw the first episode, and it's like, oh, maybe it was just a bad day for me.  I'm going to go back, now that there's a bunch of them, and maybe run through them and see what I think.  I do have a SQRL update...



LEO:  Squirrel!



STEVE:  ...that is significant.



LEO:  Okay.



STEVE:  Yes, thank you.  A major milestone yesterday.  I posted the final piece of the protocol, the so-called semantics.  I had put up the syntax before, which is the way the endpoints will communicate.  The semantics, of course, is what they will communicate.  That's now online. The denizens of the SQRL newsgroup at GRC are plowing into it, figuring out what I've done, and I'll be looking at their feedback. This was just yesterday, so it just happened.



What this means, though, is once the dust settles from this, I finally start writing code.  There is enough there that everyone, once we agree upon this, will be able to write code to implement SQRL.  So I'm very excited.  That generally goes pretty rapidly, compared to just, I mean, it's been a real process getting to where we are.  But we're there now.  We have a robust specification, future oriented, open ended so it can grow and do other things.  And I'm ready to write code.  So the people waiting for v6.1 of SpinRite will be glad of that also because it certainly represents a good step in that direction.



And speaking of SpinRite, actually in this case what we've got now is 6.0.  In keeping with the spirit of a Q&A, I ran across a question in the mailbag from Jared in Australia, who asked a question about SpinRite and solid-state media.  He was a little bit confused about SSDs because he said:  "Hearing a previous question on recovering data on SSD, I don't really get this.  On the one hand you say yes, SpinRite can be run on SSD, and you don't do anything to prevent this.  But you also say that SSD and flash media have limited write cycles.  So running SpinRite on SSD also wears them out.  How can this be a good thing?"



And so I wanted to, for people who haven't heard, and also for Jared, to answer his question, SpinRite has what we call Level 2, which is a faster operating, read-only scan which looks for any problems on media.  That makes much more sense, I mean, well, it's the only thing that makes sense for SSD, but it also makes sense because SSDs don't have defects the way hard drives do, that is, physical defects, where it makes sense to pattern test in order to find them.  So Level 4 is a read-and-write test that you do not want to run on SSD because it would tend to fatigue the SSD substrate, but which you do want to run on drives when it makes sense because it's like sort of a deeper level of testing.



So, yes, SpinRite runs on SSDs all the time.  And in fact, in the show notes I posted something else, not from Jared, but Leo, you can show this.  It's a little frightening.  It's actually from a customer.  It's a customer photo that was supplied showing SpinRite running on a brand new Kingston SSD, where the SMART system is already getting concerned.  There's a red dot at the far right end of that bar because what's happened is essentially SpinRite is running, and the SSD is using error correction to such a high degree that it...



LEO:  Look at the error count.  It's 2.9 million.



STEVE:  I know.  It is horrifying.  And so this should forever disabuse us of the notion that, because it is solid state, it is error free.  What we're seeing here is perfect evidence that they have pushed the density of SSD storage, that is, commercial pressure to cram more density essentially in smaller and smaller cells has resulted in solid-state storage having an effective error rate, arguably right up there with hard drives.  And not only is the absolute error count horrifying, nearly 3 million, depending upon how far he went.



But the other thing that is a concern is look at the spread between minimum and maximum.  What I do is those numbers are errors, corrected sectors per megabyte.  That is, I deliberately do the math so that the units have meaning.  The unit is corrections per megabyte.  And so what this says is that there was a region on the SSD where we were only needing to do about 1,500, the minimum, 1,500 corrections per megabyte.  But there was a different region where we were having to do about 25,000 corrections per megabyte, meaning there's, like, a bad area on this SSD compared to, like, the better area.  What you'd like to see with something semiconductor would be some uniformity across the surface.



So I'm seeing instances now where we're seeing the quality of these drives beginning to come down.  And I've never mentioned it on the podcast, and I sort of meant to a while ago, but our listeners may have noticed that warranty length kind of quietly crept downwards.  It used to be that I think they had, like, three-year warranties.  They've dropped them to two years and one year, just sort of very quietly saying, eh, we don't want these back after a year, so you're on your own.  Because warranty periods used to be substantially longer, and that's not the case any longer.



LEO:  Do you recommend against SSDs?  Or should you go with business class or lower density?



STEVE:  I'll tell you what I would do.  I would do what Compaq used to do, Leo, at this point.  Compaq used SpinRite on their loading dock to prequalify their drives. The manufacturers didn't like it, but they had no choice.  Compaq over-ordered what they wanted.  They ran SpinRite, and they returned the worst of those.



LEO:  Isn't that interesting.



STEVE:  I would buy two hard drives and run SpinRite on them both and see if they're different.  And if they're different, return the weakest one.



LEO:  You are the weakest link.



STEVE:  Why not?  Why not?  You know?  Everybody will take them back without questions.



LEO:  It's a great idea.



STEVE:  Yeah.



LEO:  Buy two, return one.



STEVE:  I would buy two.



LEO:  Buy three.



STEVE:  Well, see, and that's the other thing, is that people sometimes show me a screen like this and say, is this bad?  And it's like, I don't know because every...



LEO:  What's normal?



STEVE:  Every make and model differs.  Now, what is definitely bad is this one.  That SMART error, that is the drive itself rating itself as weak.  We're, I mean, if the drive is saying, wow, I'm doing more error correction than my firmware controller thinks I should be.  Because the firmware controller in the drive is separate from the medium.  The medium is like chips out there.  The firmware controller has been designed to, like, it's counting error corrections, and it's saying ow.  I'm showing - I'm dropping the health rating because this is more ECC than I expect.  So that's an absolute reason to send this back.



And this was a brand new Kingston SSD that the guy bought.  And he said, this doesn't make me feel comfortable.  And I said, and it should not.  But what you can also do, the reason - when people just show me a screen, it's like I don't know if that error count is bad or good.  But if you had two drives of the same make and model, if you bought a pair, by comparing them, if one is generating a lot more errors than the other, that's the one you don't want to keep.



LEO:  And I guess if you bought two or three, if you bought three you'd have...



STEVE:  Then you'd really know.



LEO:  You'd really know.



STEVE:  There'd be a, yes, you'd have two that are similar and an oddball that's like, ooh, boy, you go home.



LEO:  Yeah.  Cool.  Cool.  All right.  Are you ready for questions, Steve?



STEVE:  Well, now, okay.  We are, but we're approaching a hundred minutes on the podcast.



LEO:  Is that your new benchmark, the 100 minutes?



STEVE:  Well, I'd just - I always put the minutes down.



LEO:  It's a good number.



STEVE:  Yeah, it seems, I mean, that's, like, that's a good podcast.



LEO:  Yeah.



STEVE:  So what we'll do is we'll do a couple questions, and then we'll just continue next week with another attempted Q&A.



LEO:  We've been attempting this for a month now.  Here we go, listener-driven potpourri.  Doug, whoa, let me just...



STEVE:  Gernz, Gernetz...



LEO:  Germetzky, I think.



STEVE:  Gernetzky, yeah, Doug Gernetzky.



LEO:  Nice Polish name.  Doug Gernetzky in Appleton, Wisconsin, he caught Steve's attention with his subject line:  The 800-pound gorilla you won't talk about.  HealthCare.gov just had an investigation on web security.  I heard about it all week and was surprised not to hear about it on Security Now!.  If you didn't cover it because of Leo's politics [laughing]...



STEVE:  I know.  Keep going.



LEO:  Oh, lord - will you discuss it elsewhere?  It's kind of a big deal, after all.  It's only the medical records and personal info and passwords for America.  Thanks, Steve.  Phillip Lane also asks:  Have I missed it?  I was going through show notes for past shows looking for an informative show on HealthCare.gov, and I see nothing in the notes.  You've not even touched on the subject?  There's so much information out there on the ugliness of this rollout, capacity and security issues, I find it hard to believe you haven't covered this news.  Well, it's because of me.  I'm a lefty, and Steve doesn't want to go against me.



STEVE:  It's actually not because of you at all.



LEO:  Oh.



STEVE:  Phillip Lane says:  Just looking for some nonpartisan reality.  And for one thing, the whole issue is so fundamentally partisan...



LEO:  Highly partisan, thank you.



STEVE:  ...that it's difficult to know what reality is.  But mostly I just assume that it is the nightmare catastrophe, catastrophic disaster from hell.  I mean, it's like, why bother talking about it?  Just assume that it is a massive fiasco.  Apparently half, about half of the state-run sites do what we were talking about earlier.  They log you in briefly with SSL, and then you have a persistent cookie which allows anyone to take over your session and have access to all of your data.  I mean, it's like - I was explaining this to Jen because initially it wasn't even working.  I mean, like two people could use it at once.  And I just, I mean, I didn't assume anything different.  It was like, okay, this is a fabulous fiasco disaster on the part of the government.  And when I heard that it was loading, the website was loading 60, six zero, different individual JavaScript files from all over the place in order to function, it just, okay, you know, forget about it.  So...



LEO:  The problem is it's hard to get real information.  You're right, it's certainly assumable that there's a problem.  But CBS News, for instance, aired a report about security issues that was wrong.



STEVE:  Yeah, see, none of them know what they're talking about.



LEO:  That's the real problem.



STEVE:  That's one problem.  And I don't know what I'm talking about.  I only know how hard it is.  I mean, everyone who listens to this podcast knows it is so difficult for old-school serious Internet companies like Amazon or Twitter or Facebook, I mean, full of serious techie gurus, to get this right.  It is really hard.  And this was the point I made to Jen was, I said, Jenny, it doesn't even work.  I said, so, I mean, working is the first bar you have to get over before - and unfortunately security is always an afterthought.  I mean, we see this over and over.  I mean, we should just assume that there is no security whatsoever, and that some year after it finally works, maybe it'll start being secure.  I mean, it's such a catastrophe, I've just ignored it.  So the reason I haven't talked about it is that I really had nothing definitive to say.  I need details.  I need specifics.  And it's just like...



LEO:  Fox News, CNBC, CBS, you're not going to get the technical details you need.



STEVE:  Is the ocean wet?  Well, yes.  You know?  It's like beyond security.  It's just, I mean, it would just hurt you to start looking at it.  So just, I mean, there's just nothing that I have to say.  I don't want to look at it.  I don't want to take my own time.  People would much rather have SpinRite 6.1 and SQRL than me going and looking at HealthCare.gov and taking it apart.  I mean, just assume...



LEO:  Well, it's funny because of the four security experts that testified in front of Congress, one said exactly that  Avi Rubin, who we know as one of the great security guys of all time, is a professor at Johns Hopkins.  He said:  "I would need to know whether there are inherent flaws versus superficial problems that can be fixed.  If they can be fixed, that's better than shutting it down."  He, like you, said I need to - we aren't getting the information to make any conclusion.  Yes, there's possibly cross-site scripting errors.  It's certainly possible to phish people and trick them.  And some of this mainstream coverage is simply that.  You could get a link in an email that says it's HealthCare.gov, and it looks like HealthCare.gov, but it's not.  But that's going to happen with any site.  So it's hard to really know.  And I think that...



STEVE:  Well, see, and that's my point.  It's uninteresting to me.  It is such a disaster that it's uninteresting.  It's just like, okay, it's horrible.  And I'm not blaming anyone.  To me its horror is nonpartisan.  Its horror is a fact.  And someday they'll get it fixed.  I mean, now they understand that there's problems.  Security is like the next thing they're looking at after getting it working.  It still has a very pathetic number of total - I just saw the number this morning, twice in November as in October, but we're still down at a quarter million, which is way shy of seven million that they were, like, was some benchmark they were hoping for.  So, yeah, I mean, I just - it's uninteresting.  I mean, what's interesting is something I can get my teeth into.  This is just, you know, it is the 800-pound gorilla, and I don't want to try to bite it.



LEO:  Well, and there's a lot of non-, I mean, a lot of partisan information.  The four security experts who testified for Congress, one of them is the former senior law enforcement advisor to the Republican National Convention and a cybersecurity analyst for Fox News.  I have a feeling he has a partisan point of view.  A lot of these guys are, in fact, not what I would call - one guy's a former CSO of Diebold, the famous electronic voting company that had the worst security record of anybody I've ever heard of.



STEVE:  In this situation, I would say believe the worst that you hear.



LEO:  Assume the worst, yeah.



STEVE:  Yes, because we have - with security we have to assume the worst.  It is, as we know, it's about the weakest link in the chain.  I can't even begin to imagine the chain that this thing has.  I mean...



LEO:  The problem is a lot of people have to use this.  Their employers are saying, hey, we're not going to give you healthcare or whatever.  I mean, the security advice would be just don't use it till they fix it.  But a lot of people have to.



STEVE:  Well, I mean, if there's ever been a need for making up a new password when you identify yourself...



LEO:  Well, that one, for sure.



STEVE:  Do it here.



LEO:  But I presume you've got to give them your social.  I mean, you're giving them a lot of information.  I don't know if you have to give them your social, but you've got to give them a lot of personal information, including...



STEVE:  Yeah, no, I mean, it's a catastrophe.  It's a disaster.  So I hope I've satisfied any listeners who feel like I was afraid to talk about it.  It's not at all that I've been afraid to talk about it.  It's like, where do you start?  I mean, we'd like to talk about something else.  But if we have to talk about that, it's like this will become the HealthCare.gov disaster from hell podcast.



LEO:  Yeah, assume the worst.



STEVE:  I mean, oh, my god, yes.



LEO:  I like it.  Yeah, it's not good.  It's not good.



STEVE:  It's beyond - it's like it doesn't even work.  So of course it's not secure.  It has to work before it has a hope or a prayer of being secure.



LEO:  Yeah, it doesn't even work, yeah.



STEVE:  And someday they'll do that.



LEO:  Yeah.  And by the way, Web6121's pointing out that you don't have to use the website to sign up.  You can phone in, which is probably a good idea.



STEVE:  The problem is...



LEO:  We don't know how well secured the databases are.



STEVE:  I was going to say the problem is they're probably using the website on your behalf.



LEO:  Maybe they are, I don't know.



STEVE:  When you phone up, yeah.



LEO:  We don't know.  That's kind of the bottom line.  Ron Bogner in Glendale, Arizona has some thoughts about 256-bit identifiers.  Ron says:  It amazes me that people who have a problem with 256-bit identifiers do not mind a 10-character username paired with an eight-character password.  And he gives a sample BitTorrent Sync secret, which is a very long, 256-bit identifier.  Here's a sample username and password:  johndoe@yahoo.com, Monkey12.  Obviously the 256-bit secret is magnitudes more secure than the password/username combination.  And that would be true even if you used a random 15-character password instead of something more typical, like Monkey12.  He does some math.  We've said this over and over again.  I think the issue isn't so much that we don't think it's secure, the fear of collisions.



STEVE:  Yes.  Yes.  And in fact that was my math that I added there.



LEO:  Oh, that's your math, oh, all right.



STEVE:  Yeah.  It was just because I wanted to point out, people assume that 256 bits uses 8 bytes.  But if you use the full character set, a byte is 256 characters.  Well, first of all, we immediately throw a bit away because we have 127 characters.  But then when you throw all of the - and I'm sorry, 128, technically, although null is invalid, so 127.  And so that would be 7 bits.  So you would divide 256 by 7 in order to get the number of characters, except that many of those are control characters.  And I went over to my own Password Haystacks page, just to remember what the alphabet size was.  And if you use all upper, all lowercase alpha, all 10 digits, there are 33 typeable special characters.  So that's a total of a 95-character character set.



And one of the neat tricks I've always loved, if you wanted to know, like, how many bits 95 was, because it's an odd number; right?  It's bigger than 64, which is 6 bits, but it's smaller than 128, which is 7 bits.  It's 95.  It's kind of somewhere in the middle.  Well, it's like, okay, where?  So if you take the log of 95 divided by the log of 2, because 2 as in binary, that ratio gives you the exact number of bits, binary equivalent because you've dividing by the log of 2, that 95 is.  So it turns out it's 6.5699 bits per character.  We'll round it up to 6.57 bits per character.  Then you can divide that by 256 bits, which is the actual amount of entropy possible, and that tells you that it's about 39, it's 38.966, or 39 characters, rather than, for example, just 32.  So you get actually a bunch more characters when you treat the alphabet correctly.



But he's right.  Certainly that's unique.  And I think, as you said, Leo, what people are concerned about is collision.  And we do have a question we'll probably see next week, further on down here, that talks about that, how one listener thought we were being a little too glib when we said it's impossible.  Because he says, well, it's not impossible.  It's like, okay, Spock.  So...



LEO:  I believe your logic is flawed.



STEVE:  So, but that does mean that we have to be very careful with randomness because we know that that's a problem.  And I think the other thing that makes people uncomfortable is that, when you are creating an account somewhere, you put in a username, and it says, oh, that username is taken.  So you go, oh, okay.



Well, unfortunately, in the process of being told that, you now know somebody else's valid username, and you could then start guessing their password.  And of course the reason that email is so handy is it is known to be unique.  But the only reason it's known to be unique and for you is that you already - somebody else told you that there was already a johndoe@yahoo.com.  That's why you had to go johndoe2048 or something to get a unique version of johndoe.  So the idea is that then you reuse that everywhere because that's been assigned to you.  And that's the way we avoid collisions.



So the fact is, except for the Spock instance, with really, really high-quality random numbers, or pseudorandom numbers, there is no practical chance of a collision.  There is much higher chance of anything else in the universe going wrong than there being a collision of two identities.  I mean, your computer could fail.  Your power could fail.  We talked about the asteroid hitting the Earth.  I mean, everything else is going to happen before there's going to be a collision, if we choose random numbers carefully, and they're 256-bits long.



LEO:  So we are out of time.  But I want to read this 11th question because I think that it would be good to address this now.  And then we'll put some more questions together for next week.



STEVE:  Well, I'm going to carry these on to next week.



LEO:  Carry these on, yeah.



STEVE:  We'll try to get to them.



LEO:  Scott Schramm in Philadelphia says what about show notes?  I love the Security Now! podcast.  Great topics.  Usually after the show I go to the TWiT page [TWiT.tv/sn] in search of the links talked about in the show, but the show notes are always nonexistent.  There is a link to show notes, but it's always blank.  Seems to be the same with other TWiT shows.  I cannot find any show notes on the GRC page, either.  The text transcripts are great, but I don't have time to read that.  I'm looking for a short, bulleted list of all the topics mentioned and any links included with those topics.  Can you please ask Leo about this.  Thanks.



STEVE:  Okay.  So we need to explain a little bit about how we operate here.  You and I get together for two hours and do this, and then sort of go our separate ways.  After a few hours your guys put the audio together, I download it and then shrink it and get it off to Elaine.  And then she produces the transcripts, which come back to me.  For the last three weeks I have, counting this one as No. 3, I have been, finally, for the first time ever, posting the show notes on GRC.



So if you go to GRC.com/sn, which is the main Security Now! page, you will see now an additional icon in the lineup.  There used to just be five:  high-quality audio, lower quality audio, and then the transcript in three forms (text, html, and PDF).  There's now a sixth one, and it's the third one over.  It's after the two audios.  Looks like it was one of Microsoft's old icons, it's a little cubes tumbling together.  That is now a PDF of the show notes that you and I go through at the beginning of the show.  I tweet it before the show because I've had a lot of positive feedback from our real-time, our live listeners, saying, hey, it's so fun to be able to follow along, which everyone can now do.



So if your guys, Leo, want to do something with the show notes, they're welcome to.  But for what it's worth, I will from now on always have them on GRC.com.



LEO:  Yeah.  And so, and this is a terrible thing about everything that we do, is that we are highly resource constrained.  It probably feels to people like, and we certainly encourage that, that this is a big operation, and we've got editors and big studios and stuff.  But one thing we don't really do a very good job of, we had hoped to crowd-source show notes, and we don't do a very good job of that.  For a while we did do a pretty good job of keeping the Security Now! show notes up to date.  I would paste in your notes because you do very good notes.  Of all the hosts, I think you, Paul Thurrott, and Mary Jo Foley do the most complete notes.  And it would be - and I should be just putting them on the wiki.



So that's why it's a wiki, by the way.  It was our hope that people would, who listened to the show regularly, would go on the wiki and parse those notes and so forth because I don't have time to do that.  And I really - I haven't even had much time to - I'm busy doing the show, so I don't have time to paste it into the wiki, and I apologize.  I slacked off on that.  We should probably have a full-time person doing that.  I just can't afford it.  And it would be probably two full-time positions.  So we're talking 100,000 a year.



STEVE:  And in fact, yeah, and if you were going to do notes for the other podcasts that didn't, like, generate their own notes in order to drive them...



LEO:  Well, that's what I mean, it would be - yeah, right, be a lot of work.



STEVE:  ...that would be massively, massively labor intensive, yeah.



LEO:  We have always rundowns somewhere, you know, we share rundowns and Google Docs and stuff.  And we do our best to put together notes.  But I understand it's a complete failure.  We've never done a very good job.  And I apologize.  Thank goodness Steve is putting his show notes up.  And that's everything you want.  So to answer that question, it's getting done there.  But...



STEVE:  They are always available from now on there.



LEO:  It is a global failure of mine.  And I don't know what to do about it.



STEVE:  Well, it's just maybe there will be something, but at least you can always find them for Security Now! at my site.



LEO:  Yeah, thank you.  And I will talk to Lisa and see if we can figure this out.  You have to understand, hiring a staff person to do this is very expensive.  It's not just the salary, it's the benefits, it's all of that.



STEVE:  Well, and I can't speak for the value of the notes.  I guess I'm liking that I'm now publishing them because what I used to have to do before is I was, like, tweeting these links all the time.  And I would be saying, oh, I just tweeted this link, I just tweeted that link, to help people who want to, to go find it.  Now, this is what drives the podcast.  So the notes are there.  Anyone who wants to find a link knows where they're going to be.  So, but my question would be, do notes really make sense for all of your other podcasts?  Are they going to have stuff in them that people are going to want to find and follow up on?  I don't know.



LEO:  Yeah.  Well, show notes are really important, primarily because it makes it easier for a listener, but also it makes it searchable.  And that's where your transcriptions are so great, and it's one of the reasons we're going to start doing transcriptions on more shows.  We'll talk about that on Inside TWiT later today.  We're going to pay the money to do that, anyway.  That's not show notes, though, as Scott pointed out.  That's too voluminous.  So we've got to figure it out.  One of these days.  There's so many things I'd like to do, Steve.  You know how much it's going to cost.  We're redesigning the TWiT.tv's website, which we redesigned last year, and it's not working.  That was $150,000.  It's now almost twice that to do it again.  It's expensive.  I wish I had more money.  Ahem.  But at least we've got our fine sponsors.  At least we've got this great show.  And I thank you all for being here.  And I especially thank you, Steve.



We do this every Wednesday, at least for the next week, two weeks.



STEVE:  Yeah, one more.  Wait.



LEO:  Two more.



STEVE:  Oh, yeah, because Christmas will also be on Wednesday.



LEO:  Yeah, 11:00 a.m. Pacific, 2:00 p.m. Eastern time, 19:00 UTC.  Then we move to Tuesdays at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC.  That'll start January 7th.  And Christmas...



STEVE:  I'm going to like that.



LEO:  Go ahead.



STEVE:  I was going to say I'm going to like that because it'll give me another two hours to prep.  I worked from 5:00 a.m. until 6:00 to get this ready.



LEO:  Yeah.  Now you can get up at 7:00.



STEVE:  Yeah.  Well, or just be a little less frantic in the morning.



LEO:  Anyway, I really appreciate your doing that.  And I understand that it's perhaps for some a deal breaker, but we do make on-demand audio and video always available, and you can listen at any time, at your convenience, after the fact.  And it's got everything we talk about except for the bad words, which are bleeped, at TWiT.tv/sn.  Steve has 16-bit versions at his GRC website, GRC.com.  He also has a little thing called SpinRite you ought to have, if you've got a hard drive, even a solid-state one - I like this idea.  Buy three.



STEVE:  I know.



LEO:  SpinRite all three, keep one.



STEVE:  Yup.  Exactly.



LEO:  I like that idea.



STEVE:  Find the best of the crew and send the other two back.



LEO:  You could do that, too, at GRC.com.  And if you have more questions for feedback, go to GRC.com/feedback.  That's easy to remember.  Thanks, Steve.  We'll see you next week on Security Now!.



STEVE:  For Q&A continued.  Thanks, everybody.



LEO:  A little more.	



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#435

DATE:		December 18, 2013

TITLE:		Listener Feedback #180  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-435.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of news.  We'll talk about the "60 Minutes" piece on the NSA.  Steve will answer some questions about that, and we'll also answer some of your questions.  It's a Q&A episode next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 435, recorded December 18th, 2013:  Your questions, Steve's answers, #180.



It's time for Security Now!.  Drink.



STEVE GIBSON:  Gulp.



LEO:  Gulp.  But what we're drinking is coffee, so it's okay.



STEVE:  Yes.



LEO:  Take a sip every time Steve takes a sip.  Security Now! is the show all about your security and privacy online.



STEVE:  If you could stay in your seat.



LEO:  Got it.  Now, that looks like a nice little ceramic mug.  Steve Gibson's here.  He's our...



STEVE:  That is.  But I'm pouring, I'm refilling it with this.



LEO:  I see.



STEVE:  My Contigo.



LEO:  Contigo.



STEVE:  I really like my Contigo.



LEO:  Mm-hmm.  I ordered that Indiegogo or Kickstarter thing.



STEVE:  I did, too, yep.



LEO:  Yeah.  So I'll be interested to see - it's got some sort of special properties for keeping coffee warm.



STEVE:  Well, what I love is that the coffee that comes right out of the pot would scald your mouth.



LEO:  It's too hot.



STEVE:  It would burn you.  So you pour that coffee into this, and it immediately drops its temperature down to drinkable temperature by absorbing the heat.  But then it gives that heat back over the next few hours, holding the coffee at that temperature.



LEO:  Perfect.



STEVE:  I think so.



LEO:  I hope.  I hope.



STEVE:  We'll see if it's true or nonsense.  That would be good, yeah.



LEO:  We shall see.  So this is our last show for, well, wait a minute.  I don't know.



STEVE:  No, no, no.



LEO:  Next week is Christmas.  Going to be...



[Talking simultaneously]



STEVE:  Yes.  We've got, well, we have our time capsule episode, or actually three episodes from our blast from the past, when you and I first were in physical proximity with each other, when we first actually met face to face.



LEO:  "Meet space," we call it, yes.



STEVE:  Back in - meet space - back in '98, 15 years ago.  And then - and I left in, I mean, I just basically, the whole - it's an hour long.  So it's three pieces of three shows with some fun commercials from back then, and you being you back with The Screen Savers show...



LEO:  Kate Botello.



STEVE:  ...and Kate Botello.  And I was looking for, well, actually I'm sure I have some that's got Sarah, when she was in diapers still.



LEO:  She was in the - in diapers.  She was in what they called the babe - what I foolishly at the time called the "babe corral."  It was tongue-in-cheek, I assure you.  I don't think I made that up.  But, yeah, she was.  But she was a regular with tips and so forth.  Yeah, that was later.  That was the...



STEVE:  And Kevin, looking he didn't need to shave.



LEO:  Kevin Rose, 12 year old, yeah, yeah.  He didn't, actually, yeah.



STEVE:  Yup, exactly.  So I'm sure I have those.  I have everything we ever did.  So over the next...



LEO:  Wow, we could do this for years.



STEVE:  Over the next few years this will be our Christmas Special.  So then...



LEO:  So that's next week.



STEVE:  And, yeah, we did, we had such a long podcast of news last week that, even though it was nominally a Q&A, we didn't get - we answered two questions.  So I've removed those from the top and added a couple to make up.  So we're going to do another Q&A since, I mean, we've not been doing Q&As.  That as our first Q&A in a month when we did that last week because there's been so much news.  Today we've got pretty much all things NSA.  We had a week of crazy NSA stuff.  The Constitution, "60 Minutes," Obama, Silicon Valley, and who actually is Edward Snowden.  Then we have the just-occurred-today news of a new side channel attack on crypto keys.  Listening to a laptop, you can decode a 4096-bit RSA key.



LEO:  Oh, my goodness.



STEVE:  I know.  And then a lot of people have asked me - because Microsoft made some news by announcing that they've joined the FIDO Alliance, which is the Internet authentication alliance that Google and Yubico and a bunch of companies are doing.  So everyone wants to know, well, what's that relative to my work with SQRL.  And a few sci-fi tidbits and 10 great questions.  So a great show.



LEO:  Holy cow.  We'd better get going.



STEVE:  Yeah.  So, okay.



LEO:  So did you watch "60 Minutes"?



STEVE:  I did, and we'll talk about that in a second.  I thought it'd be fun to play this YouTube video, Leo, into the podcast.  It's not very long.  It's only a couple minutes.  And people, I think, will get a kick out of it.  It's clever.



LEO:  Is this from the NSA, or is this a...



STEVE:  This is "The NSA Is Coming to Town," rather than Santa Claus.



LEO:  Unfortunately, there's a 15-second commercial in front.  So we'll just pause for a moment and breathe deeply, enjoy the silence.



STEVE:  Take a sip from your coffee, everyone.



LEO:  Here we go.



[Video clip]



MALE VOICE:  Ah, the holiday season.  A time for celebration, magic, and spending time with the people you love.  But don't forget who's watching to make sure you're not being naughty.



SONG:  You better watch out, you better not Skype, you better log out, yeah, you better not type, the NSA is coming to town.



LEO:  Santa in sunglasses.



SONG:  You're making a list, they're checking it twice, they're watching almost every electronic device...



LEO:  Edward Snowden at the top of the naughty list.



SONG:  The NSA is coming to town.



LEO:  And he swaps the phones, takes a picture.



SONG:  They see when you are sleeping, they hear while you're awake...



LEO:  Only in New York.



SONG:  They know who you call and who you write so encrypt for goodness sake.



LEO:  He took his hat and stepped on it.



SONG:  With Congress in the dark and a cloak-and-dagger court, we're looking for answers and we're coming up short...



LEO:  He just ran off with her phone.  That's cold.



SONG:  The NSA is coming to town.



LEO:  Uh-oh.



SONG:  They're making a list, checking it twice, they're watching almost every electronic device, the NSA is coming to town.



LEO:  Obviously these are real people who are getting a little miffed.



STEVE:  Uh-huh.



LEO:  This is from the ACLU.



SONG:  The NSA is coming to town.  The NSA is coming to town.



LEO:  I love it.  The ACLU keeping up their record...



MALE VOICE:  You wouldn't let government agents spy on your special holiday moments in person.  Why are we letting them do it in the digital world?  Help us end the NSA's unlawful spying program.



LEO:  Wow.



MALE VOICE:  Click here and take action now.



[End video clip]



LEO:  ACLU.  That's something.  So if I get a takedown from the ACLU, I'm going to tell them to call you.



STEVE:  So I don't think - I think they'll be quite happy that we're spreading this around.



LEO:  They should, but you never know.



STEVE:  This holiday cheer.  Just so everyone knows, all of the show notes are now always at GRC.com on GRC.com/sn.  So, for example, the link to this, which Leo just played, if anyone wants to, who just heard it, isn't looking at the video, wants to play this, it's on YouTube.  You can get the link right here in the show notes, the same one that Leo just clicked on.  So everyone is certainly welcome to do that [youtube.com/watch?v=8pcWlyUu8U4].



So, yeah.  The NSA on "60 Minutes."  That generated a lot of Twitter traffic with people saying, oh, come on.  And in fact even the EFF said, they tweeted:  "We planned to write a takedown of @60Minutes' NSA puff piece yesterday, but then the DC District Court did it for us eff.org/r.fudf."  And so they gave a little link to it.  So, I mean, for me what was most interesting was right off the bat the, quote, "investigative journalist" who did the piece was no one we've ever seen before.



LEO:  Yeah, he happened to be - have a lot of ties to law enforcement over the years.



STEVE:  Yes, he used to be DNI.  But I thought it was interesting that...



LEO:  Defense...



STEVE:  That's, shoot...



LEO:  He worked for the feds.



STEVE:  Yes, yeah.



LEO:  He was intelligence.  Defense and National Intelligence.



STEVE:  That's it.  



LEO:  Or Department of National Intelligence or something.



STEVE:  But what you normally have for, like, big stories is one of the core "60 Minutes" team.  And it struck me as very odd that for a story of this clear import that they had chosen to do, none of their main people wanted to weigh in on this.  And in fact, I mean, it was a puff piece.  What annoyed me was that, on camera, to the "60 Minutes" investigator's face, they were just saying what we know to be lies.  I mean, they were asked:  "Is the NSA collecting data on millions of Americans?"  "No, we're not doing that."  Well, okay, wait a minute.  The next day...



LEO:  We're just collecting phone records, metadata.  They even said that later in the piece.



STEVE:  Yeah, they did.  And so there was - although it was a different person.  So there was some - so the piece was also self-contradictory.  So again there was, like, there were no follow-up questions.  No one was pushed hard.  They made a point of saying, "Oh, I've never been interviewed before.  I've never been on camera."  And it's like, okay.  Anyway, I was, yeah, our listeners were just sort of rolling their eyes.  So I didn't think very much of it.



And of course the next day, Monday, came the news that a federal judge ruled that in fact the mass collection of telephone metadata is unconstitutional.  So there's a huge collection of lawsuits.  Everybody is suing everyone.  There are shareholders suing IBM because IBM has indicated, or IBM didn't tell them that there would be a consequence to IBM's international sales.  Apparently IBM's China sales has just take a big hit because China's now worried that IBM is a branch of the NSA and is spying on them.  And so the shareholders of IBM are suing IBM.  Meanwhile, we've got all kinds of class action suits against AT&T and Verizon for sharing the data.  I mean, it's just a disaster.



So one other thing that happened is that yesterday, on Tuesday, the White House invited 15 of the top Silicon Valley tech execs to come and sit around a table and have a photo event, basically.  Tim Cook of Apple, Eric Schmidt of Google, execs from Twitter, Microsoft, Facebook, Salesforce, Netflix, Etsy, Dropbox, Yahoo!, Zynga, Sherpa Global, Comcast, LinkedIn, and AT&T.  So sort of like the - although I don't see any Verizon among those, but maybe they were there, 15 of them in total.  And so this was to, I don't know what, air everyone's grievances.  Barack apparently tried...



LEO:  Ostensibly it was about the HealthCare.gov debacle.



STEVE:  Oh, was it, also?  Because I knew that that was part of it.



LEO:  That seemed to be, well, the stories before the event said "meeting with Silicon Valley to talk about HealthCare.gov."  Of course these executives had a different agenda.  And apparently the President deflected them as best he could.



STEVE:  Yeah, well, for example, the Washington Post had an article.  And they quoted an industry official who was familiar with the companies' views as saying, for example:  "What the hell are you doing?  Are you really hacking into the infrastructure of American companies overseas?  The same American companies that cooperate with your lawful orders and spend a lot of money to comply with them to facilitate your intelligence collection?"  So that was - that characterized the sentiment of these companies.



And I did see an interesting counter-take on this that was a little bit of a reminder, and that is to say, well, let's not forget that these companies, to varying degrees, live  by tracking and profiling their own users.  It's literally their published business model.  Eric Schmidt has been quoted saying:  "We know where you are.  We know where you've been.  We can more or less know what you're thinking about.  Your digital identity will live forever because there's no delete button."  So he's got to be careful that he's complaining about the government spying when many consumers are concerned that Google is watching them too carefully.  I think, of course, that there is a difference.  One is disclosure.



LEO:  You can also opt out.



STEVE:  Exactly.  And power.  Google doesn't have the ability to knock on...



LEO:  They don't have [indiscernible].



STEVE:  Exactly, to knock on your door and disappear you under the Patriot Act and deny any opportunity for you to have legal representation.  You just are gone.  And our government does have that power.  And I remember a lesson I learned way back, and you'll remember, Leo, in the spyware days, when the term was born, "spyware," because I discovered this stuff on my own machine, this Aureate spyware, which was later renamed Radiate.  And this was - it was when I was beta testing the Zone Alarm firewall, which was the first firewall that did outbound blocking.  And so I installed it on my machine, and a notice popped up telling me that something I'd had no knowledge about was trying to connect to the Internet.  And it's like, what?



And it turns out that PKZIP had installed this.  It was part of their business model.  They brought this stuff in.  And even though I had registered it, it was - you downloaded the unregistered version, and then you would give them the license, and then it stops displaying ads.  Well, this was a technology that displayed ads in a window in the application.  And so this was the framework for that.  But, and even though I think I'd even uninstalled PKZIP, I was using something else by then, the instructions were explicit from Aureate, do not uninstall us because we can be shared by many different freeware in order to monetize freeware.



So this wasn't malicious.  But this was something I never was told about.  It was not consensual.  And so I wrote OptOut immediately in order to remove this stuff from my machine, which was - it turns out this was phenomenally widely spread through the Internet, and nobody knew about it.  And so it generated a huge response.  And my point is that I was privy to the letters and email people were writing to Aureate.  I mean, beyond livid.  And some of the language and the terminology, I mean, with reference to totalitarian regimes in the past.  It was sobering to see how upset people were.



And what I realized was it's because this was a surprise.  I mean, this was in their machine, and they had no knowledge of it.  It wasn't that it was malicious back then.  Stuff today is much more so.  It's just that this happened without their knowledge.  And I think also it was the beginning of this.  Now everyone's kind of like, okay, well, I've got to get this stuff out of my machine.  But this was the coining of the term "spyware."  This was the first evidence of this kind of thing happening.  So people were really upset.  And so my point is that I'm sure that a lot of the heat generated over the whole Edward Snowden revelation series is we just really didn't know.  On some level, yeah, okay, there was an assumption.  But we've seen slides with graphic details.  And so that's a different story.



LEO:  That was another funny part of the "60 Minutes" thing is the only debate over Edward Snowden was should we give him amnesty so we can get the other files back from him?  Or should we just, he's a terrorist, so throw the book at him.  You don't want to negotiate.



STEVE:  Right.  And the guy who understood the depth of the breach and the number, 1.3 million, I think, files was the number that was cited, and I've seen that elsewhere, he was of the opinion, well, it would be really nice to have those back because he knows now the extent of what, if they have a number like that, they have a sense for what has gone missing.



LEO:  I would guess they would know exactly.  I mean, there must be logs.  I would guess they...



STEVE:  I don't know.  Maybe.  But certainly they have a count.  And he knows actually how much on his good behavior Edward has been.  I mean, what hasn't been disclosed is a lot relative to what they believe he got.  And again, it's the case that Snowden had a specific goal, and that was of generating accountability.  And he is achieving that, and not more.  And so I really think he's acted responsibly so far.



LEO:  I didn't ask you, and I don't want to sidetrack you because you've moved on.  But about this BIOS virus that they were describing in this piece.



STEVE:  Okay.  So the thing that I was put in mind of was the Chernobyl virus.  That was the thing that I wrote the free recovery tool for.  I called it FIX-CIH because it was also known as the CIH virus.  And there are BIOS Flash ROM-erasing viruses around.  This was a hard drive-erasing virus.  But there have been some viruses that specifically wipe the BIOS and turn your board into a brick.  And so that's what I'm thinking.  I mean, I heard a lot of people pooh-poohing it.  It's like, well, if somebody wanted to...



LEO:  Generally the MO of people who spread malware these days, I mean, that's just malicious.



STEVE:  Well, right, because it kills the platform that the thing's on.



[Talking simultaneously]



LEO:  ...what they want.



STEVE:  Right, exactly.  And this has always been the argument against why viruses don't kill the machines they're living on is that there's always a chance they can spread more if they stay alive.  But if, for example, a foreign power wanted to really, I mean, seriously hurt the U.S., I mean, this is like Daniel Suarez sort of, you know...



LEO:  Yeah, this is cyberwarfare stuff.



STEVE:  Yeah, cyberwarfare.



LEO:  But again, I think more successful bringing down the power plant in other ways.  You know?  It's, you know.



STEVE:  Well, think about it, Leo.  If it were actually possible to spread something that zeroed the firmware on motherboards, it would, in fact...



LEO:  That'd be pretty bad.



STEVE:  Oh, it would be truly devastating.



LEO:  Seemed as if they were looking for something that would be as scary as possible to make people feel better about the work they're doing.



STEVE:  Although - okay.  See, the other thing that has come out is it's very clear, I think, to anyone looking at all of the news, that the NSA lies to Congress.  They exaggerate the benefit and the effect of this vacuuming of everything.  And, for example, someone matter-of-factly said, oh, yeah, we've thwarted at least 50 terrorist plots using the mass metadata collection.  And then upon further analysis it's like, okay, well, talk to us.  Which ones?  Oh, well, we'll have to get back to you on that.



LEO:  You know, that one.



STEVE:  You know, those bad ones.



LEO:  Those ones.  Well, they can't, I mean, in their defense, they can't - they're not really going to say...



[Talking simultaneously]



STEVE:  And as I've said, I really appreciate the tension that exists.  I mean, in my reading I did see somebody, a third party saying - and this is one of the talking head shows - mentioning that - but one of the smart people - saying, you know, the NSA says they can't tell Congress because Congress will leak it.



LEO:  Right.  General Clapper said, "I said as much as I could.  I was as honest as I could be."



STEVE:  And Leo, I've seen Congress.  They would leak it.



LEO:  Of course they would.



STEVE:  I mean, I wouldn't trust Congress as far as I could throw them.



LEO:  But that raises the issue of, if you can't trust Congress, who do you trust to do oversight?  Somebody has to do oversight.  And you can't - and I think it's not unreasonable to say you can't reveal all this stuff publicly.  I mean, you can't let the American people decide.  Their representatives have to decide.  This is not - I don't think it's all that clear.



STEVE:  Okay.  So one thing I wanted to - I want to get off this topic.  Maybe in the New Year we'll be able to.



LEO:  Yes, yes, sorry, yeah, yeah.



STEVE:  No, no, no, no, no.  I mean, like, sort of in terms of podcast future because we've beaten this thing to death.  But one of the things that annoyed me was the characterization we have seen of Snowden, and we saw it in the "60 Minutes" piece.  There was the one little anecdotal business about, well, he cheated on a test in order to get hired.  And there is a - I understand that the NSA has to paint this person as a traitor and the worst thing that ever happened to national security and a high school dropout and, I mean, really paint him as badly as possible.



But there was a piece that I linked to for anyone - oh, in Forbes.  So this is in Forbes.  And this is going a little bit, I think, overboard on the other side, where "An NSA Coworker," the headline is, "Remembers the Real Edward Snowden as a Genius Among Geniuses."  Now, okay, all of our geeks, all of we geeks have mothers who think we're geniuses.  So that's sort of, okay, you have to understand who's doing the thinking here.  I'm sure that the janitor in the NSA building thinks that all of the NSA employees are geniuses.



But, for example, before coming to - and so this is from the interview of an NSA coworker who knew Snowden well, said that:  "Before coming to the NSA in Hawaii, Snowden had impressed NSA officials by developing a backup system that the NSA had widely implemented in its codebreaking operations.  He also frequently reported security vulnerabilities that he discovered in the NSA's own software," and apparently "many of these bugs were never patched.  Snowden had been brought to Hawaii as a cybersecurity expert working for Dell's services division, but due to a problem with the contract was reassigned to become an administrator for the Microsoft Intranet management system known as SharePoint.



"Impressed with his technical abilities, Snowden's managers decided that he was the most qualified candidate to build a new web front end for one of its projects" - maybe they could get him over on HealthCare.gov.  Anyway, "despite his contractor status.  As his coworker tells it, he was given full administrator privileges, with virtually unlimited access to NSA data.  'Big mistake in hindsight,' says Snowden's former colleague.  'But if you had a guy who could do the things nobody else could, and the only problem was that his badge was green instead of blue, what would you do?'



"As further evidence that Snowden didn't hijack his colleagues' accounts for his leak" - which is one of the bogus stories we heard in order to paint him in that light, "the NSA staffer points to an occasion when Snowden was given a manager's password so that he could cover for him while the manager was on vacation.  Even then, investigators found no evidence Snowden had misused that staffer's privileges, and the source says nothing he could have uniquely accessed from the account has shown up in news reports."  Of course, we know that not everything Snowden has has shown up in news reports, but still there's another bullet point.



"Snowden's superiors were so impressed with his skills that he was at one point offered a position on the elite team of NSA hackers known as Tailored Access Operations," or TAO.  "He unexpectedly turned it down and instead joined Booz Allen to work at the NSA's Threat Operation Center.  Another hint of his whistleblower conscience, aside from the telltale hoodie" that he always wore.  He wore an EFF hoodie that showed that eagle with its talons holding all the fiber optic cables.  So, I mean, he was saying to people, look, I'm with a spying organization here, folks.  "Snowden kept a copy of the Constitution on his desk to cite when arguing against NSA activities he thought might violate it.  The source tells [the reporter that] Snowden also once nearly lost his job standing up for a coworker who was being disciplined by a superior."  And this goes on.



So my point is that there's ample evidence to say that Snowden had a conscience, that he was demonstrating it at work, and he was - characterizing him as a high school dropout who cheated on a test in order to get into the NSA is clearly not telling a fair recitation of the facts.  So there.



LEO:  So there.



STEVE:  Now...



LEO:  Take a sip, everybody.



STEVE:  Maybe we're done with the NSA for 2013.



LEO:  Yeah, let's move on.  I think that's a good idea, yeah.



STEVE:  It's been a major topic for 2013.  We will try not to have it dominate 2014.  But speaking of dominating, I posted, I tweeted a neat graphic which popped onto the 'Net last week showing - I think I tweeted "The bots are winning," or something to that effect.  This is the result of an analysis showing the bot versus human traffic distribution, which is to say the traffic on the Internet generated, not by human activity, but by automated activity.  In 2012, 51% of the traffic was nonhuman agents.  In 2013, that 51% has expanded to 61.5, so an additional 10%.  Human use has dropped to 38.5.



LEO:  But that's kind of to be expected.  This is machines talk to machines and can do it much more rapidly than a human can.



STEVE:  Yes.  And so, for example, search engines, of the 61.5 majority of the traffic, 31.1, so half of that 61.5%, 31% is search engines and other good bots.



LEO:  And this isn't a surprise to anybody who has their own website because, if you look at the log, there's always a crawler from one of the search engines in our site.  Always.



STEVE:  And in fact the other day I looked at my Perfect Passwords page, which, I mean, I'm using a password for my WiFi, to protect my various WiFi routers, that I got from GRC.  I just can't get a more absolutely unbiased random blob designed for WiFi than from GRC.  But on the day that I looked at it, there had been, like, 12,000 average pulls.  And it normally runs, like, three or four.  So I'm thinking, okay, it must now be that some automated thing is just going there and sucking a lot of pages in order to collect random noise from GRC.  It's like, okay, well, I've got to go put a stop to that one of these days.  It's not on my priority list, but...



LEO:  What is Netflix?  Is that a bot?  I mean, if I go watch a stream, is that a human interaction?



STEVE:  I wouldn't think so.



LEO:  How do they classify that?



STEVE:  Well, so 31% is search engines and other good bots.  Then 5% is scrapers, and what I just described was a scraper.  Something is scraping my site.  I designed this page for a person, one person to go and get one piece of very, very high-quality pseudorandom data for their own use.  But something, I'm thinking, is scraping my site.  And it's the same way, like Craig's List has complained about scraping.  Other people set up bots to go and, like, scrape.  And eBay has the same problem.  So they're scrapers who are pretending to be humans that are collecting data from websites.  Five percent of the bots are doing that.  Four and a half percent are hacking tools.  I don't know what that actually means, what they qualify.  Half a percent are spammers.  And then 20.5 are called "other impersonators."



Anyway, just some interesting stats that, over time, clearly human use of the Internet is increasing from 2012 to 2013.  We know that's increasing.  As all of us now have smartphones, there's additional points of entry to the Internet, allowing us to use more of our day hooked to the 'Net.  So human traffic on the Internet is growing, but nonhuman traffic is growing faster than human traffic such that we're losing out as a percentage, which is interesting.  As you said, not unexpected.  But to me the reason it makes sense is there's never been anything more automatable than the Internet.  It's a bunch of protocols that obey rules.  And so,  yes, a human running a browser can click a URL and pull up a page.  But so can a machine.  And so machines are.  People have found all kinds of reasons to have machines doing that.



I got a bunch of tweets earlier in this week, maybe it was the end of last week, concerned with the news that Google was now displaying images in Gmail.  Previously, Google, when you got email that had embedded images, you would have a "click to display this image" if you want to.  So that did a couple things.  It saved bandwidth, so that you weren't downloading stuff that you didn't care about.  But there was also some protection there because, in the same way sort of that NoScript protects you by not loading a script by default on a website you visit, this wasn't loading an image by default on email you were viewing.



And we've spent a lot of time talking about how sad it is, but true, that actual images can be malicious because the renderers in our computers that convert that image into something we can see, essentially the code representation of the image - JPEG, GIF, whatever, TIFF - into an image, that rendering code can have buffer overflows.  And it's possible to then, if you find a flaw in the rendering, you can craft, like, a fake image which will deliver malware.



So what's very cool about this - so a lot of people were saying, hey, Steve, I thought, like, this was a security problem.  And what Google has done is extremely cool.  They are proxying images.  And here's the key:   They are transcoding them.  And there are a number of reasons for doing this.  But what that means is essentially Google's own servers are following the link and obtaining the image and interpreting the image, turning it into a graphic.  Then they're taking that and re-encoding it as whatever makes sense, a PNG or a JPEG, and then embedding that in your Gmail.  So it's now safe for Gmail to display images by default.



And so this means a couple things.  First of all, that act of transcoding is the best filter you could ever have.  For example, I'm using it on GRC's packets.  I don't talk about my security technology often.  But from the beginning, before I began doing things, I implemented a packet transcoding technology which re-represents the packets in a meta language, and no packets from the outside ever come to the inside of GRC, only transcoded packets.  And it's technology I've never done anything with.  I just did it for myself.



But it provides protection because it essentially - it completely sanitizes, in Google's case, an image by discarding what could be a malicious specific representation and turning it into an image and then re-encoding it.  But the other thing Google can do is that many times somebody may send you an image which is like ridiculously high resolution, tens of megabytes in size.  So Google, because they're proxying it, is able to, in the transcoding process, is able to essentially recompress it to a size that makes sense.



So it comes into Gmail.  And you might be able to click on it to get the full size one, but it shows you a nice little thumbnail, much smaller, at a compression ratio that makes sense for the type of image and your application, which then makes your page load much faster than if your browser was going out and having to download a 20MB photo that somebody sent you in full hyper resolution without reducing it.  So it's very cool.  And it means a few other things, too, that they comment in their blog posting where they describe this, and that is that senders cannot use image loading to get information like your IP address, which they otherwise could.



If your email is collected by Google, then Google is the store-and-forward server.  But when Gmail comes to your browser, and your browser opens it, its requests for images will come from you and not from Google, which means that anyone wanting to track you based on images added to email would be getting queries from your browser at your IP address, and then they would know your location.  And they would be able - that would be a cookie transfer.  So they'd be able to set and read cookies on your browser through images.  Both of those things are thwarted by having Google proxy images in Gmail.  So that's also very cool.



But the one glitch is, if images are tagged with unique filenames in their links, then they would still be able to track you that way.  That is, if you opened the email, and then your browser asked Google for the image by name, then Google would query the image in order to transcode it and send it back to you.  And so there would still be tracking by unique image name.  But still, a nice step forward.



LEO:  And you can disable it.  You may ask, well, why would Google spend all the time and money to do this, because it's expensive.  Because they want you to see ads, frankly.  And they want - I don't really want to see those images.  So I've immediately gone into my settings and turned this feature off.  I mean, they're not - it's good they're sanitizing it.  And I guess for most people seeing images in their emails is kind of better.  But I don't want to see ads in my email.  And so, fortunately, you can go into settings and turn it off, at least for now.



STEVE:  Right.  So they flipped it back on, and you can go in and say no, no thanks, again.



LEO:  And they do explain there why it's okay now to have images in emails and so forth.  They don't have the - I'm curious what this is going to be.  Ask before displaying external images.  Used to be they wouldn't display them at all.  And what I suspect is people like MailChimp and Constant Contact said, hey, you know, we do newsletters with images.  You turned them off without asking.  So my suspicion is we're going to get pestered every time there's an image.  You want to see these images?  Come on.  I know you want to see these images.  So, you know.



STEVE:  Yeah.



LEO:  It's an ad.  I love Google.  I'm not going to complain about Google.  I love Google.  But it's an ad company.  And this is about commerce.



STEVE:  Yes, and that's exactly it.  We are Google's product, as has been said.  They're monetizing us.  And that's, I mean, television does.  And so it's funny, Leo...



LEO:  TWiT does.  We do.  I mean...



STEVE:  Yeah.  I was commenting to Jen a couple days ago, I stumbled on a site, I don't remember now what it was, but it was clean.  It was like GRC.  No ads.  And but obviously it wasn't mine.  But I just looked at it, and it's like, wow.  And I just - I realized then, look at the typical - look at what has happened to the typical website.  It's just - it's all across the bottom.  It's half of the - it's all down the right-hand side, stuff jumping around.  And then now, as you scroll down, new things, like, slide out of the bottom in order to grab your attention.  And I went to some other site that had no ads, and it's just like, oh, it was nice.



And so, yeah.  It is incredible what's happened to the 'Net.  And as you know, I'm sure, the file download sites have all just become unusable now, too.  They're all forcing you to, like, download some intermediate download manager of their own and install junk on your machine other than the file that you're trying to download.



LEO:  Yeah.  There is a difference, you know, I really - there must be a rhetorical - you know how there's names for all sorts of rhetorical tricks.  There must be a name for this rhetorical trick.  "But Leo," says somebody in the chatroom, "you're always saying it's unethical to use adblockers.  What's the difference?"  Because it's in my email.  That's different.  I'm not using a free service like Facebook and saying, well, I don't want to see the ads.  This is my email.  And I don't want to see bazooms in my email, thank you very much.  Off of soapbox.



STEVE:  Right.  So, okay.  We have to talk about this because everyone's just in a frenzy.  What was shown was, at this point, a purely academic, theoretical attack.  It is definitely interesting, and it's the kind of thing that I love to bring to our listeners because this is the kind of stuff that really makes a difference in fundamental understanding of security.  And this is a group of researchers who published a paper, and in the show notes is the link to it [www.cs.tau.ac.il/~tromer/acoustic/#].  I'm just going to share their synopsis because they do a perfect job of characterizing this.  And we'll talk about it in a little bit.  The title of their paper is "RSA Key Extraction via Low-Bandwidth Acoustic Cryptanalysis."  And so they said:  "Many computers emit a high-pitched noise during operation, due to vibration in some of their electronic components."  And this actually is the switching power supply, but we'll talk about more details in a second.



"These acoustic emanations are more than a nuisance.  They can convey information about the software running on the computer, and in particular leak sensitive information about security-related computations.  In a preliminary presentation, we have shown that different RSA keys induce different sound patterns, but it was not clear how to extract individual key bits.  The main problem was that the acoustic side channel has a very low bandwidth" - naturally, because basically it's an audio carrier, so variations in the audio carrier are going to be limited to the carrier's frequency, which is on the order of 20 kHz, which is like the switching power supply frequency.  So that's why some of us can still hear those switching power supplies.



And then, so they say - and of course they're limited by microphone bandwidth.  They say "...under 20 kHz using common microphones and a few hundred kHz using ultrasound microphones, many orders of magnitude below the GHz-scale clock rates of the attacked computers.  Here, we describe a new acoustic cryptanalysis key extraction attack, applicable to GnuPG's current implementation of RSA."  They were actually able to extract GPG RSA keys.



"The attack can extract full 4096-bit RSA decryption keys from laptop computers of various models within an hour, using the sound generated by the computer during the decryption of some chosen plaintexts.  We experimentally demonstrate that such attacks can be carried out, using either a plain [microphone planted] next to the computer, or a more sensitive microphone placed four meters away.  Beyond acoustics, we demonstrate that a similar low-bandwidth attack can be performed by measuring the electric potential of a computer chassis.  A suitably equipped attacker need merely touch the target computer with his bare hand or get the required leakage information from the ground wires at the remote end of VGA, USB, or Ethernet cables."  Oh, my lord.



So anyway, so we've talked often about side channel attacks.  This is clearly a really cool low-bandwidth side channel attack, basically using things the machine does.  Apparently vibration is another one.  And sound is one.  And subtle variations in the electric potential between the machine's ground.  So essentially, when you have an algorithm, a cryptographic algorithm where secret information changes what the machine does, even in subtle ways, that is detectable.  It varies the load that the processor puts on the power supply.  Varying the load that the processor puts on the power supply varies the ground reference of the machine, just by microvolts, but enough that you can detect it.  And it will vary the strain on the power supply that changes the sound that the power supply makes.



And so technically it's all leaking information.  It's one of the reasons, and I've mentioned this before, that the elliptic curve technology that I chose was deliberately designed by Dan Bernstein to have none of its secret information involved in any branch decisions or changing the flow of the machine in any way.  I mean, so it is side channel neutral.  But it's very difficult to write code that way and takes an extra effort.  What we're seeing is it is incredibly important to do this.  We talked last week or the week before about another attack, which was using variations in the code flow which change the caching of code and data in the microprocessor.  And so malware running in the same processor, but in a completely different virtual machine, but like in an Amazon shared hosting environment, could obtain cryptographic information from other processors running in the machine.



Now, okay.  So the reason we don't have to all run around with our hair on fire is this was an academic demonstration.  First of all, the machine could not be doing anything else at the same time.  It was absolutely set up so that it was only doing this crypto, using chosen plaintext, over and over and over and over and over.  So, I mean, that's all it was doing, with no contention.  If you were in a typical laptop where you've got all kinds of annoying stuff connected to the Internet, downloading stuff and updating and other tasks happening at the same time, all of this goes out the window.



Now, that's not to say it's then impossible, but it's very much like if everyone in a coffee shop, like in Starbucks, was absolutely quiet, and one person was talking to someone else, you could hear their conversation across a room.  Whereas, if everyone is talking to someone else, yes, that original conversation is still there.  It's part of the mix of what you're hearing.  But oh, my lord, distinguishing it from the cacophony is vastly more difficult.  So, similarly, in any real-world situation, it's going to be much more difficult to extract keys.



But this has been a focus, a recent focus of cryptographic work, the nature of side channel attacks.  And so what we're going to be seeing in the future are going to be explicitly side channel safe crypto.  I'm already using it.  Other people are going to have to start using it just so that you know you're safe against these kind of attacks because they're inherently stealthful.  It's machines and processors and boxes and hardware that you may have no control over whatsoever that are unintentionally changing what they do.  I mean, it's like the fundamental nature of the way the processors function is leaking this information.  So now we have to start designing crypto so that it is side channel-safe against these kinds of attacks.  But this was, wow, really interesting.



LEO:  You've heard of Van Eck phreaking; right?  This has been since the '80s.



STEVE:  Well, and remember, Leo, being an old-timer like me, we used to put AM radios on the top of mini computers, and we would write code with different lengths of loops in order to generate different frequencies and then, like, play Christmas carols and things, back in the old days.  And so this is the same sort of thing.  There it was the core memory.  Core memory, the nature of the way it operated was pulses of current through loops of wire, and that was inherently generating radio frequencies all over the AM band.  I mean, basically you couldn't listen to an AM radio inside of a computer shop.  And so we would tune the radio to someplace where we'd get a good intermodulation, and you could play music from a computer, just even though it had no sort of interface at all.  It was just generating - you could get it to generate deliberately really strong RF emissions.



LEO:  There's a scene in "Cryptonomicon" where somebody uses Van Eck phreaking to see what's on somebody's monitor through a hotel wall because the radiation from a monitor does travel through walls.



STEVE:  Oh, yes.



[Talking simultaneously]



LEO:  That's why there's a TEMPEST specification for highly secure...



STEVE:  Yes.  And back then when you had big CRTs that were scanning, they were sending out the contents of their screen moment to moment.



LEO:  Right, right.  Hey, we have a winner in the Mega Millions lottery.  I'm surprised you don't have this in your notes because you're big on math.  Apparently there are a lot of people confused about math.  Mega Millions, if they hadn't had a winner, would have gone to over or close to a billion dollars in the lottery prize on Friday, which means everybody was buying a ticket.  But one of the reasons they hadn't had winners in so long is because they made the odds literally astronomical.  You're more likely to get hit by an asteroid, literally more likely to get hit by an asteroid than win the Mega Millions lottery.



STEVE:  And that's way more likely than you are to have a collision of a 256-bit number.



LEO:  Right.  Since you love these big numbers, they changed the - I forgot what it is.  I think you have to pick 15 numbers between one and 75.



STEVE:  And get them all?



LEO:  Yeah, and then pick - well, yeah.  And then pick a 16th that's only between one and 15.  Get them all to win.  It's the odds are so huge, I'm surprised there was a winner.  But apparently somebody did pick it in Georgia.  One in 75, 15 times.



STEVE:  Yow.



LEO:  That's a big number.



STEVE:  That's a big number.



LEO:  Anywhere.  We have a winner.  I don't think it's - somebody does win sometimes, and that's why people do it.  On with the show.



STEVE:  That's 1.6 times 10^88, just for those 15.



LEO:  I don't know how they got a win.  How did somebody win?  I don't even understand how somebody won that.



STEVE:  Oh, no, wait.  One to 75, 15 times.  Sorry, 1.3...



LEO:  I'm sorry.  I have not ever purchased a lottery ticket or a lotto ticket in my life.  Somebody has corrected me that there are five, not 15.  So one to 75, five times.  Is that really right?  I thought it was harder than that.



STEVE:  Wow.  That begins to seem reasonable because, Leo, that other number...



LEO:  Yeah, if you make it too hard...



STEVE:  That other number was just wrong.



LEO:  Can't make it too hard.  Apparently they have two winners.  They've announced two winners in the $636 million jackpot.  Yeah, it's five numbers.  So you have...



STEVE:  Okay, so now we're at...



LEO:  Eight, 14, 17, 20, 39, and a mega ball of seven.



STEVE:  Okay.  So we're at 2.373 billion combinations, one in 2.373 billion.



LEO:  It's crazy.  It's crazy.  Your odds were not good.  But, you know, people buy enough tickets, somebody's going to win.  On with the show.  Sorry.



STEVE:  So Microsoft made a bunch of news by their joining the FIDO Alliance.



LEO:  What's that?



STEVE:  That's something that I'd never really looked at much.  Stina at Yubico always talks about FIDO Alliance, FIDO Alliance, whenever we're together.  And it is a big, slow-moving bunch of committees.  To give you a sense for it, you have to pay $25,000 a year in dues in order to join.  And so it's like, okay.  And it's what Google - Google is now involved.  And what they have is two different authentication proposals.  And so these are big, lumbering committees.  And Google has this thing, and I'm sure you're aware of it, that they're using YubiKeys internally, and they've come up with a second-factor authentication technology using YubiKeys.  And I think they've got custom plugins for Chrome that work with it and so forth.



So people have asked, where is that relative to SQRL.  And I had no idea.  So I did a little poking around.  I've got links in the show notes if anyone wants to get details.  Google has posted - they had a project called, I guess you'd pronounce it "nubby," Gnubby, which was their working name, which is their OAuth technology.  And they were calling it "Universal Second Factor," U2F.  And there are some similarities to SQRL, that is, the system that I've designed.  And, frankly, we solved many problems they haven't solved.  There's, like, SQRL is superior.  But that doesn't mean it's going to win.



I was initially a little saddened when I looked at what they were doing because it wasn't really good.  For example, their system requires the thing that you have to have, like a YubiKey; and it has to have storage, which stores keys for every site.  Well, that's one of the coolest things about SQRL is you don't have to have any - it doesn't have any state in it, like per site.  It generates it on the fly.  And then when they were trying to make these things cheaper - because they're saying, well, this will cost many tens of dollars.  And so that's the other problem is that naturally you've got a lot of entrenched biases.  Like Google wants to protect their ecosystem.  Yubico wants to sell tokens.  Everyone has their territory to protect.  And this thing, the spec is really overdesigned.  I mean, at one point there's like a certificate signing request being sent back and forth.  And it's like the kind of thing you do when you register certs with a certificate authority, and you want them to sign your certificate.  So one of the problems is it'll never be free because it's tied to a physical token.



LEO:  So it couldn't use, like, Google Authenticator.



STEVE:  Well, for example, you can't use Apple iOS ecosystem because it's also all near field.



LEO:  Well, no wonder Microsoft loves it.  That explains a lot.



STEVE:  It's all near...



LEO:  It's dead in the water, then.  You've got 400 million devices it won't work with.



STEVE:  Right.  And SQRL, of course, will work with everything.  So when I realized, well, first I realized there's a whole bunch of things we did right.  Also, we've solved the key lifetime, what we call "key lifetime management," where if worst happened, and someone did steal your identity, SQRL gives you control so you can get it back.  You can actually get it back from a hacker who has stolen it.  And there's nothing like that in FIDO, or in the FIDO proposal.



And then this other thought I had was, okay, not only is SQRL better, I mean, much easier to implement, much simpler, much more clearly, like much clearer about how it works, but it's free, and it'll work on all devices.  And it's truly free.  You don't have to buy anything.  It doesn't need near-field technology, so you can use it on Apple mobile devices.  But also it could, if FIDO ended up happening, there's nothing to prevent them from cohabitating.  I mean, like if people wanted to use the free one, which is arguably better, we'll have that, too.  And it's so simple for a website to implement SQRL, and everyone's writing libraries now for all the different major platforms, that it'll be easy to add it.  So it's like, okay.  Microsoft and Google and all these other people are happy, welcome to do that.  And I imagine that SQRL will not be kept from existing just because there's something else.



LEO:  Good.  Although, as we know in the tech industry, best technology does not always win.  In fact, it often does lose.



STEVE:  That's true.  And if it doesn't take off, well...



LEO:  You did your best.



STEVE:  I'll use it, and other people will use it.  And I will have given my expression for here's how you solve the problem the right way.  And anyone who looks at it will go, wow, this solves the problem.  And, I mean, it'll just be there.  It'll be free.  So we'll see what happens.  I am not discouraged.  And lord knows, I mean, I'm writing code.  I've got the - I assembled all of the crypto libraries and got them running on my toolchain, which is earlier than everyone else's.  So I'm deep into it now and moving ahead.  And as are a bunch of other people, who now - because the spec is finalized.  I had sort of - had a pro forma finalization.  I talked about it last Wednesday.  We're done.  It has been settled.  The semantics and the syntax are finished, and everyone's writing code.  So I think we'll have something here in probably a couple weeks.



LEO:  So we had talked last week about HealthCare.gov.



STEVE:  Yes.  And what was funny was, completely unsolicited, our wonderful podcast transcriber, Elaine, was listening to the podcast, as she is forced to do whether - actually I think she really enjoys it because she is a geek and, you know, self-ascribed.  And so when she sent me back the transcripts, text files in email, like Thursday night late, she wrote:  "Steve, I'm too sleepy to go into detail right now, but you might want to relax a bit."  Now, okay, remember what I did last week, first question we answered was why haven't we ever talked about the security catastrophe of HealthCare.gov.  And I gave everybody who thought that we were afraid to talk about it a nice rant about don't even talk to me about the security, it's just -it has to be the worst disaster anyone's ever imagined.



So Elaine says:  "I'm too sleepy to go into detail right now, but you might want to relax a wee bit about the healthcare thing."  And by the way, I should tell you I have her permission, as you'll see in a second, to repeat this.  She says:  "I got it.  It's painless.  They ask for less information than any utility company, and the website's just to allow you to compare plans available in your area.  You pick one, they send your name and address to the insurance company, who sends you an invoice for the first month's premium, and that's it.  You're done with the website, and you don't have to give a credit card number or any medical information."



LEO:  Oh, that's interesting.



STEVE:  Yes.  Now, we should also remember, though, she's in California.



LEO:  Oh, she's not using the federal site.



STEVE:  Correct.



LEO:  She's using the state site.



STEVE:  She says:  "I'm tickled pink because I haven't had insurance for nearly 20 years."



LEO:  What?  What?



STEVE:  "And I'm about to need eye surgery."



LEO:  Oh, boy.  She's been very lucky.



STEVE:  She said:  "Your major disastrous catastrophe" - she says to me, that's what I was calling it - she says:  "is my godsend."  Although we were, of course, again, we're talking about different implementations.  We're talking about HealthCare.gov national, and she's in California, so I'm presuming she's using whatever the California site is [CoveredCA.com].



So I asked Elaine whether she would mind my sharing her real-world experience with our podcast audience, and she replied:  "I don't mind at all.  I just tried to tell my farrier" - and I thought, what's a farrier?  And I knew that Elaine would not have a typo.  And that's somebody...



LEO:  "Drill, Ye Tarriers, Drill."  It's a horseshoer.



STEVE:  Yes.  So Elaine has a horseshoer, but she has no healthcare.



LEO:  Hey, if you have horses, you've got to buy them shoes.  Baby needs new shoes.



STEVE:  Yes.  So she tried - she just says:  "I just tried to tell my farrier I got health insurance (he got dropped last year and has two people with heart conditions in his family)."



LEO:  Oh, that's why he got dropped.



STEVE:  And he just went nuts on me a la Fox News.  So any little bit of truth and balance is a good thing.



LEO:  Wait a minute, he's upset because there's national healthcare, but he got canceled last year?  I don't understand.



STEVE:  Yeah, well, people will vote against their interests, unfortunately.  We see that all the time.  So she says:  "It's not spectacular news, like the woman who got a family policy for $3.16 or the person who got billed 13 cents, but it feels very solid and real to me.  I'm getting a $580 per month policy for $170 per month, with reasonable deductibles."



LEO:  Wow.  That's not bad.



STEVE:  And then she said:  "Actually, now I'm thinking it would be GREAT" - in all caps - "if you did mention it.  I'm sure lots of geeks like me have small incomes and/or have suffered catastrophe.  Remember the listener from New Orleans who wrote after Katrina?  You've got listeners in New England who suffered through Sandy.  There must have been listeners in Colorado who lost big-time in last summer's flood."



LEO:  Yeah, absolutely.



STEVE:  "Not every working mother is the CEO of Yahoo!, and the recession still exists for lots of us.  Healthcare is a definite bright spot."  So, and anyway, she said:  "Along those same lines, you can buy refurbished computers at CedarPC.com for $200-300, desktops or laptops.  You could do a little 'in case you've been struck by disaster' segment."  And so we just did.



LEO:  Very good.



STEVE:  A number of people have asked for GRC's SSL/TLS cipher suite ordering.  That is, I talked about it, how when I decided that I no longer had to worry about BEAST, I could now use an ordering of cipher suites that would put Perfect Forward Secrecy at the top of the list.  Many people said, ooh, I'd love to see what you chose.  Because what I did was I went through, for Windows Server 2008/R2, which is what I'm using, I went through all the available cipher suites very carefully and very deliberately ordered them from most secure to least secure.  It's a long - I have it in a directory on GRC.  So rather than - I didn't bother making a bit.ly link or anything.  But anyone who is interested, I did tweet it, I think.



But it's in the show notes.  So go to GRC.com/sn.  The show notes are now always the third icon over, and it's there.  So anyone who wants to is welcome to grab them: [GRC.com/miscfiles/SChannel_Cipher_Suites.txt].  And actually it's a text file.  You just make it one long - I have line breaks in it to make it easier to read.  But you take the line breaks out, and you can drop that directly into Windows Server, and it becomes your cipher suite order.



Also, I was preparing actually a list of eBooks for Bob, my friend, whom you remember, Leo, up in Vancouver.  And I ran across my directory of Honor Harrington books.  And Baen Books is the publisher, but these are all non-DRM, freely downloadable from Baen's site, although their site is a disaster to navigate.  And they even have like an ISO image you can download with all of the books on it.  But they're hard to find.  So I thought, what the heck, I'll just make them available and number them because the sequence, the proper sequence is also not clear, and there's 13 of them in the main sequence of Honor Harrington novels.



So I have them on GRC.  I tweeted it late last week.  And the server really, I mean, they're large downloads, so I saw the effect at GRC.  Many people were saying, oh, thank you, thank you, thank you.  So again, the links are in the show notes.  But I did create shortcuts.  It's bit.ly/HHkindle if you want the mobi format that run on the Kindle machines.  Or, again, bit.ly/HHitunes if you want the ePub versions.  And so I continue to think that it's one of the best series of military, really beautiful military and sort of political sci-fi intrigue, which I really enjoy.



And last thing up is just a note for people who are interested, that an interesting-looking new series is premiering January 7th on CBS called "Intelligence."  I have a YouTube link in the show notes, and I did tweet it [www.youtube.com/watch?v=wMayn0vdCpM].  And it's fabulous-looking.  Again, beggars can't be choosers.  I'm not suggesting that it's like the end of everything we could ever ask for from sci-fi.  We're just not going to get that for free on broadcast TV.  But this looks extremely good.  The show is called "Intelligence."  And apparently a chip is implanted in a guy that wires him into the Internet, so he's able to access basically...



LEO:  I'll take that.  Is that available now?



STEVE:  Oh, well, it's very much - this is the technology in Peter Hamilton's Commonwealth universe, where you just have access to your own data store.  But also Marg Helgenberger - is that how you pronounce the name?  She's in there.  She used to be on "CSI Vegas" for a while.  And anyway, extremely good.  And my server is definitely showing the effect right now, Leo, of people grabbing the Honor Harrington novels.  So I'm glad people like it.  Anyway, definitely very cool.



LEO:  Very good.



STEVE:  And I have a nice note from a Microsoft certified systems engineer that I ran across in my mailbag when I was pulling Q&A for the show.  He said:  "Steve, I'm a Microsoft certified systems engineer.  Today I restarted an older laptop of mine, a Dell Latitude D820 that had been running Windows XP without problems for years.  This morning it was locked up.  So I thought to myself, okay, a reboot is required.  But then the laptop gave me the dreaded Blue Screen of Death three times, even after the last known good configuration was selected at reboot.



"Oh, dear," he writes.  "It was a half a terabyte hard drive.  And because this laptop does a lot of stuff in the background on my home network, I dreaded the thought of having to replace the laptop or hard drive and getting everything reinstalled again.  So I decided to try the SpinRite disk I bought from GRC a couple of months ago.  After two hours it reported that Sector 125 were unrecoverable."  And he says 1-2-5, so maybe that's sectors 1, 2, and 5, or I'm not sure because he says "were," as opposed to Sector 125.  He says:  "I was crushed.  I thought, my life is chaos now.  I crossed my fingers and prayed.



"When SpinRite finished, and I checked again, SpinRite reported that there were no unrecoverable errors.  What?  How can that be, I asked myself.  But sure enough, on further inspection, SpinRite reported that there were no abnormal sectors on the hard drive.  So there I sat, after a total of three hours, hoping that SpinRite would salvage more than my day.  Once again I crossed my fingers and removed the SpinRite boot disk and restarted the laptop.  Steve, thanks for such a great hard drive maintenance and recovery software.  It took only three hours or so to recover this hard drive, and SpinRite saved me many more hours of reinstallation and possibly relicensing software.  From this day forward, SpinRite will be a part of my normal backup routine."  So just another happy SpinRite customer.



LEO:  They're all happy-go-lucky SpinRite customers here in SpinRite world.  So are you ready?  We have questions.



STEVE:  We do, yes, absolutely.



LEO:  Wow.  We've got 15 minutes.



STEVE:  We'll get through some of them.



LEO:  I am perfectly happy to do as many as you choose at the time of your choosing.  Question 1 from Richard, he asks about running SpinRite in a virtual machine.  That's interesting.  My TiVo recently stopped working.  I put the TiVo's 320GB hard drive into my PC so SpinRite could fix it.  It ran on a Level 2 scan twice.  SpinRite found and recovered data from bad sectors on both passes.  The number of bad sectors found on the second pass was fewer, but they still were present.  So I decided to run a deeper Level 4 scan to really root out the problems.



After I started the scan, SpinRite reported it was estimating 30 hours to complete the scan.  I let it go overnight, but since I needed my computer back for the work week, I had to stop the Level 4 scan at about 50%.  I then got to wondering, can I run SpinRite in a virtual machine so that I could use my PC?  Because SpinRite works in a DOS box, or a FreeDOS box.  So he wants to know, could he do that and still get to use Windows?  He says he found your tweet from January with a link to step-by-step instructions on how to use VirtualBox - the free VM - for just such a task.



I got VirtualBox installed and configured and started a Level 4 scan on the TiVo hard drive.  To my amazement, the Level 4 scan was flying.  Then, after the usual 60-second sampling, the estimated time populated.  It said it would only need about four hours.  I verified that Level 4 was in fact running.  It was.  So that long hoo-round is all to the point of saying:  Does running SpinRite in a virtual machine cause it to run better than booting it from a CD?  This is the same hardware.  Is SpinRite really working while running in the VM?  Maybe it was just making up those numbers.  Seven-fold increase in speed, what's the story?



STEVE:  Okay.  So I wanted to - this is a great case in point for what essentially is a tip for anyone who is wanting to run SpinRite at maximum speed on a motherboard BIOS that won't run at maximum speed.  And that is SpinRite 6 today.  What happened is that Richard has a BIOS that is not doing Ultra DMA by itself.  And SpinRite 6 famously still runs through the BIOS.  Many people have motherboards with BIOSes that natively support Ultra DMA transfers, in which case SpinRite gets the advantage of that and runs at full speed.  The VirtualBox virtual machine that Richard was using, and VirtualBox, has a state-of-the-art virtual BIOS.  So you can run SpinRite in a VirtualBox VM, and it will be guaranteed to run at full SpinRite 6 speed, which, as you can see, like in this case, was seven times faster on that particular motherboard.



So this was an interaction between SpinRite 6's use of the BIOS and the fact that that motherboard wasn't doing Ultra DMA.  Many other motherboards do Ultra DMA, in which case SpinRite always runs at that speed without putting it in a VM.  And of course the reason everyone's excited about SpinRite 6.1 is it will always get that speed because I will no longer be using the BIOS on any platforms.  And in fact we'll get a lot more speed because I'll be talking natively to the drives and using a 32MB buffer.  I don't remember now the benchmarks that we were making back when I was working on 6.1 before suspending that to get SQRL finished.  But I remember that - what I remember was a 4TB drive we would then be able to do overnight.  So you'd be able to run SpinRite on a full 4TB, like, overnight.



SpinRite 6 won't run that fast because it doesn't use a large enough buffer to do that.  But it can run at maximum speed in a VirtualBox VM.  So people sometimes say, hey, Steve, I'm creating a machine that I want to use just to run SpinRite on.  And so absolutely setting it up with VirtualBox and seeing whether it runs faster in VirtualBox than it does natively is something worthwhile because VirtualBox has a very good virtual BIOS that it brings along.



LEO:  That's cool



STEVE:  Isn't that neat?  Yeah.



LEO:  But so the BIOS will work on a hardware-connected drive.  It's not working on the virtual machine hard drive.  The VM has its own hard drive that's a pseudo hard drive.



STEVE:  Actually, one of the things that VirtualBox allows you to do is to get direct access to a drive.



LEO:  Because you can't.  Ah, that's cool.



STEVE:  Yes.  So you could not get direct access to the system drive because that's the one that it's running on itself.  But you can get physical hard - I mean, even VMware will allow you to do that if you're careful.  So the various virtual technologies give you direct access.



LEO:  Raw mode, basically.



STEVE:  Yes, exactly.  And then so when SpinRite makes its calls to what it thinks is the BIOS, it's of course the virtual machine BIOS.  And the virtual machine BIOS is a very nicely, recently written BIOS that then gives SpinRite Ultra DMA access to that physical hard drive.  So you're really running SpinRite raw, and you're really running a state-of-the-art BIOS.  So it's a really great solution.



LEO:  Cool.  Stephen Adams, Aurora, Illinois highlights probability versus possibility.  This has something to do with the Mega Millions jackpot, I suspect.



STEVE:  Yes, it does.



LEO:  I fully understand the concept of extremely low probability events and the fact that 256 bits provides extreme protection against collision - we're talking about BitTorrent Sync, of course, once again.  But it does not prevent collision, as you have stated.  And I agree.



STEVE:  Well, yes.  So BitTorrent Sync, Bitcoin, and SQRL, for example...



LEO:  All use the same thing.



STEVE:  ...all use 256 bits.  Yes, I'm sorry, go ahead.



LEO:  That said, it is a fallacy to state that collisions cannot happen, as you and Leo did.  I did not say that.  I'm going to defend myself.  I know the difference between probability and impossibility.



STEVE:  We were actually laughing.



LEO:  I think we were choking.



STEVE:  We were, yes, we were saying - we were laughing, saying it will not, it cannot happen.  But...



LEO:  But it could.



STEVE:  Yes.



LEO:  Extremely low probability, he points out, does not equate with impossibility, Steve.  You should know that.  No, I added that part.  While we calculate the mean time to solve something by brute force, it is entirely possible that the very first attempt succeeds.  Look, three people won the Mega Millions.  The odds against this are long, assuming a large enough range to guess from, but they are non-zero.  Because they are non-zero, it's entirely possible, though highly unlikely, that two people will have the same key.



And, frankly, all it takes is an error in a pseudorandom number generator to create a collision.  One mistake by a programmer, and all of a sudden we have collisions and chaos.  Since we can't review every single PRNG that's used by every single software that generates these random strings - he says "stings" - we are subject to the skills of the least capable or least careful coder.  And we see where this has taken us in the past.  It's obvious this guy has no sense of humor.  It's pretty clear from Security Now! that such errors are all too common.



To summarize, a pure brute-force attack is unlikely to succeed, but it is - and I highlight this in bold - possible that it will.  A collision for a properly created pseudorandom number generator is unlikely, but possible.  An error by a programmer is very possible and thus could easily create such collisions.  Fundamentally, the point is low probability does not equal impossibility.  And when human actions are involved, counting on what amounts to security by obscurity is a bad idea.  Signed, Guy With Little Sense of Humor, Stephen Adams in Aurora, Illinois.



STEVE:  Okay.  So, yes, obviously we all know what Stephen said.



LEO:  Yes.



STEVE:  The reason I selected this was that, first of all, he's very correct about the extreme dependence we have on the quality of pseudorandom numbers.  We've talked, for example, about the surprising discovery by the EFF's Observatory that completely unrelated servers were using the same private keys without knowing it because the technology that they have is that they generate the private key themselves, and then they send the public key off to the Certificate Authority to have that signed.  Basically they generate a certificate which asserts their identity with their public key.  The Certificate Authority signs it and returns it.  So what this says is that multiple servers around the world generated the same, chose for themselves the same private key.  So the lesson to we who have a stake in using 256-bit strings for our identity, for our bitcoin wallet, for our private BitTorrent network or bit sync, is we really, really do.



And so this is a good point Stephen makes.  We really, really do need high-quality random numbers.  Probably what happened in the cases of those surprising, I mean, these are probably, what, 128-bit, well, no, I'm sorry, they're RSA keys, so they're probably 1024-bit RSA keys.  So these were probably servers that were powered up or booted and hadn't had a chance yet to acquire much entropy from the universe, from the random timings of packets, from noise that they had access to, whatever they were doing to mature their entropy pool.



We talked about that recently.  They just didn't have much time.  They probably got booted, and somebody said, "Make me a key."  And so they did the best job they could with what low relative level of entropy they had.  And sure enough, multiple servers with the same OSes, running the same key generator, running the same random number generator, started off having an entropy collision and gave the same key.



So it's definitely important.  I mean, for example, we see this in TrueCrypt, where TrueCrypt makes you move your mouse around a lot.  That's just to enhance the entropy so you're not all depending upon it from a single source.  And listeners will remember how I was talking about, in SQRL, in a mobile phone setting, I'll have you wave your phone around in the air while we're streaming video from the lens into a hash to just, I mean, to create a fabulously random pool which we mix with what entropy we get from the platform we're running on in order to get a really, really random identity for users of SQRL.  So there are certainly ways to do this.  But turning a computer on and immediately having it generate a key with a limited entropy pool is obviously not - is going to be prone to collision.  And so he's right that it is something that we need to look at.



And the second thing is I just want to mention that we're all - there's a thing that makes some people uncomfortable, when they say, yeah, but my BitTorrent Sync could collide with somebody else.  In which case then I'd be, like, I'd have the key to their network.  And my bitcoin wallet could collide, in which case I'd have somebody else's wallet.  And so the reason that this is like the new model, this is the model we're heading towards, and SQRL is the same way, is that there is no central authority.  There is no one you ask:  Does anyone else have this key?  You don't ask:  Does somebody else have my bitcoin wallet key?  You don't ask:  Does somebody else have my BitTorrent Sync key?  I mean, there is no one to ask.  It's a decentralized model.



When you sign up for email, you put your email, and many times people have signed up, like for Yahoo! email, and that's why you see names like SteveGibson327.  It's because Steve Gibson nothing through 326 were already taken.  So when you have a central authority, you're able to ask it:  Is this account name available?  And then it says:  "Oh, no, you've got to choose something else."  I mean, same thing for when people sign up for Twitter.  It's like, oh, darn, I can't use that, I can't use that, I can't use that, I can't use that.  Oh, finally, here's one I can use.



But in this next-generation, no third-party, decentralized model, what we rely on is just the vastness of the keyspace and the quality of the entropy that we're able to generate.  And so everyone doing this really needs to pay attention to entropy quality.  And really, operating systems should flatly refuse to generate entropy until they've accumulated enough to be confident that they have it.  And clearly that was not done in the past.  It's something that we're seeing now.



LEO:  So just as an example, if you have a Schlage lock on your door, there are - it's only - it's one in a million that somebody has a similar key.



STEVE:  Oh, I think it's lower than that, Leo.



LEO:  It might even be lower than that.  There's some difference of opinion on how...



STEVE:  Yeah, you get the birthday scenario.  If you have a bunch of people all trying a given lock, the chances are rather high that you'll just have a collision.



LEO:  So you should just go around trying your key and...



STEVE:  Yeah, because, I mean, look.  There's a tumbler with six pins, and they don't have that many positions each.



LEO:  Right.  So, yeah, exactly.  Probably in the hundreds of thousands, at most.



STEVE:  Oh, I'm sorry, five pins.  Five pins...



LEO:  Some have five; some have six.  Yeah.  Kwikset has five; Schlages have six, I think.  Actually both Kwikset and Schlage have five and six pin.  So...



STEVE:  And they can't have that many positions because you need to be able to tolerate key wear over time and not have them constantly going out of alignment.  And they don't.  They're pretty tolerant.



LEO:  That's why it's so easy to pick a lock.



STEVE:  Yeah.



LEO:  Moving along to Question 3, Marcus in Corona, California discusses the power of the pointer.  He's apparently been taking a course in computer programming.  But, he says, I'm somewhat dyslexic and mostly an auditory learner.  My instructor does almost no lecturing and expects us to read the book and come to class with that week's subject fully understood.  Well, what does the instructor do, then?



STEVE:  Uh-huh.



LEO:  But I was having a lot of trouble with pointers, a lot of trouble.  Yeah, this is one of the first subjects you come up against in programming that could be a little confusing.  I have been listening to Security Now! for over a year, and I always listen to the current week's episode and a few "old" ones in between.  Well, almost right on cue for my exam I happened to listen to Episode 237 - like four years ago - which is where you explained the fundamentals of programming.  Long story short, I passed the test, thanks to the podcast.  I just wanted to let you know that no matter how old Security Now! gets, its content will always be relevant.  And that goes for you and Leo, too!  Just kidding.  Hey, that's awesome.  He figured out pointers because of you.



STEVE:  So I just - this was a perfect opportunity for me to bow at the altar of the pointer.



LEO:  It's a magical thing; isn't it?



STEVE:  Oh, my goodness.  It is.  I once said - I was quoted somewhere saying that God is six levels of indirection.



LEO:  I don't know what it means, but I like it.  A pointer is one level of indirection; right?



STEVE:  Correct.  The idea is, and the thing that's confusing to new programmers, is does a variable contain the thing or a pointer to the thing?  And there's nothing to prevent it being a pointer to a pointer to the thing, or a pointer to a pointer to a pointer to the thing.  And in my programming experience, whenever I have carefully set up structures that have meaning, and the structures contain pointers to other things, and then I have a pointer to that structure, it's like, I mean, I've only ever gone, like, three levels of indirection.  That's why I say God is six.  Every time I code this way, I find myself - I just get a chill.  It's just like, wow.  It is such a powerful way of working.  And I think it's powerful because pointers are the way we humans think.  We use nouns to represent something.  That's a pointer to an object is a noun, a grammatical pointer.



LEO:  A Zen Buddhist would say the finger pointing at the moon is not the moon.



STEVE:  Correct.  Anyway, so I just - I loved his note that he understood pointers, or thanks to the podcast.  And I probably maybe swooned over them back in Episode 237, I don't remember.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  But I just posted something this morning in the SQRL development newsgroup that the next thing I will do is I'm going to write a library, now that I've got all the crypto code assembled and linked, I'll write a library for SQRL's low-level plumbing, where I pass a structure containing pointers to strings to a function.  So I'll give the function a pointer to the structure, and that will contain pointers to strings.  And, I mean, that's the way I'm going to set it up.  And it's like, it's the way you do things now.  And just it makes for such an elegant description of real-world stuff.  So I bow to the altar of pointers.



LEO:  First experience, those PEEKs and POKEs on the Atari 800.  And then pointers.  And then the next thing you've got to get is recursion.  That's even a little bit harder.



STEVE:  Ooh, yes.



LEO:  And then the thing I'm still stuck on is lambdas or closures, which are anonymous functions.  And that I just don't understand at all.



STEVE:  And the one thing...



LEO:  If I'd taken Calculus 3, maybe I would.



STEVE:  The other thing that object-oriented programming introduces - because basically what I was just describing was technically object-oriented programming. 



LEO:  That's right.  That's right, yeah.



STEVE:  But you're also - it gets kind of freaky when your structures can contain pointers to functions, not just pointers to, like, variables or strings.  But you can actually have a pointer to a function, and that can change depending upon, like, the type of value that you're...



LEO:  Now you're getting into lambdas.



STEVE:  It gets pretty heavy.



LEO:  I don't want to go to lambdas, thank you.



STEVE:  You can get lost.



LEO:  That's a nice - thank you for that.  That's a nice email.  Here's a gripe, though, a complaint from GeekWrench in Chino Hills, California:  I use NoScript religiously on my laptop.  I guess he prays every time he uses it.  I don't know.  This means that when I watch Security Now! on my laptop, most of the JavaScript is blocked.  It takes time for my old machine to load the show, so I do other things.  If I so happen to make the mistake of allowing scripts on another page, it dumps the whole show, and I have to wait for it to reload all over again.  Last week I got frustrated and never bothered to finish.  This is our fault?  Is there a way to allow NoScript in a single tab?  Oh, that's an interesting idea.  Or do I just need to continue mentally flogging Leo?  Now, you see why I have a crappy job?  Because some guy has a crappy browser in an old machine, and it dumps the - and he blames me.



STEVE:  Okay.  So, okay.  Newsflash, GeekWrench.



LEO:  He's blaming me.



STEVE:  You right-click on the NoScript icon.  And where it says "Temporarily trust TWiT.tv," right below it it says "Always trust TWiT.tv."



LEO:  Always.  Always trust us.  We're safe.



STEVE:  And that's the key.



LEO:  He doesn't want to do that, apparently.



STEVE:  No, I just think he hasn't seen that, or hasn't noticed it.  And so what happens is NoScript then remembers that you trust TWiT.tv.  And so, for example, my NoScript never bothers me because it knows I trust Amazon.  I trust Google.  I trust the various sites that require scripting that I'm a repeat visitor to.  I don't trust anything by default, but I've trained NoScript over time.  And sometimes I'll be at a site like GitHub, for example, and I'll think, eh, do I - am I - is this worth trusting?  Because I'm adding a permanent entry in a database somewhere inside of NoScript to say, oh, yeah, let's always trust GitHub.  And I can go, eh, no, I don't - I'm happy to trust it on the fly rather than permanently.  But that's a huge feature of NoScript that apparently just missed your attention.  And so I wanted to call your attention to it.  Trust TWiT.tv, and you're good to go.  No more problems.



LEO:  Somebody said TNOEL, Trust No One Except Leo.  Hey, this is going to be a holiday gift I just got from SCOTTEVEST.  You might be interested in these blackout pockets.  You can put - it has RFID, or actually it's basically...



STEVE:  Ooh, drop your cell phone in.



LEO:  ...a Faraday cage in a bag.



STEVE:  Very cool.



LEO:  Yeah.  So it blocks cell phone signals.  It blocks RFID.  So if you have a passport or a credit card, you can't be skimmed or hacked.  And so you just put this - it has Velcro on the back, so you just stick it into your SCOTTEVEST.  And they have three levels of protection.



STEVE:  There was something I saw recently, gosh, I think it was a video, or maybe it was a TV show or something, where everyone entering a conference room had to drop their phones in a box...



LEO:  Yeah, in government they do that.



STEVE:  And then the lid was closed.  And you were offline.



LEO:  Snowden did that, too.  When Greenwald went to talk to Snowden, he said, "Put your cell phone in the fridge."  Same thing.



STEVE:  Okay.  You're right.  We did talk about this, yes.  Oh, and people were saying, okay, put it in the microwave, but do not turn the microwave on.



LEO:  Yeah, because a microwave is a Faraday cage.  Otherwise the high-frequency waves would fry your brain when you peered in to see if your Hot Pocket was done.



Ari in South Africa asks a fundamental NAT question.  Network attached, no, network, no, network - never mind.  Addressable something thingamajig.  Hey, Steve.  Wait a minute.  Now I'm going to have to think of it.  Network Address Translation.  Thank you.  Please could you clarify some basic Network Address Translation concepts pertaining to what a NAT router is expected to do with IP addresses of packets it lets through outbound.  See "device bypasses NAT router" post in grc.security.  Thanks, and best regards, Ari. 



STEVE:  Okay.  So we haven't talked about NAT routing technology for a long time.  And I don't want to bore our old-timers, who are, like, rolling their eyes because it's like, oh, come on, talk about something we don't know.  But I know that we're constantly getting new people on the podcast also.  So I won't spend too much time on this.



But what NAT routers do with the IP addresses of packets they let through outbound is remember them.  And this is the whole beauty of why a NAT router is such good security.  Normally there's just junk arriving at everyone's IP address all the time.  I've coined the term IBR, Internet Background Radiation.  That's what it is.  It's Code Red bots, Nimda bots, and nonsense that are living on forever and will never go away, scanning the Internet.  There are spambots and just every kind of thing you could think of, just checking ports on your IP to see if maybe you've got that port open.



The idea is that they're all coming from random IP addresses that your router knows nothing about.  So when they arrive at the router, it looks in a table to see whether it's expecting anything from that IP address on that port.  Or, like, from that IP address, from that port, into your specific port that it's addressed to.  And if not, if there isn't a match, it just drops the packet.  The packet just dies.  I mean, it's just data arriving.  It's not like they're pointy, and they're going to, like, pierce the router or somehow work their way in.  It just ignores it.



But if you send a packet from inside your network out through the router, the router takes note of the destination IP and port and the source port that it's emitting the packet from, from its IP.  And off the packet goes out onto the Internet.  Then, when that destination sends the packet back, it'll match up with an entry.  It's left an entry in this table.  So this packet comes back amid all of the other noise that's trying to get in.  But that particular packet came from an IP address and a port, destined for a port on the router that the router expected.  So that one gets let back through.  And that's how NAT works.  It's just a fabulous fundamental firewalling technology.



LEO:  Basically it will continue a conversation started from within the network and ignore any attempts to start a conversation from without the network unless otherwise...



STEVE:  You can kind of think of it like a one-way valve that allows data and transactions outwards, but blocks anything unexpected, unsolicited, as I use the phrase all over the place, coming back in. 



LEO:  Do you have any one in particular we want to do?  Because we're kind of out of time here.



STEVE:  I think we've got a good podcast behind us.



LEO:  We covered some good stuff, yeah.



STEVE:  Yes, very much.



LEO:  And we'll leave some more questions for later.  You can always ask Steve questions at his website, GRC.com/feedback.  Do not email him.  He doesn't even - you don't...



STEVE:  I don't have email.



LEO:  He has no email.



STEVE:  I don't have it.



LEO:  He's a black hole on the Internet.  His pointer points to nothing.



STEVE:  So next week we've got a fabulous, I think everyone is going to get a big kick out of it, holiday special.  One of the first of many time capsules.  Let us know what you think because I think people are going to enjoy them a lot.  That's what'll be airing on the 25th, on Christmas, will be a blast from the past.



LEO:  Yay.  Can't wait.  That's going to be fun.  You can tweet at him.  He's @SGgrc on the Twitter.  And he may tweet back at you.



STEVE:  Yes.  And everyone knows I read them and I answer them, so...



LEO:  You're going to be sorry.  He also puts 16Kb audio versions of this show, along with those great transcriptions written by Elaine Farris, on his website, GRC.com.  Stop by there to get those and, of course, SpinRite, the world's best hard drive maintenance and recovery utility.  If you have hard drives, you ought to have SpinRite.  You can also get a lot of free stuff there, like Perfect Paper Passwords and more.  GRC.com.  We do this show, well, this is - we'll be doing it one more time at 11:00 a.m. Pacific, 2:00 p.m. Eastern time.



STEVE:  Yes.



LEO:  18:00, I'm sorry, 19:00 UTC on Wednesdays.  We're moving to Tuesday at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC.



STEVE:  Yes, starting January 7th, I think it is.



LEO:  Yeah, January 7th is the first Tuesday.



STEVE:  And that's the premiere date for...



LEO:  "Intelligence."



STEVE:  ..."Intelligence" on CBS.



LEO:  Intelligence will appear here and on CBS in an amazing coincidental dual sighting.



[Talking simultaneously]



LEO:  A collision.  What else?  If you can't watch live, though, you know we make on-demand audio and video available.  He has it in lower quality audio, 16Kb audio for the bandwidth-impaired.  We have high-quality audio, even video to watch our smiling faces at TWiT.tv/sn for Security Now!.  You can also subscribe in your favorite podcatcher.  And that way you'll get every week.  And you probably want to watch the whole set.  Collect all the episodes.



STEVE:  And, yeah.  I will just tell everyone once again, because I'm getting a surprising number of questions about this, the show notes are at GRC.com/sn, and it's the third icon over.  So click on the third icon.  You get the PDF that Leo has been reading and following along with me, and that I've been reading, of the top of the show stuff, with all the links in it that I refer to.  So that's where they are.



LEO:  Thank you for doing that.  And thank you for watching.



STEVE:  Okay, my friend.  And everybody will see me in-studio with Leo all day Christmas Eve day on December 31st.



LEO:  New Year's Eve day, yes.



STEVE:  I will be up - what am I saying.  Yes, New Year's Eve day.



LEO:  Yes.  You scared me for a moment.



STEVE:  Puttering around.



LEO:  Yeah, that'll be fun.  Looking forward to it.  Thank you, Steve.  It's always great to see you.  Have a great Christmas, and we'll see you in the new year...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2013 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#437

DATE:		January 7, 2014

TITLE:		New Year's News Catch-Up  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-437.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This first podcast of 2014 catches us up on all of the news that transpired over the Christmas and New Year's holidays - and there was a LOT of it!  (Like it or not, the NSA news just keeps on coming!)



SHOW TEASE:  It's time for Security Now!.  Steve is back.  Our first show of the new year, what are we talking about:  the NSA and the ANT protocols.  Lots of security news.  We'll catch up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 437, recorded January 7th, 2014:  New Year's News Catch-Up.



It's time for Security Now!, the show that covers your security and privacy online, your safety online, with the guy in charge, the "Explainer in Chief" we call him, Steve Gibson.  Oh, my goodness, Happy New Year, Steve.



STEVE GIBSON:  Yes, indeed.  And I was wearing my Explainer in Chief T-shirt for the day up there with you for...



LEO:  I loved that.



STEVE:  I didn't make it 24 hours.  Actually I had a lot of people asking me, "Where did you get that TNO T-shirt?"  And it was from one of our listeners.  I'm so sorry that I've, like, it was so long ago, it was a couple years ago, and I just kept the T-shirt for the right occasion.  I thought this was the right occasion.



LEO:  It was the right occasion.



STEVE:  It was someone who prints T-shirts professionally, and he just sort of sent me that as a gift to thank me for the podcast.  And many people were saying, "Oh, where did you get that?" as if maybe they want one.  So if you're still listening to us, Mr. T-Shirt Maker, tweet me or drop me a note or something.



LEO:  We should make them.



STEVE:  Certainly, yeah, it was very nice.



LEO:  It said "TNO" in big letters.



STEVE:  Big letters.  And then down along the bottom, "Except the Explainer in Chief."



LEO:  So, Steve, so we've got a lot of - it's been, like, it's only been two weeks, but it feels like a year.



STEVE:  It does.



LEO:  We've got a lot to talk about.  But first I'd say, Steve, thank you for coming up to our New Year's Party.  We did 20 - it was going to be 24 hours of 2014.  It was, like, 23 hours and 48 minutes of 2014.



STEVE:  Okay.  Yeah, I bailed at about 1:30 a.m.



LEO:  Did you?



STEVE:  Well, because it was beginning to feel like it was petering out.  And I thought, okay, don't think...



LEO:  Yeah, it was a perfect time to leave.



STEVE:  ...much more is going to happen.



LEO:  What was going on there, I think it was me, Brian Brushwood, Justin Robert Young, and Will Harris.



STEVE:  Filling time, basically.



LEO:  No, it was like standing around at the bar.  It was great.



STEVE:  Oh, okay.



LEO:  If you think of it as filling time, then that's fine.



STEVE:  Well, I didn't see it.  I didn't see it, so...



LEO:  You know what we did see, and I have footage, I don't know if I - I don't know.  I don't want to embarrass you or anything.



STEVE:  Of me with Chad's hair, navigating?



LEO:  That was fun.



STEVE:  Oh, my goodness.



LEO:  And then of course at midnight, at midnight we played in the new year.  And Steve apparently danced with Captain Kirk.



STEVE:  Well, yeah, you know...



LEO:  And you're quite the dancer.  Kirk was not very responsive. 



STEVE:  No, no.



LEO:  But you?  You know how to dance.



STEVE:  And I was sober, believe it or not.  That was - actually, I couldn't have done all of that jumping around and spinning and twirling.



LEO:  You were fired on coffee.  If you didn't - now, we're taking a lot of that New Year's Eve broadcast.  There was so much.  I went to bed that night, and you know how sometimes you kind of go over the day's events and think about them.  I couldn't.  There was so much stuff from that 24 hours.  We did so many things, including...



STEVE:  Plus, in fact, toward the end we were talking about things that had happened that morning as if they were yesterday.  I mean, it felt like it was a long time ago...



LEO:  Well, it was.



STEVE:  ...that that happened.  And it was four hours, or 12 hours, yeah.



LEO:  So, but, Steve, thank you for coming.  You showed up almost at the very beginning.  We made coffee.  So what I was about to say is there were so many things, we didn't want to just put out a 24-hour video.  So our editors, once they recover, are working on chopping it into bits.  And one of the bits will be Steve making coffee.



STEVE:  Yup, we did that, as I had promised our listeners a long time ago when I came.



LEO:  Awesome.



STEVE:  Thank you.  Yes, you did like it.



LEO:  And then you were very good as the navigation officer aboard the Starship Artemis.



STEVE:  Yes, twice.  I got the hang of it the first time, and then - or, yeah, by the end of the first time.  And then we were much better navigating the second time.  So...



LEO:  First time I was the captain.  I wasn't so good.  Then we let Justin Robert Young and Brian Brushwood captain the starship.  They were different.  A lot of shouting.



STEVE:  But that was, you know, also toward the end of the night.  And, yeah, lot of fun.



LEO:  Anyway, we decided that the event was so much fun that we're going to do it again.  In fact, I think we'll be doing it every New Year.



STEVE:  Well, and the beer tasting that you and I did, I think, was another one of...



LEO:  Wasn't that fun.



STEVE:  ...the highlights that were sort of unexpected.



LEO:  Yeah.  With Mary Jo Foley.



STEVE:  Yup.  And a number of people, that very first beer, I've seen tweets thanking us for introducing them to that sweet pink one.



LEO:  The Kriek Lambic, yeah, Lambic.  It was a cherry-flavored lambic beer that, you're right, you loved.



STEVE:  Well, it was the first one.  And I agree, after we went into the tar beers, then...



LEO:  You're not a beer drinker.



STEVE:  ...going back to the cherry was like, whoa, okay.  Wait a minute, that's a little fruity.



LEO:  It's from a Belgian brewer.  It's Lindemans Kriek, and it had cherries in it.  It was almost like a fruit punch.  So, yeah, that will be another segment we'll chop up.



STEVE:  So where will our listeners find these pieces of history, which will be preserved for all time?  Will you guys be hosting them?  Will they be on TWiT.tv?  Because Simon Zerafa, our friend of the show, commented that he was seeing them appearing on the Inside TWiT YouTube account.



LEO:  That's where they'll be appearing.  So if you go to YouTube.com/insidetwit, so far we've got three segments up.  You know what, I am not fully in control of this.  What I would like eventually is to have this chopped up even more.  But we do have, from the very beginning...



STEVE:  The first Game of Geeks...



LEO:  Yeah.  But, I mean, we have - this is an hour from the - there's three segments; okay?  So there's three chopped-up segments.  Anyway, YouTube.com/insidetwit.  I can't make the editors work too hard.  So I think what they're doing, it looks like, is an hour at a time.



STEVE:  Well, and I would - I have to tip my hat to your whole crew.  I mean, you were standing there asking them, okay, now where should I stand?  Now what's next?  I mean, because this whole day was mapped out and planned and designed by them.  And it was just fabulous.  It was an absolute success.



LEO:  I think if nothing else we've demonstrated that the studio is an amazing place; that with our very, very talented and motivated staff, we can do amazing things.  And I just look forward to doing this every - in fact...



STEVE:  And none of the champagne corks broke anything.  I was amazed.  I mean, I kept waiting.  I mean, they were violent; and, you know, there were 24 of them because we kept blowing champagne every hour.  And nothing broke.



LEO:  I think you're in Hour 3.  Yeah, here's the coffee-making.  So Hour 3 stream.



[Crosstalk]



LEO:  Because when I was out wine tasting - here we are, Steve and I, making coffee, wearing his TNO shirt.  So that's in the Hour 3 of 24, just went up on Inside Twit.



STEVE:  And you can see there that I had my six-shot venti latte in front of me.



LEO:  Oh, yeah.



STEVE:  That got me going in order to get there.



LEO:  Lesson No. 1, never try to make coffee without being caffeinated, apparently.  Heavily caffeinated.  Steve's...



STEVE:  That's called "booting," booting your coffee process.



LEO:  So what you're saying is this is your firmware, and...



STEVE:  That's my BIOS.  That's my BIOS, baby.



LEO:  The other thing I wanted to mention is last week's episode, which, if you didn't see, do go see.  It's a video episode.



STEVE:  Oh.  You're talking about the holiday episode.



LEO:  Yeah, yeah.



STEVE:  Yes.  Again, fabulous feedback.  Every - I've never - I hear nothing negative.  Everyone who did say something absolutely loved our blast from the past, the so-called "time capsule episode" that was for you and me meeting the first time in the flesh, 15 years ago.  And the shows from ZDTV, the commercials, a lot of them I left in just to sort of set the tenor...



LEO:  That's kind of fun, isn't it?



STEVE:  ...of the time.  Yeah.  And talking about backing up hard drives to VHS tapes.  It's like, okay.



LEO:  Yeah.  That was a good idea - then. 



STEVE:  Yeah.  So...



LEO:  I don't know, if you had those VHS tapes today, I don't think they'd be worth anything, but...



STEVE:  I do have the one - I used to drive your production crew in those days crazy.  I would, you know, I'd fly up on my own dime and be there and do the shows with you.  All I asked for in return was the video.



LEO:  Fair enough.



STEVE:  I didn't know why, but that's what I asked for.  Even when, years later, we were doing it in Toronto and then in Vancouver, I just said, you know - and I'd sort of just politely remind them with email, uh, can you send those tapes?  And I'd get four a month.  And so I've got all of them.  So...



LEO:  That's awesome.



STEVE:  ...we'll have plenty of time capsule episodes in the future.



LEO:  That's great.  But we do have some catching up to do because...



STEVE:  Oh, my lord, yes.



LEO:  What's surprising is normally in tech news nothing happens during the holiday break.  But bad guys never rest.



STEVE:  Oh, well, and it's funny, too, because - okay, so as I have been doing, "Today on Security Now!":  New Year's Eve at the Brick House, which we've already covered.  2013 was certainly not the end of annoying NSA news, not by a long shot.  In fact, we have truly unsettling NSA news.



LEO:  Oh, boy.



STEVE:  It turns out that routers, many routers, are quietly listening on port 32764.  We'll discuss that.  We've got a note about Mozilla's screaming native code operation progress; Snapchat's massive 4.6 million username and phone number disclosure, involuntary disclosure; and even my long-awaited sci-fi reading guide and much more.  So a ton of fun stuff to talk about.



LEO:  We will begin the New Year, Security Now!, our 437th episode, in just a moment.  By the way, our new time, too.  So if you tuned in Wednesday to watch, and we weren't there, that's because we're on Tuesdays now, and not at 11:00 a.m. anymore, but 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC.  We do love you to watch live.  That's my preferred thing because you can interact.  I can watch the chatroom and so forth.  But if you cannot, fear not, because of course on-demand's always available after the fact.



STEVE:  And you know, I'm glad you mentioned the chatroom because they were so neat during the New Year's Eve event.  And I wanted to make sure that people who are in the chatroom understand the degree to which everybody there is dependent...



LEO:  Oh, yeah. 



STEVE:  ...on the chatroom.  And you know that because, as I was, someone standing basically anywhere you are in the TWiT Brick House, there is a screen monitoring real-time chat somewhere.



LEO:  Oh, yes.



STEVE:  All you have to do, you can just look anywhere you are, and there is a scroll happening with what people are saying.  I mean, so it really does, like, connect us in and make it an interactive process.



LEO:  Yeah, you probably don't realize that if you're not in the studio.



STEVE:  Exactly.  That's why I want to make it really clear to people.



LEO:  You don't watch the chatroom while you're doing your show because you're focused on what you're talking about.



STEVE:  Oh, I just couldn't get it.  Yeah, no, it would distract me like crazy.



LEO:  Well, it's a skill I've learned.  In fact, so much so that I can't do it without the chatroom.  I don't know if people know this.  We don't usually talk about when we're DDoSed, but we did get DDoSed during the show, during - I can't remember what it was.  But during one of the shows, maybe it was TNT.  And Sarah Lane and I, both who live on the chatroom all the time, the chatroom was down, and we were both thrown.  And Sarah said, "Where's the chatroom?"  And I said, "It's down, just ignore it."  And it's funny, it's like if you've been doing a Broadway show in front of a sold-out crowd for years, and then suddenly there's no one in the theater.  It's weird.  So, yeah, that's why the chatroom kept dropping connections.  Occasionally this does happen, we get DDoSed.  But we have DDoS protection.  We flipped the switch, and it was fine.  I'm not sure what was going on.



STEVE:  I just wanted everyone to know that, I mean, it's a crucial part of the operation there.



LEO:  Absolutely.  We adore it.  We adore it.  Let's get to the security news.  There's quite a bit of it.  Leo Laporte, Steve Gibson, Security Now! on the air.  Let's catch up.  What did we miss last week?



STEVE:  Okay.  So, many of our listeners were concerned when I said at the end of 2013 that we would not turn this into the NSA Now! podcast.  And so I got a lot of this through Twitter.  And so I was tweeting back, no, don't worry.  If stuff continues to happen, we'll absolutely cover it.  Well, boy.  So first of all, don't anyone worry.  In fact, next week is just going to be a deep dive into one of the stories I'm going to discuss this week, but kind of cover the surface of it because there is so much there, I just haven't had time, I haven't set aside the amount of time I'm going to need to give it the kind of coverage I want.



But first, what has to be the most disturbing news of both the old and the new year was something that came to light through a Reuters story and surprised everyone, that RSA, the famous cryptographic research and cryptography commercializing company, founded by serious academic cryptographers who developed a lot of these technologies, accepted $10 million from the NSA in order to set that weak pseudorandom number generator as the default, we believe.  That's what this Reuters story alleges.  Which is to say - now, okay.  To remind people a little bit, there was a set of four pseudorandom number generators that the National Institutes of Standards and Technology (NIST) was establishing as standards.  People could use them, and they were saying they generated really good random numbers.



So when we've covered this, as we did in 2013, and in fact even before that, when the first concerns about this so-called "dual elliptic curve deterministic random bit generator" came out, I was the one who said, "Don't worry about this.  Nobody in their right mind would use this one."  There were four, and this was the weirdest and slowest of them.  Even if we didn't know that it had been potentially and apparently compromised by the NSA, you don't want a slow random number generator that's no better than the faster ones.



And so I was thinking no one would use it.  So it's like, okay, so it's there, and maybe it's been corrupted by dark forces, but who cares.  Well, it turns out we then learned it was the default, which, like, okay, that's - you know.  And then on the podcast before, last year, I was saying, well, these are smart cryptographers.  Why is it the default?  How do you explain that that's the default?



And then the other shoe dropped.  And while $10 million may not seem like a lot of money, the year that it was paid, that was one third of RSA's annual revenue.  And there's a lot of expenses that go against revenue.  This was expense-free.  They had to set a bit somewhere in order to have that be the default random number generator that you get when you use their BSAFE library.  And I haven't mentioned this or shown this before, Leo.  But I own the BSAFE library.



LEO:  Oh.  Oh.



STEVE:  I mean, this is it.  I mean, this was the standard of cryptography at the time.  I purchased it years ago.  And in fact the copyright on this copy is 1992.  I looked this morning, yep, copyright 1992.



LEO:  So that predates this arrangement.



STEVE:  Exactly.  And here on the page of random number generators, they only have two, and they are hash-based pseudorandom number generators.  So that's before all of this happened, and it was pure then.  Subsequently, here is a page from release notes of RSA BSAFE.  This particular version of BSAFE is called Share for C/C++ 1.1.  And in the release notes, the very first item under Content says New Features, and the second item is Changes.  And on Page 2, which is where we get Changes and New Features, the very first item under Changes says:  "The changes in this release of Share for C include" - the first one - "all random numbers generated for use in Share for C are generated by the dual elliptic curve (EC) deterministic random bit generator (DRBG) using the P-256 prime curve."  And it says, "(128-bit security strength by default)."  So that is exactly, I mean, this is, and this is dated 15th of September, 2009.



LEO:  Oh, man.



STEVE:  So that's, I mean, that was the page from the release notes showing the change when this happened about five years ago.  So the wording of this in the article I thought was really perfect.  So I'm just going to share this.  This is exactly as Reuters wrote it.  They said:  "An algorithm called Dual Elliptic Curve, developed inside the NSA, was on the road to approval by the National Institutes of Standards and Technology (NIST) as one of four acceptable methods for generating random numbers. NIST's blessing is required for many products sold to the government and often sets a broader de facto standard," meaning within the entire computer industry, which certainly is the case.



"RSA adopted the Dual_EC_DRBG algorithm even before NIST approved it.  According to an official familiar with the proceedings, the NSA then cited the early use of Dual Elliptic Curve [PRNG] inside the government to argue successfully for NIST approval.  RSA's contract" - that is, this one for which they received $10 million - "made Dual Elliptic Curve the default option for producing random numbers in the RSA toolkit.  No alarms were raised, former employees said, because the deal was handled by business leaders rather than the technologists.  'The labs group had played a very intricate role at BSAFE, and they were basically gone,' said labs veteran Michael Wenocur, who left in 1999.  Within a year, major questions were raised about Dual Elliptic Curve.  Cryptography authority Bruce Schneier wrote that the weaknesses in the formula 'can only be described as a back door.'"



So what we have is sort of a classic bureaucratic bureaucracy management where the technologists weren't involved, whereby paying RSA to make it the default in their package.  After BSAFE was then in use, and it wasn't yet approved, the NSA got it approved, got the NIST to approve it because it was in use.  And it was in use only because RSA had been paid $10 million to put it in use.  So, I mean, it's stomach-turning.



LEO:  Wow, yeah.



STEVE:  Yeah.  And I want to draw some contrasts here because we're going to be talking about the Der Spiegel article here in a minute, and the amazing revelations there.  This is of concern because what we believe is that this then widely used package became the core random number generator, like throughout the industry, and that the NSA had unique knowledge of RSA's documentation, and they believed I'm sure that it gave 128 bits of strength.  It is probably not 128 bits strong if you know the way in which it's biased.  And it's probably been biased deliberately.



I mean, there was really no evidence, even as suspicious as we were of it, there was no concrete evidence.  But the fact that it's the slower of the four - and the other three are based on sound technology.  They're based on hashing, or they're based on a good cipher.  Running a cipher, using a cipher with a key to generate pseudorandom data is absolutely an acceptable, bulletproof way of generating that data.  If the cipher is good, the pseudorandom data will be good, too.  Similarly, running a hash in a cycle where the output goes back into the input, if the hash is a good hash, you're going to get out really good pseudorandom numbers.  Or if you want to key it, you use an HMAC, which is basically a means of mixing a key in with the hash and, again, putting in data that will come out pseudorandomly.  Those are all recognized strong techniques.



And then out of right field comes this thing that the NSA designed and wants added, and then arranges to make the default, even though it's unproven and improvably secure, where the other ones are, and the slowest of all of them.  So, I mean, if we didn't have enough reason already to be suspicious, the fact is that now we get this report from a very reputable source.  And people have since been interviewed, and they've said, yeah, uh, yeah.



LEO:  Yeah?  Yeah?  Yeah?



STEVE:  And RSA's conference is coming up at the end of February, the annual 2014 RSA Security Conference.



LEO:  Oh, that's going to be interesting.



STEVE:  Well, several major speakers have dropped out in protest.



LEO:  This is so damaging.



STEVE:  I know.



LEO:  True or not.  And I think it probably is true.  But true or not, this is so damaging to U.S. interests.



STEVE:  Yeah.  Yeah, well, wait till we get to damaging to U.S. interests.  That's our next story.  I will note, however, for anyone who's attending, don't leave the conference early because he'll probably be pretty funny.  Stephen Colbert has been confirmed as the closing keynote of the conference.  And so lord knows what he's going to do.



LEO:  It's all showbiz now.



STEVE:  I hope the RSA knows what he's going to do.  Yikes.  Sorry for a little noise here in the background.  We have a garbage truck is going to empty some cans.  Okay.  So, next up.  And this is what I want - I need to look at this more closely than I have been able to, and I will do it for next week because it fascinates me, and we can't do it justice along with everything else we have to talk about this week.  So this is the tease, the setup, essentially, for next week's episode.  And this is the so-called ANT division of NSA, whose catalog of exploits for nearly every major software and hardware and network came to light from an article in Der Spiegel.



And I tweeted this.  I guess I just tweeted the link to the catalog this morning.  As we have been doing now, this is the fifth episode where I have been posting the same show notes that you and I are reading right now, Leo, as part of the material over at GRC for the episode.  And I tweeted the link to the show notes before we began so that people who are watching in the chatroom can also read along.  I created a bit.ly shortcut for this catalog, so it's bit.ly/, all lowercase, nsa-ant [bit.ly/nsa-ant].  And this is a WordPress blog that's leaksource.wordpress.com is where that bit.ly expands to.  And it truly makes your head spin, to the extent that Bruce Schneier, who has also not been happy as a consequence of the Snowden links and everything that has come from it, Bruce is now doing a blog post a day to take each of these on in turn.



So to give our listeners a sense for it now, what this page describes, what it contains is a series of image slides from this catalog which lists dates when the exploits are becoming available, what versions they're in, how much they cost.  Some of these are $30.  If you just want a cable that allows you to spy on the video information going by, that's 30 bucks.  If you want your own GSM cell tower, that'll be $40,000.  But you can order one if you're an NSA division that needs that, and they've got one.  So these all go by two-word concatenated code names like DeityBounce, or IronChef, or FeedThrough, GourmetTrough, HalluxWater, JetPlow, SouffleTrough, HeadWater, SchoolMontana, SierraMontana, StuccoMontana.  They were happy with these Montanas there for a while.



LEO:  They like Montana.



STEVE:  Yeah, the CTX4000 is a model number of - I think that might be the cell tower or something.  It's data collection.



LEO:  As Schneier points out in this, though, these are all retail attacks.  They're targeted attacks; right?



STEVE:  Yes.  And so that's - so let me get through this really quickly.  So LoadAuto, NightStand, NightWatch, PhotoAnglo, Sparrow II, TawdryYard, Ginsu, HowlerMonkey, IrateMonk, JuniorMint, I mean, some of these are going to go down in history.  Maestro-II, SoberKnave, Swap, Trinity, WistfulToll, SurlySpawn, DropoutJeep - and we're going to cover that specifically in a second because that's about iPhones and generated a lot of news over the holidays.  GopherSet, MonkeyCalendar, Picasso, ToteChaser, ToteGhostly 2.0, CandyGram, CrossBeam, Cyclone Hx9, EBSR, Entourage, Genesis, Nebula, Typhon HX, WaterWitch, CottonMouth I, II, and III...



LEO:  I can't keep up.



STEVE:  ...FireWalk and RageMaster.  I mean, and this is, I mean, it sounds like a joke, but it appears absolutely authentic.  And we skimmed over that.  But the reason I need to give it a podcast, our listeners will understand next week when I do because there is a disturbing level of detail specified about each of these, what they do and how they work.  And what I want to get from studying this, and what I want to share, is sort of the overall gestalt, the mindset; and, stepping back a bit from it, what lessons does this teach us.  But what's worth mentioning, Leo, you started into, which is I consider this very different from a deliberate attempt to weaken a random number generator that the entire industry and world uses.  And as you said, this is targeted.



This is the NSA wants to penetrate a BigIron Juniper router, and one of these projects allows a division to purchase that technology, or sometimes it doesn't cost anything, to acquire that from this division of the NSA that designs penetration technology.  And again, remember that these are exploits for nearly every major hardware and software package.  All the router technologies, all, I mean, like the stuff we use all the time.  There are fake cell towers, cell tower technologies in a package that the NSA can set up when they want a bad guy's phone to connect to them rather than a real tower.



There's no evidence of collusion on the part of the companies whose material has been hacked.  And more and more, I mean, with the exception of the government letters which go to companies which prohibit them from mentioning that they've received one, but which specifically requests data in a certain case, it really, I mean, it is looking like these companies are really taking the brunt of the damage because, even though no one now thinks that they were complicit in this, it's looking like the NSA has really strong hackers who are able to dig right through secure firewalls.



So, I mean, one of the things we see often is BIOS-level attack.  And so many of these, as I was scrolling through, generating that list, I was seeing essentially the same graphic, with small variations, recurring.  And it looks like - and I'll have an absolute grip on this and grasp of it next week - that one of the things the NSA likes to do is get in and modify firmware.  That seems to be one of their approaches is they will launch a targeted attack at a person, and that person will execute code which gets under the OS, down to the motherboard, makes some changes in the firmware, and then that enables a persistent - gives the NSA persistent access to that platform.



But the point I didn't finish making was that modifying a random number generator that everybody uses is really wrong in every way.  I mean, it just - that's upsetting.  The idea that the NSA probably had this was something we all probably thought.  I was never imagining that the NSA was paying RSA $10 million to give the entire world crappy random numbers in a way that they could leverage.



But the idea that there was a division like ANT, the ANT division, that was cooking these other really cool penetration technologies up, that's what we hoped, that's how we hoped our dollars were being spent because they are targeted.  They're not blanket monitoring everyone's telephone metadata in the world.  It's we think this guy is bad; we need to get in and monitor him.



So next week I'm going to break all of those acronyms down, not individually because there's too many of them, but  it's not really necessary.  I want to be able to explain to our audience what the NSA wishes we didn't know, which is exactly what this means.  What does this mean, essentially, that they're able to do this?  And what are they able to do, based on the catalog that is now in public view?  But one of those stood out over the holidays, and that was called DropoutJeep.  And the question arose, does the NSA have total iPhone access?  And it looks like at one point they did.  We don't know where they are today.



LEO:  That's one thing to mention on all these slides, is they're old.  And DropoutJeep is 2008, the second iPhone.



STEVE:  Yes.  It came out a year after the initial introduction of the iPhone.  And remember that another thing we talked about is we know that there are baseband processor vulnerabilities.  That's not the ARM7 that Apple is using.  That's some component which is actually probably a Snapdragon or some Qualcomm chip because Qualcomm was big into cellular technology.  And so it's, like, in charge of all the cellular communications.  The ARM7 processor is, like, making icons look pretty.  It's all eyewash and GUI stuff, and it's what all of the iOS apps run on.  Whereas this Qualcomm or Snapdragon processor, that's the so-called "baseband" processor, and we talked about that a few episodes back, which no one really pays attention to, and the NSA is probably glad because that's very likely their way in is through this aspect that we're just not looking at where everyone's worrying about, oh, is my 16GB encrypted when I type my four-digit passcode, and the NSA's going, uh-huh, good luck with that.  We're not worried about that.



So what we know is the NSA had worked on software that would allow it to remotely retrieve, and this is from the reporting over the holidays, virtually all the information on an iPhone, including text messages, photos, contacts, location, voicemail, and live calls.  So the slide, of these many for DropoutJeep, says - and here you get a sense for the jargonism of the NSA.  It's a StraitBizarre, that's another concatenated pair of words, S-t-r-a-i-t, StraitBizarre - that's a noun, apparently, in this jargon - based software implant - and that's a word we see, the NSA uses the term "implant" for this kind of exploit - for the Apple iPhone - and I'm reading from the slide - operating system, and uses the ChimneyPool framework.  DropoutJeep is compliant with the FreeFlow project.  Isn't that nice.  Therefore, it is supported in the Turbulence architecture.



And so we have a block diagram, six blocks connected in a circle so that they're chasing their tail.  It starts with the NSA ROC Operator.  Then that has an arrow pointing to the Load Specified Module, which then goes to Send Data Request, which then links to iPhone Accepts the Request, and then Retrieves Requested SIGINT Data, and that points to Encrypt and Send Exfil Data.  We know that that's exfiltration, meaning out.  And then that returns, the final arrow returns us back to NSA ROC Operator.



So what that is saying is that, once an iPhone has had this implanted in it, the DropoutJeep StraitBizarre implanted in it, then in real-time the NSA ROC operator can query that iPhone over its communications protocol for whatever they want.  And so below this diagram it says "DropoutJeep is a software implant for the Apple iPhone that uses modular mission applications to provide specific SIGINT functionality.  This functionality includes the ability to remotely push/pull files from the device.  SMS retrieval, contact list retrieval, voicemail, geolocation, hot mic, camera capture, cell tower location, et cetera.  Command, control, and data exfiltration can occur over SMS messaging" - okay, slowly - "or a GPRS data connection.  All communications with the implant will be covert and encrypted."  Don't we wish our own communications with an iPhone were.



"The initial release of DropoutJeep will focus on installing the implant via close access methods.  A remote installation capability will be pursued for a future release."  So that's what we know.  I mean, that gives you a sample, a feeling of one of those incredible number of exploits that are available in the catalog.



LEO:  But because it's old, that's a snapshot of what they could do in 2008.  I mean, presumably they're keeping this stuff up to date and can do more, and work with more modern operating systems, et cetera.



STEVE:  Yeah.  Yeah.  And, I mean, if we've learned anything over the years that we've been looking closely at security on the podcast, it's that very complex software, and unfortunately all of our software today is very complex, has bugs.  I mean, it's not yet the second Tuesday of the month.  That'll be - or is it?  No, it's not.  That'll be next Tuesday.  And Microsoft will roll out their bugs du month for us at that point.  And, I mean, there's never been a month without them.



And all the other software products that are really complex have problems.  So if you have enough money, and you are sufficiently motivated, really it's hard to argue that there isn't a way in.  And so basically this is the quiver of arrows that the NSA has created for themselves and, as you said, Leo, even though these are old, has doubtless been creating even more frantically recently as the ante has been upped on this and as they've been able to obtain more money and budgets and more technology.  And look at the center that they're building down there in Utah for this.  So, yeah.  Wow.



Another little bit of news came up, and that was - it sort of put me in mind of the question, when is a power light not a power light?  And the answer is when it is separately controlled by firmware.



LEO:  I know where you're going with this one.



STEVE:  Yeah.



LEO:  Didn't we have this discussion when we first talked about the idea of taking over webcams?



STEVE:  Yes.



LEO:  Could you do that without tripping the red light?



STEVE:  Exactly.  And of course my advice, which has stood the test of time, is put a sticker over it.



LEO:  It think it will continue to stand the test of time.



STEVE:  Yeah.  I mean, it's still not the case, from what I've seen, that laptops have a mechanical shutter.  But they absolutely should.



LEO:  Some do.  They're starting to do that, yeah.



STEVE:  Oh, good.  Good, good, good, good.  They absolutely should.  I was going to mention the laser that I own, the very high-power laser, which has triple interlock, as law requires.  And one of them is a delay.  When you press the button to turn it on, there's a legally enforced delay before it engages.  It also requires a key, separately from the button, a key switch that must be engaged.  And law requires a physical shutter over the front.  And this is why.  I mean, obviously, if that shutter is closed, doesn't matter what happens electrically, you've blocked it.  You've blocked the photons.  And what you want is a reliable photon blocker, folks.  You do not want to trust, unfortunately, the technology.



So here's what came to light.  It turns out that it is possible, sadly, but hardly surprisingly, to turn on webcams and the cameras on devices.  And again, we presume that any device with a light, maybe it can be controlled separately.  Wired.co.uk had an interesting article, actually it was late last year, but I liked their description so I want to share it.  It's perfect, and we'll discuss it a little bit more.  It says:  "One signal wire line" - and this is the actual design, and I think this was an early MacBook.  Yeah, I'm sure it was a MacBook.  "One signal wire line joins the USB interface chip to an input on the imaging sensor" - and that line is called "standby," or that input is called "standby."  "When the line is held high by the interface chip, the sensor is put into standby mode and thus stops producing data.  When [that line is] held low, the sensor is taken out of standby mode and starts [streaming] data.  The same line is also wired to the negative side of an LED."



And actually that's just what you want.  So the positive side of the LED is connected probably through a resistor to 5 volts.  The negative side is connected to this wire.  So when that line is high, it'll be the same.  The negative side to the LED is at the same voltage as the positive side.  Thus the light is off, and the imaging chip is off because it's getting the high, standby-enabled signal.  When that line is pulled low, then the imaging sensor is taken out of standby.  And now the LED has voltage across it, probably 5 volts, because the bottom of it is being held at ground, held low, so the LED is on.  And now, okay, that sounds great; right?  So that whenever the sensor is taken out of standby, the LED is going to be turned on.  So in principle this should serve as a hardware interlock.



Unfortunately, the whole system is controlled by a layer of software.  When the device driver for the camera is loaded, the host PC uploads a small program into the USB controller.  It doesn't have any permanent firmware storage of its own.  So it needs to be loaded every time the camera driver is loaded, whenever the machine is turned on.  This small program, in turn, configures the imaging chip.  The imaging chip doesn't have too many configurable properties.  But one thing it does have is whether or not it pays any attention at all to the standby input.



LEO:  Why would it pay any attention?



STEVE:  So you can disable, in software, the standby input, then not bother bringing it down to take it out of standby;  and thus, turning the light on, leave it up as if it's in standby mode, thus suppressing the LED.  Yet, if you've changed the firmware associated with the driver, you're streaming data anyway.



So the Wired.co.uk article continues, saying:  "Apple's own drivers set a configuration where standby is respected.  But other configurations are possible, such as one where the chip ignores standby entirely and always produces image data.  With this knowledge in hand, the researchers" - the researchers this article is citing - "wrote a new piece of software to upload to the webcam.  This piece of software was much like the normal webcam software, but with two differences:  First, it told the imaging sensor to ignore the standby input; second, it ensured that the standby line was always held high to prevent the LED from ever illuminating.  Result:  a webcam with a hardwired LED indicator that nonetheless allowed image capture without the indicator LED ever illuminating."



LEO:  So I have to tape everything over now.



STEVE:  We really do.  I mean, that is, again, as I said, the original advice stands.  You just, I mean, and why not?  I mean, unless you're really using your camera all the time, just put a Post-it note over it.  Jenny got freaked out because she got some junk, some malware on her laptop, and it was that one that - it was extortionware that said, oh, it alleged to be from the FBI.  And because this was your first offense, you could send them money, and then they would let you off the hook.



LEO:  Yeah.  She's not running a Mac?



STEVE:  No, she's still - she's a Windows person.  I have asked her about that because I think a Mac would make a lot of sense for her, too.  But this also - so it showed some really distasteful images of child pornography which it said it found on...



LEO:  What?



STEVE:  Oh, yeah.



LEO:  That's a new thing.  That's disgusting.



STEVE:  Yes, it alleged that it had found on her computer, and of course it didn't.  But it also showed a picture of her, sitting in front of her laptop.  So this thing had used her camera in order to snap a picture of her, to increase the credibility and horror factor of this.  And so anyway, just putting a Post-it note, a little piece, just a little one-quarter by one-quarter, just snip off the sticky end of a Post-it note and just stick it over the hole.  And it peels off easily, if you ever want to use the camera.  But just leave it there, and every time you see it you can just sort of smile to yourself and say, yup, nobody's looking at me.  Have to do it.



LEO:  Wow.



STEVE:  So 32764, Leo.



LEO:  32764.



STEVE:  Yes.  Now, I know that you are thinking, ah, that's the zip code of Deltona and Osteen, Florida.



LEO:  Oh, of course.



STEVE:  And you would be correct.  But it's not what we're talking...



LEO:  There's more to it than that?



STEVE:  It turns out it can also be a port number because it's in the range between 0 and 65536, as actually are many zip codes.  32764 is interesting to me because, being Mr. Binary, we all know 32768 is an even power of 2.  It is 2^15 is 32768.  So this is four less than exactly midway in the port range.  So it's like it's four below the exact centerline of ports 0 through 65535.  A well-known hacker named Eloi Vanderbeken posted a note on GitHub when he discovered that his Linksys WAG200G wireless DSL gateway was, for no reason he knew, listening and accepting TCP connections on that port.  There's no purpose for it, no reason for it.  He then discovered that this was also true of Linksys, Netgear, Cisco, and other routers.



Now, this is important, listeners.  When I first saw this, it looked like it was LAN only.  It turns out it is not LAN only.  There are at least five known routers who have this port exposed on the WAN interface of the router, meaning the public Internet:  the Cisco WAP4410N-E, with a bunch of firmware models, 2 point something something somethings; the Linksys WAG120N; the Netgear DG834B; and the Netgear DGN2000, with a bunch of firmware models; and, finally, the OpenWAG200.  There are many more routers that are exposing this mysterious port on the LAN side.  I mean, like 30 or 40, a huge list.  All you have to do to get more information is put in the zip code of Deltona and Osteen, Florida, into Google.  You put in 32764.  Just google "32764."  The first link up currently is the link to the GitHub page.  The second and third links are, not surprisingly, relating to real estate in Florida at that zip code.



So what you should do is simply use ShieldsUP! immediately, unless you know you don't have a problem.  That's what ShieldsUP! was designed for.  And I have a custom port probe as one of the many tests there.  So just go to GRC.com, navigate through ShieldsUP!.  You'll come to a dialogue with a bunch of buttons.  Put "32764," and then click "probe my port."  And actually you could do it with a URL.  I've got a direct probe port URL.  I think you just go GRC.com/portprobe=32764.



LEO:  Oh, that's nice.



STEVE:  So you can just do it that way.  And why don't you - can you try that, Leo?  I mean...



LEO:  Yeah, that's a good question.



STEVE:  I should have been a little more prepared here.



LEO:  GRC.com/portprobe=...



STEVE:  32764.



LEO:  Yes, it does.



STEVE:  Yay, it does.  There it is.  And then...



LEO:  Well, it gives you the database; right?  I mean, does it do the probe?



STEVE:  And so then click "Probe THIS Port."



LEO:  Ah.



STEVE:  And, [sound].



LEO:  [Sound] Got it.



STEVE:  That's the sound.



LEO:  That's the probe porting sound.



STEVE:  Oh, you do a /x/ and then portprobe=32764, and it'll do it.



LEO:  All right.



STEVE:  And I got a stealth on my network.  And hopefully that's what everyone gets.  Stealth or at least closed is what you want.  So GRC.com/x/portprobe=32764, and you can instantly check to make sure your router doesn't have that exposed publicly.  That's the big concern.  Now, so here's the strange thing.  Oh, and you're stealth, too, Leo.



LEO:  I am indeed, yeah.



STEVE:  So we don't know what this is for.  There's been a conjecture that it relates to a manufacturer.  And I forgot to write it down here.  I don't see it written.  There is some, like, manufacturer, like Simcom or something.  Because what happens when you connect to this port, if you have that port, with, like, telnet or just your web browser even, you can, for example, put into your web browser http:// your gateway IP, which is often your private network, typically 192.168.0.1, or maybe it's .1.1.  Anyway, so that IP, colon, 32764.  That tells your browser to connect to port 32764 of your own router.  And it'll spit out S-c-M-M, or that backwards, which is interestingly byte-swapped.  It may put out M-M-c-S.



So we will be finding out soon because I'm sure many gifted, you know, hacking router firmware is now become an art.  And so there's lots of guys who've put together router hacking toolkits where they can download the firmware; they can unzip it, unpack it, analyze it.  I'm sure soon we will find out what's going on.  This may be nothing but a benign listener that is an undocumented service that this company put in, I have no idea why.  It's not exposed to the WAN, so it's not like they could scan the Internet and find all of their own routers.



I mean, the point is we don't know if you can do more with it than this yet.  We hope it's not some evil server, and we of course hope that the NSA had nothing to do with causing this company to allocate this high, high port up in the boonies and have it listen.  If it were really going to be stealth, it wouldn't spit out this string.  So it really seems more like just sort of a wacky ID for the firmware that someone just happened to mention, or rather notice.  I'm sure we'll see disassemblies of the firmware before long, and you know that we'll cover it here.  And if any of our listeners finds a note of that, tweet it to me so that I'm sure I don't miss it, and we'll talk about that.



So in the meantime, if you do have that port open, exposed, and in ShieldsUP! the port probe will say open if it is, what you can - the suggested workaround is to manually put in a firewall rule to block that port for the WAN side.  Having it on the LAN side, that's kind of creepy, too.  We don't know what it does.  We don't know what power it may have.  It may accept commands and other things, and if you don't give it one, that's when it spits out the little ID string.  We just don't know yet.



But putting firewall rules in and then of course retesting will allow you to immediately shut that down so that whatever it is, you don't want it.  I would not call it a beneficial feature of the router that it does this.  But it is, if you, again, google 32764, check out that GitHub posting because there is a growing list of known compromised routers.  And, I mean, it's a big list.  So whatever this company is that may have been the original progenitor of the firmware, they put a little cookie in there that we're not all happy about now.  It certainly raises some questions.



Okay.  We knew this was going to happen, and it's right on cue.  We have three CryptoLocker follow-ons that have been identified.  Initially there was something that was actually calling itself CryptoLocker 2.  So the question raised was, well, is this an improvement of CryptoLocker, or is this actually something different?  So it has now been analyzed.  It's been a few weeks now.  It's been analyzed in detail.  Whereas CryptoLocker v1 uses 2048-bit RSA public key encryption for its unbreakable work, v2 claims to use 4096, but oddly actually uses only 1024.  So that's strange.



Also, v1 was written in C++, whereas v2 is written in C#.  Very different languages, even though they both start with C.  Version 1 accepts payment in Bitcoin, MoneyPal, Ukash, and CashU; whereas v2, Bitcoin only.  Version 1 doesn't encrypt images, videos, and music files; whereas v2 does.  So that seems a little more personal attack.  Version 1 uses AES, the Rijndael cipher; whereas v2 uses 3DES.



We talked about the file header a couple weeks ago where, after the file is encrypted, the pseudorandom key which was obtained from the OS and then encrypted using the private key or public key - no, I guess it would be the private key obtained from the remote server.  That's appended to the front of the file to create a new header.  That's v1.  Version 2 does something different.  It creates, for every file it encrypts, it creates that same filename.k key file.  So it makes a whole bunch of more files containing the decryption keys required, but those keys are encrypted so that you still need to pay somebody.  And then also v2 contains a bunch of weird, fake, like, software activators and cracks for commercial software, e.g., an activator for Windows 7 and 8; an activator for Office 2013; one for Team Viewer; something for Adobe's Photoshop; and even ESET's Smart Security software.  And ESET performed this analysis.



So that sort of says, okay, that they intend to, like, salt the Internet with fake Windows 7 activators - cracks, essentially, for Windows - and get people to download them and run them in order to get themselves infected with this.  Which was nowhere in v1.  So the conclusion is we have a completely independently authored, but lookalike, because, I mean, that was what caused the confusion is that the dialogue boxes are very much the same.  So the v2 people, the CryptoLocker 2, completely implemented their own from scratch, yet emulated the look of the original CryptoLocker.  So that's one of the first, that's one of the three new ones.



There's also been found in some discussion forums discussion of something called in some places PrisonLocker, and elsewhere PowerLocker.  And it apparently is not out yet.  The concern is that the author whose forum postings have been quoted says he's intending to sell this as, like, a ready-to-go kit for $100, which is a little confusing because we've seen the numbers that CryptoLocker's evil people produced using this.  And, I mean, it was in the hundreds of thousands of dollars.  So there's also a comment where the guy says, because I read all of this forum stuff to get some sense for who he was, that this is his first C code.



LEO:  Wow.



STEVE:  And there is a lot of, like, okay, in Windows, how do I make a window stay on top, and how do I prevent them from switching away from the window?  So there's also mention of MASM elsewhere.  So it sounds like he's a lower-level coder.



LEO:  Assembly language programmer.



STEVE:  Assembly language coder, yeah, I mean, this is - and to do most of this you certainly, well, we know I would use assembler, but I wouldn't ever write a program like this.  But it sounds like that's what he's doing.  And now he's, like, learning the GUI stuff.  Oh, in fact, he said this is his first C program, and he farmed out the production of the graphical user interface to someone else, and he's going to give him a piece of the action that this thing generates.  So that's apparently really happening.



Now, what's really weird is that - and this may never get off the ground.  As far as we know, it hasn't yet.  But if we're to take the research that's been done from his postings on face value, his ICQ handle, his long string, has leaked.  And he appears to be a 23-year-old Pisces named David Klukinski.  So, David...



LEO:  What's your sign, David?



STEVE:  Yeah, you're a Pisces.  Good luck to you.  Yeah, he was born on March 3rd.  So if we've already figured out who you are, maybe you ought to abort this whole effort before you really get yourself into deep trouble.



And then, completely independently, No. 3 was reported by TheRegister.co.uk.  And this is something called Locker, just Locker.  It has been found already in the wild, so it exists, written in Delphi, which we remember is Borland's sort of Pascal outgrowth language.  And I think that went - did it go open source and public?  I think maybe it did.



LEO:  Turbo Pascal?



STEVE:  Well, Delphi.



LEO:  Delphi, oh.  I don't know.  You know who would know?  Paul Thurrott.



STEVE:  Yeah, he would.  Anyway, so...



LEO:  Yeah.  I think it's ColdFusion now, is what I think.



STEVE:  Okay.  The Register reported that it was written in Delphi using the TurboPower LockBox crypto library to encrypt files in AES-CTR mode.  But apparently it wasn't done very well, and it is possible, without payment, for smart engineers to decrypt the files.  So I imagine that'll get fixed, now that The Register's reported it.



So unfortunately, this was inevitable.  Essentially we've entered a new era.  And I don't know why we're going to go back because this could have been done 10 years ago.  And it's been nice that we had 10 years without it being done.  But with the money that CryptoLocker made, and we already said this on the podcast months ago, you know, get ready, folks, this is coming.  Because why wouldn't other malware authors decide, hey.  Oh, look, here's a crypto library.  Oh, look, here's crypto open source.  I mean, crypto is done.  Unbreakable crypto is freely available in every language now.  And so it was just a matter of time before it would get leveraged in this fashion.  And that time has arrived, unfortunately.



LEO:  Yeah, wow.



STEVE:  Now, also in the news was a massive leak, and embarrassing for Snapchat, of 4.6 million users' usernames and phone numbers of their mobile devices.  Snapchat has not performed admirably, unfortunately, in this.  They were warned back last June or July, so about five months, at least, ago about this, and they did nothing.  They didn't respond to the guys who found it.  And I have to mention, the guys who found it, unfortunately, have decided to call themselves Gibson Security.



LEO:  Now, yeah.  Well, I mean, I don't know.  They're not naming themselves that for you.



STEVE:  No.  And I know in fact now for sure that it's after "hacking the Gibson," that phrase from the classic cult movie "Hackers" with Angelina Jolie.



LEO:  But it is confusing.



STEVE:  Well, not only that, Leo.  I was bombarded by the press on Monday, all wanting to know more.  And so I...



LEO:  They googled "security" and "Gibson," and they found you, yeah.



STEVE:  Yes, yes, yes.  And, I mean, so these guys, it's GibsonSec.org, G-i-b-s-o-n-S-e-c dot org.  And many Twitter followers of mine were similarly confused because they were saying, "Bravo, posting the API."  And it's like...



LEO:  Oh, geez.



STEVE:  ...whoa, whoa, whoa, whoa.  That wasn't me, folks.  So no relationship whatsoever.  They're in Australia.  But I have to say, having now studied their postings, they seem like neat guys.  They are asking for donations, calling themselves, like, starving students or something.  But I just - I like their style.  I like the way they write, the way they think.  So they're not part of GRC in any way, but they seem like good folks.



So, okay.  Snapchat.  What Snapchat has done [exasperated sound], I mean, it is just - it is so - whoever did this should just be embarrassed because they were entirely relying on obfuscation, on no one looking closely.  And we know how well that works.  So these guys, the Gibson Security folks in Australia, completely reverse-engineered the Snapchat API and laid it all out.  Now, and this is only after they waited five months after telling Snapchat, you know, this is really bad.  This is really dumb.  And there's all kinds of things, bad things about this.  I mean, it's hard to even enumerate them.  And Snapchat blew them off, didn't respond, changed nothing.



And so then these guys just said, okay, here's the API.  And a different party, not the Gibson Security guys, a different party leveraged the information that the Gibson Security folks published to produce this 4.6 million user database.  And it's trivial to do.  I mean, with the information that's now publicly available, not a problem.  So to give you a sense, our listeners are savvy enough, and anyone who's followed the podcast for long will be able to follow this.  This gives you a sense for how poorly implemented their security is.  There are some magic numbers that cannot be well hidden.  There's a secret, a so-called secret that never changes:  iEk21fuwZ blah blah blah.  It's a pseudorandom string that looks like it's probably base64 converted.  And it's just there.  And then there's a so-called "pattern" of zeroes and ones:  000111011110111000 and so forth, just sounds like gibberish.  And all it is, is just a random string of zeroes and ones.



So to authenticate, what they call "authentication," is you first log into the Snapchat server, which returns a session token.  So you just - you say, hey, give me a token, and the server gives you a token.  Now, any API request you made needs to be authenticated using that token.  Except that authentication means that you take the time of day, and you hash it with the token, and you convert that to hex.  Okay?  That's hash 1.  Then you take that secret that never changes, and you hash that with the token, and you convert that to hex.  And now that's hash 2.  Then you use that pattern of ones and zeroes.  That directs you from whether you select the character from hash 1 or hash 2 in building a new string.  And that's how you authenticate.  I mean, it's like, what?



LEO:  Well, somebody said that just the whole notion of Find Friends is inherently problematic.  Right?



STEVE:  True.  Yes.  And I wanted to mention that I haven't looked closely at whether it's possible to make this secure.  Because exactly as you said and has been said, the idea that, I mean, the reason there is an API in there, presumably you allow Snapchat to have access to your phone book, your contacts.  And so it runs through your contacts, looking.  And essentially, through this API, it submits every phone number in your contacts list and learns from the server whether that is a Snapchat user and, if so, returns their username or allows you to connect to them and find them.



So the problem is there is no authentication, no effective authentication, no rate limiting at all.  And this is what the attackers used in order to launch this attach, is essentially they said, we'd like to log in, please, and the Snapchat server said, yeah, here you go.  And then they said, okay, now what about 0000000000?  No.  Nobody by that phone number.  How about 001?  How about 002?  How about 00 - turns out you can do easily 5,000 a minute, and that's without running parallel threads or high bandwidth or anything.  I mean, so basically Snapchat's entire, I mean, critical aspects of their database is completely wide open.



LEO:  Yeah.  By API, which is great.



STEVE:  Yes.  By an API that's now fully documented.  And, I mean, for example, I just - there's so many things that they could have done in order to make this stronger.  I mean, maybe it's, as you said, Leo, not possible to really make it stronger.  But you could certainly detect this kind of behavior and then disavow that token, and maybe remember that IP asked for that token, I mean, there are all kinds of things that...



LEO:  And they are going to rate limit going forward.



STEVE:  I hope they do.



LEO:  No, they said they would.



STEVE:  Oh, good.



LEO:  But what they're not doing is changing the API or attempting to make it more secure.  Their response to this is, well, you could turn the Find My Friends feature off, and then you won't be revealed; and we're going to rate limit.  So even if they do get some, they won't get...



STEVE:  So maybe you could turn the feature that allows you to be found...



LEO:  Yeah, that's probably it.  Yeah, yeah.



STEVE:  Okay.  That would make sense.



LEO:  In other words, take your number out of their database.



STEVE:  Right, right.  Or just...



LEO:  By default it will be in there.



STEVE:  Yeah.



LEO:  Hmm.  It's an interesting conundrum.  Their position, they didn't apologize, which is what most people got upset - I don't think that that's - that's neither here nor there.



STEVE:  Well, I did like the comment that said they were too busy turning down offers of acquisition from Google and Facebook.



LEO:  I think that what happens - this happens a lot with programmers.  They go - the same thing happened with Path - "Well, gosh, it's obvious, if you have a Find My Friends feature, that information will be revealed.  So you should have known that.  What do you want us to do?"  So, I mean, I guess allowing yourself to opt out, allowing opt-outs, although not on by default.  And then the real problem is the teenagers - I should have asked my son.  He was just here.  The teenagers who use Snapchat have no idea.



STEVE:  No.  And the point was raised also that what you obtain in return for passing it a candidate phone number is a username, and that many people reuse the same username, even if they're not using the same password.  Maybe we're beyond that, but not so much.  But they use the same username all over the place.  So this allows you to tie a phone number obtained through Snapchat to any other reuse of that username on the Internet, if it's not a common username.  And of course often it's not because you get told, oh, that username is already in use.  So it's like, oh, okay, thanks for filtering that for us.



LEO:  Yup, yup.



STEVE:  Yeah.  So I wanted to give our listeners a heads-up that the name McAfee Security will be falling into disuse...



LEO:  Really.



STEVE:  ...over the course of the next year.



LEO:  They don't like being associated with that guy.



STEVE:  Yeah, Big John finally took it too far.  And, yeah.  So it's going to be relabeled Intel Security.  So when you begin seeing Intel Security, you can think, uh-huh, McAfee.  Although they're keeping the red shield M.  They're not going to change that because I guess they feel that's too recognizable.  I'm wondering whether Intel Security is going to try to download when I update my Adobe Flash or my Adobe Reader and so forth.  It's like, whoa, here, wouldn't you like a free McAfee security scan?  No, thank you, I wouldn't.



LEO:  McAfee.  A name that will live in infamy.



STEVE:  Goodbye, John, yeah.



LEO:  Intel owns them.  So I was surprised that they kept the name for as long as they did, frankly.



STEVE:  Yeah, well, I mean, once upon a time it was a major brand, and they were certainly - they bought it for more than $7 billion.



LEO:  What?



STEVE:  7.68 or something billion dollars they paid.



LEO:  What?



STEVE:  Yeah.



LEO:  Man.  Do you ever feel like we should have, we could have - if we'd just been more prescient, you could have written an antivirus.



STEVE:  No.  Believe me, 23 people was more than I could handle.  And you're about at your limit, too, Leo, so...



LEO:  Oh, you'd better believe it, yeah.  That's why we're firing people left and right.  We just - we can't handle it.



STEVE:  I've never been happier than when I just have Greg and Sue.  It's like, okay, that's about the right number.



LEO:  And anybody who is on the, as we are, court side during all of this stuff going back to the '90s, watching the Internet explode, feels like sometimes, I think at some point, golly, maybe I should have done an app. 



STEVE:  Although I have to say, Jenny and I saw "The Wolf of Wall Street" last night.



LEO:  Ooh.  I haven't seen it yet.  I'm not sure I want to see it.



STEVE:  Well, I came away, I mean, it was fun and funny and well written.  It was long.  Scorsese and Leo, apparently, Leonardo DiCaprio...



LEO:  Yeah, don't call him Leo.



STEVE:  No, [Scorsese and] Leonardo have a great relationship because, I mean, basically this was the DiCaprio onscreen movie.  It was really all about Leo and his acting.  But - I'm sorry, Leonardo.  The point is that apparently some people are thinking, wow, that would have been kind of nice.



LEO:  No.



STEVE:  And I have to say, I was looking at it thinking, oh, what a mess.



LEO:  No.  And the guy was a con man and, I mean, I don't know.  Yeah.  I might go see it.  I don't know.



STEVE:  I don't want to have a life like that.



LEO:  His daughter, the real-life guy's daughter, wrote a scathing editorial saying, you know, don't downplay the harm this fellow did, including to his family and me.



STEVE:  Yeah.  So I just thought I would - we talked about the wrongheaded porn blocking decision that was made in the U.K. many months ago.  And Boy Genius Report (BGR) had a neat story that wrote:  "As was predicted by just about everyone, the United Kingdom's initiative to get U.K. ISPs to add default pornography filters has been a complete and utter disaster so far."



LEO:  Of course.



STEVE:  Yeah.  I mean - okay.  I'll save that for a second.  "Not only have the filters been blocking access to pornographic content, but they've also been blocking access to health information websites and charity websites, among other unintended targets."  Again, of course.  But, "There is some justice to come out of all this, however:  The Independent reports that the filters have also blocked access to the website of Conservative MP Claire Perry, who has been one of the leading crusaders for implementing porn filters in the U.K."



LEO:  That's ironic.



STEVE:  Uh-huh.  "It seems that Perry's website contained information on her assorted anti-pornography campaigns, which was apparently enough to get her site caught in the porn filter dragnet."



LEO:  Wow.  Wow.



STEVE:  And it's like, we know this can't work.  People keep trying it, and it keeps failing.  Computers have enough trouble figuring out whether someone is human or not.  I mean, that seems to be, you know, the CAPTCHA problem is an insurmountable problem.  And even the Supreme Court famously, in 1964, Supreme Court Justice Potter Stewart failed to define what pornography was, saying famously, "Well, I can't define it, but I know it when I see it."  And unfortunately, that's not a rule you can put into the firewall.



LEO:  Right.  If you see porn, let us know.



STEVE:  Yeah.  If some comes by, well, we'll apologize and turn it off.



LEO:  My sense is this was all politics.  What a surprise.



STEVE:  Yeah.  I just saw a nice note.  There's a battle waging, and I don't know how it's going to turn out, maybe it'll be all of the above, between Mozilla's asm.js - which actually is the solution I favor, even favoring it over native code, which is Google's approach.



Google has this thing called Native Client, which is an open source technology to allow web applications to be built to seamlessly execute native compiled code inside the browser.  It's like, uh, okay.  If you contain it well enough, if you VM it so that it can't misbehave, then that's a way to get essentially your browser to, like a website - the point was you could go to a website, and it would download an app, I mean a full-on native compiled app, into your browser, and run it.  And so this is Google's future.



Mozilla did the other thing, which I really think is so cool, and we've discussed it before, asm.js.  They defined a strict subset of Java, I'm sorry, of JavaScript, I will be careful, JavaScript, which is otherwise very hostile to high-speed execution.  The nature of JavaScript is that it's a dynamic language.  Which means, for example, you don't have to declare when you've stopped using memory.  You just define arrays, and it's up to the language itself, the guts, to figure out, oh, look, he's not referencing that array anywhere, so you decrement the reference count.  And when it goes to zero, then the garbage collector comes along and collects the garbage.  So that's difficult to speed up.



What asm.js does is define a strict subset of JavaScript which doesn't have any of those tricks in it, which means it can be compiled to run very fast.  And what they did over the holidays was took it from running 2x slower than native code - which already is very fast.  They've got the Unreal Engine running in it, and running Unreal 3 in their browser.  So, I mean, it is screaming.  So they took it from going two times slower to only 1.5 times slower than native code.  And of course when it gets down to one, then it's the same speed as native code, yet cross-platform, cross-chip, essentially, because this is a subset of JavaScript.  If you don't have it running on Mozilla, it'll still run because it's just JavaScript.  If you do have it running under Firefox, it goes like a bat out of hell.  So anyway, I like that approach.  Maybe we'll end up with both of them.  But I just think - I commend Mozilla for what they're doing.  I just really like that approach.



LEO:  Yeah.



STEVE:  I have a bunch of miscellaneous things I want to talk about.  But I did want to share a one-day-after-Christmas really nice note from a listener of ours named Jonathan Bailey, who's in New Orleans.  And the subject was, not surprisingly, "SpinRite Testimonial."  But a neat story, and it's not too long.  He said:  "I was at a friend's house on Christmas Day when she told us the hard drive on her laptop wasn't working.  It wouldn't boot, and even booting it off of a Live CD didn't give access to the data on it."  And I'm sort of impressed.  Either this person whose house he was at knew about Live CD, or maybe he tried that first.  But it doesn't sound like it.  Sounds like they'd already tried that, or someone did.  But that wouldn't work.



So he said:  "While the laptop was old, and she didn't care that much about it, it did have a lot of important stuff, most notable the photos of her son's wedding a few years ago, and there were no known complete backups.  I took the laptop home and, using my receipt, downloaded a fresh copy of SpinRite.  Immediately, on the first sector, it seemed to freeze" - that is, SpinRite seemed to freeze - "and it spent so long at 0% that I considered aborting it.  However, being a listener of Security Now!, I knew to be patient and put my faith in the SpinRite gods, so I went to bed with it running.  I awoke to the green 'SpinRite Complete' screen.  I took out the CD, rebooted, and,  huzzah!  The laptop booted right into Windows.  It was a true day-after-Christmas miracle.  Thank you so much for your great product.  After four years of ownership, I finally get to share my 'SpinRite saved me' story."  And Jonathan, thanks for sharing that.  That I appreciate.



LEO:  Yay.



STEVE:  So, miscellaneous loose ends.  Just we're right up here at 3:00 o'clock, so I think it's just about right.  I just had to mention, BlackBerry has sued the Typo Keyboard people over their BlackBerry-like keyboard.  We mentioned it on the show...



LEO:  Oh, yeah, what's his name's keyboard.



STEVE:  Yes.



LEO:  You were all excited about it.



STEVE:  I am.  In fact, even more so because NBC News this morning had it on.  A buddy of mine texted me because we both have been complaining about typos on our touchscreen iPhones.  And apparently NBC News said that it was an excellent keyboard, but they could not say any more about it due to the BlackBerry lawsuit, which is the biggest bunch of nonsense I've ever heard.  But maybe they don't know any better.  I mean, there's no injunction that has been filed.



LEO:  I don't watch mainstream coverage of technology anymore.  It's just painful.



STEVE:  No, no.  But the good news is somebody who used it apparently loves it.  And I can't wait.  It was mailed on the 31st, I think.



LEO:  Oh, you actually are getting one.



STEVE:  Oh, are you kidding me?  Oh, Leo.



LEO:  So you ordered it before the lawsuit, so you'll at least get to keep it.



STEVE:  Yes.  Absolutely.  And I'm...



LEO:  We did note that it looked very much like the domed key caps of a BlackBerry.



STEVE:  Well, and BlackBerry has a raft of patents on the keyboard.



LEO:  But it doesn't seem like they should be able to prevent physical keyboards attached to a phone.



STEVE:  I agree.  I agree.  And I imagine, now, there are design patents.  And this looks like a true rip-off.  I mean, I have to say that, now that mine's already in the mail.  It looks like a true rip-off, and I couldn't be more happy.



LEO:  [Laughing] Yeah, the closer it is to the BlackBerry keyboard, the happier you are.



STEVE:  The better I'm going to like it, exactly.  Certainly they could change that back into something that isn't really a clone of a BlackBerry.  And one wonders about patenting a design.  It's like not - who knows.  That's another whole issue.  I don't want to get into it.  But I am excited.  I may have a report.  I imagine by this time next week I will have been using it for a few days.  So, I mean, it just - oh, there it is, yeah.



LEO:  Yeah.  This is USA Today.  It does look like a BlackBerry keyboard, doesn't it.



STEVE:  Oh, my god.  Oh, yes.  Ooh, baby.



LEO:  Wow.  Now I wish I'd ordered one.  It's called the Typo Keyboard.  I wonder if Ryan Seacrest was there to show it off.



STEVE:  You can still order it, Leo.  They're accepting orders, and I think they're shipping and just, I mean, there's no injunction.  So as long as they get them out the door - that's TypoKeyboard.com.  And it looks great.  The other thing I'll remind you of is that oftentimes when the keyboard comes out onto the screen, you lose half your screen real estate.  And so while you lose any...



LEO:  I agree.  I don't like that part.



STEVE:  No.



LEO:  But he does say - this is Jefferson Graham writing for USA Today - that if you've gotten used to typing on the screen of the Apple, it's kind of difficult to go back.



STEVE:  Yeah, baby, bring it on.  I will be giving up my fingerprint.  You lose that because there is a Home button in the lower right.



LEO:  Oh, right, yeah.



STEVE:  The thumbprint ability disappears.  But, oh, I'll have a report next week.



LEO:  Good.  Good, look forward to it.



STEVE:  Also, for all people who listen to this in time, the new CBS show "Intelligence" premieres tonight.  Tonight is the night, January 7th on CBS at 9:00 p.m.  Don't know anything about it.  I'm not recommending it.  I'm just letting people know who think they may like it.  This is the guy that gets a chip implanted in his brain that ties him into the global information networks, and we'll go from there.  So who knows.  And if you missed it on Tuesday, and you can't find it on any of your get-them-back deals, it re-airs this Friday.  So they are airing it twice for those - after a buzz is created, hopefully tonight if it's any good, then people will go, oh, shoot, I missed it.  But you can watch it on Friday.



Also I mentioned a sci-fi reading guide.  I prepared this initially for - actually for Bob up in Canada, whom you have met, because I sent him one of my old Kindles where I had all of my books that I have read since Bob departed for parts north.  And I built a beautiful PDF where I laid everything out.  And I realized, oh, this is the "Steve's Sci-Fi Reading Guide" that everybody has been wanting for so long.  So there's a bit.ly link to it:  bit.ly/sgscifi, all lowercase, because bit.ly is case sensitive, bit.ly/sgscifi.  That link expands to a PDF.



And I got a lot of Twitter followers, because I tweeted this a couple weeks ago, saying that they were chuckling because they were getting a PDF from me, as if that was unsafe.  And it's like, okay, folks, wait a minute.  PDFs from me are not malicious.  PDFs themselves are not malicious.  It's not like PDF is a problem.  It's that, like an executable, you download GRC's EXEs night and day because you know they're not malicious.  But you're very careful when you download some random foreign executable on a download site because it might very well be malicious.  Similarly, PDFs can be dangerous.  But, sure, I love PDFs.  They're fabulous.  Leo, you're looking at one that I just made for you.  So...



LEO:  I do accept them from you.  But I think part of the issue is I always say don't accept attachments, even from people you know, because it could be posing as you.  But if you expect a PDF from Steve, and it doesn't have the appearance of an automatically generated email, I think it's probably all right.



STEVE:  Right.  As I mentioned to you when we were up, well, earlier, was it this week?  No.  I don't know what week it is.



LEO:  I don't know where we are or what we're doing.  It was a week ago, last Tuesday.



STEVE:  I had started to reread the Honor Harrington series.  I finished Book 2, so I've just finished rereading, just they're fresh now, books 1 and 2.  So I wanted to mention to everybody, something is happening.  We're going to get a movie or a series of movies or maybe a TV series.  I'm now seeing different reports.  It might have evolved into a TV series, or that might be older news than the movies.  We're going to be getting movies.  You absolutely must, if you ever plan on watching the movie, unless you really, really hate reading, you have to read these first.



I mean, I reread, rerode, reread - slow down, Steve - reread "Ender's Game" the book before the movie came out because I knew the book was going to be so much better.  And oh, my god, it was fabulously better than the movie, which really was not that good.  That goes squared for Honor Harrington.  These books are so rich, there's no way - now we've got a really loud thing going on.  These books are so rich, there's no way the movie could do them justice.  And so the reason I'm mentioning this is that Amazon now has them both free.  iBooks from Apple has books 1 and 2 both free.  And the Baen, B-a-e-n, website has both books 1 and 2 free.  So no excuse for not grabbing them.  And in fact I may be switching over to iBooks, Leo, because I just discovered, to my...



LEO:  What?



STEVE:  Yes.  I discovered to my infinite joy that the version, the new version of iBooks, 3.0, that came out late last year, allows continuous scrolling for the first time.  No more of this ridiculous page turning.  You can just put your thumb there and smoothly scroll up.  And especially for reading iBooks on a screen as small as the phone.  That just seems so much better than that page-turn, pretend-to-be-a-book baloney.  You can't, you'll never be able to do this - well, not never, never is a long time - on eInk.  Right now the technology of eInk is hostile to a page scroll.  But actually I got a second mini because I want to experiment with switching over to reading on the mini because of this update to iBooks which would allow me to scroll, like, continuously.



LEO:  And why do you want that?



STEVE:  Want what?



LEO:  Continuous scroll?  I mean, because, okay, so I'm imagining you.  You're on your Stairmaster or treadmill, whatever it is.  



STEVE:  Oh, no, no, I mean, I only do a little bit of reading there.  So that would still be page at a time.



LEO:  You don't care about it there.  Just like in real life when you're reading.



STEVE:  Yeah.  I just love the idea of being able to smoothly scroll through the book.  I just think that's going to be the right way.



LEO:  Okay.  I'll be curious.  Because it feels like I would lose my place easily doing that.



STEVE:  I know what you mean, when you're not on a discrete page.



LEO:  Yeah.



STEVE:  I know what you mean.  And of course Apple and iCloud are really good about doing cross-device synchronization now.



LEO:  Is somebody disassembling some hardware in your office?



STEVE:  No.



LEO:  What's that sound?



STEVE:  It's the dumpsters.



LEO:  It's outside?  Sounds like it's right next to you.



STEVE:  Unfortunately, this may be a side effect of us...



LEO:  Oh, 1:00 in the afternoon.



STEVE:  Yes, exactly, because this goes on every afternoon around this time.



LEO:  Every, well, hey, at least they empty the trash daily.



STEVE:  They're uniform, yes.  And I posted and got some interesting feedback about my assembly language.  We know that I program in assembler.  I'm now writing SQRL in assembler.  And I thought it would be interesting for people to see what that looks like.  And so there is an image for which I have a bit.ly link, bit.ly/, and for some reason I did mixed case.  I'm sorry about that.  I don't know why.  Capital S, lowercase q-r-l, capital S, lowercase i-g-n.  So it's SqrlSign with the two S's capitalized, S-q-r-l-S-i-g-n.  If anyone's curious, that will give you - your browser will show you what my assembly language actually does look like for the code that I'm writing for SQRL.



And speaking of that, all the crypto libraries are up and running and linked into my assembly library.  We're currently settling on an export and storage, an encrypted export and host storage format, the details of that, and also nailing down the details of the way we use the Scrypt Password-Based Key Derivation Function (PBKDF).  But we're down to the ending details, and I'm writing code, so I'm excited.  I hope to have something here before long, get that out to the world, and I'm right back to working on SpinRite 6.1.



LEO:  You are.  Awesome.



STEVE:  Yup.



LEO:  All right.  Steve, we're going to move on to the rest of the lineup on our new day, Tuesdays.



STEVE:  Yes.  And so next week I'm going to have...



LEO:  Garbage day.



STEVE:  ...an in-depth analysis of what exactly it is the NSA has up their sleeves.  I'm going to study every one of those slides and pull them together into a comprehensive take on what the NSA ANT project is, and fundamentally what they can do.



LEO:  Okay, look forward to that, the in-depth look at ANT next week on the show.  Steve Gibson is at GRC.com.  That's where his website is.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility; all the freebies Steve gives to the world, like ShieldsUP!; lots of software information about passwords; information about health and dieting.  It's not his business, it's just a sideline.  You can tweet him at @SGgrc.  That's his Twitter handle, @SGgrc.  If you have a question - I guess we're not doing feedback next week.  But if you do have a question for a future feedback episode, that would be GRC.com/feedback.  Do not email him.



STEVE:  Yeah.  We did a bunch of Q&As in a row, and we caught up a little bit.  So we'll go back to Q&A in two weeks, but I really want to do an in-depth look at the NSA ANT.



LEO:  Good.  Thank you, Steve.  Remember Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC.  That's the new time for Security Now!.  We'll see you back here next week live.  If you can't watch live, on-demand audio and video available at our site, TWiT.tv/SN for Security Now!.  Steve has 16Kb versions, plus Elaine Farris - and Elaine was in the chatroom saying, "Thank god you're back, I was getting bored."  Elaine Farris's transcripts, so you can read along as you listen, are at his website, GRC.com.  Have a great - yes.



STEVE:  Yes, and for those of you who have any additional time in your week, track down those New Year's Eve hours that Leo's group are posting.  There's a lot of fun there.  I mean, it was a blast.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#438

DATE:		January 14, 2014

TITLE:		NSA's ANT:  What We've Learned  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-438.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  As promised last week, after catching up with another crazily busy week of interesting and fun security news, we take a deep dive into the amazing NSA ANT documentation to learn what we can of the NSA's field capabilities.  What we learn is chilling and interesting, though not entirely surprising.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  All the security news, including a Microsoft Patch Tuesday update, plus an in-depth look at what the NSA is doing with its Project ANT.  It's all ahead.  Stay tuned on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 438, recorded January 14th, 2014:  NSA's ANT.



It's time for Security Now!, the show that covers your security and privacy online with this guy right here, the only guy who could see right into the hearts and minds of the NSA, Mr. Steve "Tiberius" Gibson, working in a now undisclosed location somewhere in the Western hemisphere.  What a cup of Joe that is.  Wait a minute, you're not using your Contigo mug, Steve.  What is that?



STEVE GIBSON:  Oop.  Oop, nope, Contigo, Contigo's right here.  I just did a refill with it.  Actually I've had some tweets from our listeners who have thanked us for the recommendation.  They've purchased the Contigo mugs or thermoses.



LEO:  I did, too.  I love them.



STEVE:  I know.  And it really - sometimes I'll knock it over.  It's not a problem because it really does seal perfectly.  You can drive in the car with it and open it only as you need to drink.  No, it's perfect.  It's like an adult sippy cup.



LEO:  Not "like," it is.



STEVE:  It is.



LEO:  You know, Wired writer Steven Levy, the guy who wrote, of course, "Hackers," one of the classics of the computer age, and also a book that I really like, and I don't know if it's as well known, about crypto, called "Crypto"; right?



STEVE:  Yeah.



LEO:  Which was a great book he wrote about 10 years ago.  He writes in Wired this week that, even when he did "Crypto," he really tried to get the NSA to cooperate and talk, and they would not.  They refused.  They just wouldn't have anything to do with him.  But he just recently went right into the heart of the beast at Fort Meade and got interviews, in fact, even talked to the director.



STEVE:  They've given up.  They've given up, basically.



LEO:  Well, he says it's two reasons.  He says, "The protocol officer told me that 'Crypto' had fans at Fort Meade," that they liked his book about cryptography.  But also of course the new - and we saw it with the "60 Minutes" piece, the new attempts at PR.  One of the things he got from his interviews - and he talked to the NSA's General Counsel Rajesh De; he talked to the head of private partnerships, Anne Neuberger, and Richard Ledgett, who hosts the Media Leaks Task Force, which is a task force designed to handle the Snowden leaks in the media; and he even talked to General Alexander, the head of the NSA.  But one of the things he came away with was the absolute hatred of Edward Snowden that everybody shares in the NSA.  He is really viewed within those walls as a total, utter traitor.



STEVE:  Yeah.  Well, and, I mean, today's show is, as I promised last week, what we've learned from that amazing Der Spiegel set of slides about the NSA ANT program; basically, what have we learned about the NSA's field capabilities.  And I do partly feel guilty talking about this, although it's out there now in the public domain, so it's no big deal.  I'm just reading the specs and adding some engineering spin and understanding, some clarification.  And the fact is we would hope that this is the way our tax dollars would have been spent to create this kind of technology.



But here it is, laid out, with all of their code words and their requirements, and this is how it works.  And oh, my goodness, the beginning of this talks a little bit about - I mean, the beginning of our coverage on the podcast today discusses the two major big-iron router companies, Cisco and Juniper.  And it's just very clear that, if the NSA ever has brief physical access to the router, it is forever changed in a way that favors the NSA's ability to penetrate it at will.  It doesn't look like they can do that remotely.  So I was breathing a sigh of relief.  I looked, I mean, I really read these docs carefully.  It looks like that Chinese telecommunications company - is it Huawei or Huawei?



LEO:  Huawei.



STEVE:  Huawei.  There's a "remote upgrade capability," unquote.



LEO:  Yeah, upgrade, that's the word, upgrade.



STEVE:  Yes, being used in a way that wasn't intended.  But I can completely understand the NSA's fury at essentially having the king's wardrobe revealed as completely as it has been.  We do know, apparently, that something's going to happen on Friday of this week.  The Obama administration is gearing up and is going to give some sort of presentation about how they intend to change the NSA's charter.  And top of the list is rolling back or changing the way this metadata is being collected by the telecommunications carriers.  Some have felt that maybe it would be held by a third party.  But then again, that's been regarded as just a window dressing around the problem, and that probably the way - what the people who've been watching this and caring about privacy are hoping is that it will simply become incumbent upon a major carrier to archive their metadata for some length of time and then be able to respond to queries for specific individuals.  And so the NSA would send out a blanket request to all of the carriers for a specific network and some degrees of separation.  And every network, every carrier would then perform a database query on their own metadata that they are themselves keeping sole and separate and then return that data for the NSA's aggregation.  So it'll be interesting to see.  But today on...



LEO:  Is there a sense that these, as we get into this ANT segment, that these Der Spiegel slides are part of the Snowden cache of slides?



STEVE:  That's a good question.  I don't know.  As I said last week, I wanted to be very clear that this feels different to me.  This is sort of the interior workings, the cogs in the system that we would hope our taxpayer dollars are being spent to develop.  Some of this stuff is extremely cool, and I'm looking forward to being able to explain what I've learned from studying that document because, I mean, it's just - it is really neat, Spy v. Spy-level technology.  But that's - and I don't even think that Edward probably had a problem with this.  So I would say no.  I think this is other leaked documents.  But I don't think this is part of Snowden because I don't think Snowden would have had a problem with this kind of stuff.  This is what it makes sense for our taxpayer dollars to go to, where we want...



LEO:  So where did the slides come from, then?



STEVE:  I don't know.  But maybe it's part of it, if it was just all stuff he grabbed.  But I don't think he'd have a problem with this.  He had a problem with the breaches of the Constitution which he arguably felt was going on.  I mean, this is juicy stuff; but this is just, like, wow, the kind of stuff we would hope is happening.  And now we've got real details.



LEO:  As Bruce Schneier said, this is retail spying, specific to a person or a group, as opposed to the mass collection of data that we've been upset about.



STEVE:  Yes.  For example, now I know the oft-mentioned VGA cable that for $30 allows the NSA to somehow exfiltrate what's on the screen, I know exactly how that works now.  And it's not like a Y connector.



LEO:  Ooh, interesting.



STEVE:  You beam a 2 GHz continuous wave radio beam at it, and it reflects back a modulated signal.  And it runs for years without any tending.  So anyway, we'll talk about that toward the end of today.  We've got a bunch of stuff to talk about:  Target's PoS PoS systems...



LEO:  That's point of sale, I should clarify.



STEVE:  Ah, well, one of those PoSes is.  A bad and ultra-potent next-generation DDoS technology, which is getting a lot of press, that I want to talk about.  The growing size of the RSA Security Conference boycott.  We've got to some back to port 32764 because actually there was last week the readout on it that I hadn't seen, that I was immediately - it was brought to my attention by our listeners.  So we have to talk about that because it turns out it is in fact a super-potent backdoor.  There's a new security tool on Kickstarter.  Net Neutrality took a little hit this morning, but it's not completely dead yet.



LEO:  No, in fact I wouldn't mind talking a little bit about what that means.  I don't think we've really got the full story there.



STEVE:  Yes, we will.  And of course a bunch of random miscellaneous stuff that I think people will find interesting, and what we've learned about the NSA.



LEO:  What we continue to learn about the lovely NSA with the Explainer in Chief, Steve Gibson.



STEVE:  So this is the latest possible second Tuesday of the month, since we all know that January 1st fell on Wednesday, just missing Tuesday.  You can't have a Tuesday that occurs any later than the 14th, which is what has happened now.  And it's interesting, it'd be interesting to go back a few years and look at the January Windows updates and see if they're all small.  Because it occurs to me, it's not like Windows is suddenly better in January than it was a month ago in December.



LEO:  No.  Hackers take the holidays off, just like the rest of us.



STEVE:  Well, no.  It's not the hackers, it's Microsoft.



LEO:  Oh.



STEVE:  Because they're the ones who are having to patch the problems.  So my point is the problems are still there.  We just didn't get many patches this week because there wasn't much time.



LEO:  They were busy.



STEVE:  Yeah, exactly.  So we have four sort of yawners.  None of them are critical.  Those we'll probably get next month because Microsoft's back at work now, fixing the problems.  Each of the four affects various subsets of Windows, Microsoft server platforms, and Office.  And so no emergencies.  Update, say yes, reboot your machine, and go about your life.  And that's it.  Although it is worth mentioning that April 14th continues to approach, that being 83 days away and the expiration of XP SP3's security updates.  So, and that's about right.  A few months from now I think I'll be ready to move to Windows 7.  I've made peace with Windows 7.  I like it.



LEO:  Well, it's about time, Steve.



STEVE:  I get to skip over the disaster that was Vista.  And, boy, we had some fun talking about, I remember, the security architecture mistakes that Microsoft made with Vista.



LEO:  Raw sockets and all that.



STEVE:  And needless to say, I won't be going to 8 after 7, nor 8.1, .2, .3, .4 or anything else.



LEO:  Well, the next one, we now know from Paul Thurrott, is Windows 9, codename Threshold, and that will be 2015.  So you can...



STEVE:  Yeah, but it sounds like it's still an amalgamation of their old...



LEO:  Oh, it's 8.  It's 8+.



STEVE:  Yeah, yeah.  So I'm just going to be camped out on 7.  I think the world is probably...



LEO:  You're not alone, I know.



STEVE:  ...camped out on - yeah, exactly.



LEO:  They are bringing the Start Menu back.



STEVE:  Good.  I hope they get rid of all the tiles, too.  And if you get rid of that nonsense - just give me 7, you know, just keep fixing 7.  It's just fine.



Okay.  So somehow last week I forgot to mention, just because it was, like, it was too early in the dual-week cycle that we were catching up from, the massive Target breach, which...



LEO:  I thought you were just bored with it.  It's just another example; right?



STEVE:  Well, there didn't seem to be much news.  And even today the only piece of information we got - first of all, Target did disclose an additional 70 million customers' personally identifiable information.



LEO:  I like how the exploit grew.  So it started with 40.  Then they said, well, no, it's 70.  Then they said, oh, you know what, there's no duplication, or little, between the 40 and 70.  So it's really 110 million accounts.



STEVE:  Yes, yes.  And what they're blaming it on, and this is where I got to the PoS PoS terminals, is malware infecting their point-of-sale terminals.



LEO:  Isn't that interesting.  Hmm.



STEVE:  Yeah.  And so that's clearly a targeted attack.  Now, interestingly, within the same timeframe, dating from about mid-December, turns out that brick-and-mortar, as they're called, Neiman Marcus stores have been reporting something similar.  So it's not their online problems.  But Neiman Marcus is talking about an - we don't have a size yet.



LEO:  Oh, on PoS?  Oh, interesting.



STEVE:  Yeah.  Well, some - it's that customers who shopped at Neiman Marcus for a period of about a month, somewhere around mid-December, at their physical retail locations are having problems.  So there may be a group of hackers out there who have been doing some reverse-engineering of point-of-sale terminals.  And then lord knows how you got it in all these Target stores.  I mean, it'll be really interesting to see whether we learn much about it.  There's just, still, there's a lot of reporting of the fact of this event, but no real background information that would interest me and our listeners, like, ooh, how was this done?  How did it actually happen?



However, we can make up for that because there is a new DDoS flooding technology in town, and it is nasty.  To give our listeners sort of a sense of the history and scale of this, because denial-of-service attacks are something I have a great deal of prior interest and experience with, the original attacks were the so-called SYN flood - S-Y-N, short for synchronize, is the name of the packet which is first sent when a client wants to connect to a server.  And if you don't use the operating system's regular TCP connection mechanism, but if you actually generate the SYN packets yourself using a technology known as raw sockets, then you can send the SYN packets off to a server at basically whatever your line rate is, as fast as your bandwidth will allow, because the packets are very small.  So you can get many of them in a short period of time.



And what happens is the receiving server tries to initiate connections.  Assuming that all of those packets are valid, it creates some state on the server, in the server's TCP/IP stack, to say, oh, somebody wants to connect to me.  And so it allocates memory, and it kind of gets ready for a connection.  And it eventually sends an acknowledgement, a SYN/ACK, back, which is its own synchronize, with an acknowledgment of the SYN that it received.  And what happened in the early days is that, without too many SYNs coming in, just these fake packets, you would collapse the server.  It would be unable to establish all of these pending connections and just crash.  So, and sometimes very embarrassingly.  Sometimes it just kind of went offline and stopped being able to accept any more.  And that caused a denial of service of that service that was being offered.



So then hackers got a little more clever.  They used what's called a "reflection" attack.  They would send a SYN packet to some other server with a spoofed source IP.  That is, they would change where the SYN packet appeared to originate.  So it would go to that server, and that server would acknowledge the victim.  So it would send that SYN/ACK, that second packet, that answering packet would not come back to the sender, the true sender.  It would go to the target.  And the reason that was clever is that, when the server that thought it was answering an initiation of connection didn't get an answer back, it would send it again, and again, and again, typically at least four times.  So this was a bandwidth amplification attack.  You send one small SYN packet with a bogus originating IP, source IP, to a legitimate server, and it would send four acknowledgements before it would give up.  So that amplified the attack strength by a factor of four.



Next, we went to a so-called "DNS reflection" attack, which has been very problematical in the past.  The idea with DNS is a very small query can generate a very large reply.  And the two attacks we've talked about first were TCP attacks.  DNS, as we know, uses UDP, the datagram protocol, instead of a connection.  So you send a UDP DNS packet at a DNS server with, again, a spoofed source IP.  And it sends a big response, it thinks answering the query; but you've placed the target's IP as your source IP, so the DNS server sends much more data back to the victim's server - again, a substantial bandwidth amplification attack.



So now we have a new protocol in the game.  It uses the Network Time Protocol, NTP, and it is also a reflection attack.  NTP goes over port 123, and it's built into Windows.  All of the *nix OSes have it.  Interestingly, it uses a 32-bit - is it 32 bits?  I think it's, yeah, a 32-bit time.  For some reason I'm sure there's also a 64-bit component.  Anyway, the point is that something is going to wrap with network time protocol in 2038.  And even though the Y2K problem with the year going from 1999, wrapping around to zero, didn't cause a huge problem, if there's any old equipment still, that is still using the original 32-bit NTP, we're in trouble because sometime in the year 2038 that 32 bits wraps around to zero.  And that may be the most significant 32 bits of the time protocol.  I haven't looked at it for a long time.



Anyway, so the Internet is covered with network time protocol servers.  They're everywhere.  It turns out there is a command which has actually not been supported in the NTP software since around March of 2010.  Two years, well, now, what, four years ago, yeah, update myself.  Four years ago, nearly, it was understood that the so-called "monlist" command was a bad thing to have.  It was subject to abuse.  What can happen is a 234-byte packet, so 234 bytes in a UDP packet, can contain the so-called "get monlist" command.  An attacker sends that to any identified network time protocol server on the Internet, with a spoofed source IP, again, with the IP set to the victim of this attack.  A "get monlist" command will return the IP addresses of the most recent other network time protocol servers that it has had access to, up to 600 of them.



Now, six IP addresses fit in a packet, so that's a hundred packets.  So, first of all, we have a packet rate amplification, one to a hundred.  The attacker sends out one packet to an NTP server, and it generates a hundred packets in return.  But it's also a bandwidth amplification attack because they're maximum-sized packets.  And in fact this 234-byte small packet requesting a network time protocol server to list the 600 most recent other servers it's had contact with can result in over a 48K reply.  It's a 206x amplification.  And unfortunately the Internet is full of big-iron network time protocol servers.



Many big routers on the Internet just offer NTP as a public service.  So they are very well connected and have very high bandwidth connections.  As a consequence of this, what we are beginning to see now is 100Gb DDoS attacks.  And the key is, since we're getting a factor of 206x bandwidth amplification, a relatively small set of, for example, a relatively small botnet can be used to send these "get monlist" commands, spraying them out over the Internet to known and identified NTP servers, which then innocently generate a reply and get a huge scaling of bandwidth.  So this is the attack that we're seeing more and more.



Now, the US CERT has been talking about this for a while.  As I said, this command was understood to be a problem four years ago.  But as we know, if it's not broken, it often doesn't get fixed on the Internet.  And it's the case that there will probably always be old-iron, functional, never-touched routers with network time protocol running on it.  It's easy to find them because they all respond to port 123 over UDP.  So anything that scans the Internet can find network time protocol servers.  Then you send it a monlist command, see if it responds.  And, if so, you add it to your attack directory.  It's going to be tough to mitigate this new attack.



LEO:  That's, of course, the worst thing you could tell me, but go ahead.  Because what, now, how do you normally mitigate an attack?  What did you do, for instance, when you got DDoSed?  You throw bandwidth at it; right?



STEVE:  Well, for example, the early DDoS attacks used ICMP, Internet...



LEO:  We should know that.  Internet...



STEVE:  A management protocol.  Internet...



LEO:  Ping.  It's ping.



STEVE:  Well, yeah, it is.  Well, but actually it's many different things.



LEO:  Internet Control Message Protocol.



STEVE:  There we go, yes, Control Message Protocol, thank you.  Ping uses it.  Traceroute uses it.  Many different - it's like low-level plumbing.  The key is, though, you don't absolutely have to respond to a ping.  And many servers don't, specifically because it can be used as a way to map the interior of a large ISP's network or a corporate network.  So, for example, ping is often blocked at the network boundary.  Old-school Internet gurus are annoyed by that because part of the original spec says that every Internet endpoint should respond to an ICMP, to a ping, because it's really useful for, like, figuring out what's gone wrong with the 'Net, why it's not working.  I mean, the ping command is a critical tool in the repository of commands.



LEO:  It's gone the way of finger, I'm afraid.



STEVE:  Yes, exactly.



LEO:  That command is no longer used.



STEVE:  So, for example, so if somebody were flooding you with a ping attack, you just - you ask your ISP to please drop all the ping packets at their border that are aimed at you, and then they won't get through and be able to flood your bandwidth.  But the problem with these monster, 100Gb attacks is that you need to - if you tried to filter the attack near you, then 100Gb would be getting to the point of the filter and probably crash all the incoming links.  So you really need a huge ISP who's able to filter the attack at all of the ingress points in their large network before the bandwidth gets concentrated down to a single location.



LEO:  You can do it upstream where there's a big pipe, as opposed to...



STEVE:  Precisely.



LEO:  ...downstream where it could block the pipe.  And you can no longer do it by IP.  You mentioned it, but you can't do it by IP address because of raw sockets.  You can't ignore SYN requests, or you'd be offline anyway.  So these are very effective.



STEVE:  Well, and so that's, yeah, so that's one of the - if there is, to the degree there's an advantage, it's that this is over this UDP...



LEO:  This could be ignored.



STEVE:  Right, UDP 123.  So in the same sense that, if you had to, you could ignore incoming ICMP, you could just say, okay, I'm just not going to allow - I don't need external Internet NTP service.  I can get that from my own ISP or just set my clock correctly.  But the problem is this is being used, apparently, to blast gaming sites off the Internet in specific instances where it's embarrassing to the gamers or to the sites that are offering that service.  So another powerful tool in the hands of hackers.



LEO:  It's going to get worse.  I've been thinking about it.  I was just talking with Mike Elgan about it, actually.  I think it's going to get worse because what we've created, unfortunately, is a whole generation of people who live in their basements, who don't really have a direct connection with people.  So they don't really understand fully what the personal impact - you think technically, I think psychologically - what the personal impact of this kind of attack is.  And I think in many cases these are unempowered people, anyway.  Whatever, they're nerds, they're outcasts.  And so this is a way for them to get power.  And they don't really understand the real consequence, real-world consequences of their actions.  And so as these tools - and they're script kiddies, right, because these tools - they're not building these tools.  I think it's going to get worse, I really do.  It was script kiddies attacking you; right?  There was no real reason.



STEVE:  Well, the one attacker, whose first name was Michael, who I did find and track down, was certainly that.  He didn't really know who I was.



LEO:  He didn't know what he was doing; right.



STEVE:  Someone told him something about me, and so he said, oh, I'm going to blow Gibson off the 'Net.



LEO:  I have power.



STEVE:  Yeah.



LEO:  And it's sad.  I mean, I don't - I just don't know.  I just feel like we're going to see a lot more of this.  A lot.



STEVE:  Yes.  I'm afraid that's the case.  And the beauty of the Internet, the power of the Internet, is this notion of autonomous routers where we just drop packets into this incredibly interconnected network, and they...



LEO:  They're breaking something gorgeous.



STEVE:  It is, it's a beautiful, fabulous solution.  But the nature of it fundamentally creates this weakness, which hackers are increasingly clever about exploiting.



LEO:  Yes, kids, you can tear the wings off a fly.  It might make you feel better, but it's not - you may see a beautiful flower and tear the petals off.  That might make you feel better, but you've destroyed something gorgeous.  You've destroyed a free and open Internet.  Well done.



STEVE:  Yeah.  There was, in the actual book "Under the Dome" that Stephen King wrote, I can't give it away, but we're reminded of how, as children, some of us would get a large magnifying glass for Christmas, and it turns out that you were able to focus sunlight from a large surface down into a small spot.  And ants kind of snap, crackle, and pop when they are exposed to that kind of heat.



LEO:  Mm-hmm.  That's kind of a spoiler right there, if you just think about it.  And I haven't even read the book, and I have a feel I know what you're talking about.  Continuing on.



STEVE:  So the list of security speakers who have formally announced that they're going to boycott this upcoming RSA security conference at the end of February has reached nine and is continuing to count upwards.  So, I mean, they're...



LEO:  No surprise.



STEVE:  People are - no, it's really not a surprise.  It'll be interesting to see how it actually goes.  Certainly there are people who have strong commercial interests in presenting to RSA.  And so they represent companies that are saying, "You're going.  We don't care."  But there's also a community, much more sort of the black hat sort of group, who are able to say, forget this, I'm not going to speak to RSA.  I just want to show my outrage at the idea that they would have knowingly, willingly, allowed the NSA to influence them and accept money in return, if that's indeed what they did.  We still have no formal proof of that.  But, boy, talk about a nearly smoking gun.



LEO:  Yeah.



STEVE:  One other little blurb crossed my attention in the last week, which was that another former well-known ex-NSA, really well regarded, 32-year employee, who was highly placed within the NSA - and that's William Binney.  He famously resigned in 2001, so about 13 years ago, after 32 years being with the agency.  He was regarded as one of their best mathematicians and code breakers in NSA history.  And in fact he wrote some of the software code that's being used today to spy on Internet traffic around the world.  He spoke a few months ago at a conference in Switzerland.  And what he had to say I thought was interesting and hardly surprising.  He said, apparently from first-hand knowledge, said that, "The NSA knows so much that I can no longer understand what it has."



LEO:  That's what happens.  You gather everything...



STEVE:  It's classic information overload.



LEO:  And yet I think they know that.  And the reason they do it is they presume, probably correctly, that, well, eventually we'll be able to figure it all out.  Or when we need to we'll be able to figure it all out.



STEVE:  Right.  Thus that monstrous data storage facility in Utah where, you know...



LEO:  Let's just save everything in case.



STEVE:  Exactly, yeah.  Crazy.  And I mentioned at the top of the show that apparently Friday we are going to get some new directives from - we, the NSA and the country.  The Obama administration is expected to disclose what it intends to do in terms of issuing some directives.  So I'm sure I'll have a note about that on this podcast next week.



There was a really interesting piece in the Security Watch column of PCMag.com.  Max Eddy wrote, on January 8th, about, well, the title of this column was "What It's Like When the FBI Asks You to Backdoor Your Software."



LEO:  We kind of - we heard a similar story when we were talking with, oh, what's his name, the guy who killed his email service.



STEVE:  Oh, Ladar.



LEO:  Yeah, Ladar Levison.



STEVE:  Levison, yeah.



LEO:  On Triangulation, what it's like when the FBI comes to call and says, hey, would you mind if we just - just give us the keys, and then we won't have to bug you again.



STEVE:  So a female security researcher, Nico Sell, N-i-c-o S-e-l-l, was the subject of Max's story, and I'm just going to share two pieces of his report. I tweeted the link to this this morning.  And I'm sure if you googled "What It's Like When the FBI Asks You to Backdoor Your Software," you can find the whole article.  But he said:  "At a recent RSA Security Conference" - well, now, okay, it had to have been a year ago because they're around this time each year.  The 2014 conference is end of February, so probably around this time last year - "Nico Sell was onstage announcing that her company, Wickr" - W-i-c-k-r - "was making drastic changes to ensure its users' security.  She said that the company would switch from RSA encryption to elliptic curve encryption, and that the service would not have a backdoor for anyone.  As she left the stage, before she'd even had a chance to take her microphone off" - and I was thinking, whoops, you'd like her not to be mic'd anymore when this occurs - "a man approached her and introduced himself as an agent with the Federal Bureau of Investigation."



LEO:  So boneheaded.  Boneheaded.



STEVE:  Yeah.  Speak into the mic.  "He then proceeded to 'casually' ask if she'd be willing to install a backdoor into Wickr that would allow the FBI to retrieve information."



LEO:  Now, is this - people are hearing this through the microphone?



STEVE:  No, no, no.  I think it was just an aside that she hadn't...



LEO:  That would be cool.



STEVE:  Oh, it would be very cool.



LEO:  Let me turn on my mic.  So would you ask me that again?



STEVE:  Hello, this is the FBI.  Would you be willing to install a backdoor in your software?



LEO:  Oh, man.  But for all they know, they don't know; right?  She's got a mic on.



STEVE:  Yes, yeah.  So apparently this is a common practice.  The story goes on to say:  "This encounter, and the agent's casual demeanor, is apparently business as usual as intelligence and law enforcement agencies seek to gather greater access into protected communication systems.  Since her encounter with the agent during the RSA conference, Sell says it's a story she's heard again and again."  Quoting her, it says:  "It sounds like that's how they do it now," she told Security Watch.  "Always casual, testing, because most people would say yes."



LEO:  Sure.  Most people are patriotic.



STEVE:  I wonder, though, if that's still the case.  We're hearing, for example, stories of the recruiting that the NSA routinely does on university campuses, and there it's not the way it used to be a year ago any longer.  They're getting an awful lot of flak from students who...



LEO:  Oh, yeah.  I saw the recruiter was, like, chased off, right, by a mob of angry students.



STEVE:  Yes, yes.  So I skipped a bunch of this interesting story because I love this one paragraph from Max.  He said:  "It was clear that the FBI agent didn't know who he was dealing with because Sell did not back down.  Instead, she lectured him on topics ranging from the First and Fourth Amendments to the Constitution, to George Washington's creation of a Post Office in the U.S."



LEO:  Ben Franklin, but okay.



STEVE:  Huh?



LEO:  It was Ben Franklin, but okay.



STEVE:  Oh, yeah.  The article says George Washington.  But anyway, so she said:  "My ancestor was a drummer boy under George Washington.  Washington thought it was very important to have freedom of information and private correspondence without government surveillance."



LEO:  I can just see the agent going, oh, god.  Oh, lord.



STEVE:  So that's a no?



LEO:  I'm thinking you're not interested.  Would you like to have a cup of coffee, then?  We don't know.  I mean, let's not project too much.  This guy could have been just some dude, some dufus.  We don't know.



STEVE:  Well, I know some FBI guys.  And, I mean, I'm completely sympathetic to the situation they're in.  There are bad guys who are using this technology and using encryption.  And I'm not bothering with any encrypted texting because I'm just arranging what time I'm going to meet Jenny this afternoon.  But certainly bad guys would be wanting to use this recent explosion in secure messaging.  And in fact, in response to my tweeting this article, I got a bunch of people who said, hey, what do you think about Wickr?  Is it secure?  And I said, I'm sure it is.  I haven't looked at it closely.  My favorite is Threema, T-h-r-e-e-m-a, which you and I have talked about, Leo.  That's the one with the cool little three blips, and you get either red, yellow, or green, depending upon the level of verification that you've made about the other person's identity.  And I know how that technology works, and I know it's secure.



So, I mean, I don't mean to be laughing at our law enforcement.  I recognize they have a legitimate need to solve this problem.  And it's tough.  And a lot of this is backlash.  This is backlash from us having discovered that our government is doing everything in its power to fulfill the charter they were given, and they interpret that as meaning collect everything from everyone and try to find a needle in a haystack, if it's there.



LEO:  It's amazing.



STEVE:  I saw another little piece of interesting miscellany which was that the GSM digital encryption, which is of course so common for cell phones, was deliberately crippled from the beginning.  Its team of designers wanted to use 128-bit keys.  And it was backlash from the British government back in the early '80s that wanted to be able to crack it for surveillance purposes.  So they wanted it, again, they wanted it to be good enough that individuals couldn't afford to crack it, but easy enough that they could.  West Germany, on the other hand, wanted strong keys to keep East Germany from snooping.  So there was a bunch of back-and-forth.  And the key length was first cut in half, from 128 bits to 64.  But still that was felt by the governments to be too strong.  So under, as I understand it, pressure from the British government, and we talked about this once a long time ago because I remember mentioning this bizarre fact, the last 10 bits of the key are always set to zero.



LEO:  I say, would you mind terribly?  We just want to set those last few bits to zero.  Be so much more aesthetic.



STEVE:  And of course that renders it - I'm sure that they said we want fewer.  And the crypto guy says, well, no.  Our algorithm, we've already cut it in half.



LEO:  To 64 bits, yeah.



STEVE:  And they said, well, just set 10 of them...



LEO:  Do you mind?  Ever so [indiscernible], just put [indiscernible] to zero.



STEVE:  Rendering it as a 54-bit effective...



LEO:  Let's not forget that really people do this because they're patriotic.  They want to protect their nation.  They want to protect their - they want to cooperate with law enforcement.  And it's not a bad instinct, I think.



STEVE:  Yes.  I agree.



LEO:  That's a natural instinct.



STEVE:  Yes.  I mean, if - yes.



LEO:  They're on our side.



STEVE:  Yes.



LEO:  It's not like the Russkies came to us and asked us to do that.



STEVE:  Now, port 32764, which we talked about last week, is such a problem that I have created a bit.ly shortcut to GRC's own port scanner.



LEO:  Oh, good.  So people go right to it.



STEVE:  So that everybody can check it.  You absolutely have to:  bit.ly/port32764, all lowercase, just bit.ly/port32764.  That will immediately check that port on your router.  You need it to either be closed or stealth, not open.  Open is the problem.  Now we know, because it actually had, last week when I talked about this, already been reverse-engineered.  There was something happening with GitHub where I was unable to download the file.  It was saying that it couldn't deliver files of that size right now or something.  Anyway, I finally got it.  There are, from the reverse engineering of the firmware - and as I mentioned last week, firmware, there's a whole culture that is reverse-engineering router firmware, where they take the file, they unzip it, essentially.  It uses LZMA compression, so they decompress it.  And then they run reverse-engineering tools on it, figure it all out.  That was all done.  And what was found is as bad as it could possibly be.



Thirteen commands have been identified which will respond if that port is open.  Command 1 is a dump the configuration.  You send a Command 1 to that port, and it dumps this huge blob containing things like the admin username and password and the WiFi preshared key.  So complete access to your router, if someone can get that.  Command 2 allows them to specify a configuration variable.  Command 3 allows them to set a configuration variable.  Command 4 writes any changes to nonvolatile RAM.  Command 5 turns bridge mode on.  It wasn't clear exactly what that meant.  Command 6 shows the measured Internet speed.  Command 7 gives them a command shell prompt.  Yes, from which you can then execute any Linux-style command of your choosing.  Command 8 writes a file.  Command 9 returns the version.  Command 10 returns the modem's router IP.  Command 11 restores the default NVRAM - which, it happens, turns WAN admin back on.  So if the user had properly disabled wide area network administration, as everyone should because why would you ever want that...



LEO:  Why would you need it, yeah.



STEVE:  Yeah.  The first thing that happens is you issue a Command 11 to restore the NVRAM and restart the router.  Now WAN administration is on.  Now you give a Command 1, which dumps out all of the data, including username and password.  And I don't know whether restoring the default nonvolatile RAM would reset the username and password to the router's default.  Maybe it does.  If not, Command 1 gives you the username and password.  So then you login remotely, and you've got full HTTP-style admin access to the router.  Command 12 reads some blocks, and this guy was unsure exactly what.  And Command 13 dumps the nonvolatile RAM to the internal file system and commits it.



So, I mean, this is the definition of a backdoor.  So again, bit.ly/port32764.  That's, as I mentioned last week, four fewer than exactly half of 64K, 32768.  And so this is four back from that midpoint.  Make sure you and everyone you know has this port closed.  You should get back either closed or stealth.  If you get back open, then you need to deal with it immediately.



Cisco has issued a statement saying that they will have a firmware update for their affected routers by the end of the month.  In their statement they said:  "An attacker could exploit this vulnerability by accessing the affected device from the LAN side interface."  Remember that few routers did have this exposed by default on the WAN, on the Internet wide area network side.  Huge number, like I don't remember, it's like 30 different models have been identified that had it on the LAN side.  And so Cisco is noting that:  "An attacker could exploit this vulnerability by accessing the affected device from the LAN-side interface and issuing arbitrary commands" - just like we enumerated - "in the underlying operating system.  An exploit could allow the attacker to access user credentials for the administrator account of the device and read the device configuration.  The exploit can also allow the attacker to issue arbitrary commands on the device with escalated privileges."  Yeah, the privileges of the administrator.



So this needs to get resolved.  But mostly, our listeners need to make sure it's not exposed on the public side because I'm sure scans are already occurring to find that port open, just as they were when we discovered that Universal Plug & Play was open as widely and commonly as it was over on the WAN side.  So this needs to get fixed.



So I know you've got some stuff that you want to say about this, and I'm glad.  What happened was the news this morning was that the Washington, D.C. Court of Appeals rejected the FCC's proposal for their implementation or their rulings on 'Net Neutrality.  And the Boy Genius Report story was gloom and doom.  But Tech Dirt did an article which explained that it's not as bad as it looks.



LEO:  Right.



STEVE:  That essentially what the D.C. Court of Appeals was saying was that the FCC didn't have the authority under the provisions that they were attempting to exercise it, but that they probably do have the authority in some other - by taking some other approach.  So it wasn't that it was dead forever, but that they just didn't ask right.



LEO:  The issue has been all along an issue of jurisdiction, pure and simple.  So of course we want 'Net Neutrality.  You and I and anybody who's sensible listening to this show loves the idea that - really, I don't even like the term "'Net Neutrality" because it doesn't say it.  What we want is no discrimination on the 'Net.  We want bits to be equal.  We don't want an Internet service provider to say, well, I'm going to let YouTube go through.  But TWiT, I want to slow them down.  We want - we don't want discrimination.  That's how the 'Net was designed.  The FCC has in its mandate, as part of their broadband plan, they also want to fight for 'Net Neutrality.



The issue is, and this is what Verizon - this case was a lawsuit by Verizon.  Verizon asserted the FCC doesn't have jurisdiction.  For instance, they don't have jurisdiction over TWiT.  It's a podcast.  They have jurisdiction over my radio show.  It's a broadcast.  In this case, the issue is, is a broadband service provider a common carrier?  So the FCC regulates common carriers - telcos, radio stations, stuff like that.  And up to now, the FCC has not said that the broadband - and there's good reasons for them not to say that the broadband providers are not common carriers.  Even though Verizon is a common carrier in wireless telephony, they're not in wireless data.  So that's what the court is saying:  According to your own rules, you don't have jurisdiction.



However, the court says the FCC does have the right to oversee the Internet.  So they're not saying no.  The court said that the 1996 Telecommunications Act, quote, "vests the FCC with affirmative authority to enact measures encouraging the deployment of broadband.  It even said that the agency reasonably interpreted the law to empower, to promulgate rules governing broadband providers."  But - and that was the good news.  The bad news is the way they're doing it, they don't have jurisdiction.



STEVE:  Right.



LEO:  But the attorney who represented the FCC did say, well, we know now where our jurisdiction lies.  I'm still worried about the FCC because you know the new chairman is a former cable company executive.  That bothers me a little bit.



STEVE:  Well, yeah.  And I'm worried that there's any thinking or logic to the idea that, well, consumers have a choice in how we get our broadband connectivity.  That's absolutely not the case.



LEO:  Right.  And that's because of the FCC, frankly, that awarded, in effect, duopolies, monopolies to the cable company and the phone company.  Now, in this case we're talking about wireless Internet.  We're talking about Verizon is - we're talking about cell phones.  And even Google, even Google said that broadband should be treated differently on a cell phone carrier than it should be on a cable company, the thinking being that there are some actual physical constraints to the bandwidth available on a cell phone, right, because they have to get the data out to each head end individually.  There's lots of technical reasons why it might not be regulated the same way a cable company is.  So this is a deeper, much deeper question than just this decision.  This decision doesn't change really that much.  It gives, in some ways, the FCC more direction about how it should proceed.



STEVE:  Right.  Right, it's like, okay, strike one.  Try again.



LEO:  Right, right.  And the court seems to me, and I'm not an expert, to be supportive of the idea of 'Net Neutrality.  The judge who wrote the decision said Internet service providers can damage players on the edge.



STEVE:  Good.



LEO:  So that he recognized that there is a public interest in protecting neutrality on the 'Net.



STEVE:  Yeah.  I think there's only one way this can ultimately turn out, and that's the way we believe it should; that even if it stumbles, and there are some mistakes made along the way, I just think the idea of allowing an ISP to discriminate in any fashion about the way you're connected to the Internet is doomed to failure, as much as they may want to.



LEO:  Well, and they protest.  I mean, Verizon says, oh, we don't want to harm the Internet.  But look what AT&T's doing with their subsidized broadband plans.  They're saying, hey, if Netflix wants to pay your broadband bill, then we won't count it against your cap.  But if TWiT doesn't, then we will.  And that's what I mean by 'Net Neutrality isn't a good way to express it.  Internet discrimination is the way to do it.  If you don't pay us, if you don't subsidize our customers' broadband bill, then, I'm sorry, we can't - we're going to have to count it against the customer.  So I do expect the FCC to get involved in this.



The court, you know, the judge further wrote:  "The Commission (FCC) has adequately supported and explained its conclusion that, absent rules such as those set forth in the Open Internet order, broadband providers represent a threat to Internet openness and could act in ways that would ultimately inhibit the speed and the extent of future broadband deployment."  The Court sent a very clear message:  Don't do this.  Now, in this particular case you're going to have to do it differently, FCC.  But we're watching you, you broadband providers.  That's good.



STEVE:  Yeah.  That was some good language.



LEO:  Yeah, it's a good decision.  I don't think it's a bad decision.  But it doesn't mean we're done.  You know, we're never going to be done.



STEVE:  So I have two links which I just decided to make a "techie bonus" for our show note readers.



LEO:  [Laughing]



STEVE:  Because I don't know what else to do with them, but I just couldn't throw them - I couldn't throw them away.



LEO:  It's our bonus round.



STEVE:  Yeah.  So the first is "A (Relatively Easy-to-Understand) Primer on Elliptic Curve Cryptography."  And this was written by Nick Sullivan, who is over at Cloudflare.  And so it's the blog.cloudflare.com.  And then his more recent one, the one that really caught my eye, was very interesting:  "How the NSA May Have Put a Backdoor in RSA's Cryptography," and he says, "A Technical Primer."



LEO:  I like this Nick Sullivan guy.  We've got to get more.  We've got to get him on our shows.  He's smart.



STEVE:  Yeah, it's good.  It's very smart.  He knows his crypto.  He's got nice pictures with everything.  But there's nothing I can really do with it on the podcast except to aim people at it.  So anyway, so it's in the show notes, if anyone is interested.  Or you can just google "How the NSA May Have Put a Backdoor in RSA's Cryptography," and I'm sure Google will take you to it because all that text is in the URL.



LEO:  We should mention that Cloudflare is one of those companies that provides DDoS protection.  You run your stuff through Cloudflare.  And if suddenly there's bandwidth hits, they'll take over.



STEVE:  Right.  I ran across an interesting Kickstarter that I thought certainly some of our listeners would be interested in.  An individual is putting together a universal bootable Windows password reset key.  So for anyone who...



LEO:  Oh, what a good idea.



STEVE:  Yeah.  So it's all integrated into a neat, looks like a little key, a USB, essentially, memory stick.  You can buy the software only if you want, once it's finished; or you can purchase the actual hardware key.  And the idea would be you stick it into any Windows machine, I think it runs through all of them up through 8.1.  And as long as you don't have full-disk encryption - that would defeat it; but, unfortunately, still very few people do - this allows you to go to a screen.  He shows some screenshots which are a little unnerving.  I've actually done this before myself.  There was a - actually one of my Starbucks regular morning friends is a schoolteacher who needed some things done that her district was unwilling to do.  Actually it was just to get some of her equipment working.  So I needed to be able to log in with administrator privileges, but she was locked out of that.  So, well, it turns out it's not very hard to do.



But, yeah, you could see it's just a matter of putting the key in, boot the machine, and up comes a dialogue.  You select the account you want to log in as, and it does it for you.  So anyway, so you can just google "password reset key."  And this is not something you have to pay for.  There are free, like, CDs and software kits and things available to do it.  I just think it's very neat that this thing will all be prepackaged on a key that you just stick into a Windows machine, turn it on, and you're in.  So certainly useful for people who are doing recovery and forensics, or if you get, like, who knows, used computers that you want to be able to get back into in order to recondition them or something.  So I wanted to point our listeners at that.



Let's see.  This is totally random, also.  And I mentioned this already to you, Leo.  I wanted to tell our listeners that the TSA PRE program is an incredible win.  When I was flying up over the holidays with Jenny to Northern California, she had TSA PRE, and I didn't.  And she was, like, sitting at the gate waiting for me to catch up for half an hour.  Essentially what it is, is it's a time machine that sets you to pre-9/11.  There's no one in the line because no one else is clued in to this.  So you go immediately to security.  You're in your own security area.  And all you do, there's no body scan, there's no physical pat-down, again, it's like pre-9/11.  All you have to do is take metal out of your pockets in order to go through the magnetometer door, and that's it.  You don't have to take your clothes off, I mean, nothing.  You just need to be able to go through the magnetometer like in the old days.  You can sign up online.  I did.



And in fact, when I came up for the New Year's Day with you, Leo, I already had TSA PRE qualification, and I experienced this for both directions of my trip to Northern California.  So, oh, my goodness.  Even if you only fly, like, once a year, as I do, to my way of thinking it's absolutely worthwhile.  There's an interview that you need to have, and it costs, like, $85 or something one-time fee to cover their expenses.  They just need to see you in addition to filling out the form.  And you do need proof of citizenship, but a valid birth certificate or passport.  You need more than just identification.  And then you can get this.  So for anyone who hasn't take the jump...



LEO:  How much?



STEVE:  I think it's $85, if I remember right.



LEO:  And how is it - when we talked, you hadn't yet been interviewed.  How was the interview?



STEVE:  Actually, that's tomorrow.  I don't quite understand how it is that this appeared on my boarding pass.  And then I half figured that maybe it wouldn't scan.  But I got green lights at - so maybe they were able to do enough from the form I filled out.  I filled out the online form, scheduled an appointment for, like, a month and a half in advance - this was after Christmas, but before New Year's.  And I was surprised when I printed out my Southwest Airline's boarding pass that said TSA PRE on it.  And I was really delighted.  And it worked.  So because there's a chance it may have, like, been a fluke, I'm going for my interview tomorrow because I don't ever want to lose this.  It's just too valuable.



LEO:  It is 85 bucks.  And does it expire, or...



STEVE:  I don't think so.  I think the one-time fee, just to cover the cost, and also to set the bar.  I think they don't want to get flooded with people doing this.  They'd like to say, well, it's going to cost you $85.  We need to see you.  And then it'll happen.  I can't explain why I got it prior to the interview.  Maybe I'm in some database somewhere where I'm on some level pre-cleared.  Who knows?  But I'm doing the interview tomorrow anyway because, oh, my goodness, it was a win.



LEO:  I'm enrolling right now, Stevie.



STEVE:  It was a real win.  A brief SQRL update.  I mentioned I'm still at it.  That's what I'm doing.  We've just been benchmarking the Scrypt, the password-based key derivation function.  You'll remember that one of the things we're deliberately working on is making brute-force attacking, user password cracking, extremely difficult.  And so, again, all of the crypto code is done.  We're just nailing down the protocol for exactly how to delay the recognition of the password in such a way that GPUs, FPGAs, and ASICs cannot be employed in a reasonable fashion to accelerate that process.  And that's happening.



And the other trick is we want to be able to have this be a dynamically adaptable process so that, for example, on your cell phone, even if you have an underpowered smart phone and you wanted to use this, you would type in your password, and it would show you a progress bar and take five seconds just for you to authenticate.  The point is we've made it take five seconds because we want a brute-force technology that is super resistant to someone guessing all possible passwords.  And the idea is, if you type your password incorrectly, five seconds with a nice progress bar isn't too long to wait to prove to your phone that you are you because of course your phone, what SQRL does is absolutely empower your phone to represent your identity on your behalf.  So it's necessary for us still to prove that we are who we are, until we get, like, bulletproof biometrics or some other authentication approach to use.  So that looks like it's pretty much nailed down, and then I'm going to continue coding.  So that's what I'm doing before I return to SpinRite.



Speaking of which, I just found - actually this was dated the 21st of December - a nice note from a Ron Kurr who's in Auburn, New Hampshire.  And I thought this would be of interest to our listeners because many people are having very good experiences with SpinRite in VirtualBox.  Virtual Box is a free virtual machine technology that is also cross-platform - PC, Mac, and Linux.  And he said:  "Steve, I've stumbled upon something that I think others might be interested in, but I wanted you to clarify something first.



"A little context seems appropriate.  I'm a Linux weenie and noticed that most of the directions for getting SpinRite to operate within VirtualBox were all Windows-based.  Having an hour to spare, I decided to try to get SpinRite to run under VirtualBox on my Linux i7.  In a nutshell, Linux makes it much easier to do than Windows does, and I was able to run several SpinRite virtual machines concurrently as I did real work.  As an experiment, I tried using the SpinRite/VirtualBox combination with some of the USB hard drives I carry with me to and from work.  Normally, SpinRite doesn't see the drives, so I could never exercise the disks like you recommend.  But the SpinRite/VirtualBox combination saw it like any other hard drive.



"So here's my question:  Is SpinRite able to use the same deep scanning techniques with a virtualized USB drive as it does with a standard SATA drive?  I know in the past you have recommended that people extract their USB drives from the enclosures and attach them directly to their motherboard's drive controller so SpinRite can perform its deepest scans.  Does VirtualBox's drive controller emulation actually allow SpinRite to treat the USB drive as if it were a native SATA drive?  Or is the emulation just tricking SpinRite into thinking that it's doing a deep level scan when, in fact, it is not?  I'm very curious to hear your thoughts.  Thanks, Ron Kurr."



So, as I said, many people are having success with SpinRite in VirtualBox.  And in fact, it is a way to get SpinRite running on Mac drives on Mac machines natively, essentially, because it solves the one problem SpinRite 6.0 has, which I've already resolved in 6.1 here in the lab and will be incorporating into 6.1 as soon as I'm able to get it finished.  And that is that the Mac uses a USB emulation that does not emulate the PC's hardware, and VirtualBox provides a BIOS that solves that problem, that does emulate the hardware by virtue of being a virtual machine.  So SpinRite runs just fine on a Mac inside a VirtualBox.



LEO:  Interesting.



STEVE:  I can't really answer Ron's question definitively because I'm not sure we're ever going to get the same level of communications through a serial interface like USB, with a physical connection.  That is something I'm putting off exploring until v6.2 of SpinRite, just because I don't want to slow down the release of 6.1 any further.  So I'm going to get all of the low-level, super high-speed SATA stuff operating, both with the older IDE and the newer AHCI hardware, and release SpinRite 6.1 like that, and then tackle immediately the USB side.  I'm a little concerned that it may not be possible to communicate through the serial interface and do things that SpinRite does for some of its really, really, like, down-to-the-hardware, low-level stuff.  There are ways, for example, that SpinRite is able to truly read a sector which is unreadable.



But I'm afraid that the USB interface is always going to just, I mean, it's going to be - it's a barrier that nothing could bypass, that it just won't allow me to issue those commands to the hard drive.  If I'm limited to read and write, then I can't do the fancy things where I'm taking advantage of the entire ATA vocabulary of commands that are available.  So the good news is you can run SpinRite in many more places under VirtualBox, and it will likely do as much as is possible, for now.  And then 6.1 will push it further, and SpinRite 6.2 will - and actually 6.1 will eliminate any need for VirtualBox stuff because it'll run natively on the Mac and on Windows and Linux and so forth.



LEO:  I just - a couple of things.  Five years on the TSA PRE.



STEVE:  Oh, really.



LEO:  Yeah.  And I've just looked at it, and you have to be able to go to - what are these?  They're not in airports?  What are these centers you have to go to?



STEVE:  Yeah, I'm going to Long Beach, which is the closest...



LEO:  The nearest one to me is Sacramento.  There's nothing in San Francisco, San Jose, or Oakland.  So it's not convenient.



STEVE:  You know, Leo, I would fill out the form and just see if you get it.  I got it.



LEO:  They say if you have a criminal record, you shouldn't bother.



STEVE:  Don't bother giving us - don't bother submitting, yes.



LEO:  They say no refunds.



STEVE:  Yes.  Although you're able to pay with a credit card, and you take it with you to the interview, so that you don't have to pay in advance.  And I got PRE somehow.



LEO:  I'll fill it out.  They say don't do it if you don't have - you can't get to a center within 120 days.  So that gives me four months.  I guess worst case I'd drive to Sacramento.



STEVE:  I agree.  I've driven to Sacramento, and it's not fun.



LEO:  Somebody's saying, and somebody mentioned that they got it through Delta, that some air - maybe through frequent flyer programs some airlines will facilitate it.  I'll have to look.  Time to talk about ANTs.



STEVE:  Okay.  So my goal here, you know, last week we had fun running through the crazy terminology which the NSA uses.  I would almost think that they have some random word-pairing software that takes two words, like as if you had a big bowl...



LEO:  I think that's the case.  It's a code generator.



STEVE:  Yeah, exactly, except that some of them really do, okay, it's like BananaGlee.  Okay, it's not clear at all what that has to do with exfiltrating data from target networks, which is what it does.  So that one, oh, and JetPlow, same thing.  But there are some where there may be just a coincidental naming, or maybe the person who requests a code word for their project is able to sort of say, well, it's kind of about this and this and this, and the selector helps you, comes out with something a little more memorable.  But we have some terminology we need first.



"Interdiction" is the terminology they use for physical access.  So anything requiring interdiction means that they had to visit the hardware and, like, physically do something.  So, for example, installing that VGA cable that I mentioned at the top of the show, that would be interdiction into the system, where they would presumably sneak in at night and swap the VGA cable with their own.  Nobody would know the difference.  It all works fine.  Except that, as I mentioned, in this case there's a passive RF ultra-high frequency reflector which modulates itself based on the video signal going down the cable, and it doesn't itself radiate any RF energy.



So that's clearly where the technology has gone now.  The ANT documentation is full of these passive RF reflectors, the idea being that they can, if they need power, they only draw a few microamps so that the battery's own self-discharge, it just loses its charge over a couple years, that's a greater effect than the actual drain on the battery itself.  So for all intents and purposes they run for many years without ever needing to have the battery changed, and they do not radiate.  So all of the movies we see where someone, like, sweeps the room to check for bugs, well, that doesn't work here because there is nothing that a receiver can receive.



It's not until somebody deliberately decides now they want to obtain information from some distant location, they send a focused beam of radio frequency energy targeted at the location of where this passive re-radiator is.  And while it's always been running, it's not until it gets illuminated by this coherent wave, that is, a non-modulated RF energy, that it then reradiates back to the receiver.  The receiver picks that up and mixes the outgoing signal with the incoming signal.  And Leo, you'll remember this from your ham licensing days.  It heterodynes the reflected signal with the outgoing signal, and it uses the sum and differences of sines.  There's a law there where you're essentially multiplying two sine waves on a log function to get the sum and difference.  The sum will be like, if you've got a 2 GHz carrier, the sum will be up at 4 GHz of the two.  And the difference is what you really want.  That will be the original frequency which is doing a modulating of this passive reflector.  And that's, for example, a video signal that is going through the cable.



Then they have other technologies that are enumerated in this document that, for example, allow them to capture the audio, if it's a bug.  One of these things is a passive bug.  It is, like, half an inch in size.  And I noted in there that it talks about its COTS, which is the acronym for Common Off  The Shelf, and they specifically say so that there will be nothing tying it back to the NSA.  So it uses just generic components.  And so if someone did discover it, it's like, you know, what's this?  And there's nothing to tell them where it came from.



So in these cases they do need so-called "interdiction" in order to plant this initially.  But once done, these things can run for years.  They do not give off any radiation themselves.  And of course, if they were radiating actively, that would inherently mean that they were consuming more power.  So this is part of the cool architecture that they've got where the thing doesn't generate power, so it can't be found.  And it will only generate a signal when it is itself essentially being illuminated by this remote source of detection.  They call it radar.  It's not technically radar.  It's just a 1 to 2 GHz beam of RF energy that this thing modulates and reflects.



Then the other term that they use is an "implant."  And implants can be hardware or software.  And that's just something implanted into another device.  They're big on persistence, meaning that it survives a reboot or OS upgrades and so forth.  There's even mention of their ability to have an architecture of exploits where, if they install this in a router down at the lowest level, like down in the BIOS, yet the router's software, the OS running on it, they don't have an active exploit for yet, their persistence allows them to automatically reacquire access to the router if at some future point that router is upgraded, that is, the router's OS is upgraded to one that they do have an exploit for.  It'll automatically recognize that and then exploit that OS during boot.  And it talks about how it's able to modify the in-memory image on the fly of Cisco and Juniper network routers, which are pretty much what glues the Internet together at the high end.



So these documents talk about, as I was mentioning before, this BananaGlee is a portion of sort of an exploit stack.  In the work I was doing, trying to understand this, I ran across some terms that I didn't know.  For example, one was "DNT Payload."  And I thought, well, what is DNT?  So in googling for that, I discovered that there was another source of this information that has been put together, sort of a coherent document that runs through all of the acronyms we know of, over and beyond what has been revealed by this NSA ANT.



So I created a bit.ly shortcut.  The bit.ly shortcut I created last week was all lowercase, bit.ly/nsa-ant.  This one, the new one, for another cool page, I called nsa-ref.  So bit.ly/nsa-ref, obviously short for reference.  And this is an incredible page of this NSA jargon.  And through that I learned that DNT is actually a commercial company, Digital Network Technologies, that is a subcontractor of the NSA.  So there's a commercial company that is generating these technologies for the NSA's use in doing this.  And so, for example, this BananaGlee acronym says - it's on that nsa-ref page - a software exploit made by Digital Network Technologies (DNT).



LEO:  Some of this stuff is for sale.



STEVE:  Yes.



LEO:  I can buy, for $50,000, SomberKnave, a software-based malware that bridges air gaps.  Holy cow.



STEVE:  Yeah.  In fact, one of these things, I don't think it's SomberKnave, I've got it in my notes down below, is an air gap-bridging USB cable, very similar to the VGA cable.  So it looks like a USB connector on each end.  And hidden in the connector on one end is a radio transmitter.  I don't remember if it's this passive RF reflector technology or not.  We'll get down to that in a second.  But, yeah, you're right, Leo.  And these are...



LEO:  What you really want is to rent, not buy, because you can't buy it, the Typhoon HX is a GSM base station router used to collect call logs from targeted phones.  You administer it with a laptop via SMS.  Standalone unit a mere $175,000 for a four-month rental.  So who makes this?  Who rents this?  Is this DNT, as well?  It's crazy.



STEVE:  Yeah.  So all of this hardware.  Some looks like it's - I don't know if DNT is software.  They seem to be software people.  I think the NSA has a bunch of their own hardware people because it's looking like this ANT division supplies the TAO, T-A-O.  That's the Tailored Access Operations.



LEO:  Here's the beauty part.  You could buy - you could pay for all this with bitcoin.  So you really - no, I'm just kidding. 



STEVE:  No, no, no, no.



LEO:  That's exactly what you can't do.



STEVE:  So as I'm looking at this, I'm thinking, how do Cisco's and Juniper's corporations react to this clear, blatant knowledge that their routers are compromisable?



LEO:  I bet there's two reactions - one public, one private.



STEVE:  Yeah.  Exactly.  Well, and the public one is we have never and never would provide any cooperation...



LEO:  Absolutely not.



STEVE:  ...willingly to the NSA.



LEO:  No, never.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  And, I mean, I think this is all behind their back.  I don't think they've done this.  I think, for example, as I mentioned at the top of the show, looking at this, reading this very carefully, I don't see evidence of remote exploitation of Cisco and Juniper routers.  There has to be a so-called "interdiction."  So, for example, the description of JetPlow:  "JetPlow is a firmware persistence implant for Cisco PIX series, a very popular Cisco product, and ASA (Adaptive Security Appliance) firewalls.  It persists DNT's BananaGlee software implant."  And so that's when I said, wait a minute, BananaGlee.  So then I look up - so BananaGlee, "a software exploit made by Digital Network Technologies (DNT) for Juniper NetScreen ns5xt, ns50, ns200, ns500, ISG 1000, ssg140, ssg5," on and on and on and on on model numbers, for another three lines' worth of them.  "Also works on Cisco PIX 500 series and ASA," and then another set of five model numbers, "series firewalls.  Used for exfiltrating data from target networks."



So there's BananaGlee, which is this technology from DNT, from Digital Network Technologies.  And then JetPlow is a firmware persistent implant for Cisco PIX series and ASA firewalls.  It persists DNT's BananaGlee software implant.  So it sounds like JetPlow lives in the BIOS and is used - sort of hosts BananaGlee.  And it says JetPlow also has a persistent backdoor capability.  That's another acronym, PBD, Persistent Back Door, that we also see throughout these.  It says:  "JetPlow is a firmware persistent implant for Cisco PIX series and ASA" - I guess they're being a little redundant here.  Yeah, it is repeating the same thing.  "If BananaGlee support is not available for the booting operating system, it can install a persistent backdoor (PBD) designed to work with BananaGlee's communication structure so that full access can be reacquired at a later time.  A typical JetPlow deployment on a target firewall with an exfiltration path to the remote operations center is shown above, and there's a diagram.  JetPlow is remotely upgradeable and is also remotely installable, provided BananaGlee is already on the firewall of interest."



So now this sounds like I misstated it, that BananaGlee is the lowest level thing in the BIOS.  And again, so notice that it's saying that JetPlow can be installed if BananaGlee is already - and remotely installable.  JetPlow can be remotely installed if BananaGlee is there first.



LEO:  I'm just glad the NSA pays attention to interoperability.



STEVE:  Well, actually I was impressed, as I'm running through this, that they really do.  They have the notion of a software stack of these exploit modules which are interdependent and hierarchical.  So if you get BananaGlee stuck into a router, into its BIOS somehow, which runs at a level below the OS, then it'll create a persistent backdoor, and that will then allow remote operators to install the higher level exploits as they are and become available.



So I've got so much else to talk about here, I'm going to skip over some of these.  It does look like, as I mentioned before, that this Chinese multinational networking and telecommunications equipment services company headquartered in Shenzhen, Guangdong, and you knew how to pronounce it, it's not...



LEO:  Shenzhen, Guangdong.



STEVE:  Shenzhen, Guangdong.



LEO:  It doesn't matter.



STEVE:  Is it Huawei?



LEO:  Huawei.



STEVE:  Huawei.



LEO:  Huawei. 



STEVE:  Their big router, and I remember seeing the name of it somewhere, well, the NSA project is HeadWater.  And it appears to install 100% remotely.  The document says:  "HeadWater is a persistent backdoor (PBD) software implant for selected" - I just cannot pronounce this name.  Huawei?



LEO:  Huawei.



STEVE:  Huawei?  Huawei routers.



LEO:  Forget the H's.  Huawei.



STEVE:  Huawei, ah, thank you.  "The implant will enable covert functions to be remotely executed within the router via an Internet connection.  HeadWater PBD implant will be transferred remotely over the Internet to the selected target router by Remote Operations Center personnel."  Okay, so again, this implant is transferred remotely, does not require a local install.  "After the transfer process is complete, the persistent backdoor will be installed in the router's boot ROM via an upgrade command.  The persistent backdoor will then be activated after a system reboot.  Once activated, the ROC" - that's the Remote Operations Center - "operators will be able to use DNT's" - and there those guys are again - their "HammerMill Insertion Tool (HIT) to control..."



LEO:  See, they had to have planned that one.



STEVE:  Yeah, HIT.



LEO:  HammerMill thing.



STEVE:  HIT, uh-huh, "to control the persistent backdoor as it captures and examines all IP packets passing through the host router."  Whoopsie.  And then here's another example of why it can't be coincidence:  "HeadWater is the cover term for the persistent backdoor for Huawei Technologies routers."



LEO:  You're never going to get it.



STEVE:  I am never going to get it.  Whatever it's pronounced.  "PBD has been adopted for use in the joint NSA/CIA effort to exploit [that] network equipment."



LEO:  [Laughing]



STEVE:  And then here it is.



LEO:  Nice.  Nicely done.



STEVE:  Thank you.  The cover name for this joint project is TurboPanda.  So, okay.  Panda had to have been chosen deliberately.  Oh, and by the way, the status:  On the shelf, ready for deployment.



LEO:  OTS.  But I really think these slides are old, though; right?  Because the hack on the iPhone is for the second-generation iPhone, for 2008.



STEVE:  Yes.



LEO:  I'm thinking that these slides are roughly 2008 era; right?



STEVE:  Yes, and they're all dated 2008.



LEO:  Yeah, so...



STEVE:  We understand that.  So this has all been going on and continuing.



LEO:  It's not up to date.  It's five years old.  This could...



STEVE:  Right.  And which again is another reason to think, okay, well, maybe Snowden was not the source of this.  Remember that there were three Montana things that we just sort of glanced over last week:  SchoolMontana, SierraMontana, and StuccoMontana.  Those are, respectively, for the Juniper J, M, and T series routers.  And so those are similar persistent backdoors that allow the NSA to get in.



LEO:  So I sense, by the way, a naming schema here.



STEVE:  Yes.



LEO:  Because those are all SMs.  And in fact somebody did say that the military often uses a codename generator that generates, not the names, but the two letters.



STEVE:  Ah, okay.



LEO:  And then a human will - and the example they gave, this was in the chatroom, is Operation Desert Storm was Operation DS.  And they added something that actually seemed appropriate, Desert and Storm, but really the designation was DS. 



STEVE:  Ah, got it.



LEO:  So in this case I think the designation is SM, and they distinguished the different hardware that it was a hack for with different S's. 



STEVE:  Right.  And it makes it more memorable and...



LEO:  Oh, yeah.  The human mind loves it.  It's an image.



STEVE:  ...and less ambiguous if it's, like, over a poor quality communications channel.



LEO:  Exactly.  It's like the phonetic alphabet, yeah.



STEVE:  So LoudAuto, here's details on a very cool passive bug, audio bug.  So LoudAuto says:  "Audio-based RF retro-reflector."  So that's what they're calling these.  "Provides room audio from targeted space using radar and basic post-processing.  LoudAuto's current design maximizes the gain of the microphone.  This makes it extremely useful for picking up room audio.  It can pick up speech at a standard office volume from over 20 feet away."  That is, where this bug is located.  It says:  "(Note:  Concealments may reduce this distance.)"  Yeah, if you put it in a box, it's going to be muffled.



"It uses very little power" - and it says approximately 15 microamps at 3 volts - "so little, in fact, that battery self-discharge is more of an issue for serviceable lifetime than the power draw from this unit.  The simplicity of the design allows the form factor to be tailored for specific operational requirements.  All components at COTS and so are non-attributable to NSA," meaning, again, Common Off The Shelf.



"Room audio is picked up" - and I should say they show a picture of this.  It is a little over 16/32 of an inch in maximum dimension.  The length of this thing is a little over half an inch.  So this is micro size and uses almost no power.  So you just tuck this anywhere and let it sit for years.



"Room audio is picked up by the microphone and converted into an analog electrical signal.  This signal is used to Pulse Position Modulate (PPM) a square wave signal running at a preset frequency.  This square wave is used to turn a FET (Field Effect Transistor) on and off.  When the unit is illuminated with a CW" - that's continuous wave - "signal from a nearby radar unit, the illuminating signal is amplitude modulated with the PPM square wave.  This signal is reradiated" - that is, by the bug - "where it is picked up by the radar, then processed to recover the room audio.  Processing is currently performed by COTS equipment with FM demodulation capability."  Then it lists some names and brands.



Then it says that "LoudAuto is part of the AngryNeighbor family of radar retro-reflectors."  And indeed, there are many.  There's one that can be stuck in a keyboard cable or in the keyboard itself.  And once again, like all these other ones, it doesn't itself generate a signal.  It needs to have a beam illuminate it, a radio beam illuminate it, and that is then able to sense the signal.  And notice the other thing about this retro-reflective technology.  It's necessary to mix the reflected energy with the incoming energy in order to demodulate this.  Which means that, even if you could passively pick up this reflection, you wouldn't be able to listen to it yourself because you need to have access to the correct phase of the incoming radar beam in order to perform this signal demodulation.  So just crazy, really cool technology.



LEO:  Just keep that in mind when you use the HannahMontana technology.



STEVE:  Exactly.



LEO:  And does it strike you that it's also completely possible - you ever read any Graham Greene?  One of his great stories, "Our Man in Havana" I think it was called, is about a completely innocuous, innocent tailor who is mistaken for a British spy.  And they start giving him money, and so he builds a phony network of spies and all of this stuff, pretending to be a British spy, but he's not.  He's just some little mousy tailor.  It strikes me, this is so novelistic, that it could just be some guy, maybe even within the NSA, made all this up.  Remember, this benefits the NSA.  They always say, oh, this is really bad because now the bad guys know what we're up to.  Well, first of all, this is five years ago, so this is - it seems to me that there could be a genuine value to the NSA in the sense that, look, bad guys, we got it covered.  We can hear everything.  You're screwed.



STEVE:  Don't even bother.



LEO:  "Don't even try because you're screwed" could very well be the point of all of this.



STEVE:  Just buy lottery tickets and hope.



LEO:  Yeah.



STEVE:  Because that's the only way you're going to...



LEO:  Don't attempt to attack us because, god, we've got stuff in your stuff that you don't even know about.



STEVE:  Yeah, you're right.  I mean, this is chilling.



LEO:  But it could be completely made up.  I mean, I don't, you know...



STEVE:  I'll just skim over some more of this because we're about done here.  IrateMonk modifies hard drive firmware.  It "provides persistence on desktop and laptop computers by implanting the hard drive firmware to gain execution through master boot record substitution."  So it doesn't matter if you reformat your drive, if you low-level format your drive, if you clean your master boot record off, because underneath that the hard drive firmware has decided that it wants the master boot record to be what it says it's going to be.



"This technique supports systems without RAID hardware that boot from a variety of Western Digital, Seagate, Maxtor, and Samsung hard drives.  The supported file systems are FAT, NTFS, EXT3, and UFS.  Through remote access or interdiction, UnitedRake or StraitBizarre [sp] are used in conjunction with SlickerVicar to upload the hard drive firmware onto the target machine..."



LEO:  It's SlickerVicar.



STEVE:  SlickerVicar, that works better - "to implant IrateMonk and its payload," it says, "(the implant installer).  Once implanted, IrateMonk's frequency of execution, dropping the payload, is configurable and will occur when the target machine powers on."  So essentially it sounds like this UnitedRake, StraitBizarre, and SlickerVicar, those are PC-level, like Windows-level exploits that briefly pass through your machine, burrow all the way down into the firmware of your drive, and then persistently live from there on.  And there ain't much you can do about it.  Wow.



LEO:  That's one SlickerVicar.



STEVE:  We talked about the keyboard is another one of these retro - a keyboard spy retro vector.  I learned something, and that is there's a project called GopherSet.  It's a software implant for GSM Subscriber Identify Module, that's SIM, the SIM card, Subscriber Identify Module.  So this is a SIM card.  "This implant pulls phonebook, SMS, and call log information from a target handset and exfiltrates it to a user-defined phone number via SMS."  So as I read that, I think, wait a minute.  A SIM card is just data; right?  No.  "Modern SIM cards Phase 2+," I'm reading from the slide, "have, conveniently, an application program interface known as the SIM Toolkit, or STK.  The SIM Toolkit has a suite of proactive commands that allow..."



LEO:  When we say sweep, we mean sweep.



STEVE: "...that allow the SIM card itself to issue commands and make..."



LEO:  What?



STEVE:  Yes.  Yes.  The SIM card itself...



LEO:  Who knew?



STEVE:  ...can issue commands - I know - and make requests to the handset.  "GopherSet uses STK commands to retrieve the requested information and to exfiltrate this data via SMS.  After the GopherSet file is compiled, the program is loaded onto the SIM card using either a USB smartcard reader or over-the-air provisioning.  In both cases, keys to the card may be required to install the application, depending on the service provider's security configuration."  So it's actually possible for your SIM card to run a program to query the other memory in your phone and exfiltrate that without your knowledge over SMS.  



Okay, and why did I grab MonkeyCalendar, aside from the fact that it's a wonderful name?



LEO:  My password.



STEVE:  Oh, because it goes a little further.  This implant pulls geolocation information from a target handset and exfiltrates it to a user-defined phone number via SMS.  So this gets loaded into your SIM card, and it's continually sending out, at whatever period they specify, your current GPS coordinates to an SMS phone number of their choosing.  Wow.



There is also something called Genesis, which it takes a standard consumer handset, and they change the guts to install an SDR, a Software Defined Radio.  So a spy, literally, an agent carrying this innocuous-looking standard cell phone, is able to scan, do a complete detailed RF spectrum analysis within this phone in order to record and perform an analysis on everything going on around them because this phone essentially has been retrofitted with complete RF analysis capability in something that's the regular size of the handset.  And there was one last thing.  Ah, CottonMouth, yes.



LEO:  Which is what you're getting after this long recitation.



STEVE:  It is what I mentioned before, is the USB cable that is - it's a hardware implant, obviously you need to go in and swap cables - which will provide a wireless bridge into a target network, as well as the ability to load exploit software onto target PCs.  So someone makes a midnight visit, swaps USB cables with this thing, and now you've got - there's an RF transceiver for so-called "air gap-bridging," software persistence capability, in-field reprogrammability, and covert communications with a host software implant over USB.  And back again, Data Network Technologies (DNT) is involved, along with StraitBizarre.  So, yes, this looks like to me StraitBizarre is OS-level stuff.  So, yes, the NSA, as you said, Leo, the bad guys might as well read this and just say, well, okay.  We're going to go straight.



LEO:  Yeah.  No more terrorism.  We give up.  We're just going to sell hotdogs in the bazaar.



STEVE:  Yeah.  So again, I don't think that Edward Snowden would have any problem with this.  This is what we would expect the NSA to do and to have, the capabilities we would like them to have, as opposed to doing wholesale data collection, which it looks like they may have less of here in the future.



LEO:  Yeah, yeah.  Well, Steve, this is a fun subject, and I'm sure there's a lot more you could have said.  But we probably should wrap it up at the two-hour mark.



STEVE:  I think so.  And I think we've certainly given our listeners a very good sense for what this technology is and how it works.  And that was our goal for revisiting NSA ANT, hopefully one final time.



LEO:  Steve Gibson is the Explainer in Chief at GRC.com.  That's where you can find 16Kb audio versions of this show for the bandwidth-impaired.  There's even text transcriptions written by an actual human being, one who owns her own farrier or something.  Elaine Farrieris [Farris].  And you can get that at GRC.com.  Will we do questions next week?  You going to do a Q&A?



STEVE:  Yes, let's do a Q&A.  It's been a couple weeks, so we will entertain questions, by all means.



LEO:  So you can ask a question at GRC.com/feedback.  And this doesn't have to be restricted to today's episode.  Any question about security or any topic Steve likes to address, you're welcome to leave.



STEVE:  Potpourri, a potpourri.



LEO:  That's why we like doing those.  You can also find full-quality audio and video at our website, TWiT.tv/sn for Security Now!.  But it's nice if you can watch live.  And this is our new time.  I should mention we're now on Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC, if you want to watch live Tuesdays.  And we do appreciate it when you come in live and join us in the chatroom.  But again, you can listen anytime.  Our goal is just to give it to you any way you want.  You want it, you've got it - audio, video, black-and-white, color, I don't - whatever you want.  GRC.com is also the home of SpinRite, let's not forget, the world's finest hard drive recovery and maintenance utility.  It even works in virtual machines.  And many other freebies that Steve gives away, including his port check.  Let's mention it again:  bit.ly/port - what was the number?



STEVE:  3276...



LEO:  4?



STEVE:  4.  32764.  Bit.ly/port32764.  You've got to have that closed.



LEO:  Yeah.  And it's an automatic check.  It'll do it all for you.  Just remember, 865 - no, no, that's wrong, 30 [mumbling].  It's in the show notes.  Show notes, by the way - hey, thank you, Steve - now available on Steve's website, as well.  He takes his notes - very nice notes this week, by the way, lots of pictures and so forth - and puts them up on his web page there at GRC.com.  Steve, we'll see you next Tuesday, God and the NSA willing.



STEVE:  Yes, Leo.  Thanks very much.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#439

DATE:		January 21, 2014

TITLE:		Listener Feedback #181  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-439.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll talk about the NSA speech by President Obama, and Steve will give his report card.  We'll also answer some of your questions, too.  It's a jam-packed Security Now!, up next.  Stay tuned.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 439, recorded January 21st, 2014:  Your questions, Steve's answers, #181.



It's time for Security Now!, the show that covers your security and privacy online with my good friend, Explainer in Chief himself, he's waving and pointing at his head, Steve Gibson.



STEVE GIBSON:  I am a talking head.  There's nothing below here.  I'm mounted on a tripod.  



LEO:  Do you wear - I never asked you this.  Do you wear shorts when you do the show, or do you wear pants at all?



STEVE:  Yes, in fact, I'll never forget the time I stood up to check something or get something, and you said, oh, you have no pants on.  And I said, Leo, on the audio podcast that really won't - that won't come across very well.  So better, better...



LEO:  Very funny.



STEVE:  Yeah, I have shorts mostly because I get worked up during the podcast, and I'll get too overheated otherwise.  



LEO:  Really.



STEVE:  So we kind of have, yeah, we kind of have a - yeah.  We have kind of a gloomy day today, so it's staying cool.  It's 74 degrees in the office, and some doves are building a nest...



LEO:  [Cooing]



STEVE:  ...outside.  Yeah, they're kind of nice to hear in the background.



LEO:  So today's a Q&A.  We haven't done one in ages, it seems like.



STEVE:  It is.  It was funny because I had to go digging back because we actually did a raft of them toward the end of the year.  We were doing them to sort of catch up.  And then we had all of our New Year's things going on, and then we had our New Year's catch-up episode.  So, yeah, #181 for Episode 439.  And we'll talk briefly because there's really not much to say this week about Barack's Friday announcement, what I call the "do nothing" NSA speech.  We've got some news on the famous Target retail PoS malware that we were expecting.  I want to revisit CryptoLocker a little bit because some numbers have come in on just how much of a windfall those bad guys made.  I'll talk a little bit about my TSA interview that I did last Wednesday and about Evan's note for a superior alternative that means you don't have to go to Sacramento.  And I have verified you can just go to SFO.



LEO:  Yeah.  Evan sent that note to me, too.  And, yeah, I'm curious.



STEVE:  Yep.  Also a little, sort of in miscellanea, I found a fabulous free email archiving solution for those email packrats among us.  I'm one.  Eudora, which I'm still using, just began to collapse under the weight of, I'm not kidding you, a quarter million pieces of email.



LEO:  Well, and Qualcomm stopped updating it; right?  I mean, it's orphan software.



STEVE:  Yeah, but it works fine.



LEO:  I guess email doesn't change that much.



STEVE:  Just like my XP.  And also some news about SQRL's password encryption technology.  I've become an expert on the Scrypt algorithm, which we talked about in a podcast many moons ago [SN-388].  Remember memory hard algorithms, which resist being accelerated by GPUs, FPGAs, and ASICs chips.  And of course it's a Q&A.  So we've got, actually, nine.  I don't know why, but nine felt like the right number.



LEO:  Given all the other stuff, you may be lucky to get to that.



STEVE:  Yeah, so a great podcast.



LEO:  Very good.  I'm excited.  So, let's see, Steve.  We should probably talk about the news.



STEVE:  Yeah.  I spoke many times last week about the upcoming speech or presentation or whatever it was, pronouncement, that we were expecting from Barack Obama, the current U.S. President, obviously, about his administration's reaction to the NSA.  We were hoping for something.  And essentially we got nothing.  The EFF, I suspected, would have a nice analysis of it, and indeed they did.  I created a bit.ly shortcut for people who are interested because - and you might want to bring this chart up, Leo:  bit.ly/ all lowercase b-o, as in Barack Obama, hyphen n-s-a [bit.ly/bo-nsa].  And this is their scorecard of his speech.  Basically, they gave him - they had 12 points, 12 major issues that they were hoping he would make some movement on.  And so they could have all been ones, in which case he would have scored a 12 out of 12.  As it was, at least half of them were zeroes, and there were only a couple that were ones.  And actually they were both, I think both of the ones were FISA comments.  One was oppose the FISA Improvements Act, which he is doing, and reform the FISA court, which he is doing.  Those were the two ones.



Overall he got a 3.5 out of 12, not even out of 10, out of 12.  So, and as I was listening to it, I was in real-time during the speech, most of it seemed just like punting, like he was saying, well, we will be in the future doing this, and we will be in the future doing that.  We're going to have a committee do this.  And a lot of stuff was being turned over to Congress.  So it's like, well, okay.  I guess, you know, I'm sure he did what he felt he should.  But mostly it was just sort of a nothing speech.  So I wanted to follow up on my having mentioned that that would be happening on Friday.  And it's like, yeah, okay.  Maybe he did all that he could.  I don't know.



LEO:  I have to think that you get in the - in fact, somebody said this, you know, because he was very, as a Senator, aggressively outspoken against this kind of government surveillance.  And somebody said, imagine day one, you just got inaugurated, you come, you sit down in the Oval Office, and they say, "Mr. President, here's the daily threat assessment."  And you go, oh, my god.  We've got to do something about this.  So I hate to rush to judgment, given that we don't, we just don't know how much risk there is out there.  But he has paid lip service, and I think it should be more than lip service, to the notion that we've got to balance protection with freedoms and constitutional freedoms.  What do you think about this, the NSA doesn't get to - somebody's going to collect the data, but the NSA doesn't get to store it.  They have to petition for a request.  Does that not seem like an improvement?



STEVE:  It does.  And really the way I think this should be set up, the only way that it is feasible is if there is a burden imposed on the providers.  And they don't want...



LEO:  They don't want this at all.



STEVE:  Yes.  They don't want it.  But I say, tough.  Look at what you're getting.  I mean, the amount of revenue you're generating and the piss-poor way you're treating your customers, typically.  I mean, the idea that I'm not using all my bandwidth in a month and so it resets at the beginning of the next month, and the idea that in many places I'm being charged for text messaging, I mean, that's just ridiculous.  I mean, anyway, they've got a sweet deal.



So given the cost of mass storage, the fact that cloud storage is essentially free for individuals now because it's so cheap to purchase drives, in return for the privilege of having the sweet deal that the providers have, they archive these records.  And they don't have to go back forever.  Ten years, for example, is fine.  And it is metadata.  It is not large data.  It is tiny little entries of a start and an end of a call and what account it was and what cell towers it was on, basically the metadata.  For one thing, it'll compress like crazy.  And tell them they have to store it for 10 years.  That's their obligation, in today's new world, if they want the privilege of being able to provide this service.  And then they have to have an infrastructure that allows them to respond in obviously automated fashion to approve requests for a query from that data.  That's the only way I can see that there is a believable wall between the government wanting this kind of data and the people who are holding it.  If a third party is set up, that will just be seen as a...



LEO:  Yeah, let's let Target store it.  Why not, yeah.



STEVE:  Precisely.  Well, or...



LEO:  It's got to be the phone companies.  It's got to be the telcos.



STEVE:  Well, or it'll just be seen as a surrogate for the NSA storage.  It's got to be fragmented.  The NSA has to put out a request to all the providers, and then they provide what they have, and then the NSA links it together.  And it's worth mentioning, also, that it's standing out that, for all of the furor that this metadata collection has generated, there has been no clear terrorism win in return for all of this.  That is, it turns out to be one of the weakest sources of information in terms of actually delivering verifiable results from what we know.



LEO:  Well, but again I acknowledge that we probably don't know everything, and maybe they can't talk about the wins for a variety of reasons.  I mean, one of the things that, you know, you can't - this has always been a problem with espionage and crypto, in fact.  Remember with the Enigma machine it was a real issue for us, the Allies, to use information they got from the German Enigma machine during World War II because it would be, in effect, an admission we'd cracked it.



STEVE:  Right.  They had to, like, set up fake convoys that would just by chance encounter these ships at sea and then radio in, in order to explain how they had the information.



LEO:  So, I mean, look.  I don't want to be an apologist, but I also understand completely that nobody wants to be the guy who said we're going to stop all of this spying, and then there's a terrorist attack the following week.  And then of course the howls for saying that you've hobbled the agencies, and you're not letting them do their job, and of course we got attacked.  This is very, very difficult.



STEVE:  I think the whole thing is a foreseeable, reasonable set of outcomes.  That is, again, as we mentioned last week, Edward Snowden is hated within the NSA.  I would say of course he is.  He is heralded in other freedom-loving organizations.  And again, of course he is.  I think that what we saw was an overreach in our own kneejerk reaction post-9/11.  It was please don't ever - you can have anything you want so that this never happens again.  And then we now understand what that means better.  And so there will be some compromise.  There will be some negotiation where we find a middle ground.  And I also think ultimately we're going to get used to this.  I think we're going to be surveilled.



LEO:  It's the new normal.



STEVE:  Yes.



LEO:  Well, and I think that's the bigger question, is given these technologies, the Internet and telecommunications, the kinds of technologies we rely on and we use every day now, is our conception of privacy really kind of antiquated?  Because, if you're going to use these technologies, it just kind of goes along for the ride that privacy might not be possible.



STEVE:  Back in the analog cell phone days, I remember that I had my Jeep Cherokee with the cell phone in the center console where you picked it up, and it had a spiral cord coming off of it because all the equipment was, like, stored under the back seat, and it had the antenna, I mean, the old-style analog cell phone.  And I remember also having a scanner at the time, which scanned those cell phone frequencies.  And it was moderately interesting to listen to some of these conversations.  These were conversations that most people didn't understand were radio.  I mean, it was in the clear.  It was right there.



And my point is that many times I would be having a cell phone conversation with my attorney, and I would say, "Okay, I will call you back when I get to the office because I'm heading there now, and I don't want to talk to you about this now," because it was just radio.  And so back then we were using a technology that was convenient, and it was incredibly insecure, so that anybody just scanning could be listening to one half, you only got one half of the conversation, which was sort of interesting because you could sort of guess what was going on on the other side of the conversation from the part that you could hear.



So step forward now 20 years, and we have the Internet and essentially the same sort of thing.  If you want to have a non-private meeting, a multi-way meeting over the Internet, you certainly can do that, with the understanding that it may not be as private as you think.  If you absolutely want privacy, then the five of you go meet physically somewhere and have a private conversation in a room that is hopefully secure.  So, yeah, I mean, it's a different sort of paradigm.  And it is the case that we've lost this notion of this being a private medium.



LEO:  Yeah.  It's very challenging.  And I think we speak a lot about - and certainly people who do this show and all of our audience, we're libertarians, and we don't want government intervention.  But I think it's important to raise the point that these are not, I don't think, evil people.  They're doing what they believe is right, and they are patriots, I would say almost certainly.  And the issue is that we do have a Constitution, and we do have some rights, and we've got to fight for those rights.  And I agree with that, as well.  So it's just - it's tough.  And I think that part of the problem really may be this larger global thing that we've moved into a world of tech.  This is a change, as you said, this is inevitable given what's happened in technology, that, A, because you could collect all this and analyze this massive amount of big data, that somebody would.  And it was just inevitable.  And so maybe we have antiquated notions of privacy because it's crazy to assume that you can use all this stuff freely and get all the benefits of it and not be spied on.



STEVE:  Well, and this, too, is no big surprise.  It's always the case that the social side lags behind the technology side.  Technology is zooming ahead, creating new capabilities.  And it's the understanding of it and the social adapting that takes time.  I think that kids who are growing up now who have never known a pre-Internet world just sort of assume that stuff is being monitored.  That's just - it comes with the territory.  So their whole life, as they're living it over the next hundred years, will be framed differently than ours was, where we actually used to imagine that paper mail coming to our mailbox hadn't been opened and inspected, and that there wasn't a keyword search being done on all of our mail as it went to and from for the purpose of monetizing our eyeballs with relevant ads connected to the email that we were reading.  But that's just - that's today's world now.



LEO:  What a world, what a world.



STEVE:  So we do have some more information about the point-of-sale software, malware, which was installed in the 40,000 Target point-of-sale machines, apparently.  It was originally generated by a 23-year-old Russian youngster.  And apparently the guy who sort of has been initially targeted was some guy named Sergey Taraspov.  And he's, I think, 17.  And apparently he was doing, like, tech support for the 23 year old.  And this 23 year old has formally confessed to being the original developer of this.  The Target point-of-sale devices are - wait for it - XP.



LEO:  Of course they are.



STEVE:  They're running a modified version of Windows XP, the embedded version, which essentially is a sort of a toolkit.  I remember looking at XP Embedded, like, years ago, wondering if maybe that would be a useful platform for SpinRite to run on, if I could get a license for that.  But I'm not paying Microsoft any per-instance licensing, so, no, that didn't make sense.  But I did learn about it.  And it's essentially - it allows you to produce an XP from, like, a componentized model, where you only choose the components of an XP OS that you actually need in your embedded application.  So it ends up being much smaller and arguably has a much smaller attack surface.  Unfortunately, it still does run XP applications.



And so since it's crossing over into XP's world, this is a piece of malware which runs on XP, which is able to do what's called "memory scraping."  Essentially it opens the PoS process, thus gaining access to the point-of-sale process memory.  And it just does a - it does memory scraping.  It searches memory for the credentials while they're briefly in RAM after the card has been swiped and the user has entered their PIN code.  It captures those and pulls them over into its own process space.  So we know that this thing is called BlackPOS.  And we've got our weekly trash pickup happening next door.



LEO:  We're here to pick up the trash.  You just, you know, anything you want to throw in here, bills, letters, anything, documents, passwords, you should go right ahead and throw those in there.



STEVE:  So as late as January 16th no antimalware software is recognizing this.  So it's been known for, like, it was first seen back in September of last year, of 2013.  And it is believed that Target discovered it around mid-December because it was briefly uploaded to the Google-owned VirusTotal site and appeared there and then was taken down not long after.  So there's a research lab, Seculert, that found the sample and actually executed it under a virtual environment of Windows XP.  And they discovered that it has two stages.  It first infected their checkout counters, their point-of-sale devices, to extract credit card numbers, and it collected them for six days.  Then it uploaded those to another machine in Target's network.  And I did notice some reports saying that part of the way they got in was poor passwords.  Apparently the internal passwords were easily guessable, and so the software used those in order to move the collected customer data onto the central server after six days.



And then it was exfiltrated to another website somewhere else in the world, and that location was never given.  And that appeared to be a hijacked website that was running an open FTP server.  So that FTP server collected this data.  And then a third virtual private server located in Russia was used to download that stolen data from that hijacked intermediate server over the course of two weeks, pulling a total of 11GB of stolen sensitive customer information over the course of that time.  And these guys say that there was no indication, given the FTP logs, the only connections they saw were to Target servers, or from Target servers to this FTP server.  And they didn't see any indication that the also-suspected Neiman Marcus compromise was also going on at the same time.  However, in very up-to-the-minute rumors which are beginning to surface, there are apparently six other retailers that have been identified, but not disclosed, that also appear to be victims of this software.  So that's happening.



LEO:  You want me to mention the garbage man again?  If you're hearing - it sounds like perhaps Steve has something going on behind the scenes.  It's just the garbage guys.  They'll be gone in a minute.  Yeah.  There's always something.  When you live in suburbia, you've got...



STEVE:  That's right.



LEO:  ...your garbage men.  You've got your lawn...



STEVE:  We had construction work going on this morning.  And I thought, oh, lord, how long is this going to go on.



LEO:  It's fine.  It's not...



STEVE:  Yeah.



LEO:  It's fine.  Don't worry about it.



STEVE:  It's a real environment.



LEO:  Exactly.



STEVE:  So, CryptoLocker.  I wanted to touch back on CryptoLocker because Dell SecureWorks, they have something that they call the SecureWorks, I mean the Dell that we all know about, something called the Counter Threat Unit Threat Intelligence.  And what I liked about this was they had a very sort of executive summary they put together for discussing CryptoLocker.  So they said, as far as the crypto side goes - and I liked this because it was very clear, very succinct, and also used the latest information that we have.



They said:  "Instead of using a custom cryptographic implementation like many other malware families, CryptoLocker uses strong third-party certified cryptography offered by Microsoft's CryptoAPI.  By using a sound implementation and following best practices, the malware authors have created a robust program that is difficult to circumvent.  The malware uses the Microsoft Enhanced RSA and AES Cryptographic Provider to create keys and to encrypt data with the RSA and AES algorithms," as we talked before, public key and private key technology.



"The encryption process begins after CryptoLocker has established its presence on the system and successfully located, connected to, and communicated with an attacker-controlled command-and-control server.  This communication provides the malware unit with the threat actors' RSA public key, which is used throughout the encryption process."



Many people have had questions about which drives CryptoLocker would infect.  And this made it very clear:  "The malware begins the encryption process by using the GetLogicalDrives() API call to enumerate the disks on the system that have been assigned a drive letter, e.g., C:.  In early CryptoLocker samples, the GetDriveType() API call then determines if the drives are local fixed disks or network drives, either DRIVE_FIXED or DRIVE_REMOTE, respectively.  Only those two drive types are selected for file encryption in early samples.  Samples since late September also select removable drives, which can include USB thumb drives and external hard disks, as well.  After selecting a list of disks to attack, the malware lists all files on those disks that match the 72 filename extension patterns that the drive encrypts.  Over time, the threat actors adjusted which types of files are selected for encryption.  For example, PDF files were not encrypted in very early samples, but were added in mid-September."



Okay.  Under "Action":  "Each file is encrypted with a unique AES key."  And that's obtained from Microsoft's cryptographic provider random number call.  So it's unfortunately a high-quality random AES key.  And that key is then in turn encrypted with the RSA public key received from the command-and-control server.  Consequently, due to the nature of public key crypto, you have to have the private key to decrypt that AES key.  And that is never on the computer until the person pays the ransom.



"The encrypted key, plus a small amount of metadata and the encrypted file contents, are then written back to the disk, replacing the original file."  And as we said a couple weeks ago, there's like a little header shim added to the top of the file.  And then also - oh, and then it explains that:  "As a form of bookkeeping, the malware stores the location" - and I haven't seen this anywhere else, by the way, so this is new information - "the malware stores the location of every encrypted file in the Files subkey of the HKEY CURRENT USER\SOFTWARE\CryptoLocker registry key."  And that may also be CryptoLocker_0388.  But so there's a registry key there that has the path of every file that was encrypted.  And apparently that's what the decryption software enumerates in order to go find all the files that it encrypted in order to decrypt them after you've paid your ransom.



Then, after finishing the file encryption process, and this was also important:  "CryptoLocker periodically rescans the system for new drives and files to encrypt."  So if anything comes along, you plug in a USB drive, if the drive is there during one of these rescans, it'll grab it and encrypt those files, as well.  "The malware does not reveal its presence to the victim until all targeted files have been encrypted.  The victim is presented with a splash screen containing instructions and an ominous countdown timer," and so forth.  And finally it talks about payment options, which we have only had fragmentary coverage of, but we'll wrap this up with an amazing analysis of the amount of bitcoins and their current value which have been transacted, because that has been tracked back.



So, payment:  The ransom amount varied in very early samples and, as we know, we covered this, settled at what was essentially $300 U.S., or two bitcoins, back in the early days when CryptoLocker was introduced and a bitcoin was valued at $150.  But in their analysis they say:  "Dramatic Bitcoin price inflation in the later months of 2013," which we've talked about, "prompted the threat actors to reduce the ransom," first to one bitcoin, then to half a bitcoin, and then finally to 0.3 bitcoin, where it remains as of the date of this publication.  And that's where it is now.  So, and then this talks about how various payment options were offered, and ultimately MoneyPak and Bitcoin are where things settled out.  And apparently the malware does a scan for the CryptoLocker command-and-control server every 50 minutes, waiting to verify that the payment has been accepted.  And then, when it has, it'll then obtain the private key and start the decryption process.



So the reason I've been saying since this first arose that this was unfortunately going to set a precedent for the future is just how profitable this has been.  Ziff-Davis did some research using some of the bitcoin chain tracking software, tracing four addresses which were used and were determined from multiple CryptoLocker victims who, after paying their money, made public the address that they had sent payment to.  The CryptoLocker extortionware acquired a total of 41, just shy of 42,000 bitcoins, 41,928 bitcoins.



LEO:  Wow.  Wow.



STEVE:  Yes.  And, see, that makes sense when you multiply it by, from another standpoint, the known number of infections was somewhere between 200,000 and 250,000.  So 41,928 bitcoins at today's value of $960 per bitcoin, means that this generated more than $40 million.



LEO:  Wow.  A million dollars a day, says Violet Blue on...



STEVE:  40 million.  Yes, in fact in one day there was - they tracked - in one day they tracked a million dollars' worth of bitcoin payment.



LEO:  All going to the same bitcoin address.



STEVE:  Yup.



LEO:  Wow.



STEVE:  So the bad news is all these guys did, remember, this was written in C++, so they used the built-in API, the Cryptographic API sitting there in Windows.  Didn't have to bring any crypto themselves.  I mean, that's trivial to do, but they didn't have to.  It's all there in Windows.  They simply wrote some software that did the crypto right, and they used the state-of-the-art botnet technology we've talked about where, based on the calendar, a large set of candidate domain names, random-based, again, cryptographically derived, date-based, a huge variety of date-based domain names, one or two of which were actually valid, making it very difficult for bad guys to track them down.  And so basically a state-of-the-art network arranged for command and control of this.  And they netted themselves $40 million.  What this means is we've not seen the last of it.  And this unfortunately is - it's too lucrative not to be copied.



LEO:  It's not - it's interesting that that was a single bitcoin address, implying that that was a particular, one particular person.  But there's no reason to assume it's just one person doing CryptoLocker.  Or is there?



STEVE:  Yeah, I think it's one person.



LEO:  Just one guy.



STEVE:  Yeah, well, or one organization.  I mean, it was well written.  It may be organized crime in Russia.  But it's believed to have Russian roots from looking at the code.  But I think it had a single origin.  There was a copy that we talked about, not written in C++, written in Delphi I think it was.  And there are some others which there's some buzz in the online forums of other things coming, but that haven't happened yet.  And there's been some not-quite-done-as-well me-toos already.  But it just makes too much money.  This is way more profitable than putting some clickware on someone's machine that's going to click on ad links.  This is the big-time now.



LEO:  All the major antiviruses recognize it now, and of course awareness is raised.  So I presume it's slowing down.  I don't know.  Is it?



STEVE:  Oh, yeah, yeah.  Yes, in fact, there are some charts that show the rate of infection, and it is now way, way down.



LEO:  So you make your money quickly and get out.



STEVE:  Yup, exactly.  Well, I mean, it's, look, many months.  And it was getting, it was biting a lot of people.  So there will be another one, and it will not be seen by antimalware, and it will just - all it has to do is copy this.  Do the crypto right.  There's been total coverage of it.  So even someone who has no idea how to do it right, now they know how to do it right.  It's just, as I keep saying, it's just not hard to do this anymore.  All of the technology is available.



LEO:  Yeah.  I love that they're using a Microsoft library for the crypto.



STEVE:  Yup, yup.  And I ran across this in some of this coverage.  Carbonite, one of this show's sponsors, was reported in November to have been dealing with several thousands of phone calls from CryptoLocker-infected victims because, remember, Carbonite does not map a drive letter, which means that the Carbonite data stored was not accessible to CryptoLocker.  And so what you wanted to do was you wanted to make sure that Carbonite didn't back up your encrypted files for you; or, if it did, that you went back to a further, pre-encryption version.  But now Carbonite has a dedicated team for dealing with CryptoLocker recoveries, meaning that they have trained...



LEO:  I hate to say it, but it's good for their business.



STEVE:  Yeah.  They've trained up a subset of their tech support people to specifically help people with recovering from CryptoLocker.



LEO:  Wow.



STEVE:  Yeah.  So we have a friend of the show, you and I, Leo, Evan Katz, who I think he hails from the East Coast, but he was out here in sunny L.A. when he sent you a note and copied me on it.  He travels a lot.  And so he said:  "Re TSA pre-check," he said, "you probably do not want to get it," essentially addressing you, Leo.  He said:  "Rather, you and your family and friends should do the global entry program run by the Department of Homeland Security," which is of course distinct from the TSA.  Evan continued, he said:  "The reason why you want to do global entry and not pre-check is a global entry includes very expedited coming back into the U.S. from overseas, and pre-check does not."  And so, you know, I'm not a big overseas traveler.  But so certainly, when you've been leaving the country, Leo, that certainly makes sense for getting back.



He said:  "Moreover, the DHS program has many more locations that you can go to which will be much closer to where you live."  And I verified that.  We talked last week about how your closest TSA PRE was Sacramento, whereas I verified that DHS has an office at San Francisco Airport.  So way more convenient.  And he says:  "And the DHS program costs only $15 more than pre-check."  That's correct.  Pre-check is $85; the DHS program is $100 for the same five years.  Anyway, so he says - he signs off saying hope all is well with you and wish you all the best and so forth.



So I did, myself, I did my TSA PRE check screening Wednesday, so I'm now officially - I get something within 21 days in the mail.  And they fingerprinted me.  Interestingly, my left hand wouldn't fingerprint at all.  We tried, like, eight times to get my four fingers of my left hand to register, and they wouldn't.  And what I noticed was on the screen it was doing a feature extraction in real time, right there.  So, for example, first I did the four fingers of my right hand.  And it took a couple tries, but then it worked.  And then they wanted both thumbs at the same time, so I gave them both thumbs, and that worked.  But when they wanted the four fingers from my left hand, and I'm left-handed, maybe I just don't have any fingerprints over there.  I don't know.  And I was looking at the screen.  You could see, like, it imaging.  And there was just nothing recognizable as fingerprints coming up on the screen, no matter how, I mean, he had me try eight times.  And then he said, okay, you don't need them.  I was like, oh, okay, fine.



So it was sort of strange.  And so basically it was an interview.  It confirmed the information that I filled in online.  And I'm annoyed that this only lasts five years because I'm probably only going to travel five times in the next five years.  I go home for the holidays, basically.  But still, it's such a fabulous program, especially for anybody whose business has them traveling a lot.  I just can't recommend it highly enough.  It is an absolute win.



LEO:  They want to know what - so where did you do your Q&A for the TSA PRE?



STEVE:  I had to go up to Long Beach.



LEO:  It's not an airport.  You go to a government building.



STEVE:  Yeah, oh, and, boy, this thing was really low rent.  I was thinking, okay...



LEO:  No, you want government buildings to be low rent.  Understand, we're paying the rent.



STEVE:  I am glad I'm there during the day and not at night.  It was Suite E105, and there was like a tractor-trailer dumping ground next door.  It was in the - and there was, like, old oil wells being pumped on the other side in Long Beach.  It was way - it was the wrong side of the tracks.



LEO:  And what did they ask?  What kind of questions did they ask?  How do you feel about al Qaeda or anything?  No.



STEVE:  No, nothing, not at all like that.  They asked me to read the things that I had already filled out online, which were where were you born, you are a U.S. citizen, I mean, nothing about my philosophy, nothing about my past.  Basically, are you a citizen?  Is this your current address?  And that's it.  I mean, it was just sort of to look at me in the flesh.  There was a camera aimed at me, so I assume at one point either I was being videoed or a picture was snapped, as is the case with a passport.  And they were - it was like a fingerprinting center.  They were doing this sort of thing, identity screening, for other organizations or agencies also.  So it was like it was a multipurpose setup.



LEO:  So presumably the real check is against you and no-fly lists and criminal record checks and things like that.  That's all done in an automated fashion.



STEVE:  Well, and what's so bizarre, too, is that people are reporting that they're getting random TSA PRE on their boarding passes.  Just sort of...



LEO:  Shhhhh.  Shhhhh.



STEVE:  Yeah, like when Jenny said she never went through it, it's right.  She just lucked out and got random PRE on her boarding pass.



LEO:  [Whispering] That never happens.



STEVE:  Oh, okay, yeah.  And my point is, as a security guy who's always been screaming about how ridiculous it is that I have to take my shoes off and be patted down and be body scanned when I'm flying 500 miles north to San Francisco, here they're just sort of saying, oh, you know, don't bother with that.  We've selected you at random from a list, and you don't have to do that today.



LEO:  Weird.



STEVE:  It's like, what?  Then why does everybody else have to?  Oh, it just makes my blood boil, the whole nonsense of all this.  Okay.  So, Leo, you're going to need - center yourself securely over your ball.



LEO:  I'm on my ball.  Okay, yes?



STEVE:  My copy of Eudora, which I'm still using on XP, was beginning to have problems with the - it might have been the 53,000 pieces of Security Now! email.



LEO:  You don't even do email, I thought.



STEVE:  No, no, that's where the Q&As come from.



LEO:  Oh, the Q&As go there, okay.



STEVE:  Yeah.  So I have received 53,000 pieces of email from Security Now! listeners over the course of this, what is it, 9.5 years or something.  Or maybe we're ninth year, and it's 8.5 years.  Anyway.  And in addition to that, I had 200,000 other pieces of email because I don't ever want to throw them away.  And it's very handy to, like, what was that something or other?  And so I go searching through it and find something.  Anyway, Eudora was just collapsing completely under the weight of this and had been getting worse and worse and worse for maybe about the last year.  Finally this weekend I thought, okay, I have to do something about this.



My point is, the point for bringing this up is I am now, oh, my god, I am in heaven.  I found something free which I can recommend to all.  I know among our listeners there are people like me.  There are people who just want to be able to find a piece of email that they're sure they received or sent 10 years ago, and whatever means they have of managing it now might be causing problems.  So MailStore.com, m-a-i-l-s-t-o-r-e dotcom.



There's two versions of this thing.  There's Mail Store Server, which is their commercial side, which, eh, it's a couple hundred dollars for five client licenses.  And then there's Mail Store Home, which is completely free.  And it is unbroken completely free.  I mean, it works great.  It's what I've ended up using because it was enough for me.  I didn't like Mail Store the commercial version, only because it occupied, like, 50 to 100MB for the server component always running in the background, and then the client when you ran it.  And I didn't want this thing running on my server because I like getting my mail off of the server, just for security's sake, and having it all be on my own workstation.  So basically this is a very nice...



LEO:  This is a good idea.  I like this.



STEVE:  Yes, a very nice indexer.  So either the home - the commercial version has some additional features.  The home version will pull from Microsoft Exchange, Google Mail - now, there's an example, Google Mail, all these people who are using Google Mail, and Google has all your mail.  Well, all you have to do is turn this thing loose on your Google Mail account.  It will suck it all out of Google and index it and store it for you on your own drive.  You can tell it where you want it to go, so it could be on an offline drive or some other drive than your normal work drive or on a network drive.  Works with IMAP and POP3 and others.  For local systems it can pull from Outlook, Outlook Express, Windows Live Mail, Thunderbird, SeaMonkey, and also EML, MSG, and MBOX files.  So Eudora stores everything in MBOX files.  So I was able to just have it - basically it just sucked everything out of all of my various folders in Eudora and indexed them very quickly.  You can also export, without any encumbrances, anything that it has archived.  So you can put stuff back out of it to Exchange mailbox, IMAP, or mail it to any email address via SMTP.  And it also supports Outlook, Outlook Express, Thunderbird, and SeaMonkey for exporting in addition to these various email file formats.



Anyway, I love it.  So what I have now is Eudora is stripped back down and is running at full speed again because, for example, all of those Security Now! emails are indexed.  And the indexing system and the searching system is spectacularly fast.  I can put in any - oh, and it understands regular expressions and so forth.  I can put in any phrase that I think I dimly remember was in an email somewhere, and almost instantly I am looking back through time at those things where it occurs.  And I know that contemporary email systems offer that feature, too, and certainly you can search your Google Mail and so forth.  But if you'd like the control of a very nice indexing/archiving system, I can't recommend this thing highly enough.  And it's free.  So I just wanted to share it with our listeners.



LEO:  I'm looking at a variety of similar programs.  A lot of them are commercial.  A lot of them do cloud, which of course you wouldn't want.  But the reason I am is because I'm on a Mac, and this is Windows only.



STEVE:  Ah, okay.



LEO:  And there are some open source solutions that are cross-platform and so forth.  I mean, the idea is fairly simple.  You pull down all the mail and store it in a file and then index it.  But so I think this is a great idea.  I found one called Got Your Back that's an open source Gmail backup program that works cross-platform.  But I'm sure there's others, as well.  So, good.  A great idea.  And, you know, I just leave everything in Gmail because that was the promise of Gmail originally is just store everything there.



STEVE:  Now, where is - everyone knows your email address, Leo.  That's not a secret, I realize.  Where is all that email?



LEO:  Well, that's what I'm saying.  It's on Gmail.  You just leave it.



STEVE:  Even though you don't have a Gmail address?



LEO:  Oh, yes, I see what you're saying.  So the address I use actually goes through two servers.  It goes first to - where does it go first?  I think first to Gmail for spam removal, and then to another IMAP company, a commercial IMAP.



STEVE:  So you had Gmail pulling that account.



LEO:  It pushes to Gmail.  So basically you hit Leoville.com, the server just says, you know, it has an MX record, says I don't do mail, but these guys over here at Google seem to.  And so everything goes boom, bounces off my server to Gmail, where it's stored.  And then I pull it from Gmail.  I can't remember which - truthfully, I don't remember who gets it first.  But both have it.  And Gmail has such good antispam features that I always run it through Gmail.  But that way you can keep it forever on Gmail.  But you keep it on Gmail.  Be nice to have a local copy, I think.  Yeah.



STEVE:  So Jenny and I saw a movie yesterday.  We're in miscellanea time, if you hadn't realized.  I just wanted to give a shout-out to the new Tom Clancy movie, "Jack Ryan:  Shadow Recruit."  I loved it.  I mean, and I also loved "Patriot Games" and "Hunt for Red October" and "Clear and Present Danger" and "The Sum of All Fears."  So consider that.  If you are a listener who also loved all of those, and that kind of movie, you've got another treat in store because this was just, oh, my goodness, it was rip-roaring wonderful.  It was just spectacular.  And, boy, Keira Knightley is easy to look at, too.  So, yeah.  Recommendation.



LEO:  Good.



STEVE:  GRC is about to get true quantum random numbers.



LEO:  Ooh.



STEVE:  Yes.  This came a couple days ago.  It's from a company in Finland that produces a USB dongle - and here is a picture of it, holding it up in front of the camera there - which uses, we've talked about this before, it uses a reverse-biased semiconductor junction to generate wide-band Gaussian white noise.  The noise is amplified and digitized through an A/D converter.  The raw output bits from the A/D are then further processed through an embedded microprocessor to combine the entropy from multiple samples into each final output bit, resulting in a random bitstream that's practically free from bias and correlation.  And so what I'm going to do is that will be plugged into GRC's server, and the server will be pulling from it.  The data rate from these is typically not super high.  If you want really super high, then you can spend more money.  But this is several hundred thousand pseudorandom - or, I'm sorry, I'm in the habit of saying "pseudo."  This is not.  This is the holy grail of random.  This is absolutely quantum phenomenon unpredictability.



So what GRC's server is going to do is fill up a big ring buffer of this.  And then anytime someone goes to GRC's random, you know, the Perfect Passwords page, I will pull a set of truly random numbers from this generator and use them to seed the existing algorithm, which is now just running forward.  And so essentially every single person who goes to the page will have truly random numbers that seed this otherwise really good pseudorandom number generator because I want to be able to handle a high traffic level, which that page is now generating.  But the pages will, as soon as I get this installed, and this will be some time in the future, true random numbers.  And I will let everybody know when we switch over.  Actually, I'll put a picture of this on the page and change the diagram to show that we're actually pulling from a stream of the universe's entropy.



LEO:  Isn't that a beautiful thing.



STEVE:  So I got a nice little note about SpinRite.  And the guy, for whatever reason, said "Please keep my name off the air for this testimonial."  And he just said, "Thanks again for a great tool.  I use it on all my drives personal.  It has even brought back some drives that were getting recycled.  If I came across a disk that failed a DBAN DoD wipe, I would run the disk on SpinRite at Level 1 until completed.  Then, if it failed DBAN again, I would run the disk through SpinRite at Level 2.  If again the disk failed at DBAN, it would be run at SpinRite Level 4. Only 1 drive out of 100," and he says "literally, needed a drilled-platter treatment.  For every other dead drive, SpinRite was able to bring it back to life for DBAN wiping."



So this guy had drives that had died that he had compromising information or private information, I mean, and just really any drive that dies you probably don't want anyone else getting access to that data.  So it was often the case, since the drive had died, that DBAN - and by the way, DBAN is Darik's Boot and Nuke, D-a-r-i-k-'-s, Darik's Boot and Nuke, which is as it sounds, a bootable media.  I think you can set it up for either CD or USB.  And it boots a little environment that runs this program that will do a relatively good wiping of your drive.  The problem was these drives had died, and so DBAN wouldn't run.  So he wasn't using SpinRite to bring them back to life to use them, but mostly to be able to run DBAN on them.



And so the good news is, not long from now, that will no longer be necessary because there will be a product, an inexpensive product from me, which has already been named, and I've had the trademark for it for years, and that's called "Beyond Recall."  And so what the plan is, as soon as I get SpinRite 6.1 finished and out the door, I'm then going to basically take the core of that new technology that I developed to make 6.1 run so fast and repurpose it as a GRC-grade drive-wiping tool, which just ought to blow the doors off DBAN and everything else in terms of its performance because it will use, for example, the 32MB buffer technology that I've got running already in the work that's been done on SpinRite 6.1, where we can do multiple terabytes in the course of a few hours.  And so it will bring that kind of wiping, and actually it'll be the second commercial product that GRC has.



LEO:  After all this time, that's only your second product?



STEVE:  Yup.



LEO:  Isn't that great.



STEVE:  It's funny, I was considering and proposed putting it into SpinRite.  And the chorus was unanimous among all of the guys hanging out in the spinrite.dev group at GRC, no, no, no, no, no, do not put something that wipes data in a program that restores data.  And that's like, oh.  How about if I made this green, then?  How about, like, red and flashing neon?  No, no, no, no, no, no, no.  I said, okay, fine.  If you're going to make me charge more for it, then I guess I will.  So...



LEO:  How much are you going to charge, do you know?



STEVE:  Maybe 19 bucks?



LEO:  Okay, yeah.



STEVE:  And it'll live forever and run.  And you can run it on all your drives and so on and so forth.



LEO:  Very nice.  Very nice.



STEVE:  Yeah.  And, I mean, again, you can use the free one from DBAN, or you can use Beyond Recall.  And I don't even know what it's going to do yet except a perfect job.  Which means understand about the relocated sectors and understand about drives that support their own low-level formatting or their own ATA wiping.  And whatever it is, it'll do the Cadillac job of wiping a drive.  So everyone has my guarantee of that.



LEO:  How cool that you're doing that, thank you.



STEVE:  And there is a chart that came out.  I tweeted this today.  Backblaze, the big cloud storage folks, they just blogged today a blog posting:  "What Hard Drive Should I Buy?"  I imagine if you just google "what hard drive should I buy," that'll probably take you there.  And scroll down to that bar chart, Leo, because I've got it in the show notes.



LEO:  The annual failure rates.



STEVE:  Yes.



LEO:  It is way lower on...



STEVE:  Hitachi.



LEO:  ...Hitachi's.  Seagate's way higher.



STEVE:  Yeah.  And in fact they're seeing, in one case, 120% annual failure rate on Seagate drives, meaning they don't even last one year.



LEO:  Wow.



STEVE:  Yeah, the ones...



LEO:  So Western Digital's kind of in the middle and fairly consistent.  But Hitachi's way down there, below 2%.



STEVE:  Yeah, now, the bad news is that Western Digital bought Hitachi.  So we hope they leave them alone.  But that's apparently - Hitachi at the moment seems to be the sweet buy.  They're a little more expensive.  And I mentioned, too, I saw a bunch of dialogue about warrantees, that warrantees are important.  And I had also mentioned already that, yes, that's true, and that the drive manufacturers very quietly snuck the warrantees down.  They used to be three years.  They're now one year.  And so they were realizing, wow, we're losing too much revenue because our drives are no longer lasting three years, which is a chilling fact.  And it's a reason I'm selling SpinRite to this day.



LEO:  They point out that they haven't had any Toshiba or Samsung, or enough Samsung and Toshiba drives, for good statistics.  They do have quite a few.  They have 12,000 Seagate and Hitachi drives, almost 3,000 Western Digital drives, and then a handful of Toshiba and Samsung drives.  So this is probably statistically relevant.  Although I would point out that most of these drives are more than a year old, in some cases two and more years old.  And so as a result what you're buying today may not be the same thing by any means.



STEVE:  True.  Also it is the case, and they mention this, that they generally are doing write-intensive work, not read-intensive work.  Whereas most users use of drives is the reverse.  It's read-intensive and barely writing.  So that's also worth keeping in mind.  And the drives are never being powered down.  That's actually the way I run all of mine.  My servers are never powered down, and my own workstations here are never powered down.  Drives really seem to last a long time if you just leave them alone and let them - don't get them too hot, and you let them just keep spinning.



LEO:  We've got questions, nine of them.  We're going to get to those in just a second.  Yes?



STEVE:  Yep.  I just wanted to give people a little update on SQRL.  Code exists now.  I will, by this time next week, it will be online and available for download if people want to play.  It's not SQRL code yet.  This is - because, again, I'm marching forward, laying down a foundation of technology as we go.  This is the password-encrypting technology that deliberately takes five seconds on a smartphone, or maybe 30 seconds if you're wanting to export a key, like your galactic master identity key, where you want - obviously you want to keep it safe.  And you're exporting it so that it's going to be safe, but you want to put it under a password which cannot be accelerated.



And so we do a couple things.  First of all, we needed a process that could last 30 seconds.  And it turns out there weren't any.  I mean, nowhere is there a means of having something take 30 seconds.  No existing technology does that.  So we have developed it because that's what we want.  We want something so resistant to brute force attack that a brute-force attacker, no matter how much technology and desire, and I mean even the NSA, cannot crack this.



So on one hand we want it to take a long time so that every single guess anyone makes, even you, even when you put the right password in, you're going to have to sit there and wait 30 seconds.  Well, that's not a problem if it's for importing your offline-saved galactic master password.  But even when you're authenticating to your phone, the idea is, remember, that SQRL provides slam-dunk replacement for username and password.  But you still need to prove it's you using your phone.  So there our feeling is, eh, five seconds, if you only have to do it, like, whenever you run SQRL, that's not too long to wait for the security of a bad guy having to wait that long to guess those passwords.



So what we did was we created this notion of using Scrypt, S-c-r-y-p-t.  That was the technology that Colin Percival developed for his Tarsnap multiplatform cloud backup solution.  We've talked about that.  Tarsnap is a very good multiplatform solution for allowing people to do offsite storage, powerfully encrypted.  He wanted something better than Bcrypt, which is all that was there at the time.  And of course we've talked about PBKDF2, Password-Based Key Derivation Function 2.  There's an RFC for it.  It has an ITF standard.  It iterates, but unfortunately it uses typically the SHA-256 hash.  Well, that's the hash that all of the crypto currencies are using, so people have hugely accelerated the speed of that hash.  You can easily find FPGA code and even now, of course, ASICs, which have been custom designed to do SHA-256 at light speed.  So basing an iterative password-based solution on SHA-256, unfortunately, allows it to be hardware-accelerated much too quickly.



So what Colin did was he created this notion of a memory hard function that we talked about, where you use a pseudorandom function to fill a large area of memory.  And our standard is 16MB because no GPU or FPGA or ASIC has fast access to 16MB.  They may have local caches - and same thing for a regular CPU.  They may have local caches that give them access to a fraction of that.  But the way this thing works is it uses the random data in the 16MB to choose the next access of somewhere in the 16MB.  And the data there chooses the next access in the 16MB.  So it all has to be there at once.  And there's essentially no way to spoof that.  So what this does is this thwarts any attempt at using hardware acceleration.  But even Scrypt, when you're using those sorts of parameters for 16MB, it doesn't take long enough.



But it turns out you can chain Scrypt.  So what we do is the user's password is put in, along with a random salt, into the first instance of Scrypt, which probably runs, in the benchmarks that we've been doing, it runs maybe a 30th of a second.  It results in 256 bits, or 32 bytes.  We use that as the seed for the next one, and again the user's password, and run that.  And then use the output of that as the seed for the third instance, and so forth.  So we iterate over Scrypt each one of these instances requiring 16MB, and the output of that one being the input to the next one.  Then we end up XORing all of the outputs which occurred, and that gives us our final 256-bit key, which is derived from the user's password.  And as far as we know, there is no way to speed it up.



And the other thing that's so cool about this solution is that you can run it either for "N" number of iterations or for "S" number of seconds.  So you can say, give me a 30-second encryption of my password, and it iterates watching the time pass until that length of time has occurred and then says, here you go, and here's how many iterations that was.  Because, when you're decrypting it, you need to use the same iteration count as you used when you encrypted it.  But so we end up with a system for SQRL which allows you to either specify time or iterations.  It's memory hard and no way to speed it up.  And this is brand new crypto technology.  Nothing like this exists in the industry now.



The project I am on when I finish this podcast today is getting this documented.  And I do have a very cool Windows console app which has been well vetted.  Two other people have reimplemented the algorithm that I explained verbally in the newsgroup, in different languages, and they generated exactly the same output given the same input.  So we have verified three ways that we're all in agreement about making this thing cross-platform.  And one of them, by the way, is someone who's doing SQRL for iOS.  And so it'll be available there.  And somebody else is doing it for Android.  So next week I'll have some URLs for people.



But anyone who has Windows or Wine on any of the UNIX systems can run this, and it serves as an interesting benchmark because this shows how many iterations your computer requires.  Or you tell it you want a hundred iterations, and it shows how long it takes to do a hundred iterations.  So you're able to compare, essentially, the memory bandwidth and throughput of your machine.  It's very cool.



LEO:  Can't wait.  Can't wait.  Let's get to our questions.  Are you ready, Steve Gibson?



STEVE:  I am.  I did want to just mention a bit of errata.  Many people commented that I was calling COTS, the acronym for Commercial Off the Shelf, I was saying "common off the shelf."  So I certainly stand corrected.  I know the difference.  I just got started on the wrong track, and I kept saying the wrong thing all through the podcast.



LEO:  Happens all the time.  To me, not to you.  Here we go, Steve.  We've got some cooking in here, as well.  Just watched the coffee-making - this is from Guillaume Auclair in Sherbrooke, Quebec, Canada.  Just watched the coffee-making episode that you and Leo did on New Year's Eve.  Did I not get the ratio of beans per hot water, ounces of bean versus ounces of water?  So Steve has his recipe here.  This is the key.



STEVE:  Yeah.  We're going to do this again next year.  But so that people don't have to wait, I did some measuring so that I could give people what the ratio is.  So I take what is a quarter-cup dry measure, 60ml is also written on my little quarter-cup scoop, of whole Starbucks Espresso bean.  And that's a level quarter cup, not heaping.  When I've  made it heaping by mistake, the coffee's been a little too strong for me.  So just sort of a flat level quarter cup of beans.  So then I grind them for drip brewing, which is a rather coarse grind, using a good burr grinder.  Then they are drip brewed through a brown paper Melitta-style paper filter.  And the input is about 750ml of clean reverse-osmosis-filtered drinking water.  So that's the ratio, 750ml of water through a quarter cup of drip-ground beans, filtered through a Melitta-style filter.  And, boy, I mean, I've had people stunned by how good this coffee is - smooth, rich, and creamy.  And people who normally need cream and sugar for their coffee just don't need it with this.  So that's the recipe.



LEO:  Here's a tweet from @daveheld_info.  Seems a bit confused, he says, about the NSA ANT coverage:  If the NSA can do this in 2008 - and those were the ANT slides we saw, five years old - who else can do it now?  Aren't you worried?  Is it all a big joke, like the podcast was?  I don't know what that means.



STEVE:  Well, okay.  So I think Dave is upset with me that I'm not more upset about this.  And that's sort of my nature.  I mean, I don't get upset about things I don't have any control over.  And I have no control over this.  So I don't think this is a joke at all.  I think this is worrisome.  But on the other hand, none of this was mass surveillance technology.  This was old school, bug somebody's office because you need information from them, and irradiate their bug with a cool radar beam in order to get that information.  And, yes, this is old technology.  But this is what I would hope our taxpayer dollars are going for.  I mean, we want our intelligence gathering to be able to do this kind of job.  So I'm not upset by this because I'm here to report it and to sort of explain the technology.  And again, to me, this seems an appropriate use of these kinds of spying resources.



LEO:  Yeah.  I guess you could have the attitude that nobody should be allowed to spy on anybody else.  But good luck.



STEVE:  Well, yeah.  Good luck with that.



LEO:  No spying allowed.  I don't know.  I don't think that's an unreasonable point of view.  But it's not practical in this day and age.



STEVE:  And it's not going to change the world.





LEO:  No.  Bill Gearhiser, Boca Raton, raises a common question about VPNs.  He says he signed up for proXPN, heard about it on the show:  I wonder if Steve's evaluated the issue of identifying the far end of the pipe on proXPN.  For example, if I connect to Amsterdam and start browsing, I know that's fairly anonymous.  Now, we've got to explain, a VPN is not about anonymity, but all right.  But if during that session my mailer does a poll for email, won't that poll pop out at the same end of the pipe to Amsterdam?  Won't that identify who owns the pipe?  If so, what does one have to do to anonymize a bit better?  VPN has never been about anonymity.



STEVE:  Yeah, and that's why I chose this question, because it is a common misunderstanding.  The way to think about a VPN is that it protects your local environment.  That is, without that at Starbucks, you are really not safe because Starbucks is open WiFi that is unencrypted, and anybody sitting there sniffing the traffic gets anything that's unencrypted.  So, which typically is like all of your email, unless you're explicitly encrypting, for example, using Google Mail now finally is over HTTPS connections.  But typical POP email is still often an IMAP or still often not.  So the idea is you use a VPN to get out of your local environment, whether it's Starbucks or the hotel that you're in, which is another common source of attack, or even your ISP that increasingly is, unfortunately, not very trustworthy with your own traffic.  You want to get it away from them.



So it is absolutely true that, when it emerges on the Internet at one of these aggregation points, where the VPN server is that you've connected to, then essentially it's out of the vicinity that was in danger, and now you're just sort of out in the middle of the Internet somewhere, probably without anybody looking at it, although you could argue that VPN servers are other targets of opportunity, sort of in a variant of the way the Tor servers, the Tor exit nodes represent a target of opportunity.  But...



LEO:  I guess the difference is it's the difference between local anonymity and global anonymity.  You are locally anonymous, but you're not globally anonymous.  And so 8bitsteve made the point in the chatroom, it does say in the proXPN copy, surf the web anonymously.  And I haven't read the copy, but we should probably explain that that means, from the point of view of your ISP or anybody sitting next to you in a coffee shop, not globally anonymous.  And as it turns out, global anonymity is challenging even with Tor.



STEVE:  Yes, yes.



LEO:  It's a tough thing to achieve.



STEVE:  It's really not something that the Internet offers.  It wasn't designed...



LEO:  Yeah, that's kind of my point earlier on is that we're asking an awful lot of the Internet when we say we want to do everything privately.



STEVE:  Right.



LEO:  Eric in Santa Cruz, my old stomping grounds, wonders about an IPv6 version of ShieldsUP!:  Curious when you plan to set up ShieldsUP! over IPv6.  I think it would be a great addition.  Do you have any plans for that?



STEVE:  So I would love the time to do that.  I actually did purchase some hardware that would begin to take me in that direction.  I talked to Level 3, my main pipe provider at GRC, and also to Cogent, that runs my T1s, because I would need my T1s to have IPv6 space in order to develop the technology here, which I would then carry to Level 3 and install at GRC.  All I need is time.  I would love to rewrite for v6.  But as everybody knows, I have a bunch of things on my plate at the moment.  I've got to get SQRL launched.  Then it's back to SpinRite to get 6.1 launched.  Then it's, I think, Beyond Recall, to get that done.



Then I'm really thinking, the way the world has gone, I should go back and take a look at CryptoLink, but do it as open source software, never intending for it to be commercial.  But we'll sort of play that by ear.  We'll see what the world looks like when I'm on the other side of SpinRite 6.1, and everybody's got that, and I've probably got Beyond Recall finished because I think that needs to follow.  Then we'll sort of see where we stand.  All I need is time, and I'm the only one writing the code, and I'm sort of - I'm a turtle.  I'm slow and methodical, but the stuff lasts a long time.  So it's just a matter of getting to it.



LEO:  Jeff Levy in Poughkeepsie, New York, asks about TrueCrypt:  I recently bought a 64GB flash drive, decided to do whole-drive encryption with TrueCrypt.  While going through the process, I noticed all of TrueCrypt's algorithms are 256-bit.  Does that mean my drive has only 256-bit encryption, even though my password is 30 characters long?  Or does the strength of the encryption lie in the password length?  Love the show.  Long-time SpinRite user.



STEVE:  Now, you know, I'm not sure, if you chain encryption algorithms, they almost certainly use 256 bits for the various key lengths.  I don't know if the other encryption algorithms - because I didn't do any research on this specific.  This just occurred to me as I was listening to Leo read the question.  If you use AES, which is the standard, then you could use it with 256 bits.  And it is, 256 bits, I mean, that's now, as I have said in the past, 256 bits is the new black.  It is all anybody needs.  It is your absolutely private bitcoin identity that no one can guess.  It is your BitTorrent Sync ID that no one can guess.  It is your master key for SQRL, my project of the moment, which no one can guess.  I mean, it is impossible to guess that.



So what they do is they use your password to encrypt a randomly chosen 256-bit key.  When you're setting up TrueCrypt, and they ask you to, like, move the mouse around in random directions in order to, like, add additional entropy to what they've already got, that's the pseudorandom, 256-bit master key which is used to encrypt your drive.  But then that is encrypted under your password.  So the way someone would crack your TrueCrypt-encoded volume, they would never, never try to start guessing 256-bit keys.  There are just too many of them.  They would always guess passwords, run it through TrueCrypt's algorithm to decrypt the password into a candidate 256-bit key, and then see if that works.  That's the way you crack it.



Now, it is likely, because I'm sure the TrueCrypt guys did this right, that if you chain cryptos - remember that there's an option in TrueCrypt of not only using just AES, but also using Blowfish or maybe 3DES and who knows what, if you chain - and you could, like, use them all.  They probably take another chunk of entropy for the key for the second one and another chunk of entropy as the key for the third and so forth.  So you actually do get a longer key.  But to my mind, that's just crazy overkill.  The only reason you would want that is if a defect were found in the crypto you were using, having them chained would protect you under the other ones.  But AES is really living up to its reputation, and no one is finding any problems with it, despite looking really hard.



LEO:  Good.



STEVE:  Yes.



LEO:  Dan Murfin in London, U.K., notes another remote access router disaster:  As a customer of EE in the U.K.,  and someone who uses their Bright Box 2, I was a little dismayed to learn this morning that it is subject to yet another remote access vulnerability.  My question is can we really trust any of these ISP-provided routers?  Or should any security-conscious user buy a third-party router they can fully configure?



STEVE:  I think, given what we have just seen with this port 32764 disaster - and you know what, Leo, I'm feeling, like, guilty that I didn't suggest I jump onto your...



LEO:  Well, we talked about it.  We talked about it on the show.



STEVE:  ...weekend show.  Actually, I thought you had because I saw some traffic patterns on the weekend where I thought, oh.  I looked at the clock when I saw the site...



LEO:  Realized who was on.



STEVE:  I thought, okay, Leo must have just talked about this port because - yeah.



LEO:  Yeah.  I was talking about securing a wireless router.  I do this talk fairly frequently, you know, the five things you need to do.  Except now we have to add another one, which is test your - go to bit.ly/port32764 and test that router.



STEVE:  Yep, exactly.  And so my feeling is, given what we've just learned, anybody who is concerned about their security ought to get a router that can accept either the Tomato or the DDWRT known clean firmware and load that up.  Both of those projects produce a beautiful router that is feature complete and - just reflash a router that can accept it, and then you know what you've got.  Otherwise, look what we keep learning.  Not long ago it was the open  UPnP port disaster.  And now we've got this obscure random port up in a high port space.  Wow.  I just think, just switch to some firmware that you can trust because this is your Internet-facing self.  This is what the world has of you is your router.



LEO:  Do you like OpenWRT?  What is it that you like the best, Steve?



STEVE:  I'm in big-iron routing, so I'm not using any.  But I always say either OpenWRT or the Tomato firmware, both.



LEO:  And those are open source, so people keep them up to date and avoid these kinds of...



STEVE:  Yeah.  And there's a great team in both cases that are maintaining those.



LEO:  Tom Walker, Littleton, Colorado.



STEVE:  Speaking of the devil.



LEO:  Speaking of the devil.  He's wondering about port 32764, as well.  Steve, a quick question.  Wouldn't either my Windows Firewall or my antivirus firewall block port 32764?  For some reason, he says, this reminds me of the first program I wrote back in 1979:  Let X=0, X=X+1, PRINT X, GOTO 20.  In other words, have the computer count up by one.  He said:  I wanted to see how long it took a computer, a TRS-80 Model 1 with 4K of memory, to count to a million.  It never went past 32767, then errored out with "Overflow occurred at line 20."  So is it a coincidence?  Is 32764...



STEVE:  Actually, they're closely related.  The fact that his TRS-80 crashed out at 32767 tells us that that version of BASIC was using integer math with 16-bit variables because - oh, and it's signed, by the way, because 32767 is one less than half of 65536.  And the way two's complement math, which is what this is using, the way it works is the high bit, the most significant bit is considered the sign bit.  So if you force that to be zero, meaning the number is positive, and all the other one bits are on, then that value is 32767.  So the maximum positive value that a 16-bit signed value can contain is 32767.  So when his BASIC program was at 32767 and tried to increment that, it overflowed its representation.  It could not represent 32768, the next one up, in a 16-bit signed register.  And so it just exploded.



And as I mentioned before, 32764 is four down from the midpoint of the port range, which goes from 1 to 36765.  The midpoint is 32768, and 32764 is four less than that.  So, yes, they are related.  And the answer to Tom's question, which we sort of answered just in the prior one, the problem with that port 32764 is not Windows Firewall or Windows or anything inside your network.  It's the router itself.  It's the router that's on the front line.  That's where there is a service, an obscure little backdoor trojan, really, which is listening to that port and accepting commands.  So nothing inside your network can help you because it's the router itself that is going to accept that connection and execute commands from a bad guy.



LEO:  Let's see.  Andrew Stenenson, Dorset, U.K., muses about XP updates in our next question:  Should Microsoft stop all security patches for XP?  Or maybe should they have done it more gradually?  I don't know how you do it gradually.  What I mean is it seems rather brutal - brutal - to pull the plug on all security patches all at once.  Maybe they should continue to patch the most severe remote code execution vulnerabilities until XP usage has dropped to an arbitrary percentage.  Slightly good news for XP users:  Microsoft has extended update support, he says, for Security Essentials until July 2015.  That's not quite true.  They're going to update the virus definitions but will not update Security Essentials.  Big difference.



STEVE:  Yeah.  So as an XP user, I guess the only thing - there's a number of things happening here all at once.  First of all, the thing that's annoying is that Microsoft is essentially getting XP security fixes for free for the most part because all the same things, what we keep seeing is when there are vulnerabilities found, they exist in Windows 8 and 7 and Vista and XP because it's a common code base.  My complaint with this constant version churn is that it's not for the users' sake, it's for Microsoft's sake.  It's for upgrade revenue, largely.  I mean, look at what a catastrophe Windows 8 has been.  Why did they force everyone off 7?  Well, because they can get revenue from upgrading people.



So I guess what's annoying is, if there was a security vulnerability that only affected XP, I could understand them not patching it.  But they're actually addressing vulnerabilities in the core shared code of all of these OSes.  So why not toss in XP if it applies, rather than just saying no, from April 8 on of 2014, you don't get patched.  Because what that does, of course, is it's forcing upgrades of people who don't want to upgrade.  Their XP is working just fine, like mine is.  I have no interest in upgrading.  But I'm not - I and a world of other people are, what is it, it's like 43% of Windows is still running XP, something crazy like that, because it's just fine.  But Microsoft is saying, okay, we're not going to continue patching, even when we have the patches.  Even when we develop them, we're not going to give them to you because we're going to make you upgrade.  It's like, eh, okay, well...



LEO:  It has been 13 years, Steve.



STEVE:  But Leo, Eudora's working just fine for me.



LEO:  They haven't updated that, either.



STEVE:  I know.  They're dead and gone, but it works just fine.  There's this weird, weird mindset that people have developed that new stuff is better.  Look at Windows 8.  I don't think that's any better.  Paul, didn't Paul declare it a complete disaster?



LEO:  I don't think Paul said that, although I keep trying to get him to.  It's pretty - it's a disaster, all right.



STEVE:  Yeah, talk about keeping yourself busy just explaining to people how to use it.



LEO:  This next one seems to come from the same person, Andrew Stevenson in Dorset, U.K.



STEVE:  Oh, it's weird that I - it's funny, too, because when I was putting it in, I thought, wow, we've got a lot of people in Dorset, U.K.



LEO:  Yeah, same guy, I think.  So...



STEVE:  So sorry to everybody else.  I didn't mean to be giving Andrew excess time.



LEO:  I think it's a typo.  But maybe not.  So you're saying this actually is the same guy?



STEVE:  It probably is.



LEO:  Steve and Leo, there's been a change to the way that SSL Labs rates TLS connections.  Congratulations, Steve, you're now an A+ with extra credit because you use Strict Transport Security.  If you want to attain the green bar on SSL Labs for using forward secrecy ciphers, I believe you need to add the older DHE cipher suites to your server, which would change your rating from "with modern browsers" to "robust," which you can see down in the protocol details.  I guess Ivan Ristic, who writes these tests, has written about what he's changed.  This is an ever-changing standard, in a way; right?



STEVE:  Well, but this is significant because SSL Labs is a site that I know our users are huge fans of - it's ssllabs.com - because you can put any server into it, like Google or Microsoft or GRC, dotcom in every case, and it'll tell you about the security suites that the server offers.  To get that security, your browser, as we know with SSL, has to be able to have compatible security suites.  But this will show what the server offers.  The big change here is Strict Transport Security is not SSL, it's HTTP.



So what has happened is SSL Labs has dropped to the, depending upon how you look at it, the layer above or the layer below, probably the layer above, at the protocol application layer, and it's noticed that GRC, when you make a query from GRC over SSL, or not, actually, it doesn't matter, although GRC now forces SSL, or if you try to connect without it, we redirect you to the same page over SSL, so that we've upgraded all of our links and so forth.  The point is that, after your connection, anything, any asset you request from GRC, we send back the Strict Transport Security header with a long expiration.  It's, I don't know, what is it, 301 something something something.  It's like basically I'm saying, forever use only SSL.  So what that does is browsers will cache that, and browsers will then silently upgrade the HTTPS connections themselves to - I'm sorry, the HTTP connections to HTTPS, because they have cached permission to do that that they received from GRC for that long period of time.  And so we're now rating an A+ at SSL Labs because we're doing that.



And of course, as our listeners will remember, I went one step further and asked Adam over at Google to build that knowledge into Chrome so that even the first time, there's one little tiny remaining exploit possibility, which is if a browser had never visited GRC or didn't understand about Strict Transport Security, the first connection could be over HTTP.  Not with Chrome.  Chrome knows, it's built into Chrome that GRC.com will always be HTTPS.  And so even the very first time you connect, Chrome elevates the connection, upgrades it to SSL, even if you didn't ask for it.  So this is a nice step forward for SSL Labs.  They're making their tests more comprehensive by going past the SSL handshake into the actual HTTP protocol and looking at what the server does.  So that's very cool.  So thanks for bringing that to my attention, and now our listeners'.



LEO:  Yes.  Well, my friend, we have run out of time.  No, we haven't, we've run out of questions.



STEVE:  We've run out of run out.



LEO:  Run out.  We're all out.  But it's always fun to do this.  If you have a question for Steve for future episodes, don't email him, just go to GRC.com/feedback.  That's his feedback form.  And I guess it does, I didn't know this, but it does go to his email box, where it will join 50,000 other questions.



STEVE:  It goes actually to a separate, like off on the side, Security Now! email box.  And then I normally pull it when we're doing a Q&A to get the latest.  And I sort through those, browse through them, and find good things.



LEO:  Very nice.



STEVE:  And the good news is it's not piling up forever any longer.  Now I've got MailStore to send them all off to.



LEO:  When does, what is it, Total Recall, Total Non-Recall, go on sale?



STEVE:  Oh, Beyond Recall.  It'll be after SpinRite 6.1.



LEO:  Okay.  So SpinRite is there at GRC.com, SpinRite 6.0.  Free upgrades for life to 6.1.



STEVE:  Free upgrades to 6.1.



LEO:  You'll also find a lot of freebies.  Steve's very generous with his time, and a lot of security updates and things like that.  And 16Kb versions of the show, which Steve edits with his very own hands using a razor blade and a grease pencil.  He also makes transcripts, handwritten transcripts available, from Elaine Farris, at the same place, GRC.com.  We have somewhat larger, automatically edited versions of audio and video available at our site, TWiT.tv/sn.  And of course you can always subscribe after the fact, anytime, at all of your favorite podcatch clients.  We do the show, I said Wednesdays, Tuesdays now, 11:00 a.m. Pacific - no, I'm sorry, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC.  That old time creeps in.



[Talking simultaneously]



STEVE:  Old habits die hard.



LEO:  ...long time.  Long time.  And you can watch live.  We love it if you do.  Otherwise we'll see you on the Internet.  Thanks, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#440

DATE:		January 28, 2014

TITLE:		Listener Feedback #182  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-440.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here with the usual great security news.  We're going to answer some questions.  And he's come up with a way - I don't think anybody's ever mentioned this; in fact, I think it's a complete and utter scoop and a breakthrough - to improve beyond question the fingerprint reading on the iPhone 5s.  Stay tuned.  He's a wizard.  He's a genius.  Steve Gibson and Security Now! coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 440, recorded January 28th, 2014:  Your questions, Steve's answers, #182.



It's time for Security Now!, the show that protects you, your loved ones, your privacy, your online stuff with this guy right here, the Explainer in Chief, Mr. Steve "Tiberius Rumpelstiltskin" Gibson.  Because, yo, because he's the man.  Steve, you know, I was just reading, it's so funny, I was just reading, I think it was on Google+, and of course everybody's talking about this port 32647 stuff.  And somebody, I can't remember who it was, somebody we all know, said "I completely forgot about ShieldsUP!" and put a link on there to the ShieldsUP!.  I guess somebody had mentioned you in an article about testing that port.  So you're famous, Steve.



STEVE GIBSON:  Well, and if you just google that integer now, I'm the first link that comes up.



LEO:  You own 32764.



STEVE:  Yeah, that's my port, Leo.



LEO:  That's great.  We're going to do something a little off-color today.



STEVE:  Well, we did skip a bunch of Q&As toward the end of 2013.  There was just - either we were overrun with news, or there were specific things we wanted to talk about.  And so we were missing them.  And then when I archived all my email, and I found out that I had 53,000 pieces of Security Now! mail, I thought...



LEO:  Oh, wow.



STEVE:  ...you know, let's answer a few more of those.  And we didn't have - there was nothing that was really grabbing me.  Actually the last question in today's Q&A is a teaser for next week's show topic.  So we do have a show topic for next week.  And actually I have a couple backed up, but just need to be able to pull them all together.  So we have a lot - we have an interesting grab bag of news.  I have a "I just can't believe they did this" nightmare to get into technically with Bluetooth Low Energy.



LEO:  Oh, no.  Tell me.  Oh, no.  Don't tell me.  Oh, well.



STEVE:  Yeah, yeah.



LEO:  And I presume that you want to talk about that new slide that surfaced yesterday, the...



STEVE:  Yep, we've got to talk about, well, I don't have much to say.  But even that is - we'll definitely touch on it.  So we've got more news on the point-of-sale malware.  I promised everybody in Twitter that I would share how I managed to make Apple's Touch ID reliable.  And I apparently have.  It's just I don't - I no longer have touch fade, and there's a trick for that that I will share.  CryptoLocker, it turns out, far from dead.  There's new versions of that.  Of course we have the never-ending NSA news machine.  This Bluetooth nightmare that I alluded to.  And I found a couple of interesting, actually one very interesting, for our listeners, new security sites.  So lots of fun stuff to talk about.



LEO:  Steve Gibson, Leo Laporte.  Let's begin.  Let's launch.



STEVE:  So we, sort of from the ether, we got the sense that there were going to be more point-of-sale breaches in the future.  That is, we know for sure now that that's how Target got themselves compromised.  Neiman Marcus has since confirmed that they have also been a victim of infected point-of-sale terminals.  And then just a couple days ago Brian Krebs reported what initially started out to be a rumor, that the chain Michaels, which is an arts and framing chain, big chain, I guess sort of in the Southeast, 1,100-branch chain...



LEO:  No, we have one here.  They're all over.



STEVE:  Oh, okay.  That they appeared to be - we have Aaron Bros., is the one that I think of.



LEO:  Same company, yeah.  They own Aaron Bros., too, yeah.  And they were both breached.



STEVE:  Well, yes.  And so they have now confirmed it.  Before Brian could get confirmation, he said that multiple sources in the banking industry say they're tracking a pattern of fraud on cards that were all recently used at Irving, Texas-based Michaels stores, Brian writes, "an arts-and-crafts retailer that has more than 1,100 stores in the United States and Canada.  On Friday, KrebsOnSecurity heard from a fraud analyst at a large credit card processor that was seeing fraud on hundreds of cards over the previous two days that had all recently been used at Michaels.  The fraudulent purchases on those cards, the source said, took place at the usual big box stores like Best Buy and Target."  So there's another one.



And for some reason the number "8" is stuck in my head.  I think there was, like, there have been - there's some reason to believe we're going to have more of these.  That is, essentially, the underlying configuration of these point-of-sale terminals are Windows XP Embedded, and this malware that was created is essentially - it's chain agnostic.  It will happily infect anyone's point-of-sale terminal that's written on Windows XP Embedded.  So I sure hope that any other similar companies that are using this technology that may not yet be victims take this seriously because this is clearly something you could preempt if you realized, oh, wait, those are ours.  We're using the same point-of-sale terminals that Target is.  How is our security?  So...



LEO:  And a tip of the hat to Brian Krebs because we were all worried when he left the Washington Post, and he said, "I'm going to do it on my own; I'm going to do my own KrebsOnSecurity blog."  And he has been breaking these stories.  He's been knocking it out of the park all on his own.  And good for him.



STEVE:  Yeah, he's doing a great job.



LEO:  Nice job.



STEVE:  So, okay.  Apple's Touch ID.  Many people have experienced sort of what's described or feels like a fade of the recognition of their thumb or finger or whatever.  And there have been a number of suggestions for fixing that.  For example, and I had suggested that you could - there are, I think it's maybe five slots that Apple makes available where you can register fingers.  And I said, well, rather than registering different fingers, how about registering the same finger in different slots, therefore essentially giving it more opportunity to find a match.



Well, it turns out that there is a way to what I call "overtrain," to overtrain the recognizer.  And so, through some experimenting, it's possible to demonstrate to yourself that the overtraining is actually happening.  And what I think will end up being understood at some point after we sort of collectively get more experience with this is that there was the typical tradeoff made between user convenience and recognition percentage.  Meaning that, during the typical training, they would probably have loved to have three times more fingerprints.  But this was brand new.  No other phone had this technology.  This was Apple's first.



And I'm sure the UI guys said, well, if we got more fingerprints, we'd get a better sample.  We'd be able to eliminate noise by comparing multiple reads.  I mean, we could just do a much better sample if we got more.  But the human factors guys said, oh, we just can't ask people to sit there pressing that button all morning.  We can't.  So someone made a decision, well, okay, we'll take this many samples.  And I'm sure they tried it, and it seemed good enough.  Well, apparently for some people that's not good enough.



So here's how you can give your phone as much of a sample size as you want.  It will never give up on you.  It will never get tired of accepting additional fingerprint data.  And what I've learned is it absolutely goes far out the curve in terms of recognition.  I now never get a miss.  So you just go - you open the settings app, the standard little wacky-looking gear thing, Settings.  Then go under General, and then Touch ID & Passcode is the next level.  And then in there you go into - oh, and I think, when you do Touch ID & Passcode, it requires you to enter your passcode at that point to get into the Touch ID section.  So then you go into Touch ID.  At the bottom of that screen is a list of the registered fingerprints.  And it is training there.  So that, if you give it a fingerprint like the thumb that you normally use, you will see that item - it actually, well, it highlights by going dark briefly and then coming back.  It also was a training event.  You can verify...



LEO:  Oh, that's interesting.  It's taking more readings just within that spot.  Huh.



STEVE:  Yes, yes.  And it never gets tired of doing so.



LEO:  Now, how do you verify that it is actually adding a reading?



STEVE:  The way you can verify is you can do something that it won't read, like say you give it way too far out at the end of your thumb, where it hasn't been trained.  And you'll notice, like, do something like that where it won't recognize it and convince yourself it doesn't know the end of your thumb.  Then go back to the trained area, and in multiple trainings slowly move forward so that you're essentially expanding the recognized area of your thumb surface.  And you can walk it right back out to the same area that it used to not recognize, and now it will.



LEO:  Interesting.  They don't tell people this.



STEVE:  None of this is documented.  I was just messing around with it.



LEO:  How interesting.  So you're not in the train - you're not actually training.  It's in the screen before you say let's go, let's train.



STEVE:  Correct.



LEO:  And it's keeping track, and it's actually doing training.



STEVE:  Yes.



LEO:  They must have put that there on purpose.



STEVE:  Yes, well, see, they would like more samples.  But someone said no, no, no, we can't - only ask them for 10.  Otherwise it's just going to seem like it's broken.



LEO:  It's too much.  It does.  In fact, it's annoying.  It takes a while to do it.



STEVE:  Yeah.  But now, so here what they're doing is, they're just sort of sneaking some more samples from you.  They're just sort of like, you know, you put your finger on it, and it says, oh, yeah, that's the one.  And I assume that if you had, like, multiple fingers trained, then when you put different fingers on, the proper one would highlight.  Well, it's also sneaking another sample from you.  We can use that in order to just overload it with samples.



LEO:  So that's how, if you have multiple samples on there, it says, oh.  It highlights the one that you're using.  So it says, oh, yeah, I recognize that, I recognize that.



STEVE:  Correct.



LEO:  But it's at the same time recording more data points.



STEVE:  Yes, yes.



LEO:  Very, very sneaky.  Actually in a good way.



STEVE:  Yes.  And unfortunately they don't tell anybody that because it would be nice if that was somehow noted, if you'd like to give us more samples...



LEO:  How did you find this?  You just - by chance?



STEVE:  Yeah.  And then I was - and it raised the question, is this training?  And then I worked out a way of verifying that in fact I am training at that point, and it never gets tired.



LEO:  So our previous recommendation was to use all of the possible fingers, but do it with the same finger so that you give it more datasets for that same finger.  But this would be a superior way to do it.



STEVE:  Oh, absolutely, because you have - somewhere there's a geometric model of an individual finger's print.  We don't know anything about the way they've built it, but it's doing some sort of recognition and feature extraction, and it builds a feature map.  And what you'd like for greater reliability is two things.  You'd like that the feature map for the region you use typically to, like, have all the noise removed and to find all the relevant features that are available.  And so you get that just by giving it more chances to read.  And also, for example, under different conditions, when it's colder, when it's drier, when it's more humid and so forth.  So this allows you to just keep going back any time you want to and give it some more samples.



But the second thing you'd like to do is to expand the size of the feature map so that it does incorporate out further out the end of your thumb and around both sides and maybe back further, just so that when you put your thumb down, you don't have to be as careful about giving it exactly the same spot on your thumb.  And so this allows you to deliberately expand the feature map by just sort of walking the map out to the periphery of your thumb.  And it'll follow you as long as it still recognizes it.  It'll say, oh, look, I got 80% of what I really have already seen.  And here's an extra 20% slice that I'm going to now extend the feature map out in order to incorporate.  And you can play with it, and it all works.



LEO:  You have discovered - you've got to call, call the media, alert the media.  Nobody knows this.  This is great stuff.  That's a - what a discovery.



STEVE:  Yeah, every so often we come up with new stuff on this podcast.



LEO:  Wow.  All right.  Well, I wish I'd known about this a few minutes ago on MacBreak Weekly.  I would have told everybody.  But I'll tell them next week and give you credit.  That's great.



STEVE:  Yeah, cool.  So thanks to Simon Zerafa, our friend and contributor in Wales.  He found two more new samples of CryptoLocker which are, well, they're very different.  Clearly CryptoLocker, they're one third the size.  CryptoLocker used to be - the samples I was already hosting on the malware page at GRC for people who wanted to experiment, they were on the order of 900K, as I remember.  These are - I think it was 900.  And these are, like, 300K.  So it's interesting that they're that much smaller.  I don't know if they're just - if they've just run it through a compressor or what's going on.  But they are new samples.  They are the real CryptoLocker.  And they are very poorly detected by any AV right now.



So if we've got people, I know that my samples that I was offering have been very popular.  It's just at GRC.com/malware, and you can add .htm if you want.  And so I posted those a few days ago, and I wanted to notify people that they are there because I know that we've got people in, for example, in corporate infrastructures and IT that were using those to make sure that whatever AV tools they're using are detecting those; or, if not, see about making that happen.  And I think, for example, when I posted this, one of them was only detected by six out of 40 different AV tools.  So way back down at the bottom again.  And I remember last week, Leo, you were noting that CryptoLocker, the old CryptoLocker, was now being seen by all of them.  So it was being blocked by everybody.



LEO:  Yeah, that's kind of how it happens; right?  And then they modify it and...



STEVE:  Yes.  And that it is the problem is that it's not the specific characteristics necessarily, but just, unfortunately, signatures that are being used.  And as soon as the malware guys see that they're being blocked, they are able to engineer around it.  I mean, this is the problem we still have, that unfortunately our model is block what's bad rather than own what's run good.  Someday, at some point, that's where we're probably going to end up being.  And I've used the example of firewalls.



LEO:  A whitelist instead of a blacklist.



STEVE:  Exactly.  And to some degree the iOS Store is a curated applications store.  We see examples of stuff sneaking by.  There were stories last week we didn't cover because it wasn't really too much on topic.  But what was it, it was people were - existing apps were being sold to other companies that were then using them to embed ads in them.  And so that I think it was in the Android Store they would update the app, and now suddenly it became like, wait a minute.  It's sort of like...



LEO:  It's Chrome plugins.



STEVE:  It's like letting a domain go bad, and now it's turned into just a junkie search engine thing.



LEO:  It's kind of worse than that because what happens is, if a Chrome plugin becomes successful, the bad guys come along and offer the developer money to buy it.  And the problem is that Google does not, once you have got a Chrome plugin...



STEVE:  Approved, right.



LEO:  ...on the store, they don't then check again.  And so you can then push updates to this Chrome plugin at will, including whatever you want, malware, whatever.



STEVE:  I think maybe I should have covered that last week.  Should have looked at it more closely.



LEO:  It's pretty nasty, yeah.  And I think Google needs to respond to it, frankly.



STEVE:  Yeah.  So I said without evidence last week, I made the comment that the NSA's phone metadata collection was ineffective.  I was hearing that from the various discussions that I follow, but I didn't have any specific  evidence.  Well, on Thursday, two days after the podcast, the government's review panel that was looking at all this finally issued their statement.  They warned that the National Security Agency's daily collection of Americans' phone records is illegal, in their opinion - and of course judges have been going back and forth on this so far - and recommended that President Obama abandon the program and destroy the hundreds of millions of phone records already collected.



Quoting from their report, they said:  "In addition to concluding that the daily collection of phone records is illegal, the board also determined that the practice was ineffective.  Quote, 'We have not identified a single instance involving a threat to the United States in which the program made a concrete difference in the outcome of a counterterrorism investigation,' and added, 'We are aware of no instance in which the program directly contributed to the discovery of a previously unknown terrorist plot or the disruption of a terrorist attack.'"



So it said:  "The NSA should instead seek individual records relevant to terror cases directly from phone service providers under existing laws."  And of course that's my only suggestion for something that would be effective is, as I said last week, we require that the carriers maintain records.  If they want the privilege of having access to FCC-allotted bandwidth and common carrier status, then what comes with that is the obligation to maintain metadata records and then require individual requests.  And I did note also, I think it was Verizon that finally published the number of requests that they had entertained.  Oh, lord, it was like 370,000 requests in a year.  So that's, what, a thousand a day, about.  So it's like, yikes.



But still, arguably, I mean, maybe what that would do is raise the cost of performing this collection to the point where, if it's really not generating any value, they would just stop bothering because it's like, well, okay, we're having to jump through bigger hoops now.  So we'll just abandon doing it because it's not providing any value.



And the slide you referred to, the NSA slide that was just revealed, was another one of these wacky-named projects, this one Golden Nugget.  And everybody picked up on the news.  TechCrunch's headline was "NSA May Want Mobile Data Including Info From Angry Birds and Maps."  And of course  Rovio, the publisher of Angry Birds, vigorously denied cooperating with the NSA.  And I'm sure they're not.  It very much looks like we now understand that this is all extrinsic acquisition of data on the Internet.  And as I've said, the NSA is full of smart people.  If it can be done, and they want it, and they've got the budget for it, it will be done.  And so they're just doing everything they can.



And so they've got smart guys sitting around thinking, well, what about social networking apps?  Well, in fact that's our next story is that the Facebook update - this is not NSA related, as long as the NSA can't get their hands on it.  But Facebook's update to Android now requires permission to access all of your text messages.



LEO:  Oy.



STEVE:  I know.  A screen was posted in the story that first brought this to light.  And under "App Permissions," that comes up when the Facebook app updates, it says "Facebook needs access to additional permissions," and then it lists them.  And under "Your messages" it says "NEW," in all caps, "Read your text messages (SMS or MMS)."  And down further, it sort of scrolls off the bottom, but under "Your personal information," also "NEW," this was similarly disturbing.  It says "Add or modify calendar events and send email to guests without owner's knowledge.  Read calendar events plus confidential information.  Read your own contact card.  Modify your contacts, read call log, read your contacts, write call log...."  And then it kind of - it keeps going, but scrolls off.  And I'm looking at that going, oh, my lord.



Now, so note that here's certainly equivalent plumbing of personal information that a commercial enterprise is doing that echoes what the NSA is doing.  So, and my point is it's been noted that, yes, we're all up in arms over what the NSA is doing.  But in fact we're giving permission to corporations to do very much the same sort of aggregation and social engineering.



LEO:  Yeah, and it's usually a tit-for-tat thing.  I mean, these are - so, I mean, you see this all the time in these apps.  It's nice that Android gives you the list of new permissions before you accept it, and you can read them.



STEVE:  Yes.  Well, and Facebook cannot knock on your door and say that we think that maybe you're up to no good, and we're going to take you away.



LEO:  Yeah, they don't have guns.



STEVE:  Precisely.



LEO:  Don't have tanks.  They don't have black helicopters.  But the other thing is that the way it's set up, a lot of times you ask for one permission, you get a block of those, and all of those have to be disclosed.  That's part of the way the API works.  The other issue is - and what I suspect is this is Facebook in effect saying we want to add some new services, or we want Facebook Messenger to use text messaging in that case.  And so these are things that are features that people presumably want.  And you can always say no and not install it.  I mean, that's...



STEVE:  Right.



LEO:  There's an opt-out.



STEVE:  Although it is an all-or-nothing.



LEO:  Yeah.  I wish it were more granular, and it's not.



STEVE:  Yes.  It would be nice if they had check - and we've discussed this before - if they had checkboxes on the things they want access to, and if they explained to the user why they want it.  There's no "why we want this" as part of that.  It's you must consent to this laundry list of permissions so that Android, the OS, will give us access to those aspects that are otherwise sandboxed from us.  And so first they don't tell you why, and then they don't allow you to say, well, I'll take this one and this one, but I'm not giving you this one.



LEO:  Yeah, I mean, that's troubling, too, because, I mean, it's difficult for them to do because if you say, yeah, I'd like this SMS feature, but you can't have this, the whole feature breaks.  And I also understand why they don't give you a lengthy explanation, at least on that page, because nobody wanted to piss people off to say, I don't want to read all this, I just want to - get out of my....  But they should somewhere.  Somewhere they should say, and if you want to know more about what we're up to, we have a page here that you can read.  I agree, that kind of disclosure would be very valuable.  It should be required.



STEVE:  Okay.  So center yourself, Leo.



LEO:  I'm sitting on my ball carefully here.



STEVE:  Over your ball.  And listeners, when you hear the phrase "Bluetooth LE 'Just Works' Pairing," when something is called "It Just Works," this is where you're entirely expected to have what we're now calling a "Gibsonian reaction."



LEO:  It doesn't pair at all, frankly.  It just works in the sense that, if you have a Bluetooth LE app, it works.  There's no pairing at all.



STEVE:  Well, there actually is.



LEO:  Oh, is there.



STEVE:  Oh, yeah.  And in fact, I mean, they went to some trouble.  For example, I found an interesting page at the nih.gov site that says:  "Pairing comprises three phases."  Now, we should mention, Leo, what you're referring to is the experience, and you're completely correct.  That is, the experience is that it just works.



LEO:  Yeah, it's all invisible to you.



STEVE:  And we've discussed Bluetooth pairing.  I've explained carefully exactly how it works and that the way it was originally designed was secure except during a brief sort of theoretical window where, if you really wanted security, you needed to go out into the middle of an empty parking lot somewhere so that you could see all the way around yourself and knew that nobody was sniffing.  The reason that's important is there are, for example, very powerful Bluetooth radios with long antennas on them...



LEO:  Steve's showing one right now.



STEVE:  ...which hugely extend the range at which Bluetooth will function.  And the hackers know about that.  So on this NIH.gov site, they say:  "Pairing comprises three phases.  In the first phase, the two connected devices" - now, they're not actually connected yet, but want to be connected devices - "announce their input/output capabilities; and, based on these, they choose a suitable method for the second phase.  The second phase has the purpose of generating [what's called] the Short-Term Key (STK), which will be used in the third phase to secure the distribution of key material.  In the second phase, the devices first agree on a Temporary Key (TK), by means of the Out Of Band, the Passkey Entry, or the Just Works methods.  The Out Of Band method uses out-of-band communication means."  Now, that could be NFC, or it could be the typical Bluetooth style where something with a screen shows you something which you then enter into the other device.



Now, of course, that requires that there's a screen on one side and a keyboard on the other so that you're able, you the human are able to move the out-of-band information from one device to the other in a mode where no one eavesdropping can know what that out-of-band information is.  That's the point of it being out of band.  Or, for example, NFC.  Assuming that NFC requires near contact, then that would be good.  You sort of tap these things together.  That allows them to exchange the very short-range secret, which they then leverage into a longer range secret by going out of band.  But that's expensive, too.  So what ends up happening often is that Just Works is used.



So continuing the NIH thing, they say:  "The Out Of Band method uses out-of-band communications means for the TK" - that's the temporary key - "agreement.  In the Passkey Entry method, the user passes six numeric digits" - so that's also out of band, but it's sort of formally defined as six numeric digits.  Now, okay, turns out that's not enough digits, as we'll see in a second - "as the TK" - as the temporary key - "between the devices.  When none of the first two methods can be used" - I would have written "either" at that point, but that's all right - "the Just Works method is employed" - and this is where we have our Gibsonian reaction - "although it is not authenticated, and it does not provide protection against man-in-the-middle attacks.  Based on the TK, and on random values generated by each pairing device, the STK is then obtained by both devices, which leads to the end of the second phase."



So they just sort of gloss over that minor problem with Just Works pairing, correctly noting that it provides no protection against man-in-the-middle attacks.  It turns out that it's worse than that because a man in the middle typically means you are intercepting, that is, you are - they mention it's not authenticated.  Well, that's true.  And the typical man-in-the-middle attack allows the person to insert themselves and, if there's no authentication, then they're able to establish communications against each of the other ends.  And the other ends each think they're talking to each other when in fact they're talking to the man in the middle.  That's the vulnerability with no authentication.  That's what, for example, SSL certificates prevent because the server that you're connecting to is authenticated, and no man in the middle has the certificate that the actual web domain and web server has.  So it's the authentication aspect that prevents an active man-in-the-middle from splicing themselves in.  It turns out this is subject to passive eavesdropping, which is where the real concern comes in.



So I went then to Bluetooth.org to look at, like, what do the actual Bluetooth guys who developed this say?  And under "Association Models," where you're associating the two endpoints, they say:  "Bluetooth Smart" - which is their formal name for the low energy technology, which turns out to not be so smart - "uses three association models referred to as Just Works, Out Of Band, and Passkey Entry," as we just learned.  "Bluetooth Low Energy technology does not have an equivalent of numeric comparison.  Each of these association models is similar to Secure Simple Pairing with the following exception:  Just Works and Passkey Entry do not provide any passive eavesdropping protection.  This is because Secure Simple Pairing uses" - and here it is - "Elliptic Curve Diffie-Hellman."  That's the good way to do this kind of key agreement.  That is, so full-strength real Bluetooth, the Secure Simple Pairing, uses Elliptic Curve Diffie-Hellman key agreement.



LEO:  Well, that's good.



STEVE:  Yes.  Whereas Bluetooth Smart, which we now need to put in air quotes, does not.  The use of each association model is based on the I/O capabilities of the devices in a similar manner as Secure Simple Pairing.  So they sort of gloss over that at this point; but they do note that, for whatever reason, they didn't build Elliptic Curve Diffie-Hellman into Bluetooth Low Energy.  Maybe they were just - their target was really, really, really low cost.  And we know that these Bluetooth LE things are really, really, really low cost.



So finally we get to the guy that cracked it.  And this is actually not even new.  This is nearly two years old, I think, that this was done, but somehow just sort of escaped attention.  So Mike Ryan put together a paper titled "Bluetooth:  With Low Energy Comes Low Security."  And after laying down a foundation of, like, all of this, he built a proof-of-concept system based on a standard, essentially sort of a software radio-style Bluetooth dongle, a USB dongle.  And so he says in his paper, down on paragraph or section 6, says:  "BTLE [Bluetooth Low Energy] features encryption and in-band key exchange."  As opposed to out-of-band, which we were talking about, where you deliberately go out of band so that somebody who is eavesdropping in-band, that is able to capture the packets that are being exchanged, can't see what's happening outside of that band, out of band.



But BTLE features, as Mike writes, "encryption and in-band key exchange.  Rather than relying on a well-established key exchange protocol such as one based on Elliptic Curve Diffie-Hellman" - which, by the way, for example, is what SSL and TLS now is using, and made it ephemeral so that you're always renegotiating keys because it's easy to do that now, and that's where we get our perfect forward secrecy, so they don't have to worry about anyone capturing certificates and being able to decrypt communications in the future that were stored.  Rather than that, he says, "the Bluetooth SIG" - which is the formal definition guys - "invented their own key exchange protocol."



So this is where we go to, yes, we never learn these lessons.  We have perfectly good, well-established, secure solutions.  But no, we're going to invent another one.  We're going to invent our own.  So Mike says, using the royal "we":  "We demonstrate that this key exchange protocol has fundamental weaknesses that undermine the privacy of communications against passive" - and he has in italics for emphasis - "eavesdroppers."  Meaning all you have to do is capture the packets.  "We note that the session encryption provided by Bluetooth Low Energy is known to be relatively secure.  BTLE uses AES CCM" - now, he's talking about session encryption, not establishment, he says - "against which there are no known practical attacks."  So that is to say, once you get a secure key agreed to, then the session is well encrypted.  The problem is, how do you establish that initial key?



He says:  "Our attack targets the key exchange rather than the encryption itself.  Our technique is similar in principle to" - and he quotes a couple - "in which an offline brute-force attack is mounted to recover a secret value when all other values are transmitted over the air."  And that is the case here.  So he says:  "Before establishing an encrypted session, a master and slave must establish a shared secret, known as a long-term key.  Under typical operation, a master and slave establish a long-term key once and then reuse it for future sessions.  Otherwise, the master and slave establish a long-term key through a key exchange protocol."



And finally he says:  "The key exchange protocol begins by selecting a temporary key, a 128-bit AES key whose value depends on pairing mode.  The master and slave use this value to calculate a so-called 'confirm' value.  Aside from the temporary key, all values used to calculate the confirm are exchanged in plaintext over the air.  The confirm value itself is also exchanged over the air in plaintext."  And this is the problem with the protocol.  Mike says:  "We exploit the fact that all values except the temporary key are publicly known in order to brute force the temporary key.  As noted, the temporary key value depends on pairing mode.  Three pairing modes are defined:  Just Works, a six-digit PIN, and Out Of Band."



The temporary key is as follows:  For Just Works, it is zero.  It's nothing.  It's null.  For the six-digit PIN, a value between zero and 999,999, padded to 128 bits.  So that's where they get this 128-bit key is it is just literally the six-digit PIN padded out to that bit length.  And then, if you have out-of-band exchange, for example, we were talking about near field, you would use that to exchange a true strong 128-bit value.  So that's going to be super safe.  The problem is, if you use a six-digit PIN, well, then you've got a value between zero and essentially a million, 999,999.  But if you're just in Just Works mode, then they don't even try.  It's just zero.



So he says, finishing this, he says:  "We use a simplistic brute-force algorithm to guess the temporary key.  We calculate the confirm for every possible TK value between zero and 999,999.  If the master and slave used Just Works or a six-digit PIN, we will quickly find the proper temporary key whose confirm matches the value exchanged over the air."  So essentially the confirm is exchanged in plaintext, making this trivial to brute force.  And he says:  "In practice, we find that a temporary key can be cracked in less than one second on a single-core Intel i7 CPU.  This figure could be improved by brute-forcing in parallel and/or using processor-specific AES extensions," none of which they even bother with, making this an absolutely practical attack.  Once that's done, then the temporary key is cracked, and you use that to leverage the agreement of the long-term key, meaning that the entire future interaction of those devices is then crackable.



So what does this mean?  Well, as we know, LE is often used for things you really don't, whose security you really don't care about, like temperature sensors or all those little tracking badges that people are coming up with now.  Or iBeacon, for example, Apple's iBeacon.  It isn't actually exchanging any valuable data over that link.  It's only saying I'm here, or I'm a pair of red shoes, who knows.  It's arguably not very important.  The problem is that this is the way these things start.



So, for example, that interesting Coin credit card is also using Bluetooth Low Energy.  And the question is, did they do, do they do a full 128-bit temporary key, or are they displaying, and I'm afraid they probably are, a six-digit PIN?  And now we know that, if you were ever passively recording the traffic during the pairing of that card, the Coin card, using Bluetooth LE, where you could argue in fact there is valuable information now being exchanged, and they use, for user convenience, a six-digit PIN, that communication can be completely cracked.



So the concern here is that we're going to start seeing applications using Bluetooth LE or Bluetooth Smart, which isn't very, where unfortunately, for user convenience, they've sacrificed the full-strength, 128-bit key exchange, and it turns out it's possible due to the fact that they did not use good Diffie-Hellman elliptic curve encryption.  They just used their own protocol, where everything is in the clear, and a six-digit PIN can be cracked in under a second easily, and much more quickly if you develop some software to do so.  So listeners beware.



LEO:  But it doesn't have to use this less secure system.  There are three systems, and some are more secure; right?



STEVE:  There's one system which gets its security from exchanging a full 128-bit key.



LEO:  And that's secure.



STEVE:  And that's secure.  But that requires that you actually arrange to exchange a 128-bit key.  The problem is, that's inconvenient.  Or, for example, if it uses near field technology, then it's trivial to generate a random 128-bit key on one side and give it to the other.  And then that will be out of band.  But the problem is that we're all - everyone's trying to minimize expenses.  And I'm signed up for Coin, so I will find out how you do the Coin pairing.  The problem is Coin uses Bluetooth LE.  We know that.  And absent high security out of band, you are reduced to using method number two or one, which is either zero, a key value of zero, which you could instantly verify; or you do a brute-force attack, and you're going to guess the PIN in less than a second.



So the problem is it's like, yes, you could pair securely.  And if you pair, again, where you are absolutely sure no eavesdroppers can intercept your communications, then you're secure also.  Once you've established your pairing, then you've agreed on a secure key.  And that's never exchanged in plaintext.  But it's that first instance of pairing that unfortunately Bluetooth LE is very vulnerable, much more so than regular Bluetooth because regular Bluetooth uses a strong cipher.  It must have been that they said we can't afford the cost to do elliptic curve crypto in a temperature sensor that you're going to stick on the wall.  We want Bluetooth LE to have a wide application...



LEO:  And who cares if they know what temperature I have.



STEVE:  Precisely.



LEO:  I guess my response to this would be that it may be cost, but I think it also may be looking at how people use Bluetooth.  It's been such a pain to pair with Bluetooth that almost every device now just says it's 0000.



STEVE:  I know.



LEO:  They don't attempt, even though the security is possible, they don't attempt it.  And that's become de facto how you pair stuff.  It's rare that I have to use a number; and, when I do, I'm pissed off.  In my car I have to.  And I don't care, oh, my god, somebody might actually add their phone to my car's list of accepted phones is not an issue for me.  So I think a lot of the times we use Bluetooth, as with a thermostat, it's probably not an issue.  It's a big issue if Apple uses Bluetooth LE for its payment system because they don't have NFC on Apple, or Coin, as you used as an example.  Of course, I didn't buy a Coin.  I thought it was stupid from the beginning.



STEVE:  Well, and I do, too.  But I just need to - I've got to take mine, I have to take mine apart.



LEO:  You have to.  So I would guess that the people who designed this recognized that there are lots of situations where zero security is appropriate, and it's going to make everybody happy.  I use Bluetooth LE for my little slot car set, that Anki that we played with.  There's no reason I should worry about a man-in-the-middle attack on a remote control.  It doesn't make - it's not an issue.



STEVE:  Yeah.  The TiVo Roamio uses Bluetooth now, and it's very convenient to have...



LEO:  You don't want to have to enter a four-digit code to pair your remote control with your TV.  That's crazy.



STEVE:  Yup.  And it's funny, too.  It comes up in pairing mode.  And the first time you put the batteries in and plug the TiVo in, and you press any button on the remote control, they immediately find each other, do this exchange, a Just Works exchange, and now they know each other.



LEO:  Yeah.  So I think that it makes sense.  In fact, I think this is a sensible response to have three levels of security, or really sounds more like two effectively, good security and no security.



STEVE:  Right.



LEO:  And then count on implementations to choose the right thing.  And by the way, you could use a QR code if you didn't have NFC.  So it's conceivable that Apple and iPhone might pass this out of band.



STEVE:  That's a very good point.  For example, the Coin folks could print a static QR code, a random QR code on the back, or on a sticker.  So it's on the sticker.  You scan it once, and then you peel the sticker off so that nobody else can - and hide the sticker somewhere safe.



LEO:  The places I've used Bluetooth LE, pairing to a scale, pairing to my slot cars, it's been great because there is no - it doesn't look like there's any pairing going on at all.  In effect, it sounds like what they're doing is what we would do manually, which is 0000, and we just eliminate that whole process.



STEVE:  Well, and that's what Just Works pairing is, is literally all zeroes.  And so you could instantly crack their attempted encryption.  The problem is, and my concern is, there is this presumption that there was an attempted encryption.  And so I just wanted our listeners to know, for now and forever, that that's useless, and don't assume you're being protected.  And Bluetooth LE is, I mean, it's wonderful.  I learned a little bit more about it.  For example, I was always sort of curious, how could you have Bluetooth, because I've always thought of it as being a static association, that is, that it had to be a powered-up link.  It turns out that is not the case, that the little TiVo remote control I was holding up a second ago, when you press the button, it sends off a little Bluetooth burst.  So they've managed to get this thing so that it's able - the radios come up, they find each other, they handshake, they link, they exchange their message, and they shut down again.



LEO:  Isn't that clever.



STEVE:  Which is just like an IR burst does.  It's fabulous.



LEO:  So the real, I would say, the real takeaway on this is, on things where you do want it to be secure, you should ask, how is the pairing happening? 



STEVE:  Correct.



LEO:  And you're not using the easy one, you're using the secure one, right.



STEVE:  Correct.  And we will find out how...



LEO:  It's up to the implementer to do it right.



STEVE:  We will find out how Coin pairs.  And in fact, if Ryan Seacrest ever sends me my keyboard, which, you know...



LEO:  Is that supposed to be LE?



STEVE:  Yeah, it's Bluetooth LE.



LEO:  Oh, interesting.



STEVE:  Yeah.  And so the question will be, I mean, there again, I'm sure it just will automatically find my phone, and they'll be happy.



LEO:  Yeah.



STEVE:  Following up a little bit on Precheck, TSA Precheck, because so many - this captivated the interest of our audience because people think, wow, I'd like to have that.  I did receive, the day after the podcast last week, so that is to say exactly one week after my TSA Precheck appointment, I received a letter from the happy Pre people.  And what I received was my eight-digit Known Traveler number.  So that's what I have now.  I have a good-for-five-years Known Traveler number.  And I presume, when I am in the future making reservations on airlines, there will be somewhere I can put in my Known Traveler number, and then I'll get - my boarding pass will say TSA Pre.



One of our listeners, Martin Ruby, commented.  He said:  "Steve, I've been a TSA Pre flyer since the days when it was a test.  There are two ways to get TSA Pre.  The first is the way you did, by applying for it.  The second is by being an airline frequent flyer.  If your airline participates in TSA Pre, they can submit your information to the TSA, vouching for you as a Known Traveler on that airline.  The difference between the two is when you apply to the TSA, it is good on any airline that participates in the program; and, if it's by the airline submitting your information" - I should have edited this better.  It says:  "But if it's by the airline submitting your information," he says, "it's only valid on that airline."



Then he says:  "I'm a proud owner of SpinRite since the days of OCIPUG."  That's an acronym I haven't seen for a while, Orange County IPM PC Users Group.  I heard you talking about user groups, by the way, Leo, in the earlier - in MacBreak Weekly.  And, yes, those were fun times back then.  He says:  "...when you would come and present."  And he says:  "I've used SpinRite many times to fix drive issues.  Thank you for a great podcast and a fantastic product.  Martin."



And then the one that I got a kick out of, looking through the mailbag this morning to put together our Q&A, was someone who said re TSA Pre screen:  "Steve, it's almost certain you have a file and a set of agents assigned to you.  Of course they don't need to interview you.  The file probably says, 'Smart guy, mostly harmless.'"



LEO:  Mostly harmless, I like it.



STEVE:  "Smart guy, mostly harmless, best not to annoy him."



LEO:  And never say "It just works" 'cause he'll get you.



STEVE:  Yeah.  Don't just tell me, oh, yeah, the key agreement, don't worry, it just works.  So, two cool security sites.  Leo, you're going to want to bring this one up.



LEO:  All right.



STEVE:  HowsMySSL.com, h-o-w-s-m-y-s-s-l dotcom.  Type it in quickly before we bring the site down.  Oop, and there it us.  So we're seeing on your screen, "Your SSL client is improvable."  I assume you're using Safari.



LEO:  Safari, yeah.



STEVE:  Because in fact, in my notes, Safari says it's improvable.  Firefox, "Your SSL client is bad."  So, first of all, back off a little bit, or I'll back off a bit.  What this is doing is something actually I started to do for GRC, but I had other priorities, and everyone would agree.  So I thought, well, okay, I'll either leave that to somebody else or do it later.  And it's been left to somebody else:  HowsMySSL.com.



What this does is it creates a web page based on the details of the initial SSL handshake packet.  Remember from our discussions of this that the first thing that happens when your browser connects to a web server is it establishes a TCP connection through the three-way handshake.  Then the first packet is a packet saying I want to bring up an SSL tunnel.  Here's my SSL versions and my cipher suites.  These are all the cipher suites that I know about.  So what this site simply does is publish, essentially make it very human-readable, publish the details of what your client browser is offering.  So this is sort of the reverse of the SSL Labs test.  SSL Labs will test the server on the other end of your browser connection.  This one checks your browser.



So Firefox, it says, is bad.  I don't think the people at Mozilla will appreciate that very much.  And I don't really know that I really agree, either.  Firefox gets a "bad" because they support TLS 1.1, not 1.2.  It's like, okay, well, yes, there is a 1.2, but 1.1 is fine.  But it really upsets this site because listed among the cipher suites, way down at the bottom, but still there, is a suite that they don't like.  It's SSL_RSA_FIPS_WITH_3DES_EDE_CBC_SHA.  So in the parlance of cipher suites, it's chosen a set of cryptography which is like, eh, okay, so it's not super spiffy.  They said:  "This cipher was meant to die with SSL 3.0 and is of unknown safety."  Well, yes.  It's not of known unsafety.  And it's not actually...



LEO:  Of unknown safety.



STEVE:  It's not actually even unknown safety.  It's like, okay, 3DES.  That's like the Edsel.  But still, it's okay.  So anyway, Firefox gets a "bad."  Now, the reason this is not such - the only way this could be a concern is if you - I guess it would be a cipher suite downgrade attack where a man in the middle saw all of those going off to a server and removed all but that one, and then the server also supported that and then grumbled and said, okay, fine, we'll use that.  Well, even then we don't know there's a problem because this is not of known un-security.  It's just that, unfortunately, HowsMySSL site is in the business of being critical.  And so they said, okay, we don't like this suite any longer.



Opera got "SSL client is bad," the latest version of Opera.  And we know that Opera is very secure.  But they only support TLS v1.0.  And they don't support TLS session tickets.  Session tickets are the TLS version of caching.  We've talked about SSL caching, where after performing the expensive public key encryption, essentially you resume a session on subsequent connections by saying, hey, here's my session ID from the prior session.  If this is still in your cache server, then let's just reestablish our agreed-upon crypto material.  And that's very effective.  Session tickets is the terminology and the way that's being done for TLS, and Opera doesn't support it.  Neither does IE 11.



I got a better grade on IE 11.  It says "Your SSL client is improvable."  So it's not bad, as is Firefox and Opera.  It's improvable.  It's like, okay, well, they're all improvable.  So they had to come up with a term for, like, okay, not in the gutter, but we're not really happy, either.  IE 11 got improvable.  Safari got improvable.  The only thing that I have seen got - and this is the best they'll give.  They'll begrudgingly say that Chrome "is probably okay."  It's like, okay.  So it gets a "good" on everything, and so it's probably okay.



LEO:  Probably okay.



STEVE:  So anyway, I thought - I knew that our listeners would get a kick out of HowsMySSL [h-o-w-s-m-y-s-s-l] dotcom.  And I've seen other people asking me, Steve, what's going on with that TrueCrypt audit?



LEO:  Oh, yeah.  I meant to ask you about that last week when we talked about TrueCrypt.



STEVE:  Yup, and there's a handy-dandy site to answer the question, IsTrueCryptAuditedYet.com.  And the answer is not yet.  But the project is getting good support.  There is progress being made, and it's looking good.  So all run together, one word, IsTrue - and, by the way, it's T-r-u-e Crypt, and don't drop the "e" - IsTrueCryptAuditedYet.com.  And the answer is not yet.  But if you want to, you can make a shortcut or something to check in on that from time to time.  And if the status changes, by all means, someone notice that and tweet me because I would love to know.



I mentioned last week, I was working on the SQRL page to document the use of Scrypt.  That's Colin Percival of Tarsnap's memory hard password encryption technology, or password hashing is really the better term because it's not reversible.  I called it EnScrypt because we EnScrypt the password using essentially an iterative use of Scrypt.  I did that because Scrypt, even if you give it a lot of memory, still is too fast.  We really want to penalize a bad guy who is doing password guessing.  The only known attack on this is trying all possible passwords.  And so while, yes, what would really be good is if users chose pure entropy from, like, GRC's passwords page or something, most people don't do that.



And so the only thing I can think of, the only thing feasible, is to make any wrong guess so painful that an attacker - actually I think that SQRL is going to get a reputation instantly for not even being worth attacking because everyone's going to know you can only do one every, well, in the case of a statically stored password, I'm proposing that you have to take 30 seconds to encrypt this in order to export it.  And they just won't bother.



But anyway, the point is that what I ended up writing was much more of a tutorial than I started out to write, which I think would be of great interest to our listeners.  That is, we have discussed password encryption and hashing and management in the past, like adding salt, and storing the salt with the password, and adding iterations of a hash in order to make it take longer.  What I ended up writing on that page - and it's grc.com/sqrl/scrypt, and it's actually page 10 of 18 on the SQRL sort of subsite.  You can also just go in the menu, so find SQRL under Research, and then it's page no. 10 is SQRL's use of Scrypt.



I ended up sort of taking the reader through the entire history of how passwords have been handled through time, which I think our listeners would probably enjoy reading.  So I recommend it for that.  And I think you'll find it interesting also.  And I expect this will end up moving into common use.  Oh, and I also mentioned that I'd written software.  It's there.  There's a screenshot of the software.  You can download my reference version of EnScrypt, which does this, which is sort of a fun little benchmark.  You can say "Run it for five seconds" or "Run it for 30 seconds," and then it will tell you how many iterations of Scrypt your system is fast enough to perform.  And that really tells you a lot about the speed of your processor, but mostly about your memory bandwidth, the throughput to main memory, because this is all about busting the caches in order to force main memory access.  That's something that GPUs don't have.



GPUs can have a couple gigs on the graphics card, but they don't have high-speed access to it.  They've got high-speed access to local cache, but this uses 16MB of memory, forcing them to go outside of the cache, down in the main memory.  And that's what levels the playing field and prevents the acceleration of this password hashing that we see, for example, famously in Bitcoin, that just uses SHA-256.  And so now there's ASICs, which are just screamingly fast at doing this.  The whole goal was absolutely prevent that from being done with SQRL's passwords.  And I think we've achieved that.



And just I had a short little shout-out from a James Cavanaugh who's in Dresden, Germany.  He said:  "I just wanted to say thanks for recovering my apparently dead drive's data when nothing else could.  I tried so many other programs, unsuccessfully.  And after all of them, SpinRite's apparent ease of success really convinced me.  What a difference.  Also intuitive and easy to use."  He says:  "It just does the job.  Great product."  So, James, thanks for saying so.



LEO:  Well, we all agree with James.  All right, Steve.  I have in front of me, in my hand, questions from our listener-driven potpourri.  Are you ready?



STEVE:  You bet.



LEO:  Shall I fire away?  Here we go, starting with Rick Lieb in Monessen, PA.  He wonders about a safe way to keep using XP after the April cut-off:  Steve, I've watched and read every episode of Security Now! since the beginning.  I'm a SpinRite owner.  Just upgraded both computers to Windows 7 Pro 64-bit from XP.  In order to keep using some software in XP that will not run any other version, I'm using the XP Mode Virtual Machine.  This older software does not need to access the Internet, by the way.  Once support stops, my plan is to disable networking in the virtual machine so it can't access the Internet.  I'm very careful about the media I hook to the computer.  So is this a reasonably safe thing to do?  Rick Lieb, Monessen, PA. 



STEVE:  Yeah.  Of course I'm famously still using XP.  And I did note that April 8th, the last day of support, happens to fall on a Tuesday.  So it couldn't be more appropriate.



LEO:  Maybe they'll Patch Tuesday us one last time.



STEVE:  It will be a - oh, yeah.  It will be the second Tuesday of April, also.



LEO:  That's probably why they do it.  They're going to give you one more update, and then that's it.



STEVE:  One final sendoff.  They didn't want to do it on April Fool's because that would be a problem.  So, yes, you're right, the second Tuesday of the month.  And it happens to be it'll be a podcast day.  So that will be fitting.  But I would say disable it now.  Well, no, I guess you still want to keep - you want any updates that XP will get for the next several months.  That is, by the way, 69 days from now, just for those of you who are counting.  And, yes, once XP is in its final resting state, then you could disable its access to the Internet.



I guess the problem would be if you downloaded new software that required XP mode, that would then be able to leverage a problem with the XP Virtual Machine.  What's not clear to me is what mischief it could get up to.  Now, again, the bad guys are clever.  Maybe they'll figure out some way to do something.  But, for example, if you had the typical containment of a virtual machine, then it could mess with your virtual environment, but perhaps not anything outside of that.



So I have a feeling I'll be following in your footsteps because I'm sure I've got software.  I'm sure Brief, you know, I'm still using the Brief text editor in a DOS box.  And I'm sure it's going to choke.  Someone said that Eudora was still functioning under Windows 7 without any trouble.  So although I don't think the 64-bit version of Windows 7, which I would want to use because I would want access to more memory, I don't think that's going to run Eudora.  But anyway, we'll find out.  But certainly, yes, disabling networking would isolate the virtual machine.  You may want to turn it on from time to time specifically to receive the Security Essentials updates, because those are going to continue to flow through sometime in 2015, so like maybe one more year worth of those, just because.  And then definitely shut it down.



LEO:  Gregg Keizer writes at Computerworld that Microsoft is going to continue to update the Malicious Software Removal Tool, MRT, through July 14, 2015.  So another 15 months of MRT.  That's the tool that normally operates completely silently.  You can invoke it if you know the command line.  But normally it just runs in the background.  And it's not exactly antivirus, but it is a removal tool.



STEVE:  Yes, in fact, I think...



LEO:  And of course all third-party antiviruses will see this as an opportunity.  In fact, I'm surprised that some company hasn't stepped forward and said, hey, we'll lock you down.  I mean, they don't have the source codes, but at least they could, I don't know, offer some sort of service.



STEVE:  Well, and remember that what we're going to be seeing are problems not unique to XP.  There are problems in Vista and Windows 7 and Windows 8 because of the common code base that goes all the way back, actually back to NT.  And so what Microsoft is saying - and this is what annoys me.  I mean, I understand their need, but they're saying even though the same things we are fixing in Vista and 7 and 8 also affect XP, we're still not going to fix XP for you.  We're just going to say no.  So it's like, eh.



LEO:  And of course you wouldn't want to leave your machine on the 'Net to download the monthly Malicious Software Removal Tool update, but they do offer it for download on the Microsoft site.  I think he's smart.  I think getting off the 'Net after April 8th is probably the best thing to do.



STEVE:  Well, and, for example, most people get into trouble by surfing in a browser connected to the Internet.  So I would say don't surf in your XP virtual machine.  And as he said, the software he needs to keep using, this database or something, has no need to access the Internet anyway.  So, yeah.



LEO:  No problem.  Edward in Daytona Beach wonders about memory hard encryption:  The memory hard encryption technique, any known hardware platforms that would wear out flash memory used as main memory?  Is there similar potential for wear?



STEVE:  It's an interesting question that really hadn't occurred to me.  I had to think for a second, is there any platform that uses flash for main memory? 



LEO:  Not that I know of.



STEVE:  And I'm sure the answer is no.  Flash, we know that flash fatigues because writing to flash, as I have explained before, essentially forces - uses high voltage to force electrons across a deliberately insulating boundary or barrier, and in the process fatigues that barrier.  So all the flash that I'm aware of is not scratchpad.  And you definitely, for example, don't want to set up a swap drive on flash memory because that'll burn it out, too.  But mostly it's that it's so slow.  So nothing wants to use flash as main memory because it really does take a lot of time in order to write to flash.  So it's always used as, I mean, in every instance I could think of, and Leo, you would concur...



LEO:  Might be some low, low-speed embedded tool that might use it.  But I can't - doesn't seem likely.



STEVE:  Yeah.  And in any event, nothing that you'd be running a SQRL client on.  So I think you're going to be safe.



LEO:  I think you're safe.  So in other words, the memory is not storage.  The memory is RAM.



STEVE:  Yes.  And it is volatile by nature.



LEO:  Right.  Michael in Brisbane, Australia wonders about femtocell security:  Steve, I recently disconnected our VOIP and switched to just mobile phones at home.  However, my wife has on-call shifts, and we had some black spots in the house where there was no mobile reception.  The phone carrier, Optus, provides us with a femtocell - they call it a Home Zone - which I've attached to solve our home's coverage problems.  The way a femtocell works, it connects to your Internet service and then is in effect a little cell transmitter in your house.  I've also received a new gateway modem/router.  I've seen some less than favorable write-ups on femtocells.  I was wondering what your take is, since I really don't have the option of not having one.  Love the show.



STEVE:  So I wanted to get your opinion, just sort of from an amazing-how-much-stuff-you-know kind of mode.  But what I do know is that there's nothing fundamentally a problem with a femtocell.  About four years ago Vodafone in the U.K. had a complete screw-up with their security.  And I think that's what really sort of damaged the reputation is that they basically, I mean, as could happen with any technology, they just didn't do security correct.  And it ended up being possible for bad guys to download their own firmware to intercept updates, to update with malicious firmware, to intercept calls and communications.  And so that sort of scared people in general about the idea of these little femtocell base stations.  But that's four years ago.  And, I mean, sure, anyone could make a mistake.  We've obviously been talking about how routers have firmware which in some cases is open and created a backdoor listening to the Internet.  So mistakes happen.  But fundamentally there's really no problem with femtocell base stations from a security standpoint.



LEO:  You would know this.  Aren't modern cell phones, CDMA and GSM, encrypted...



STEVE:  Yes.



LEO:  ...from your phone, that transmission, I don't know how well encrypted, but it's encrypted from your phone to the base unit; right?



STEVE:  Correct.  It's two things.  It's encryption and spectrum...



LEO:  Spread spectrum.  They're moving around a lot.



STEVE:  Exactly.  And so...



LEO:  [Indiscernible] a little chunk at a time on any given frequency.



STEVE:  Yes.  And so it's very difficult for the amateur to intercept that.  We do know...



LEO:  So that technology would be the same from you to your femtocell.



STEVE:  Correct.



LEO:  Exactly the same because the phone doesn't know.  Now, I don't know, once it gets on the Internet, does it remain encrypted?  It's obviously no longer spread spectrum.



STEVE:  Right.  And there again, I'm sure it's not in the clear.  I'm sure it brings up an encrypted tunnel and does the right thing, does what you would hope.



LEO:  But as we know, one should never assume.



STEVE:  Right.  Yeah, it might be Just Works.  I wonder if it Just Works when you plug it in.



LEO:  [Shuddering] Just Works.



STEVE:  I'm teasing.  There's just really no reason to - I'm sure.  Because I did do a little bit of browsing, and I see nothing except for, like, four years ago where there have been problems.  And we would know if there were, like, contemporary femtocell security problems.



LEO:  I think it's safe to say it's probably as secure as your cell phone communications are anyway.



STEVE:  Yes, yes.



LEO:  No less secure.



STEVE:  Yes.  And the weak link is going to be, as you spotted, Leo, the weak link is going to be that first radio gap between your phone and the base station.  And, boy, you'd rather have it be a 10-foot link...



LEO:  Yeah, in your house.



STEVE:  ...than a 10-mile link.



LEO:  Yeah, exactly.  John Kirby, Davis, California says, "I miss Hamachi."  We all miss Hamachi.



STEVE:  Yeah.



LEO:  LogMeIn's not free anymore.  They discontinued...



STEVE:  And we don't mean the tuna.



LEO:  No.  Yes, we get plenty of that.  Actually, Steve does not.  He no longer eats tuna.



STEVE:  No.  No.



LEO:  As you may have heard, LogMeIn has discontinued the free version.  That's fine.  They have the right to do that.  Unfortunately, I use the free version because it passes through all the security hoops I'm looking for.  But I also depend on it for the central hub aspects, so I can connect my home computer even as its IP address changes.  It's nice to be able to connect with my mom's or sister's computers a couple of times a year to make sure everything is still up to snuff.  Then he uses it for that.  So this brings me to a request for a Security Now! show, which is remote desktop clients which work with dynamic IP addresses.  I've used VNC and Microsoft's Remote Desktop client many years ago, but both of these required a known IP address.  I also realize that GoToAssist/GoToMyPC is a show sponsor, so I cannot ignore them, although I have no experience with them, only because I haven't needed to yet.



I can answer that question.  They use NAT traversal.  They're using a third party, so it is not necessary to have a fixed IP address.  In fact, I would guess in a lot of cases, well, I'll let you answer.  I know this will not be a quick, five-minute Q&A, as each of these solutions will undoubtedly need some background research before you can give any formal review.  Thank you for the wonderfully entertaining and enlightening show.  I look forward to it every week.  John.  For what it's worth, I'm staying with LogMeIn.



STEVE:  So when I saw this, I thought, wow, yes.  I saw so many tweets in the last few days, people bemoaning the change that LogMeIn made, essentially discontinuing their free service.  And I think, as you say, Leo, or actually as John said, it's their right to do what they want to with the service.



LEO:  Well, it's hard to do this stuff for free, frankly.



STEVE:  Well, yeah.  And they're a publicly traded company.  They've got shareholders.  I'm sure they're looking around for more revenue.  It's like, okay, where can we get some more money?  And it's like, well, those freeloaders who are still using our version of Hamachi, it's time to cut them off.  And no doubt John will be going from free to paid, so this is a perfect example of the LogMeIn strategy functioning.  The problem that any other solution will have, as you mentioned, Leo, is that, first of all, many people's IPs change - not often, typically, unless they're always disconnecting and reconnecting their Internet-facing device.  Like some DSL systems are, like, actually disconnect completely and then get an IP when they essentially do the equivalent of a DSL dial-up.  So there you're going to get very rapid IP change.



But, for example, I use - Sue, my bookkeeper and office manager, we use her IP as one of several factors of authentication for her access to GRC's servers because a TCP connection, can't spoof that.  And so maybe every three months or four months she'll say, hey, I can't connect, and so I'll get her IP from her email headers and connect to GRC and just update that IP, and then she has connectivity again.  But what that does is that shows me how infrequently her router's typically technically dynamic, but practically static, IP changes.  So in many cases you could open ports through a router in order to allow remote incoming access to a remote desktop server.



But the beauty of Hamachi was that they were operating a very robust NAT traversal server so that all of the Hamachi clients phoned out through their local networks behind routers to the central hub.  And then you created an account with Hamachi.  Then of course the other amazing thing at the time was that he was using 5-dot IP addresses, which had never been allocated in the history of the Internet.  We weren't running out of IPs back then.  I think his name was Dave, wasn't it?  I remember we used to call him "Hamachi Dave," the guy who designed all of this [Alex Pankratov].  And so everybody would have a 5-dot IP, of which there were 16 million, so there were enough of them for his network.  And it was the NAT traversal that just sort of made this thing work.  But of course he created a useful service and sold it to the LogMeIn folks, who initially didn't change it much, and then began to change things.  And now...



LEO:  There's a moral here.  It costs money to do things.  And I think this is a unique area.  There's a lot of places freemium works.  It's very big in the App Store.  We just saw it from Apple's results, 92% of all Apple apps are freemium.  That is, free, but you pay for in-app purchases, for upgrades.  It's how you make money.  92% of the revenue in the App Store, I misstated it, 92% of the revenue in the App Store comes from free apps within app purchases.  So it's a very successful model.  The problem is, I think, the people who use LogMeIn free and TeamViewer are a certain class of geeks who just never pay.  And you just can't upgrade them.  And I would guess, I have no inside information, that what happened is LogMeIn realized that, that there are some people who are going to pay up.  But the people who are using the free service are going to keep using that forever, free.  We cannot convert them.



STEVE:  Right.  And it's funny, too, because remember they did another stage in this evolution where it used to be that people could have Hamachi, or LogMeIn version of Hamachi, on servers, and then could network into those servers for, like, remote server maintenance.  And one of the things that LogMeIn changed, this is maybe, what, six months ago or so, was nope, can't do that anymore.  You've got to be, like, have a logged-in desktop session and be active in order to use it.  And so that forced some set of remote server admins...



LEO:  It moved them up, yeah.



STEVE:  Yeah, moved them up, or they just said, screw this, I'm not going to go up that curve.



LEO:  I always worry when something I really love is free because free is not sustainable forever.  People have to eat.



STEVE:  Right.  Well, and my model is somewhat different.  I look at things GRC could do which I would like to do, but which would create a dependence of people on GRC.  And I just - I don't - I'm not comfortable with that model.  I don't want to, like...



LEO:  We don't do it either.  We don't do it either.  I just, you know.



STEVE:  Right.  So I do everything for free, and...



LEO:  And you have one thing that pays you money.



STEVE:  And SpinRite pays the bills, right.



LEO:  And as long as that works, which it apparently does, you're going to keep doing it.



STEVE:  Yeah.  I think - so if you don't want a third party, and the third party is the way to easily solve the router transversal, the NAT transversal problem, then one thing you can do is you can use one of the Dyn DNS services, which most routers now support, where essentially you get a DNS string, a DNS machine name whose IP dynamically tracks the router's public IP.  That way you can install in your mother's and your sister's system a means of contacting a server, a desktop server behind your router, which would track your IP.  So that link wouldn't break.  I think Dyn DNS, I know that there are paid versions of that.  But I think there are still free versions, too.  So it requires some setup and configuration, but it would solve the problem.  But except for things like GoToAssist, GoToMyPC, and similar services, I don't know of anything else.



LEO:  Well, there's TeamViewer.  I think a lot of people use TeamViewer.



STEVE:  Oh, great, and TeamViewer, also.



LEO:  And that's free, yeah.  See, I think TeamViewer might stick around because they charge so much for the paid version that they don't need to convert everybody.  It supports this strata of people who will never give you money.



STEVE:  Yup.



LEO:  Johnathan Rabkin, Dartmouth, New Hampshire wonders about suspend to disk security.  Actually a couple of people do.  I was wondering if, when a computer suspends to disk - that's hibernate, basically; right?



STEVE:  Yes.



LEO:  Yeah, laptops primarily, you could remove the disk, take it out of the computer, scrape the RAM image in the swap partition as a way of accessing passwords and encryption keys.  Moreover, I was wondering if that RAM image is overwritten on disk after the machine wakes up, or whether they just leave it around, maybe you could get it later.  And that ties into CZ in Washington, who wonders about "Inception" and breaking whole disk encryption.  He points to a link at breaknenter.org/projects/inception.  He says it appears TrueCrypt, BitLocker, and FileVault are a good deal less useful.  So what is this Inception thing?



STEVE:  Well, Inception was interesting.  First of all, it's a copyright violation, I'm sure.



LEO:  Oh, but this is where - this is like freezing the RAM.



STEVE:  Correct.  Exactly.  But one of the things this confirmed was a conjecture we made quite a while ago on this show, and that was that Thunderbolt was going to have the same problem as Firewire.  And indeed it does.



LEO:  Because it uses DMA, Direct Memory Access.



STEVE:  Exactly.  Exactly.  It is essentially a direct port into your machine's running memory.  So as we've talked about on the podcast before, if you can use a Firewire-linked - I think Inception supports Linux or FreeBSD machines.  If you can use a Firewire-linked machine, and it's powered on and running - even if it's in standby, often the Firewire interface will still be live - you're able to browse around through the memory.  And there are tools available, forensics tools, which have been designed to interpret the binary hash of RAM and locate keys that are in the hash.



Now, Johnathan's question about suspend the disk, this is a big problem, too.  And in fact for the first portion of its life, TrueCrypt did not offer encryption of the hibernation file, which was a known problem.  That is, if you had whole disk encryption, and you used TrueCrypt and hibernated, the hibernation file wasn't encrypted because it takes just extra technology and hooks, essentially, down into the OS and the kernel, to be able to come out of encryption, where the encrypted file is encrypted and decrypted in a safe way.  I remember when they added that, and it was like, oh, good, because that was something that was missing.



But in answering Johnathan's question, yes, if you're not explicitly performing whole disk encryption, and that whole disk encryption includes the encryption of the hibernation file, then the hibernation file lives in the root directory of your boot drive, and it's there all the time.  So it's written to when you hibernate, and it is read from after you wake up.  And I'm not aware that it is deliberately scrubbed.  I think that just the OS says, well, the guy's up and running in memory anyway, so who cares whether there's, like, a second copy of it sitting around.



LEO:  And it would be unencrypted.  It would just be - it's just a memory dump.  They don't process it in any way; right?



STEVE:  It is an image, yes.



LEO:  Yeah, just a dump of memory.  Hmm.



STEVE:  So to get security there, you need whole disk encryption.



LEO:  I don't like hibernation.  I never use it.  It's slow.



STEVE:  No.  Yes.



LEO:  Either leave the computer on or reboot and load everything.



STEVE:  Yeah, or just use standby and remember that you're in...



LEO:  Standby's fine.



STEVE:  Yes, remember that you're in standby.



LEO:  Eric Foss, Bakersfield, California has a question about MailStore:  I don't know how you got MailStore Home to work with Eudora, but I have hundreds of .mbx files, and clicking on each one ain't gonna happen.  I have most of my mail back to 1997  wow - so it would be nice to be able to search it.  But, well, if you get a chance, I hope you'll explain how you used MailStore.  MailStore was this program that allowed you to search all your old email; right?



STEVE:  Yeah.  Actually, again, it was another popular recommendation of mine which followed a discovery weekend before last.  Okay.  So I didn't go into it in more detail.  But I got so much feedback from people who were like, oh, this is fabulous, blah blah blah, that I thought I'd take a little bit - I'd talk about it a little bit more.



First of all, I used the commercial version also, which - because I was experimenting.  I mean, I thought maybe I was going to settle, I mean, I have settled on MailStore.  But it turns out I was able to completely work with MailStore Home, but not until I got things settled.  I used - the MailStore Commercial version is free for 30 days.  And I only needed it for one day.  So what I did was I installed the commercial version, and it's actually two portions.  It's a server that runs in the background, and then the MailStore client that runs in the foreground.  MailStore Home, the free version, has some limitations.  For example, you can only create three of one type of profile, as they call them, like archiving three mailboxes.  The Server, the commercial version, has no limits at all.



So what I ended up doing was informing the - I installed the Server version.  And, by the way, they can cohabitate at the same time.  They were both living, the Home version and the Server version, both living on my system at the same time with no problem.  And I actually did all of the importation of my many Eudora folders into the server version.  And at one point I had, like, 27 or 28 simultaneous folders being encrypted and indexed at the same time, and it handled them with no trouble at all.



Once I had that, I then exported it to a Microsoft Outlook PST file because that was the common cross-version file format that they both supported.  And then I used MailStore Home and imported that Microsoft PST file and then re-indexed it in order to create a MailStore Home index.  So I sort of came up with a bit of a kluge.  Basically I just wanted to do this once.  For me, I had email going back, a quarter million pieces of email nearly, going back to '07, so I just needed to get it into MailStore Home once.  And once that was done, then, all of my incremental archiving is being done very happily under MailStore Home.



Now, Eric has a slightly different problem because he says he's got hundreds of MBX files.  So the solution there is that, in Eudora, you're able to simply drop one folder onto another, and it'll move them over.  So I would say create a separate directory tree of all these MBX files, use Eudora to very quickly consolidate them.  You can just select all your messages and drop them on a folder; select all, drop them on a folder; select all, drop them on a folder.  That'll consolidate all of those mailbox files into one huge file, and then just let either version of MailStore, either Home or the Server, chew on that one MBX file, creating an index.  So that's a way you can - again, you only have to do it once.  And you might want to use Server, though, because it will allow you to do 30 things at once.  Actually, I think there's - no, 25 was the limit in how many threads it will run at once.  So I set it to the limit, 25.  But I gave it even more.  And as soon as it finished with those, it picked up on the other ones.  So it ended up working great.



LEO:  John Seybold has a question about SpinRite 6.1 vs. SpinRite 7:  As a very long SpinRite user - I think I originally bought v2, I know I bought v5 on a 5.25" disk, and I've purchased multiple copies of SpinRite 6 - I find it odd that you're talking about 6.1 and 6.2 rather than 7 or 8.  From your discussions on Security Now! - great podcast - this certainly seems like a major version upgrade, not an incremental release.  Why did you call it 6.1?



STEVE:  Okay.  So I understand what John is saying, and part of me sort of agrees.  But I'm fine with the sales that I have of SpinRite.  I dislike companies that really leverage their users' upgrades a lot.  Now, again, 10 years would not be a lot.  But to me this feels like the right thing to do.  I am resisting adding features.  This is all about speed and compatibility, essentially.  So to me, for a speed and compatibility change, it feels right to do this.  Also, we will be introducing - 6.1 will run on a Mac.  And so that will dramatically expand SpinRite's market additionally.  So in that sense it's a new version.  It will open up a big new market for SpinRite.



My plan for 7 is a complete rewrite.  And so for me this creates a boundary, kind of a clean boundary.  The UI in SpinRite 6.0 is set up to do what it does.  And it would just be a - it would take too much time, basically, to make it do a lot more.  So I can, if I restrict 6 and 6's future to speeding it up and introducing it to all the hardware and to the USB keyboard on the Mac and so forth, that I can do in a short time.  And so that's my goal:  Get SQRL finished; get back to 6.1, get that out; then tackle USB interfaces with 6.2, get that out.  And my point is that then can hold us while I work on 7.



And 7 I start by rewriting the UI.  7 will do all the other things that people would like from SpinRite, like be file system aware, do file recovery rather than sector-level recovery so that, for example, if a drive is dying, it'll pull all the files off of the drive and note the areas that it has trouble, but skip those, and get all the other files that it can, then come back and do data recovery on the files that wouldn't go.  And recover a drive in an image format to a different drive, rather than to the same drive.  All the kind of things that, yes, now that drives are commodity items, it makes sense to do.  That's my target for SpinRite 7.  But that's going to take a while.  And I can't hold a new SpinRite back for 7.  So that's why I decided, do something basically that sort of catches SpinRite 6 up to today.  And that'll effectively buy me time to do what I really want to do, which is 7.  And there'll be an upgrade fee for that, which I imagine people will be excited about because 7 will go so much further than SpinRite 6.



LEO:  That's quite an ambitious plan you've got there, young Stevie.



STEVE:  That's my plan.  And meanwhile we'll be doing podcasts every week, Leo.



LEO:  Holy cow.  File recovery.  Paul White writes to us from 45 25' 5.1312" North, 122 46' 30.5652" West - which, by the way, is about Beaverton, Oregon - had a thought about CryptoLocker:  Listening to SN-439, you said something about the way CryptoLocker works that turned on a light bulb in my head.  You said if one plugs a USB drive into an infected machine, on the next cycle that drive would have its files encrypted.  If one had two identical USB drives and connected one to the machine and allowed it to be encrypted, could the files on the two drives be compared and - whoa - reverse engineered to reverse the encryption?  Happy SpinRite owner, blah, blah, blah.  SN best 'cast ever, blah blah blah.  Paul in Portland.



STEVE:  And we know exactly where Paul is, by the way, in Portland.



LEO:  Yeah, I actually see a picture of his house when I put that in my maps thing.



STEVE:  So, okay.  So, Paul, no.  The good news is that won't allow CryptoLocker to be reverse engineered.  And that's a good thing because, if that did work, it would work with all other encryption, and that would be a bad thing because what you're describing is called the "known plaintext attack."  And the classic example, for example, and we talked about this when we were discussing crypto years ago, the Caesar cipher was a simple substitution cipher where you substituted letters for other letters.  And so what came out looked like gobbledy-gook unless you really looked at it closely.



Now, if you had the decrypted version of an encrypted message, with a simple substitution cipher, you could instantly create the equivalence table that turns plaintext into ciphertext and back.  So that's an example of a so-called "known plaintext attack."  Now, of course that cipher, the Caesar cipher, is weak because, even if you didn't have the plaintext, you could do a frequency analysis if you knew the language that the plaintext was written in and the character occurrence frequency.  You could do a frequency analysis of the plaintext and figure out what the characters were just by how often they appeared in the ciphertext.



But the ciphers that we use now, that CryptoLocker uses, which is AES, and that SSL uses, and that all of our full disk encryption uses and cloud encryption uses, everybody's using, are specifically immune to plaintext attack.  That's important because many of the things that we are encrypting have known plaintext, like the beginnings of web pages have standard headers.  The beginnings of files have standard file headers.  There's a lot that is known.  And so if there was a way to map the ciphertext to the plaintext that gave up any information about the key that was used, that would be a problem.  And so one of the very most important characteristics of contemporary ciphers, one of the first things people look at is does any information leak about the key that was used in transiting between the plaintext and the ciphertext.  And in good ciphers, all the ones we  use, the answer to that is a definitive no.  Knowing what it was when it was not encrypted doesn't give you any information that's useful about the key.



LEO:  It's not reversible.  That's what I would have said.



STEVE:  Okay.



LEO:  Wayne in Park City, Utah wonders whether he's missing something:  I listened to your Episode 439 on the Target problems.  Am I missing something?  Why isn't every authentication server or set of servers or server set or service, why aren't they set to only allow a few bad logins before both logging and alerting the attempt, then blocking additional logins for a few minutes?  Thus password guessing is not a viable technique, duh.  Yet Windows Server doesn't set this as its default, or even remind admins to change these defaults during an installation.  Isn't there a downside, or is there a downside, to making these changes to the defaults?  Shouldn't people just prevent that?  What do you say, Steverino?



STEVE:  So this is what I said was the - this is our last question of the day and is our teaser for next week's episode.



LEO:  Oh.



STEVE:  The answer, essentially, is that, while that would inarguably provide greater security, we also know that it would provide headaches for the support people because people who used to have four or five common passwords, they would not remember which one of their four or five common passwords they used, and so they would put a few in, trying to guess, and then the thing would say, oop, sorry, you're out of guesses, contact your administrator or wait some length of time or whatever.  So unfortunately, today, these things are still wide open.  There was a recent survey done of exactly what the industry's current password policies are, and we're going to discuss that next week.



LEO:  Ah, very good, very good.  All right, Steverino.  Hey, one other story.  Have you ever heard of EVE Online?



STEVE:  No.



LEO:  This seems like this would kind of intrigue you.  It's a massively multiplayer online role-playing game, MMORPG, where thousands of people engage in space battles with one another.  They've got territory, and it's been going on for 10 years.  It's a very popular game.



STEVE:  My word.



LEO:  Yesterday they had the largest online war in its history, 4,000 players simultaneously in the same space, battling each other because apparently a battle star neglected to pay its rent or protection money, really, to the - anyway, it's a very complicated reason.  But unbelievable, 4,000.  I wish I had video.  I'm looking to see if I could find it on Twitch or somewhere.  But, wow, wow.



STEVE:  And so it sounds like it's very much like what we did on New Year's Eve.



LEO:  Yeah.



STEVE:  So it's an online starship battle simulation.



LEO:  Yeah.  Well, except, I mean, if you look at it, it's beautiful.  You're really in it.  This is a still from the war.  I mean, imagine with 4,000 ships converging on one another.



STEVE:  Oh, lord.



LEO:  In a single system.  That is pretty amazing.



STEVE:  Wow.



LEO:  Steve is at GRC.com.  If he were doing this, he wouldn't have time to do all the other things he does for us, including not only this show, but also all the freebies he posts on his website.  ShieldsUP!, you could still test your port 32764.  If you go to bit.ly/port32764, you all should do that, make sure your router is not vulnerable.



STEVE:  Now you can just put 32764 in Google, and the first link that comes up is mine.



LEO:  Steve.  You'll find him.  He's closely associated with the number.  And all of this is pro bono.  The one thing he does that makes money is his SpinRite thing.  So if you don't - if you've got hard drives, you really ought to have it.  It's the world's best hard drive maintenance and recovery utility.  It's just fabulous.



STEVE:  You know, we talk almost always about recovery because of course no one's going to get it just because, for what the heck.  But there are people who have purchased it, and I thank them, just to say thanks for everything I'm doing.  And I would encourage them, run SpinRite on your drives.  It will keep them from failing.  We've heard testimonials from people who bought SpinRite to say thanks, but just left it on the shelf, waiting for a hard drive problem.  And so it's like, well, if you have it, run it, because it absolutely does prevent hard drives from crashing.



LEO:  Yeah, absolutely, get it.  And don't be put off thinking, oh, I'm going to wait till v7 because I don't want to pay the upgrade fee.  It's going to be a long time.  Get v6.  Steve's a very ambitious fellow, and he's a fast coder, I'm sure.



STEVE:  That's true.  There will be no benefit to waiting.  And everyone who gets SpinRite 6 now does get 6.1 and 6.2 for free.  That's my promise.



LEO:  Seven, we're not talking this winter.  Maybe next - maybe sometime in this decade, maybe.



STEVE:  Well, and that's if no more SQRLs attack.



LEO:  Yeah, SQRL is also there, all the information about SQRL.  Somebody said, where does Steve put all the health and nutrition stuff he talks about?  Is that written up anywhere?  Yes, it is, GRC.com.  Also 16Kb audio versions of this show; handwritten, human written transcripts of everything he says available there.  We have higher quality audio and video of the show, as well, at our site, TWiT.tv/sn.  You can also subscribe in your favorite netcast catcher, and it'll just come to you every week.  Or watch us live.  I think, more and more, some of the fun of this is watching live.  And you could do that by visiting us on, what is this, Tuesdays at 1:00 p.m. Pacific...



STEVE:  What day is it?



LEO:  I have no idea.  I'm very confused because of this new schedule.  Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC on TWiT.tv.  Before You Buy coming up next.  Thank you, Steve.



STEVE:  Thanks, my friend.  Talk to you next week.  And we will analyze the industry's current password policies, and it's not good news.



LEO:  Yeah.  I've actually often wondered this.  Why don't you just time out after three bad requests?



STEVE:  Not good news.



LEO:  Yeah.  Although when that happens to me, I hate it.



STEVE:  Exactly.



LEO:  Because I've got big thumbs, and I make a mistake, and then I've got to wait.



STEVE:  Exactly.



LEO:  Or I can't remember the password, and I try all my regular ones, and then I've got to wait.  All right, Steve, see you next time.



STEVE:  Thanks, buddy.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#441

DATE:		February 4, 2014

TITLE:		Password Policies  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-441.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with a bunch of interesting news, Steve and Leo examine a terrific piece of research performed by Dashlane, makers of a password manager.  They have researched and presented the current state of the top 100 web retailers' password policies.  Fascinating!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about the top 100 retailers and their password policies.  You'd be amazed at some of the easygoing password policies, low-security password policies some of these online stores have.  We also have all the security news for you.  Steve Gibson's next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 441, recorded February 4th, 2014:  Password Policies.



It's time for Security Now!, the show that protects you, your loved ones, your privacy, all the stuff you need to stay safe online with this guy, the Explainer in Cheap - Chief, not Cheap.



STEVE GIBSON:  Yeah, I'm the Explainer in Cheap.



LEO:  Cheap.  You're the Cheap Explainer.  Well, it's a free show.  I guess he is the Explainer in Cheap.  We could charge for this stuff, you know.  Mr. Steven "Tiberius" Gibson.  He is, of course, the man in charge of GRC.com, the Gibson Research Corporation, has written many really useful tools.  You've probably heard of a great many of them, including ShieldsUP!; and his bread-and-butter is SpinRite, the world's finest hard drive maintenance utility.  It's time for a show, no questions, just answers show.



STEVE:  Correct.



LEO:  Right?



STEVE:  Correct.  What came to my attention last week, and I mentioned it at the end of, I think, the podcast last week was a study that was done by a company, Dashlane, who make a password management utility.  Everyone of course is familiar with those.  Everyone knows my favorite is LastPass.  I want to make sure we give Dashlane credit for this research and let people know that they're there because we're taking advantage of their research, and I don't want to - I want to give them their due.



So what they did was they performed a set of tests to essentially reverse-engineer, from interacting just with the web interface of the industry's current top 100 web retailers, which they obtained from some other list - I mean, it's the who's who of the Internet.  Amazon's there, Apple's there, Microsoft, I mean, we'll be talking about these names toward the end of the podcast because they reverse-engineered the login policies of this top 100 set of retailers and found some really interesting things.  Like I was saying to you before we began, before you hit the Record button, there are some really curious things.  They looked at the minimum password acceptable.  And there are some sites whose minimum password is one.



LEO:  What?



STEVE:  Well, first of all...



LEO:  That's no password; right?



STEVE:  That's understandable because less than that would be none.  And so basically they're saying did you leave the password field blank or not? 



LEO:  Right, right.



STEVE:  But there are also some that have a minimum length of three.  And it's like, wait, wait.  So someone wrote code to see whether you had a password of one or two characters, and that was not okay, but three was?  Anyway, some really interesting things come out of this.  This is a problem because there's a spreadsheet that's online, which I now understand is a Google spreadsheet.  You just explained to me that you can't an infinite number of people looking at it.  But I created a bit.ly shortcut, bit.ly/sn441, which is the number of the podcast, sheet, s-h-e-e-t [bit.ly/sn441sheet].



So our listeners, who will be listening at various times of day, will probably be able to bring this up because I doubt that there'll be more than a hundred at any one time.  But this is the raw data from Dashlane's study, which we'll be looking at later on in the podcast, which is - and I've got all kinds of summaries and things that I've already established from that, which is really just fascinating because, for example, is there a limit to the number of times you can attempt to log in, and what is that limit, and so forth.



So, neat analysis that we're going to go into on today's Password Policies.  I initially put in 2014, but that would make the title too long.  So I thought, okay, well, we'll just leave it as Password Policies.  And some interesting news.  So this week on Security Now! we've got a new version of Firefox we'll be looking at.  An emergency update to Flash from Adobe...



LEO:  Yeah, I saw that one.



STEVE:  ...just happened today, and it's important for Windows PCs, Macs, and even Linux because this was a zero-day flaw which allows code to be executed in your machine if you let Flash run.  So, bad news.



LEO:  God.



STEVE:  Also, something picked up on the return of HoneyWords.  We talked about honey passwords, shortened to honey words, I think, last summer when this happened.  But for some reason they sort of came back.  So I thought I would just mention them briefly.  We're seeing a troubling rise in malicious ads.  I found a very interesting Windows Firewall add-on that I want to talk about.  And my own research brought me to why tossing a coin is not fair, which we'll talk about.



LEO:  Really.



STEVE:  And did the NSA ask me to build a backdoor into CryptoLink?  Someone did a blog posting positing that maybe that had happened.  And much more, this week.  So lots of fun stuff.



LEO:  Wow.  Boy, I would expect you would mention it if it had, but...



STEVE:  So, well, actually I said that I would simply stop talking about it.  And I did stop talking about it, about CryptoLink.  So...



LEO:  Whoa.  All right, well, shhhh.  Whoa.  Never Say Anything, NSA.



STEVE:  Today.  Oh, what?



LEO:  Go ahead.



STEVE:  I was going to say today we got a new version of Firefox, v27.  And one of the things that they commented on was that TLS v1.2 has been implemented.  Now, other people, in response to last week's comments about the HowsMySSL.com site, h-o-w-s-m-y-s-s-l dotcom, they commented that, well, in 26 you could turn it on, but it wasn't on by default.  So when I updated to 27, which just happened hours ago, and I went to HowsMySSL, it was a little happier.  Last week I got "bad" because it had two problems with my v26.  Well, then I got "improvable," I think it was, and it was still complaining that I was using TLS v1.1.  So I thought, huh?  What?



So anyway, what happened was - and to our listeners, who may also be affected by this, I went into - the way you go into Firefox's config is about:config you stick up in the URL address bar.  That takes you to this overwhelming number of things you can tweak.  And then in the search area you put in TLS.  And that brings it down to a manageable eight or so things that involve TLS.  Well, sure enough, it turns out that sometime in the past I had overridden Firefox's then-conservative max level, pushing it forward; but now it was pushed back because Firefox had been marching forward, and my override was now behind the times.  It used to be setting the TLS max version higher than it was the default.  But it was sticky, so now it was setting it lower than the default.



So if you right-click - and you can see that any overrides will be in bold in the Firefox about:config screen after you've whittled it down.  So I just right-clicked and hit Reset, and it removed the highlighting, allowing v27, which is today's, to now run at TLS v1.2, where it wants to.  And sure enough, HowsMySSL now says "probably okay," because remember it's pretty stingy about - it doesn't get very excited about even when everything is perfect.  It's like, eh, it's probably okay.  So that's the best you can get.  However, they did, with v27 from last week, remove that one pesky 3DES SSL cipher.  I remember I made you laugh, Leo, because the comment was "This cipher was meant to die with SSL 3.0 and is of unknown safety."  It's like, eh, okay, fine.  So anyway, that's gone now.



So Firefox have brought themselves up to the "probably okay" status with HowsMySSL, which is the best anybody can get.  And nothing much else got fixed.  They are continuing to move forward towards improving standard support and interoperability.  So I dove into the, you know, what do the developers think, what do the webmasters think.  And there were, like, all kinds of fixes down in the details of this got added and this and that now being supported and this we removed and blah blah blah.  But no huge security changes or anything, just moving us forward.



And also taking TLS 1.2, making that now the default, rather than, as was the case before today, you had to, like, push it.  It was there, but you had to turn it on on purpose.  Now they said, okay, fine, it seems to be working.  We'll let everybody use it  So this is good news, that we're now at 1.2 across the board with our major browsers.  It's been a while coming.  The standard's been available for quite a while.  But now that we're seeing servers supporting it and browsers are supporting it, some of those pesky edge cases where there were theoretical attacks that worried people, those are pretty much falling by the wayside.  And that's good.



So unless you're using the latest version of IE, that is, IE 11, or Chrome, both of which will be immediately made aware automatically that Adobe has a newer version of Flash, you really do need to update.  If you're running any kind of Flash blocker, as of course everyone is who's using NoScript, then you're probably more okay.  The reason this is a problem is that an integer underflow bug has been found.  This was detected by the guys at Kaspersky, who found it being used in the wild.  So they, in doing their research, their malware research, they found instances where people were running - going to a page that ran Flash, and they were getting malware installed just by visiting that page that had Flash-enabled content.  I don't know whether this was ads or something from the page.



Actually one of the things I want to talk about here in a second is a troubling increase in the level of malware we're seeing in ads.  And of course ads are often delivering Flash content, to the annoyance of web surfers everywhere.  But Adobe's got an update that they pushed out under emergency terms to deal with what is this zero-day flaw.  So it's important for people whose browsers are not updating themselves automatically to go get that.  You really should either have, I mean, it's hard to work without Flash.  It's still something that people are using and depending upon.  There's a site that I like, NutritionData.Self.com, which is really a nice way to research the content of stuff that you eat.  But all of their little charts require Flash.  So I'm often wanting to do it on an iOS device, which famously doesn't support Flash.  So I can see some of the stats, but not the little charts.  That's sort of annoying.



LEO:  We were talking - because we were talking about the exploit.  We were talking about it on MacBreak Weekly.  And who was it, Alex or Aaron Hillegass, one of the guests said, you know, they've been very successful in recoding everything in HTML 5.  No problems.  They've solved all the latency issues.  Just - Flash should just die.



STEVE:  It really should.



LEO:  There's no reason to use it anymore.



STEVE:  Yup.



LEO:  And it locks you out of every iOS device.  So besides the security issue, you're losing a big portion of the mobile audience.  Just don't use it.



STEVE:  And of course the mobile audience is a growing portion of the audience.



LEO:  Yeah.  I presume the site you're talking about is from Self magazine, and you'd think they would care about that kind of stuff.



STEVE:  Yeah.



LEO:  But they've already coded it, and they don't want to recode it, and...



STEVE:  Yes.  Yeah.  And in fact it's interesting, I moved all of my site's videos, like the SpinRite demo and other stuff, over to HTML5 some time ago.  But the PDP-8 videos that I did years back I still haven't done.  And I did the work to create a really nice set of files because actually there's three different formats you want.  There's MP4, WebM, and OGV.  And I came up with some simple batch files that I use that run FFmpeg to, like, automatically take an existing video in any format you have and re-transcribe it into - transcode it, that was the word I was looking for, transcode it into each of those three at an acceptably low bitrate and converts the audio and does all that stuff.  And I just thought I really ought to share this with the world because it took a while to come up with all of the - if you've ever seen a command line of FFmpeg, it's like, oh, my goodness.



LEO:  We do because every show we do is encoded with FFmpeg, and Russell Tammany has written a bunch of scripts using very, very long FFmpeg command lines.  Holy moly, yeah.



STEVE:  So Honey Passwords, I guess it was Net-Security.org made a posting about this which Gizmodo picked up on.  And when Gizmodo picks up on it, everybody starts tweeting me the link because it's like, oh, my god, you know.  And when I saw it coming in, I'm thinking, wait a minute, this isn't news.  This was, like, last summer.  And so I checked to make sure that it wasn't anything new.  And sure enough, this was interesting research by two guys whom we talked about, Ari Juels from RSA Labs, and of course Ron Rivest is the "R" of RSA, who's now at MIT.  And this was HoneyWords, or sort of the honeypot passwords concept.  The idea was that you would salt your web server's database with a bunch of fake user accounts with easily crackable hashes of passwords, like "password" and "123456."  That is, you would pretend to be really - okay, I almost said "stupid," but I didn't.  I didn't.



LEO:  Silly.



STEVE:  Users who would have those really poor passwords.  But you would tie them into a sentinel on your server.  And the idea was that it would sort of be like a canary in the coal mine, where if anyone tried to log into these fake accounts using really easily crackable passwords, that would let you know that your database somehow had been exfiltrated from your control.



LEO:  Clever.



STEVE:  Yeah, it is.  And so this paper was published on May 2nd of 2013.  Bruce Schneier blogged about it four days later, saying:  "Here is a simple but clever idea.  Seed password files with dummy entries that will trigger an alarm when used.  That way a site can know when a hacker is trying to decrypt the password file."  So since today is all about passwords, I thought, okay.



LEO:  That's a good idea.



STEVE:  I'll acknowledge the fact that I did see all those tweets from people who picked up on Gizmodo's delayed announcement of something that we talked about some months ago.



LEO:  It really does happen that, for some reason, lately a lot, blogs come back to stories they published months ago.  And people don't look - or the worst thing is I see tweets from stories of years ago, and people actually - oh, I just read this.  You've got to read the date.



STEVE:  Read the date.



LEO:  Yeah, always a good idea.  And go to the original source is the other thing I do.  Very important.  Go to the original.  Follow the back tracks to the original story.  And then you'll see, oh, yeah, this is ancient.



STEVE:  And I want the original source because I don't want the digested version.



LEO:  Right, the interpretation, yes.



STEVE:  Yes.  I want to go and get, you know, there's typically much more interesting information there.  So the Wall Street Journal did a piece where they talked about the growing problem of malware in ads.  And of course Yahoo! famously got infected, about maybe a couple weeks ago.  I don't think I covered it, just because we just - we've been running out of time on the podcast, and I had to just say, okay, wait, there's just not enough time to talk about this.  And there really wasn't much to say except that Yahoo! had been serving an ad that had been infecting people for some time.  And I found some stats that I thought were interesting and a little troubling.  RiskIQ, Inc. had been tracking malicious ads.  In 2011 they found on the order of 70,000 of them.  A year later...



LEO:  What?



STEVE:  Oh, yeah.  A year later, in 2012, 205,000.  And last year, 384,000...



LEO:  Oh, my god.



STEVE:  ...of them.



LEO:  Now, what does that mean?  Individual - I don't - what's the count of?



STEVE:  Yeah, that's a good question.



LEO:  Online, I see it somewhere online thing?



STEVE:  Right.  But they're unique instances of ads.



LEO:  That's crazy.



STEVE:  Yeah.  And Google in 2012 disabled ads from more than 123,000 sites.  But a year later, across 2013, disabled ads from more than 400,000 sites.



LEO:  Holy moly.



STEVE:  And so, finally, the last stat here is that the problem here is that - and we talked about this, for example, with CryptoLocker, where the older versions were now being caught by pretty much all of the AV.  But those samples that I posted, when I posted them two weeks ago, they were only being seen by four or five out of 47.  Well, these recent malicious ads are being missed by 44 out of 47 AV programs over on VirusTotal.



LEO:  Now, I don't want to encourage this.  But if you used AdBlock, you wouldn't be vulnerable to them; right?



STEVE:  Correct.  These things, I mean, first of all, the malicious ad probably needs execution privileges.  That is, it needs scripting or, as we were just talking about Flash, it needs Flash.  I say "probably" because we have seen just static image vulnerabilities, where the...



LEO:  Malformed JPGs, for instance.



STEVE:  Correctly, exactly.  We have seen malformed JPGs - a JPG, a PNG, a whatever - that are being rendered in your machine.  The bad guys cleverly find a rendering flaw that is able to - where they're able to, like, actually put code in the image.  The image won't display, typically, but it'll crash the renderer.  But in the process it runs code that they've also provided.  Those are rare.  What's more typical is that the ad actually is containing scripting and will run JavaScript or, god help you, Java itself, and take over your machine, execute the attacker's code.  So really just - you could still show ads if you just didn't let them run script.  And of course NoScript will do that for you.  It solves that problem.



LEO:  I have no ethical issue with doing that, by the way.



STEVE:  Right.  The other thing that's cool, we talked about how Google is starting to render the images for you, which is a huge win.  So rather than your page showing ads that your browser has fetched directly from the source of the image, if Google has provided the page, or if you're in Gmail, and that's typically where it's going to happen, you're looking at an HTML page with ads in it.  Google will pull the image and render it essentially on its own server, then take a picture of it and sort of re-render it.  And we've talked about the idea of transcoding the image.  For example, Opera famously does that in order to reduce the size of overly large images for their mobile platform.  When you're using Opera mobile, you actually get a good speed improvement because your browser's not having to go out and grab overly large images.  So that's also going to inherently clean up your advertising images and prevent it from being a problem.



But I guess - this just sort of came across my radar, and I wanted to take a minute to say that, I mean, it makes sense that this would be a new vector because, if bad guys are able to purchase ads and get them into major ad feed streams, and if those ads bypass the AV - so even a web advertiser that is doing a good job of protecting, trying to protect their feed from malware, if ads are staying ahead of AV detection, they'll go through.  So it's uncommon that a static image is going to have a problem.  So this is further reason not to let ads execute code.  And you see them where they're, like, amazing animations in these ads, where fishes are swimming around, and bubbles are blowing, and the seaweed is undulating.  And it's funny because I only see that when I look at other people's browsers.  My browsers all have NoScript installed.  And so I see ads, but I see their fallback image, which is, for one thing, way less distracting than these crazy Flash ads.



LEO:  It's really, the other point to be made is that it is the ad networks that are really at fault here because they allow people to put an ad up unchecked.  Here's a hundred dollars.  Take my ad.  And they don't check the code.  They don't check the ad.  They don't make sure everything's okay.  And they're the ones who are propagating these viruses.  I really don't understand why the ad networks aren't getting more heat from this because it's them - the Googles, the Facebooks, and all the other ones that are supplying these ads - that are making this possible.



STEVE:  Yeah.  There was one piece I read following some links that talked about how, in some cases, when the companies behind the malicious, like, discovered malicious ads, they tried to backtrack.  Not surprisingly, they were dead ends.  They were like nonexistent companies.



LEO:  Yeah, of course.  So it might be easy to check that.



STEVE:  Precisely.  Do it before you host their ad on hundreds of thousands of people's web browsers.



LEO:  The problem is that these ad networks really have completely automated ways of buying an ad.  Go on Facebook, and you can buy an ad directly, have it start showing up in people's pages right now, in seconds.  And that shouldn't - they make it too easy, in other words.



STEVE:  Right.  And so what they've done is they've essentially created a malware anonymizing service that allows...



LEO:  Yes.  Yes.  Why don't they get more heat for that?



STEVE:  And a malware distribution...



LEO:  We've got a malware distribution network here.



STEVE:  Yeah.



LEO:  So you're going to legitimate sites.  The site's safe, but the ad on the site isn't.



STEVE:  Precisely.



LEO:  I think they really should get more heat for that.  And frankly, it's going to kill their business because what do people do?  They run AdBlock.



STEVE:  Yeah.



LEO:  And I can't really blame people for running AdBlock if they're worried that ads are going to put malware on their system.



STEVE:  You know, AdBlock must allow some things through.



LEO:  Oh, they do.



STEVE:  Because I was going to say, I...



LEO:  You can make a deal with AdBlock to be a premium ad client that AdBlock will not block.  So there's different - there's two different - there's AdBlock and Adblock Plus.  And one is less good than the other, and I'm not sure which.



STEVE:  I have ABP on my Firefox.  And I see ads.  I just don't see really - I don't see things skipping across my screen and really bothering me.



LEO:  Yeah.  Adblock Plus was kind of - ABP was, for a while, I thought, the nonprofit kind of.  But apparently - remember we saw that story that they were offering people...



STEVE:  And there is a checkbox at the bottom of the config screen.  Let's see, configure...



LEO:  It says:  "How do we make money?  We are being paid by some larger properties that serve nonintrusive advertisements."  They have the Acceptable Ads Initiative.



STEVE:  Yeah, and, see, again, I'm kind of okay with that because...



LEO:  I think it's extortion.



STEVE:  They're doing some curating so that...



LEO:  Yeah.  You know how they curate?  Give me some money.  I think it's extortion.  They're saying, well, you know, you want people to see your ads, you'd better give us some money.  "Extortion" is not the right word.



STEVE:  But you also can't have, hey, I've got color TV, you know, shouting out of your ad.



LEO:  Well, they say that.



STEVE:  My point is, my experience is...



LEO:  Yeah, they do do that, yeah.



STEVE:  Yeah.  I'm never - I see other people's browsers, and I think, oh, my goodness, how do you sit in front of that?



LEO:  Oh, yeah, it's garbage.



STEVE:  And mine's just very sedate.



LEO:  And that's the other, I mean, so here's - I've mentioned my position before.  But you're using a free site that is ad supported.  By not looking at the ads, you're really cheating.  You're saying, well, I'm not going to see the ads, but I still want the free service.  So the ethical way would be not go to those sites that have really annoying ads, or see the ads.  But to block them and go to the site is kind of, to me, it's clearly unethical.  However, they're bringing this on themselves by having intrusive ads, malware-based ads.  And I can't really blame somebody for wanting to block that.



STEVE:  Well, and the perfect compromise is just make sure you've got scripting shut down because I don't want to say it can't happen, because we know it can.  You can have a malicious static image.  But you're 99.999% safe if you simply block scripting because that's the way the malicious ads are being served.  And if you block scripting, you'll still see their backup, static content.  You just won't see - it won't look like a circus that's happening.



LEO:  Yeah.  It really is.  Some of this stuff is terrible.



STEVE:  Oh, god.  It's just awful.  Okay.  So I have the link here in the show notes, Leo, under Intelligence Law Blog.  And this was, I guess, it says 2013/12, so it must have been December of last year that this - it's a very well-written blog posting.  And I won't read the whole thing.  I'm just going to say that this blogger, who's a listener, he's a fan of the show, says - he asks the question, "Did the NSA or FBI Threaten Steve Gibson to Force Him to Abandon CryptoLink?"  And he runs through the timeline where he explains how excited I was, and I was talking about it all the time and getting trademarks and buying domain names.  And in fact I did buy CryptoLink.com.  It's the only domain name I think I've ever purchased from someone.  It was a chunk of change, actually, because I was like, this was - I was going to make this a commercial product, and I wanted CryptoLink.com, and so I got that. 



And then he says, at one point, he says that I was speaking of CryptoLink often and enthusiastically and once said:  "If you ever hear of me or learn of me discontinuing CryptoLink for no reason, you'll know that for whatever reason I felt no longer able to offer something whose security I could put my reputation behind because I'll kill it before I would compromise it."  And then he goes on to say, like on some, like, last podcast...



LEO:  March 4th, 2010 you spoke those fateful words.



STEVE:  Yup, and then never mentioned it again.  And of course it's interesting because I did just mention it a couple weeks ago, but of course that's not fair.  This blog post was more than a few weeks ago.  It was eight weeks ago or six or something.  Because I explained that - and I guess at some point I remember saying that.  I did deliberately say, okay, I can't do this because - and we talked about it at the time.  I was reading the handwriting on the wall, even pre-Snowden, that our government seemed to be really uncomfortable with crypto technology on the Internet that it didn't have a backdoor to.  And my concern was that I would invest a year of my time developing CryptoLink to be commercial and then have someone approach me and say, "Steve, we need access to your customers' use of this tool."  And there's no way I could allow that.  I mean, in the same way that Ladar and others have said no, this is not okay.



And so I stopped working on it because I was concerned that was going to happen.  And then of course we've had all of the NSA revelations of the past year, since Snowden, and so forth.  So my current plan that I...



LEO:  So just to be clear, you did that preemptively.  It wasn't that you were approached.



STEVE:  Correct.



LEO:  You did it because you figured eventually you would be approached, and you just didn't want to be in the position of doing a crypto solution.



STEVE:  Well, I didn't want to be in a position of having invested a year of my time in something that I then had to kill.



LEO:  But just to be clear, the feds have not contacted you, did not contact you.



STEVE:  They have not.  Absolutely have not, and never have.



LEO:  Okay.  And there's nothing to contact you over at this point.



STEVE:  And probably I couldn't say it.  I wouldn't answer the question.



LEO:  It depends on how they contact you.  I mean, if they walked up to you, as they did to that woman at the security conference, at the RSA Conference, and said, would you mind if we put a backdoor in there, on mic?  That's not - you can tell people that that happened.  If they send you a National Security Letter, then it's a different...



STEVE:  And so my current plan is to do CryptoLink as freeware in the future.



LEO:  Okay.



STEVE:  And then I feel different about it.  If I always intend to make it free, then it's, first of all, and for some reason I can't, then okay, well...



LEO:  No harm, no foul, yeah.



STEVE:  Yeah, exactly.  So that's the plan.  And by the way, I keep meaning to get to this.  Is there something called Freelan.org?  Can you put that in real quick, Leo?



LEO:  I would check.  Yeah, that sounds familiar.



STEVE:  Yeah, it's good.  It's techie.  It's not easy to use.  And it looks like they did everything right.  Yes, there it is.  Someone's tweeted it to me, and I think I've got it in notes somewhere so that I can give them credit.



LEO:  So this would be like a Hamachi replacement?



STEVE:  Yes.  This is a very much done right, TNO, Hamachi replacement.  It's not for the faint of heart.  But it will allow you - it is cross-platform, Windows, Mac, and Linux.  And it will allow you to build Hamachi-style private networks, like in your own IP space.  You wouldn't want to use five-dot anymore.  And I think they use nine-dot, which is owned by IBM.  There was another one that I thought would be a better choice.  But anyway, I wanted to just - this is completely sort of - I'm not prepared to do a full presentation about it.  But I have spent some time digging into it.  And it's very nice looking.  So Freelan.org.  And you can either do client-server or a peer-to-peer network or a hybrid, very much like Hamachi.  And all of the crypto looks very correctly done.



LEO:  Neat.  Freelan, F-r-e-e-l-a-n dot o-r-g.



STEVE:  Yeah.  So Windows users who are also a little more on the techie side, I ran across something called Windows Firewall Control, which is free.  It's Bini, B-i-n-i, Soft.org [BiniSoft.org].  And they only - they have two things that they offer.  One of them is unregistratable.  Registratable?  Registrationable?  Anyway.  Registerable, I guess, yeah.  And that's something that allows...



LEO:  I don't know.



STEVE:  Can't register it?  Anyway, registrate...



LEO:  Registerable.  Registrable.



STEVE:  Register.



LEO:  Ask Dr. Mom.  She knows all that stuff.



STEVE:  You do not need to register, even to get...



LEO:  Yes, that's right.  Circumlocute, that's always the solution.



STEVE:  I hate adding stuff to my machine.  But if it's there already, and I can tweak it, I'm much happier.  Well, we've had Windows Firewall, famously, since XP.  Initially it wasn't on by default, then they turned it on in SP2, and they've continued to add features to it to make it more powerful ever since.  Windows Firewall Control is a very nifty add-on - I think you need Windows 7, doesn't support XP, but it runs from Windows 7 or Vista or 8 or 8.1, and also Server 2008 - that gives you control.  Just from their description:  "Windows Firewall Control is a nifty little application which extends the functionality of the Windows Firewall" - which, and this is my point, is already there in your machine - "and provides quick access to the most frequent options of Windows Firewall.  It runs in the system tray and allows users to control the native firewall easily, without having to waste time by navigating to the specific part of the firewall."  Believe me, it is a - it's hard to get in there.  Microsoft doesn't make it easy to find.



So, for example, they say:  "Windows Firewall Control offers four filtering modes which can be switched with just a single mouse click."  High filtering, suddenly all outbound and inbound connections are blocked.  This setting blocks all attempts to connect to and from your computer.  Which is kind of cool.  Sometimes you might want to do that.



Someone was asking the other day if there was - they wanted to run, I don't remember what it was, I think it was the Off The Grid, my Off The Grid password generator based on Latin Squares.  They loved it, but they were trying to run it on a disconnected machine, and I ended up suggesting, well, you could do it in a VM.  They just liked the idea of generating - of running the randomness without any access to GRC because I think GRC helps, it provides some of the entropy seeding of the ultra-high entropy random number generator that I developed for the Off The Grid thing.



But here you could just switch on high filtering to essentially disconnect yourself from the Internet for some period of time.  Medium filtering says outbound connections that do not match a rule are blocked.  Only the programs that you allow can initiate outbound connections.  And that's cool.  So this is bringing back this notion of famously ZoneAlarm-style blocking, where you are able to control specifically which applications have access to the Internet.  Low filtering, outbound connections that do not match a rule are allowed.  The user can block the programs he doesn't want to initiate outbound connections.  Or no filtering, Windows Firewall is turned off.  It says avoid using this setting unless you have another firewall running on your computer.  And then they've just got a ton of really interesting features.  I won't go through them all at length.  But I'm impressed.



So if this sounds interesting to you, there's just, like, all kinds of additional things that they've added to it that really impress me.  And for a $10 donation, which you can make through PayPal, you get with registering this a notification system, where you can get notification, for example, of things that are trying to access the Internet that you haven't been made aware of.  And of course, famously, I was beta testing ZoneAlarm, and that's how I discovered that I had the ad alert, or the adware stuff, the Radiate and Aureate, they were calling themselves at the time, spyware in my machine.



So anyway, I'm impressed with this little app.  I'm not running it yet because I'm on XP.  But anyone who's 7 or later can.  And again, it just runs with the existing firewall, which I like a lot better than installing a third-party firewall into an existing system, since there's a perfectly good one already present.



And they do, by the way, for free, also make a USB flash drive controller, which enables you just to do a complete enable and disable of all USB flash drives on your machine.  You can deny execution from the flash drive to protect yourself from anything running off of it.  Many people just use their flash drives for data, and they want to be protected from, example, malware that might get into their system that way.  And this could do that.  Famously, probably, Stuxnet would have never been able to operate had this been present.  You can also cause them to be mounted read-only, so your system can never write to flash drives, which could also come in handy.  And that's a little freebie from the same people, which I think is neat.



LEO:  Cool, yeah.



STEVE:  Okay.  What I think we're starting to see is another - it's been described as a "land grab" by malware furiously going after point-of-sale terminals.  Famously, of course, we've been talking for the last few weeks about the Target infiltration of malware into their Windows XP Embedded POS terminals, which ended up causing 110 million people's credit card data to be exfiltrated from Target over some period of time.  Then Neiman Marcus has now confessed a similar breach.  Just this morning they were in front of a Senate hearing, and Reuters was tweeting live from the hearing.  Apparently their CIO said that a maximum of 1.1 million accounts were potentially exposed to malware in a data breach that they suffered, but probably somewhat less than that.  And this occurred, they're saying, during transactions at 77 of 85 Neiman Marcus stores between July and October of last year, of 2013.



LEO:  Boy, these point-of-sale systems really are a target, aren't they.



STEVE:  Yes.  And that's what...



LEO:  They're so vulnerable.



STEVE:  Yes.  I think that's what is going to happen.  In fact, I jumped on TNT yesterday morning to talk about this briefly with Mike and company because there was some additional news that had just surfaced.  The RSA has uncovered a botnet which they're calling "Chewbacca."  I don't know why.



LEO:  [Wookiee sounds]



STEVE:  But it's a keylogging and memory-scraping botnet which they have acquired the binary and reverse-engineered the binary.  They discovered that it uses Tor hidden servers.  So there is a Tor client in the binary which goes through the Tor network to hide the server that it is contacting.  And it's exfiltrating this user credit card and PIN and other transaction date from point-of-sale terminals wherever this is installed.  It puts itself in the startup folder.  It again takes advantage of the fact that most of these systems are running Windows XP, the embedded version.  And unfortunately, in 62 days, that'll no longer be getting any security updates.



LEO:  No, Embedded goes longer.  I think Embedded...



STEVE:  Oh, it does.  Oh, you're right, it does.  Yes, yes, yes.  But I wonder whether Embedded XP running out in some little terminal, is it getting updates?



LEO:  Yeah, how is it being updated?  Yeah, yeah.



STEVE:  I'd be surprised, actually, if it were pulling security updates because they probably figure, well, no one's able to browse anywhere, so why keep it current?



LEO:  Oh.  Oh.  Lordy, lordy.



STEVE:  So I think what we're seeing is a new, unfortunately, a new and very vulnerable attack vector.  Think of all the little chains and stores that are...



LEO:  And they all use the same software; right?  I mean, that's part of the problem.



STEVE:  Yup.  There's a low number of original sources of this, and they're all leasing it or purchasing it, and it's probably got the same, and it's probably just old crap that's in there because it's like, eh, you know, hey, it works.  Why update it?  Well, why, indeed?



Okay.  So this is completely random, or that's actually a bad pun because I'm now working, as I'll explain for a different reason in a minute, on the user interface side of the SQRL project.  It's been coming along beautifully.  And I'm now working on what the user sees as they use SQRL.  And I'm doing this just prior to starting to write code because I'm at the point now where we're ready to write code.  And I was spending some time on the problem of generating entropy because one of the things that SQRL needs, as everything does that's doing crypto, is a really, really, really, really, really good source of randomness.  And it's easy to say that.  But we've talked about, for example, the bizarreness of the discovery that SSL certificates are using the same private key because they're being generated by UNIX systems or Linux systems which are turned on and immediately asked to generate a key.



Well, if you turn the same systems, the same version of Linux or UNIX on and immediately ask it to generate a key, it hasn't had a chance to get much randomness because they're all starting from the absolutely same initial condition when they boot.  And so it turns out that enough companies did that, that they generated the same random keys for their SSL certificates.  No one knew until the EFF started looking at all of the random keys and found, surprisingly, collisions between them.  So that's an example of where we think we have something random, but we actually don't.  And in a system like SQRL, we don't want to make that kind of mistake.



So I was brainstorming sources of randomness.  And I've already talked about some that I think are kind of clever, like having the user turn their camera on and just shake it and point it around.  And while SQRL is streaming the video in and just absorbing all of that absolutely high level of random noise that would go into a random pool in order to generate the user's single unique identity, which they can potentially then maintain for the rest of their lives and identify themselves uniquely on the Internet.  So I was thinking about this.  I just thought, well, you know, what about a coin toss?  What about giving - again, I'm working on the user interface side.  So one option would be, okay, get a coin.  And we're going to set the counter to zero.



LEO:  All right.



STEVE:  And you toss the coin.  When it lands, you press heads or tails.  Okay?  That's one.  Now you do it again.  And if you did it 256 times, you would generate a 256-bit absolutely incredibly high entropy random number.



LEO:  Right.



STEVE:  Or would you?



LEO:  A heads is one and a tails is zero.



STEVE:  Exactly.



LEO:  Yeah.



STEVE:  And 50/50 chance.  And so wouldn't that be random?



LEO:  Yeah.



STEVE:  So I thought, you know, I'd better make sure that that would be random before I suggest that to anybody.  Turns out it's not.



LEO:  What?



STEVE:  I found some interesting analysis.  The guys, there's a group called "statweb" at Stanford that published a 31-page paper of physics that is the "Dynamical Bias in the Coin Toss."  And it's a fascinating read.  The show notes, which of course now we're publishing, the links are in the show notes.  But their abstract on this 31-page paper reads:  "We analyze the natural process of flipping a coin which is caught in the hand.  We prove that vigorously flipped coins..."



LEO:  Vigorously flipped.



STEVE:  Oh, yeah.  And it matters.  We have some takeaways here that I'll cover in a second.  But "...vigorously flipped coins are biased to come up the same way they started."



LEO:  Ah.  Biased by how much, though?



STEVE:  Well, but, you know, I need...



LEO:  Any bias is nonrandom, so...



STEVE:  Oh, exactly.  "The amount of bias depends on a single parameter, the angle between the normal to the coin and the angular momentum vector."



LEO:  Well.



STEVE:  And so I did say I was going to simplify this.  "Measurements of this parameter based on high-speed photography are reported.  For natural flips" - and look at this.  You're scrolling through this right now.  It's like it's head-spinning physics.  "For natural flips, the chance of coming up as started is about 0.51."  So not 0.50.



LEO:  You're likely, if you flip a "1," to flip another "1," by a small amount.



STEVE:  Correct.  Exactly.  Or if you don't randomize the starting orientation, then you're going to be biased on the way it falls.  So here's a set of really interesting takeaways from, I mean, like, okay, who hasn't flipped a coin or had an occasion to do that?  So here on the Security Now! podcast, here's the wisdom from the research of guys who really studied this:  If the coin is tossed and caught, it has about a 51% chance of landing on the same face it was launched.  So in other words, if it starts out as heads, there's a 51% chance it will end as heads.  But if the coin is spun rather than tossed, it can have...



LEO:  There's a flick that people do; right?



STEVE:  Yes.  It can have a much-larger-than-50% chance of ending with the heavier side down.  Not really surprising, when you think about it.  Turns out that spun coins can exhibit a huge bias.  It says some coins will fall tails-up 80% of the time.  So if you can trick somebody into choosing tails or, no, choosing heads, and spin the coin, that can be a huge win for you, depending upon the coin.



LEO:  So if you can get heads, flick it so that it spins.  And the more vigorously you flip it, the better.



STEVE:  Well, now, spinning is meant like this.



LEO:  Oh, like that.  Not flicking it.



STEVE:  Twirling it.



LEO:  Nobody's going to let you spin a coin that way.



STEVE:  Twirling it on a hard surface, yeah.



LEO:  That's not how you flip a coin.



STEVE:  That's the problem.  If the coin...



LEO:  Okay.  I want to pick heads, and I'm going to spin it.



STEVE:  Yes.  And it turns out 80% of the time...



LEO:  So this doesn't count, like flicking it like that?  Because that's - I don't know.



STEVE:  They were talking about - they were definitely talking about spinning it on a hard surface.  If the coin is tossed and allowed to clatter to the floor, they say, this probably adds randomness.  



LEO:  Yes, of course.



STEVE:  Okay.  If the coin is tossed and - oh, sorry.  Oh, I got that one twice.  Oh, no.  If the coin is tossed and  allowed to clatter to the floor where it spins, as will sometimes happen, the above spinning bias probably comes into play.  So that's not surprising.  Now, get this one.  A coin will land on its edge around one in 6000 throws, creating what they called a "flipistic singularity."



LEO:  Yes.



STEVE:  So there you go, baby, you've hit the flipistic singularity.



LEO:  You know, if you'd asked me, I would have thought it would be much less likely than one in 6,000.



STEVE:  I did, too.  I've never had it happen.



LEO:  I've never seen that happen.



STEVE:  Unh-unh.  Never seen it happen.  But they're saying, eh, one in 6,000.  So, and you could probably prove that at home because...



LEO:  Get going.  Get to work.  You could tell us next week.



STEVE:  If you do, I want a picture.  Turn, you know, be sure you've got your webcam or your phone recording it.  Otherwise we're not believing it.



LEO:  Yeah.  I imagine there's some bias introduced by the fact that they're using automated flippers and things.



STEVE:  No, no, no.  They removed that.  The same initial coin-flipping conditions produced the same coin flip result.  That is - oh, yes, they did actually create - their automated coin flipper, they were able to set it up so that every time it flipped it, it got the same result.  Period.



LEO:  Yeah.  Period.  Wow.  Because that's super consistent, yeah.



STEVE:  The same initial coin-flipping conditions produce the same coin flip result.  So it says, that is, there's a certain amount of determinism to the coin flip.



LEO:  Because it's a mechanical device, yeah.



STEVE:  Right.  Oh, and the more robust coin toss, which is to say the more revolutions, lower the bias.  So if you, for whatever reason, you have to get a coin toss, and say you're the person who's calling it, if someone does sort of a lame toss where it's not really flipping, it's like in the air, but it's not really spinning fast, eh, that's going to tend to have more bias than if it spins really fast.  And I guess we didn't really learn much.



LEO:  Just don't gamble with professionals is what I learned.



STEVE:  Finally, many people just tweeted something which I haven't had a chance to dig into because it's just hot off the press.  But it's a breakthrough in zero-knowledge proofs.  And I'll just quote from this because it's a nice teaser.  I will dig into it and figure out what it means and talk about it probably next week.  And this is a guy, Amit Sahai.



"As a graduate student at the Massachusetts Institute of Technology (MIT) in '96, Amit Sahai was fascinated by the strange notion of a 'zero-knowledge' proof" - which we've actually covered on the podcast, and I'll remind our listeners and point people here in a second at where we talked about Ali Baba's Cave, famously - "a type of mathematical protocol for convincing someone that something is true without revealing any details of why it is true.  As Sahai mulled over this counterintuitive concept, it led him to consider an even more daring notion:  What if it were possible to mask the inner workings, not just of a proof, but of a computer program, so that people could use the computer program without being able to figure out how it worked."  That is, not being able to see into it and reverse-engineer it.  And there's actually apparently a breakthrough that makes this possible, which is very cool.



So as an intro to this concept of zero-knowledge interactive proofs, that's the title of podcast No. 363, where we tell the tale of Ali Baba's Cave.  So long-time listeners will remember the podcast about Ali Baba's Cave.  If that sounds new to you, that was on August 1st of 2012.  Go check out Security Now! No. 363.  You're going to need it because we will assume that that's knowledge in evidence when we go into how this can be leveraged, apparently, into the design of software, which can be used, but cannot be understood.



LEO:  I didn't understand it the first time, but okay, go ahead.  And I was there.



STEVE:  I did want to mention, Leo, I heard you mentioning on MacBreak Weekly, as you said you would, my discovery of the overtrain...



LEO:  Yeah.



STEVE:  ...of Touch ID.  It has been a huge hit in the past week.  I've just - there have been so many tweets from people, even people creating blogs and web pages and things to retell and reexplain how this operates.  And so I did create - I don't know if I had a bit.ly shortcut for that.



LEO:  You did.



STEVE:  Okay, bit.ly/sgtid.  And that must in fact expand out to somebody's blog posting because...



LEO:  No, no, it goes to YouTube and goes right to the part of the show where you walk us through it.



STEVE:  Oh, exactly, yes.  Exactly.  So for people who may have forgotten about it or haven't had a chance to try it, for what it's worth, now we've a much larger base of experience of people saying, wow, it works.



LEO:  Yeah, yeah.  Yeah, it was a really good tip.  I was glad I could mention it on MacBreak Weekly.  And I don't know if you saw, but it was written up on iMore.com, and I suspect more and more people will play with it.  It's really good.  By the way, that is not a garbage truck in your backyard, everybody.  You're listening to Steve's.  It's our regular NSA pickup of his documents.



STEVE:  Our weekly, yes, it turns out that you can scan them.  And what they're actually doing at that large facility in Utah is they are taking pictures of the shreds.



LEO:  The shreds, in case they need to reassemble them.



STEVE:  And Watson is reassembling them, just to see if there's anything good.



LEO:  Awesome.  Awesome.



STEVE:  Yeah.



LEO:  It's just metadata.  Don't worry about it.



STEVE:  I did want to mention I'm now working on, as I did say, on SQRL's UI.  And what's interesting, and not surprising, is that my work on the user interface is feeding back into the technology because this thing will not succeed if it's confusing to anyone.  And so now I'm working on the de-confusing part, where we want to have this thing still be feature-rich, without overwhelming people.  So what's happened is, almost inevitably, as I've been struggling with how to make its operation clear, I've realized, okay, now, wait a minute.  We have, like, too many degrees of freedom built into the back end of the technology.  So I've been making some changes which have ended up in some really nice additional functionality, essentially.



So there is a new page finished as a result of this.  It's not the UI yet.  But the SQRL region of GRC now has 20 pages, and not all of them are finished, but this one is.  No. 5 is what I call the Key Flow.  And so it's got a URL.  But, yeah, if, Leo, you click on - oh, you found it.  There it is, yeah.  And it'll make your eyes cross a little bit when you first see the flowchart.  But if you spend some time, other people in our newsgroups, the GRC newsgroup where we're working on this stuff have spent some time looking at it and reading through it and said, wow, I actually understand that.  So the way SQRL manages passwords and keys, which we've ended up adding some features actually, and at the same time reducing the complexity of the user interface.  So we're getting there.



And I'm now working on the UI, the actual what-the-user-sees in order to make it all go.  So if you're interested in this, I commend you to take a look at page no. 5 of the SQRL site, which is the Key Flow [GRC.com/sqrl/key-flow.htm].  I think you'll enjoy looking at the chart, thinking about it, and then reading the text below where I explain sort of step-by-step what each facet of that is about.



And as you mentioned, Leo, the source of my income that allows me to spend time on things that I don't charge for everyone of course knows is SpinRite.  We had a really nice testimonial from a Philip Cooke.  He said:  "I started my day with a Blue Screen of Death" - whoops, that's not a good way to start your day.



LEO:  No.



STEVE:  "...advising that I had an unmountable boot volume."  Which of course Windows users have seen from time to time, unfortunately.  He said:  "Efforts by a Dell tech only led him to the conclusion that we should reformat the" - yeah, we.  The tech and I are going to "reformat the drive and lose all my data.  Nothing would recognize the drive, and all the chkdsk commands in the book could not even see it or result in anything but the same blue screen on every reboot.  A Maxtor utility I ran advised me to return the drive for a replacement.  But I couldn't."



He said:  "After getting estimates ranging from $400 to $2700 to recover my data" - and, by the way, they don't come with a guarantee - "and trying numerous other 'tricks,'" he says in quotes, "recommended by online chats, et cetera, I was fortunate to come across SpinRite.  At first the glowing testimonials" - which obviously he means on my site, and of course I'm reading one such, which he then contributed.  But he said:  "At first the glowing testimonials seemed just too good to be true, and I will admit that I thought they may even have been fake," as he now, again, contributes one that really does sound that way.



He said:  "So I invested the $89, downloaded the file, and fired it up.  At first I thought that it was going nowhere because after four hours it still said 2% complete."  Which of course meant it hit a bad spot, and SpinRite was just going to work until it fixed it.  He says:  "I figured I would leave it running.  And imagine my surprise when I came back, saw the message that it had completed.  It booted up, ran chkdsk, and then started Windows.  All I can say is wow.  Thanks for taking the time to create this program.  It's bad enough losing data, but I also saved the hours it would have taken to recreate my desktop, links, et cetera.  Needless to say, I'm impressed.  Philip Cooke."  So thank you, Philip, for a very nice affirmation of SpinRite's capabilities.



LEO:  Steve Gibson is here, and we are ready to talk about the subject of the day.



STEVE:  So I love this data because it, first of all, was methodically and very nicely pulled together.  And I liked it also because it's sort of a snapshot of where we are at the beginning of 2014, the current Internet password policy.  So we know what the problems are.  We've talked about it a lot.  In non-multifactor, user-generated passwords, they're going to typically have low entropy.  They're going to generally be reused.  And they're going to be like their own favorite secret, the birthdates or dogs' names or sometimes a string of digits, 123456 and so forth.  So the incoming password is already in trouble.



Then we have the problem of websites storing them in plaintext or in unsalted simple hashes.  And of course we always talk about the large number of instances where databases of stored passwords get loose.  The hackers run them against the hash that was being done and crack all of the easy ones because, again, the poor storage on the website couples with the poor generation on the user side, and people's passwords get loose.  And of course then famously, since people are generally reusing these weak secrets that they have, their account data gets loose, and it's possible for them to get impersonated on other sites, let alone the one that just suffered the breach.  So this is just a big mess.



And yesterday, when I was on with Mike, I sort of explained, on TNT briefly, I explained that one of the problems is that, like, why do we have these problems?  Why are there so many websites with really inadequate security?  And I think one of the reasons is that security is invisible.  There's no visibility from the user's view into the security of the site.  Yes, sometimes if there's no password policy shown, if it accepts a two-character password, that would be a concern.  I mean, so there are some things that the user can test.  But most people don't.  And the problem is that we know that security tends to conflict with usability.  That is, the more restrictive the policies are, the more people that are not going to be able to use their favorite password, and so they're going to grumble about that.  So the tradeoff is made, well, we don't want to inconvenience our users.  So we're not going to impose strict regulations on what they're able to do.



But more than that, it's really not possible to know what's happening behind the scenes, how a website's security actually looks.  And if there were some way of making that really visible in a usable fashion, well, then, to a much greater degree than I think we see today, websites would take the time to improve the security that they're offering because then it would become a feature.  Then it would become something that they could be held to account for.  And so that's another one of the reasons that I really like the work that Dashlane did, is that to the degree that this gets some press and some publication beyond the scope of our own listeners, who probably already have much greater and better password habits than the typical Internet user, this is a good thing.



So Dashlane, first of all, just I want to make sure we give them credit for this.  They are another one of the password manager sort of companies.  And of course we know LastPass is the one I use, only because - it's just of inertia, I guess.  It does everything that I want.  And I was able to get a full readout on the technology and verify the way it functions.  People are always tweeting me, what about 1Password or this password or that password, or even Dashlane?  And I just say, well, it's probably okay.  And sometimes I'll take a look at the security and confirm that it looks okay.  But I just haven't done the deep dive.



So Dashlane is another of those.  They're a little pricey for their registered version.  They ask for $30 a year, whereas LastPass asks for $12.  And I don't really see anything to differentiate them.  They've got mobile platforms and cloud synchronization, cross-device synchronization and so forth.  But they are a password manager.  And actually I don't know if I see multifactor support in their list of things.



LEO:  Yeah, I mean, that's one of the things I love about LastPass.  I can use a YubiKey or Google Authenticator.



STEVE:  Yes, yes.  Yeah.  But anyway, I did want to give them a tip of the hat because they produced the data which was really interesting.  Now, at the beginning of the day today, I grabbed their raw data and created a massively large PNG file.  And that link, and I'm serving that from my site, is bit.ly/sn441, all lowercase.  And that of course is the episode of Security Now!, sn441, all lowercase.  And the problem of course just being a huge PNG, and this is of their raw data, is that you lose the labels of the companies, the websites, on the left and the headings of the columns on the top.



And so someone said in the dialogue in Twitter this morning, hey, wouldn't it be great to create a big - this really needs to be turned into a spreadsheet.  And so this was initiated by Jon M., who is @Liquidretro is his Twitter handle.  He created it.  And then a few other people jumped in, and I added some highlighting to the right-hand side of the score columns in order to make it a little more clear how they were paired.  Somebody else added coloration.  So now we have this very cool Google spreadsheet, which I recommend people take a look at.  There may be a problem, depending upon how many people are trying to get it at once because, Leo, you explained to me that Google puts a limit on how many people can.



Anyway, it is bit.ly/, and again, all lowercase, sn441sheet, s-h-e-e-t [bit.ly/sn441sheet].  And it is fascinating what Dashlane found when they essentially had to - I don't know if they did this manually, or they probably wrote a script that they were able to maybe aim at these different sites because they have reverse-engineered the password policies, the online login password policies of the Internet's current top 100 retailers.  So, and there are some - there's a summary that I'll discuss in a second.



But as I was, like, browsing around in the spreadsheet, I came across, like, the most curious things.  And I talked about some of them at the top of the show.  But, for example, I could understand, because one of the columns, for example, is minimum password length.  Do companies enforce a minimum length?  And, if so, what is it? 



So it turns out that many companies do support a minimum length of eight.  Eight seems to be common.  We would argue, those of us who are Security Now! podcast-involved people, that eight's not enough, that you need more than eight in order to get security.  But the problem is of course that's going to really start hampering people.  They're going to be upset that their eight-character password is not enough if someone asks for more than eight.  But eight was regarded as enough, if it wasn't a common eight-character password like the word "password."



So what I was curious about, looking down the minimum password length column, was that there was, like, there were some, like Northern Tool and 1-800-Flowers, which is a major Internet website, has a minimum password length of one.  Now, okay.  So that means your password can be "q," and they'll say, okay, fine.  So a minimum password length of one is basically checking between blank and anything.  So all it's really doing is seeing do you have - did you leave the password field blank?  So I can understand that test.  But there's a company called Build that has a minimum password length of two, which is really curious to me.  It's like, so somebody checked to make sure the password field wasn't blank.  But if it's one, then they say, no, no, you can't have one character.  You need at least two.



LEO:  [Laughing]



STEVE:  Okay.  But get this, Leo.  CafePress has a minimum length of three, as does Scholastic, Inc., and Urban Outfitter, and Nutrisystem.  It's like, major websites.  So you can use a password of four characters at CafePress, but not three.  I just - okay.  So somebody had to write code to say, unh-unh, no, three-character password, not good.  Four, oh, yeah, we like that.  Four is fine.  Wow.  And a minimum length of - and then, like, one notch up, minimum password length of four - I'm sorry.  CafePress is minimum length of three.  So I misspoke just then.  So three characters is enough for CafePress, but not two.  It's like, oh, just crazy.  Karmaloop, Vitacost, Fresh Direct, Shutterfly - Shutterfly has a minimum length of four.  Victoria's Secret, minimum length of four.  Maybe that's so you can make your password be "love."  And ShopNBC, minimum length of four.  So anyway, there were some surprising numbers in here.  And again, I ask myself, who is going to write code to set a minimum length of two, three, or four?  That's just - I don't get it.



And then, it was interesting, of the top 100 sites, even like the really, really, really bad ones, and there are some really bad ones at the bottom of this pile.  By the way, that spreadsheet is sorted in order of the overall  total, the score that each site achieved in the test.  So what Dashlane did was they took all these different parameters, and they set weights on the different policies that they tested.  And then they were able to sum them together.  So a hundred is a perfect score.  A minus a hundred is, like, the worst you can get.  And so this list, this spreadsheet is sorted by final score.



So like the column on the very far right, you can see it goes from a hundred down to minus whatever it is, for like the worst one.  But every single company masks the password during entry.  And I have to say, that's one of the things that I've never understood.  And so, for example, in my SQRL UI, it'll be masked, but right there will be a button saying show me the password that I'm entering.  Because I have never understood, like, the great security value.  It's almost as if not showing it to the user somehow conveys some magic, where it's like...



LEO:  It's imaginary.



STEVE:  It's like, ooh, nothing in the world can see it.  Everyone should understand that it's just the screen, just the display has been instructed not to show you the shape of the character whose button you just pressed.  It exists everywhere else - in your mind, and in the computer, and in the browser, and in the field, and in the form, and on the wire, everywhere except just those little pixels are not being lit up in its shape.  Which I just - the only possible reason is that you're, like, you're entering your password with a crowd gathered behind you.



LEO:  Watching you.



STEVE:  All watching you.



LEO:  Well, in fact, that's exactly how I enter my passwords.  But I'm the only one.



STEVE:  But, Leo, you'll be glad to know, every single one...



LEO:  They all do that.  I don't understand it.



STEVE:  ...of the hundred, even the crazy sites that do everything else wrong, everything else wrong.



LEO:  One-character passwords, but no one can see it.



STEVE:  Yes.  They cannot tell when you type "q."  Because, Leo, who would come up with "q"?  It's only the most obvious one...



LEO:  Well, you have a chance, one in 26.



STEVE:  ...up there.  No, no, look at that.  Look at your keyboard.  "Q" is right...



LEO:  "Q" is like the first one,  yeah.



STEVE:  That's where your eyes immediately go, to "q," yeah.  And I'll bet that's actually the one everyone's typing.



LEO:  Probably.



STEVE:  So, okay.  I just have to say that's the stupidest thing.



LEO:  Thank you.  I thought it was just me.  I've always - and it's particularly annoying on smartphones.



STEVE:  Yes.



LEO:  Or you know where they do it?



STEVE:  Whose keyboard you're typing things wrong all the time anyway.



LEO:  All the time.  You need to see it.



STEVE:  Yes.



LEO:  It's just crazy.



STEVE:  Yeah.  I mean, it ought to have, right there, turn off the dots.  I don't want dots.  I want to see what I'm typing.  Because, yes, I mean, Apple did the clever idea of showing you the most recent one you've hit.  But then you have to look at it every single time to make sure.



LEO:  You've got to watch, yeah.



STEVE:  And the point is it's not hiding it from anybody except you.



LEO:  You know, Facebook, to their credit, they know this.  Obviously Mark's a geek.  Mark Zuckerberg probably thought, this is stupid.  I've got to do it.  But after you enter it wrong once, it then puts it in plaintext.  It says, okay, let me give you a hand, in the mobile devices anyway.



STEVE:  Okay, yeah.



LEO:  Let me give you a hand.  It's pretty stupid.  Thank you for saying that because it's been driving me crazy.



STEVE:  Something very worthwhile is when sites offer you advice because this is a teaching opportunity.  My mom needs help.  And so no one's really told her, when she started logging into, as she calls it, AWOL, she didn't - it's like, oh, I have to create an account.  Hmm.  Oh, I know.  I'll use my children's names, or who knows what Mom uses.  I don't know.  But I'm sure it's not a high-quality password.  And if right then there had been a few lines to explain to her some of the things she should consider, then she'd have not made a mistake.  And but that was missing.



So to a greater degree than - actually to a surprising degree this is one of the things that is ranked, and you can see it on the spreadsheet.  In that column there's a lot of Y's under "Is password advice being offered right there."  Now, one of the things that's annoying is when they have a lot of criteria, and they don't tell you what those are right upfront.  That's another gripe of mine is where you're wanting to create a high-quality password, but you don't know are they going to allow me to use special characters? Can I put digits in this or not?  Because it's not until it fails that it then says, oh, sorry, you can't, you know, you have to use only this or that.  Well, why not tell me right there upfront?  So sometimes they do, sometimes they don't.



Another interesting aspect that they checked was whether mixed case was required.  Clearly a good thing because that increases the size of the alphabet and makes brute-forcing the password more difficult.  Not a perfect solution, but we see over and over and over many people use all lowercase because it's easier for them to type.  They don't have to do the shift key.  And again, especially in a mobile platform, where shift is something you have to more explicitly and deliberately do.



Now, the onscreen password strength meter is one of the best things you can do because there is a teachable moment right there.  Also, if you're not just showing them a meter, but telling them why they're not doing so well, or have a series of checkboxes, sort of like what I did over on the Password Haystacks page, where as they were typing things, when they, like, added uppercase, then blink, light up a light saying, ah, you've got some uppercase.  When they hit a digit, whoop, another light lights up.  Oh, good, you got a digit there.  And so forth.



Now, to do that interactively you need scripting on.  There's no way you're going to do this otherwise.  The way to do it without scripting would require them to submit a bad password and then come back to them and explain why this password wasn't up to snuff.  So not nearly as good as scripting.  But we're seeing more and more instances where you really can't operate without scripting.  And you could make your password entry page just tell them, in order to handle password entry, you need to turn scripting on, just for this page, please.  And then give them a little built-in tutorial.



So the notion of an interactive password strength meter, that's really great.  Yet today only 7 of the top 100 retail sites do it.  So we see it.  I know that LastPass does it, although they weren't on this list.  But Apple actually is the No. 1 site in the survey.  And we'll talk about some of the reasons why in a second.  But that's clearly a useful thing to do.



Now, the final two, I mean, there are some other criteria worth looking at, but do they block login after four missed attempts?  We see instance after instance where you can just guess forever.  And we know why - first, of all, maybe they're not doing it because they don't care.  Or maybe they're not doing it because they don't want the support burden of somebody who now cannot log in after four failed attempts.  But Apple blocks you after four misses.



LEO:  Good, good.  This prevents brute-forcing it.



STEVE:  Yes.  Newegg blocks you.  Nordstrom blocks you.  Hayneedle, whoever they are.  Foot Locker, Costco, Staples, ShopNBC.  Now, I noticed that ShopNBC blocks you after four tries, but also allows a four-character password.  So I guess...



LEO:  That's okay, though; right?  Because the chances, well, I guess if it's "qwer," that's the first one I'd guess.  But if you have four random characters...



STEVE:  Right, right.



LEO:  If you have four random characters it would take you a few times to guess it.  So in some ways that makes up for weak policies in other...



STEVE:  Really, blocking after four is, I mean, I get it that it's going to be a problem.  I mean, you're going to have - you have to have online tech support.  It's going to be a problem.  But as you said, Leo, I can see the necessity for a site like Apple, which is a high-value...



LEO:  You don't want robots attacking the login.



STEVE:  Yeah.  Now, again, because it's online, you're going to have a delay loop.  And in fact, if you could afford it, and server architectures don't make this easy, but to be able to hold up the response to mistaken passwords, for example, UNIX has famously done this, where as you keep making a mistake...



LEO:  It slows it down, yeah.



STEVE:  ...it waits longer and longer and longer to come back.  That's beautiful.  But that works because you're on the computer.  The computer you're trying to log into is right there in front of you, typically, or remote login and so forth.  But a web server typically has an architectural problem of holding up a response for a long time.  It could be designed so that it's not a problem to do that.  But that would be the nice thing.



So these guys, Dashlane, test blocking after four and blocking after 10, those two.  Microsoft blocks after 10, but not after four.  Target, same thing, 10.  CDW, Amway, Musician's Friend, WW Grainger, Walgreens, CVS, and others.  So there are major sites that do put a limit.  But, for example, Amazon doesn't.  You can sit there and guess someone's login password till the cows come home, just keep on going.



So overall summary of the stats from this analysis:  73%, so nearly three quarters of the current top 100 retail online websites, accept passwords having six or fewer characters.  So many are just ridiculously, like not checking your length.  Or again, I can't understand, oh, four is enough.  Okay.  62% do not require a mixture of letters and numbers.  So nearly two thirds don't care if it's all alpha.  They won't reject it saying, oh, sorry, please add some numbers to your password.  But frankly, the fact that a third do, I guess I'm surprised it's that many, and I'm glad that it's that many.



LEO:  That seems to be one of the most commonly adopted security measures is to - you've got to have a number.  Kind of drives me crazy because I have a long alphanumeric that I use.  I mean alpha-alphic, alphabetic.



STEVE:  Right.  I've run across that being annoying, too.



LEO:  I should point out these are retail sites.  These are retailers, not...



STEVE:  Well, yeah, but, I mean...



LEO:  So they have a strong economic interest in you...



STEVE:  ...[indiscernible] traffic.



LEO:  Yes, understand.  But they have a strong economic interest in you creating an account.  So they have to balance appropriate security with inconveniencing the customer too much.



STEVE:  Yeah.  I forgot to mention, I had it in my notes, but with SQRL there's none of this.  This all goes away.



LEO:  It goes away, yeah.



STEVE:  Of course passwords go away.  And breaches go away.  SQRL gives the website nothing that it has to protect.  Its database can get stolen.  It doesn't matter.  I mean, there's no way to impersonate someone, even if they get the database for a given site.  So this fixes all of this.  And so fingers crossed that this will end up happening.



Okay.  Now, I was surprised about this number, too.  55% accept 10 of the most commonly used weak passwords - 123456, 111111, or the word "password" and so forth.  So they test, and the spreadsheet shows, the 10 most commonly used passwords.  55% accept 10 of those, which is to say they're not checking.  But I was impressed that that means 45% are actually checking to see, hopefully before they hash it, whether it's one of these really dumb passwords, and just say no.  No, sorry, come on.  You try harder.  You could do better than that.  So I'm somewhat encouraged by that.



Half the sites, 51%, make no attempt to block entry after 10 incorrect password entries.  And those 51% include Amazon, Dell, Best Buy, Macy's, and Williams-Sonoma.  No attempt.  You can guess forever.  So that's a little disturbing because, as you said, Leo, I mean, 10 is a lot.  10 it's like, okay, sorry.  Call us.  Click here.  Do something.



LEO:  Ten seems to be enough.  And it's a high enough number that it should give you plenty of opportunities.  Because I understand people go, oh - and I do this a lot - which password did I use, or that kind of thing.



STEVE:  Yeah, well, exactly.  That's the failure model is you can't remember which one of your collection of common passwords that you used there.  61% don't provide any advice on how to create a strong password during signup.  Although, again, I'm encouraged that that means 40 or 39% do provide advice because that's something clearly useful.



93% do not, because remember we said that only 7% did, that's 7 out of those 100, do provide onscreen strength assessment, which is really, I mean, that's just a win.  That is, like, the No. 1 way to get people just to sort of passively encourage them to create a good password, show them that they're in the red, and give them some clues about what they ought to add to the password they're building in order to get their score higher and generate a stronger result.  I like that.



So overall, of the 100 that were checked, only 10% scored above the threshold for good password policies.  That was, in this standard of measure, 45 points or more in the roundup.  And you could go, you'd get a hundred, as far as a positive hundred, or as poor as a negative hundred.  And only 10%, 10 out of that 100 pushed it over a score of 45.  And then one of the other things they checked is, oh, I forgot my password, what is it?  Eight sites, including Toys R Us, J. Crew, 1-800-Flowers, which actually no longer surprises me because they accept one-character passwords, send passwords in plaintext via email.



LEO:  Wow.  Really, that many?  Wow.



STEVE:  Yeah, yeah.  Eight out of those top 100 just say, oh, here's your password.  And I get tweets about...



LEO:  Which means they have it in the clear, as well; right?  They have it.



STEVE:  Yes, exactly.  Actually, someone just tweeted me the other day, Yahoo! said, in response to them having to change their password, your new password is too similar to your previous password.



LEO:  Yeah, I've seen that in places, yeah.



STEVE:  And what does that tell you?



LEO:  They know your password.



STEVE:  Exactly.



LEO:  Because a hash wouldn't reveal how close it was.



STEVE:  Exactly.  A hash would have looked completely different if you'd just changed one character.  So that means Yahoo! is also storing it in the clear.



LEO:  Yeah, wow.



STEVE:  Which actually is no surprise, knowing how great Yahoo! security is.



LEO:  Their policies are not great, yeah.



STEVE:  Apple received the highest rating and was the only retailer of those hundred to get a perfect score.  Apple was perfect.  Newegg, Microsoft, and Chegg - what is Chegg, C-h-e-g-g?



LEO:  I don't know.



STEVE:  Anyway, whoever they are, they're big somewhere.  They all tied for second place.  And Target rounded out at third place.  So their online password handling is pretty good, even if their in-store point-of-sale terminals have had some problems.



LEO:  Chegg is a textbook store for students.



STEVE:  Ah.  Also MLB.com, Karmaloop, and Dick's Sporting Goods received the three lowest scores.  And I got a kick out of noticing, of course MLB, I did the math here in my head, I figured that had to be Major League Baseball.



LEO:  Yeah.



STEVE:  And they allow the password "baseball" on their site.



LEO:  [Laughing] I bet that's No. 1 on their site.



STEVE:  How many people do you think might be "protecting themselves," unquote, with the password "baseball" on MLB.com?  Amazon, Walmart, Victoria's Secret, Toys R Us, were also among the lowest ranked sites, receiving scores of negative 35 or below.  So again, Amazon, Walmart, Victoria's Secret, Toys R Us, very, very poor policies.



LEO:  What this doesn't reflect, though - I mean, look, Target was, what, No. 3? - is other security policies.  For instance, that people could hack in.  And Apple, No. 1, quite notoriously gave up Mat Honan's account information to social engineering.  They've changed that so it doesn't work, that technique, anyway, doesn't work anymore.  But that's one of the things we've learned from the Mat Honan case and others is that having great passwords and great password security is not necessarily all that's required to securing your account.



STEVE:  Right, right.  So these guys sum up their overview by distilling all of this to four simple password management strategies, or advice to websites:  Require that passwords contain at least eight characters, and a combination of upper and lowercase, numbers, and symbols.  Block account access after four failed login attempts.  I think that's a little short.



LEO:  That's low, yeah.



STEVE:  Yeah, I do.  I think that's going to really cause some problems.



LEO:  Ten's plenty.



STEVE:  Yeah, I think so.



LEO:  Ten is enough to stop brute force.



STEVE:  I think so.  Provide users with onscreen advice on how to choose a strong password during signup.  I love the onscreen advice.  And provide users with an onscreen assessment of password strength while they're choosing a password.  That is, basically, look at the password.  And the dictionary of most commonly used passwords is so short, which is really sad, but that you could easily have that as part of your JavaScript.  So I'm immediately thinking of you don't want to be making a roundtrip to check the password entered so far against the database.  And the point is you don't have to.



LEO:  Just do it at the end, yeah.



STEVE:  The list of really bad passwords will easily fit in the JavaScript, which is also showing you, like, do you have characters, upper and lowercase and so forth.  Add a simple dictionary to say, okay, yes, but this is something you can't use.  And actually, most of those common passwords would fail the upper/lowercase, numbers and symbols tests because they don't have any of that.  They're all numbers, or they're all lowercase alpha.



So anyway, that's it.  I encourage listeners who are interested to go check out, just scroll around this web sheet, or the online web page spreadsheet at Google.  It's really interesting to see what companies are doing.  And with any luck, we will see evolution over time.  Clearly, the best companies weren't always this good.  They decided to take this seriously and tighten down the screws, batten down the hatches, make their online login tighter because, again, this isn't automatic that these things happen.  You do need to write some code and make it so.



LEO:  And here's one more password we want to add to the most common list.  It would be 'w3Lc0m3!HERE' in leet speak.  You probably shouldn't use that one.  This is a video, I'm sure you saw this story.



STEVE:  Oh, my god, yeah.



LEO:  Of the super secret Super Bowl security center that ran on CBS, and of course there's a big screen, a lot of big screens.  By the way, a lot of these screens running it looks like Windows XP, I've got to tell you.  When I look at that menu bar, that's a very XP-like menu bar right there.  They also neglected to pull down or, I don't know, they had a big screen that said WiFi access login "marko," password "w3Lc0m3!HERE" in leet speak.



STEVE:  Yeah, m-a-r-k-o was the SSID for the WiFi, and then that's the shared...



LEO:  Oh, that's the SSID, of course, not the login, right.  It was apparently an internal WiFi access spot.  But just, you know, just a little tip.  Oh, it's so funny.



Hey, thank you, Steve Gibson.  As always, a very interesting show.  You get the show notes Steve now posts on his website, GRC.com, with the rest of the Security Now! stuff, including 16Kb versions of the audio for the bandwidth-impaired, people who still want to listen, but don't want to download a giant file.  Transcripts, too, written by Elaine Farris, very nicely done there.  You'll get full versions of the show on our website, TWiT.tv/sn, in higher quality video and audio.  You can also find it wherever podcasts are aggregated - netcasts, I guess we call them - including iTunes and Stitcher and all those places.  If you visit GRC.com, don't forget to check out all the great stuff, the freebies, ShieldsUP! and the Perfect Paper Passwords and all of that.  And if you're so inclined, wouldn't be a bad thing to tip Steve by purchasing a copy of SpinRite, the world's best hard drive and maintenance recovery utility.



STEVE:  Even if you don't think you need it, it does actually prevent hard drives from failing, as many users have found.  I get reports, it's like, well, you know, I've never had a failure.  I run SpinRite every couple months.



LEO:  It's a good idea.



STEVE:  And it keeps my drives from failing.  It actually does work.



LEO:  It's like an oil change for your hard drive.



STEVE:  Exactly.



LEO:  Our show we do now at a new time, and I want to remind you that we do it Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, that is 21:00 UTC, at TWiT.tv.  Right after MacBreak Weekly, if you tune in and MacBreak Weekly is still going on, it'll be on soon.  We also, as I said, make it available after the fact.  Thank you, Steve Gibson, and everybody else who's joined us here today.  See you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










